{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from large_scale_prediction import large_scale_predictor, large_scale_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = 'NO_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3 (PC Version - Run on Laptop)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:56:53,834]\u001b[0m A new study created in RDB with name: NO_2_2018\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:57:24,218]\u001b[0m Trial 0 finished with value: 2.2067782684633404 and parameters: {'n_hidden': 4, 'learning_rate': 0.07339037260697179, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03331364717955992, 'dropout_rate_Layer_2': 0.279337387638424, 'dropout_rate_Layer_3': 0.02950947259150052, 'dropout_rate_Layer_4': 0.24104877565348667, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.03870625125046244, 'l1_Layer_2': 0.07799346782820255, 'l1_Layer_3': 0.009604043137974815, 'l1_Layer_4': 0.021285787500336318, 'n_units_Layer_1': 90, 'n_units_Layer_2': 70, 'n_units_Layer_3': 95, 'n_units_Layer_4': 60}. Best is trial 0 with value: 2.2067782684633404.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.21 | sMAPE for Validation Set is: 7.82% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 12.69 | sMAPE for Test Set is: 32.54% | rMAE for Test Set is: 2.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:58:11,247]\u001b[0m Trial 1 finished with value: 2.1790727262789975 and parameters: {'n_hidden': 3, 'learning_rate': 0.015420571678437554, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2778174138256031, 'dropout_rate_Layer_2': 0.27654990232790655, 'dropout_rate_Layer_3': 0.37915420841228464, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00902069426450468, 'l1_Layer_2': 0.00014906033389483204, 'l1_Layer_3': 3.262345940579145e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 215, 'n_units_Layer_3': 285}. Best is trial 1 with value: 2.1790727262789975.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.18 | sMAPE for Validation Set is: 7.65% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 12.25 | sMAPE for Test Set is: 31.29% | rMAE for Test Set is: 2.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:58:35,319]\u001b[0m Trial 3 finished with value: 3.887457476603474 and parameters: {'n_hidden': 4, 'learning_rate': 0.0789231296572988, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13336811214953084, 'dropout_rate_Layer_2': 0.13897514303471162, 'dropout_rate_Layer_3': 0.07271464148651723, 'dropout_rate_Layer_4': 0.017681878529482553, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008916949643996762, 'l1_Layer_2': 0.001333669053893976, 'l1_Layer_3': 2.193293234681669e-05, 'l1_Layer_4': 0.0030695104761473036, 'n_units_Layer_1': 200, 'n_units_Layer_2': 245, 'n_units_Layer_3': 195, 'n_units_Layer_4': 260}. Best is trial 1 with value: 2.1790727262789975.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 13.91% | rMAE for Validation Set is: 1.53\n",
      "MAE for Test Set is: 18.14 | sMAPE for Test Set is: 50.63% | rMAE for Test Set is: 3.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:58:43,433]\u001b[0m Trial 2 finished with value: 1.627974433570379 and parameters: {'n_hidden': 3, 'learning_rate': 0.009839871937982319, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33263279778961485, 'dropout_rate_Layer_2': 0.07124107829253008, 'dropout_rate_Layer_3': 0.26618852279630506, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006232003813192081, 'l1_Layer_2': 0.06572465948221072, 'l1_Layer_3': 3.490467685307312e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 170, 'n_units_Layer_3': 95}. Best is trial 2 with value: 1.627974433570379.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.63 | sMAPE for Validation Set is: 5.76% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 14.26% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:58:48,295]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:58:53,410]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:59:21,023]\u001b[0m Trial 7 finished with value: 1.8830425170901988 and parameters: {'n_hidden': 3, 'learning_rate': 0.03203580688369645, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14393256877330513, 'dropout_rate_Layer_2': 0.25298531297784205, 'dropout_rate_Layer_3': 0.30855845151173983, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.011897025624286604, 'l1_Layer_2': 4.063199201445778e-05, 'l1_Layer_3': 0.002006318023789222, 'n_units_Layer_1': 140, 'n_units_Layer_2': 295, 'n_units_Layer_3': 295}. Best is trial 2 with value: 1.627974433570379.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.88 | sMAPE for Validation Set is: 6.64% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 12.02 | sMAPE for Test Set is: 30.58% | rMAE for Test Set is: 2.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:59:30,714]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:59:43,697]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:59:50,930]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:59:58,476]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:00:08,923]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:00:15,842]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:00:20,803]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:00:23,170]\u001b[0m Trial 4 finished with value: 1.4566380584839338 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012609700045535237, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05283308692067643, 'dropout_rate_Layer_2': 0.27943678936995237, 'dropout_rate_Layer_3': 0.031098731666410598, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.029235672628488273, 'l1_Layer_2': 0.029365320640875, 'l1_Layer_3': 0.0017230130294556161, 'n_units_Layer_1': 255, 'n_units_Layer_2': 210, 'n_units_Layer_3': 280}. Best is trial 4 with value: 1.4566380584839338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 5.17% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.85 | sMAPE for Test Set is: 21.67% | rMAE for Test Set is: 1.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:00:25,510]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:00:34,972]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:00:35,251]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:00:42,741]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:00:47,527]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:00:47,899]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:01:02,212]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:01:07,668]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:01:12,178]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:01:15,555]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:01:20,606]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:01:24,707]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:01:42,292]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:01:47,527]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:01:51,737]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:02:39,568]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:02:46,708]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:02:53,432]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:03:20,721]\u001b[0m Trial 34 finished with value: 2.175234531095352 and parameters: {'n_hidden': 3, 'learning_rate': 0.03720896411852634, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14695494856010669, 'dropout_rate_Layer_2': 0.18644428138817604, 'dropout_rate_Layer_3': 0.16349299238541426, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 3.912300331253561e-05, 'l1_Layer_2': 0.0006547969514443145, 'l1_Layer_3': 1.571274360504838e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 110, 'n_units_Layer_3': 200}. Best is trial 4 with value: 1.4566380584839338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.18 | sMAPE for Validation Set is: 7.68% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 10.99 | sMAPE for Test Set is: 27.59% | rMAE for Test Set is: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:03:25,750]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:03:36,025]\u001b[0m Trial 31 finished with value: 1.8054407864842332 and parameters: {'n_hidden': 4, 'learning_rate': 0.019395566462975626, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39495678240930254, 'dropout_rate_Layer_2': 0.14417850907997098, 'dropout_rate_Layer_3': 0.2671493297760574, 'dropout_rate_Layer_4': 0.03158637946441654, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.012156788508621532, 'l1_Layer_2': 0.00023519942858134596, 'l1_Layer_3': 0.08617266221457859, 'l1_Layer_4': 0.0005475045224402198, 'n_units_Layer_1': 170, 'n_units_Layer_2': 275, 'n_units_Layer_3': 170, 'n_units_Layer_4': 275}. Best is trial 4 with value: 1.4566380584839338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.81 | sMAPE for Validation Set is: 6.36% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 9.14 | sMAPE for Test Set is: 22.51% | rMAE for Test Set is: 1.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:03:40,856]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:03:41,059]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:03:47,733]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:03:50,854]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:03:55,224]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:03:58,834]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:04:03,106]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:04:08,594]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:04:28,415]\u001b[0m Trial 45 finished with value: 1.7749907626786043 and parameters: {'n_hidden': 4, 'learning_rate': 0.010312099465313676, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17664568792053792, 'dropout_rate_Layer_2': 0.1666784023798106, 'dropout_rate_Layer_3': 0.23892645073033536, 'dropout_rate_Layer_4': 0.019258321620391608, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.060226101233682924, 'l1_Layer_2': 2.826294448397268e-05, 'l1_Layer_3': 1.2901467639501591e-05, 'l1_Layer_4': 4.3965187584931505e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 50, 'n_units_Layer_3': 300, 'n_units_Layer_4': 235}. Best is trial 4 with value: 1.4566380584839338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.77 | sMAPE for Validation Set is: 6.23% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 9.99 | sMAPE for Test Set is: 24.74% | rMAE for Test Set is: 2.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:04:49,853]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:04:57,791]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:05:07,461]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:05:26,995]\u001b[0m Trial 43 finished with value: 1.5020573601953586 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007741631714675029, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3986353819210056, 'dropout_rate_Layer_2': 0.002340334823596177, 'dropout_rate_Layer_3': 0.2700463430673001, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0806542262116996, 'l1_Layer_2': 0.0026171365558094123, 'l1_Layer_3': 0.00014408534680768022, 'n_units_Layer_1': 70, 'n_units_Layer_2': 300, 'n_units_Layer_3': 290}. Best is trial 4 with value: 1.4566380584839338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.33% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.15 | sMAPE for Test Set is: 17.31% | rMAE for Test Set is: 1.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:05:31,415]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:05:38,848]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:05:42,154]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:05:51,406]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:07:15,063]\u001b[0m Trial 51 finished with value: 1.4811109205730801 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005370143868665825, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3979520683124298, 'dropout_rate_Layer_2': 0.0009001813962896121, 'dropout_rate_Layer_3': 0.27160965490494593, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08646966706463584, 'l1_Layer_2': 0.0029607684062061402, 'l1_Layer_3': 0.00015088391065273696, 'n_units_Layer_1': 50, 'n_units_Layer_2': 300, 'n_units_Layer_3': 300}. Best is trial 4 with value: 1.4566380584839338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.25% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.89 | sMAPE for Test Set is: 16.65% | rMAE for Test Set is: 1.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:08:17,859]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:08:22,657]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:08:29,239]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:08:32,454]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:08:43,828]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:08:49,208]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:08:56,537]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:09:01,365]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:09:06,777]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:09:11,365]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:09:14,324]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:09:26,396]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:09:35,660]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:09:38,711]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:09:45,422]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:09:56,008]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:09:58,603]\u001b[0m Trial 54 finished with value: 1.882688739810354 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032690835060487497, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3651774630853084, 'dropout_rate_Layer_2': 0.2191526106154322, 'dropout_rate_Layer_3': 0.07518219225288064, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020447852184008738, 'l1_Layer_2': 0.0011090194980214578, 'l1_Layer_3': 1.0301356342273885e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 225, 'n_units_Layer_3': 200}. Best is trial 4 with value: 1.4566380584839338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.88 | sMAPE for Validation Set is: 6.55% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 11.10 | sMAPE for Test Set is: 27.87% | rMAE for Test Set is: 2.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:10:05,233]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:10:07,581]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:10:11,087]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:10:17,538]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:10:23,018]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:10:32,448]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:10:38,002]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:10:47,415]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:10:52,821]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:11:00,501]\u001b[0m Trial 75 finished with value: 17.396381773709468 and parameters: {'n_hidden': 3, 'learning_rate': 0.08098639505087434, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2570899259000449, 'dropout_rate_Layer_2': 0.20438813354487886, 'dropout_rate_Layer_3': 0.30977410258908594, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.162886899421948e-05, 'l1_Layer_2': 0.0001344797112122261, 'l1_Layer_3': 0.026575878860604106, 'n_units_Layer_1': 115, 'n_units_Layer_2': 145, 'n_units_Layer_3': 240}. Best is trial 4 with value: 1.4566380584839338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.40 | sMAPE for Validation Set is: 58.34% | rMAE for Validation Set is: 6.83\n",
      "MAE for Test Set is: 19.68 | sMAPE for Test Set is: 63.07% | rMAE for Test Set is: 4.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:11:09,833]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:11:12,340]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:11:17,041]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:11:19,797]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:11:24,834]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:11:29,703]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:11:29,989]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:11:47,862]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:11:48,209]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:11:56,312]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:11:56,467]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:12:07,088]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:12:11,936]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:12:19,246]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:12:21,649]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:12:27,029]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:12:31,856]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:12:36,408]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:12:41,215]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:12:46,061]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:12:55,709]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:13:00,771]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:13:06,059]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:13:13,322]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:13:18,112]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:14:04,414]\u001b[0m Trial 107 finished with value: 1.7595502403905716 and parameters: {'n_hidden': 4, 'learning_rate': 0.003925133301539674, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17571302282448836, 'dropout_rate_Layer_2': 0.3509331994220449, 'dropout_rate_Layer_3': 0.015197729624336853, 'dropout_rate_Layer_4': 0.3590214836228509, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.6938048500570676e-05, 'l1_Layer_2': 0.00036962445029616845, 'l1_Layer_3': 0.0005452250044621769, 'l1_Layer_4': 0.0003625891795588176, 'n_units_Layer_1': 125, 'n_units_Layer_2': 205, 'n_units_Layer_3': 90, 'n_units_Layer_4': 130}. Best is trial 4 with value: 1.4566380584839338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.76 | sMAPE for Validation Set is: 6.20% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.07 | sMAPE for Test Set is: 25.05% | rMAE for Test Set is: 2.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:14:13,191]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:14:45,036]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:14:55,392]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:15:02,232]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:15:19,743]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:15:24,759]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:15:34,489]\u001b[0m Trial 102 finished with value: 1.6797012792619246 and parameters: {'n_hidden': 3, 'learning_rate': 0.004007880935227921, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3986829309467539, 'dropout_rate_Layer_2': 0.2924167996333054, 'dropout_rate_Layer_3': 0.35522397613036816, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04382511789384064, 'l1_Layer_2': 0.0001893695648308747, 'l1_Layer_3': 0.004780486824738588, 'n_units_Layer_1': 95, 'n_units_Layer_2': 240, 'n_units_Layer_3': 150}. Best is trial 4 with value: 1.4566380584839338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.68 | sMAPE for Validation Set is: 5.93% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 3.84 | sMAPE for Test Set is: 9.69% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:15:39,793]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:15:51,797]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:15:57,047]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:16:02,036]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:16:08,597]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:16:13,869]\u001b[0m Trial 114 finished with value: 1.4834479589524439 and parameters: {'n_hidden': 3, 'learning_rate': 0.003477542187844489, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01838171101895661, 'dropout_rate_Layer_2': 0.21478931740573537, 'dropout_rate_Layer_3': 0.22036920469504467, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004861068260396873, 'l1_Layer_2': 0.00013558819421730531, 'l1_Layer_3': 5.789117179203984e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 170, 'n_units_Layer_3': 290}. Best is trial 4 with value: 1.4566380584839338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.26% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.04 | sMAPE for Test Set is: 16.99% | rMAE for Test Set is: 1.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:16:23,590]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:16:28,572]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:16:35,658]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:16:39,058]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:16:50,041]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:16:51,758]\u001b[0m Trial 122 finished with value: 1.678114332309204 and parameters: {'n_hidden': 4, 'learning_rate': 0.002853348376124612, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.047803511049092084, 'dropout_rate_Layer_2': 0.3663355429923056, 'dropout_rate_Layer_3': 0.3742768149743431, 'dropout_rate_Layer_4': 0.00010122085315012949, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0018812437785356577, 'l1_Layer_2': 1.2427786825764212e-05, 'l1_Layer_3': 2.2442053760563177e-05, 'l1_Layer_4': 1.0572809444916818e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 95, 'n_units_Layer_3': 220, 'n_units_Layer_4': 175}. Best is trial 4 with value: 1.4566380584839338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.68 | sMAPE for Validation Set is: 5.93% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.27 | sMAPE for Test Set is: 20.11% | rMAE for Test Set is: 1.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:17:11,121]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:17:11,363]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:17:20,097]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:17:40,022]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:17:54,636]\u001b[0m Trial 129 finished with value: 1.7041620230985532 and parameters: {'n_hidden': 3, 'learning_rate': 0.002780931082502817, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39944578961379007, 'dropout_rate_Layer_2': 0.31521627912664857, 'dropout_rate_Layer_3': 0.008439182973825635, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022676218122946845, 'l1_Layer_2': 0.000221542796046069, 'l1_Layer_3': 0.00012512337850044357, 'n_units_Layer_1': 290, 'n_units_Layer_2': 200, 'n_units_Layer_3': 150}. Best is trial 4 with value: 1.4566380584839338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.70 | sMAPE for Validation Set is: 5.98% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.06 | sMAPE for Test Set is: 25.01% | rMAE for Test Set is: 2.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:18:02,215]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:18:16,967]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:18:21,240]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:18:26,187]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:18:29,098]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:18:38,533]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:18:46,097]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:19:33,435]\u001b[0m Trial 136 finished with value: 1.464772989008458 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022688335814277, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33430333873506834, 'dropout_rate_Layer_2': 0.3479998496073442, 'dropout_rate_Layer_3': 0.15961625604095236, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018589728346200704, 'l1_Layer_2': 0.0006038551727420644, 'l1_Layer_3': 6.068163923944777e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 205, 'n_units_Layer_3': 210}. Best is trial 4 with value: 1.4566380584839338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 5.20% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.22 | sMAPE for Test Set is: 20.04% | rMAE for Test Set is: 1.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:20:43,589]\u001b[0m Trial 140 finished with value: 1.633372177922304 and parameters: {'n_hidden': 3, 'learning_rate': 0.001954915304833251, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33511624863908906, 'dropout_rate_Layer_2': 0.3468293015702456, 'dropout_rate_Layer_3': 0.15836606561606548, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00018060427176799294, 'l1_Layer_2': 0.002829403395388221, 'l1_Layer_3': 5.1805962451801175e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 195, 'n_units_Layer_3': 210}. Best is trial 4 with value: 1.4566380584839338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.63 | sMAPE for Validation Set is: 5.74% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.59 | sMAPE for Test Set is: 26.44% | rMAE for Test Set is: 2.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:20:53,015]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:21:03,075]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:21:09,803]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:21:14,899]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:21:20,237]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:21:42,055]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:21:47,387]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:21:55,084]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:22:04,881]\u001b[0m Trial 139 finished with value: 1.4308927399219746 and parameters: {'n_hidden': 3, 'learning_rate': 0.002180958610773592, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06433972533697561, 'dropout_rate_Layer_2': 0.3392051251205095, 'dropout_rate_Layer_3': 0.1729126594193408, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018570880492551478, 'l1_Layer_2': 0.0046464664031217314, 'l1_Layer_3': 7.4369933134255e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 210, 'n_units_Layer_3': 210}. Best is trial 139 with value: 1.4308927399219746.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 5.09% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.96 | sMAPE for Test Set is: 22.03% | rMAE for Test Set is: 1.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:22:09,233]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:22:09,422]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:22:16,679]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:22:17,023]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:22:23,189]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:22:23,366]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:22:31,413]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:22:32,366]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:22:56,623]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:23:02,058]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:23:06,493]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:23:40,795]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:23:45,529]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:23:53,453]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:24:10,246]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:24:15,331]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:24:19,755]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:24:29,275]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:24:34,753]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:24:39,211]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:24:39,550]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:24:47,615]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:24:52,533]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:24:57,246]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:25:05,123]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:25:07,590]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:25:14,873]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:25:21,628]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:25:26,362]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:25:31,064]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:25:32,547]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:25:36,209]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:25:38,604]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:25:43,567]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:25:46,204]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:25:48,508]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:25:52,940]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:25:53,217]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:26:11,376]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:26:11,492]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:26:21,755]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:26:27,115]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:26:32,395]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:26:36,429]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:26:39,887]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:26:49,311]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:27:45,897]\u001b[0m Trial 195 finished with value: 1.4990301885951165 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022850051818496674, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3311668810412488, 'dropout_rate_Layer_2': 0.2606211671863735, 'dropout_rate_Layer_3': 0.18161378599182104, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002571990140172116, 'l1_Layer_2': 0.0004584475219968182, 'l1_Layer_3': 0.00048213651780968167, 'n_units_Layer_1': 300, 'n_units_Layer_2': 155, 'n_units_Layer_3': 195}. Best is trial 139 with value: 1.4308927399219746.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.32% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.85 | sMAPE for Test Set is: 24.36% | rMAE for Test Set is: 2.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:27:50,879]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:27:57,978]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:28:03,613]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:28:08,665]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:28:08,726]\u001b[0m Trial 196 finished with value: 1.4080976467825181 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008234947096668525, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3503726414454523, 'dropout_rate_Layer_2': 0.01717769974673014, 'dropout_rate_Layer_3': 0.03050944609760381, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0061631284704545646, 'l1_Layer_2': 0.0022102989368792242, 'l1_Layer_3': 0.0006069434540611458, 'n_units_Layer_1': 170, 'n_units_Layer_2': 265, 'n_units_Layer_3': 280}. Best is trial 196 with value: 1.4080976467825181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.41 | sMAPE for Validation Set is: 4.98% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.96 | sMAPE for Test Set is: 16.80% | rMAE for Test Set is: 1.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:28:14,718]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:28:25,403]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:28:31,980]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:28:40,166]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:28:45,220]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:29:15,461]\u001b[0m Trial 205 finished with value: 1.5271949911428342 and parameters: {'n_hidden': 3, 'learning_rate': 0.002124172628157449, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30943975040239924, 'dropout_rate_Layer_2': 0.2792296240534976, 'dropout_rate_Layer_3': 0.18439974072460844, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007334668749864296, 'l1_Layer_2': 0.00016441927145237337, 'l1_Layer_3': 0.00037149259632660795, 'n_units_Layer_1': 125, 'n_units_Layer_2': 180, 'n_units_Layer_3': 295}. Best is trial 196 with value: 1.4080976467825181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.42% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.27 | sMAPE for Test Set is: 20.16% | rMAE for Test Set is: 1.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:29:24,461]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:29:34,860]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:29:37,556]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:31:48,074]\u001b[0m Trial 210 finished with value: 1.529165607515438 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010605456035404578, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1811997677533695, 'dropout_rate_Layer_2': 0.14026785154606294, 'dropout_rate_Layer_3': 0.1296039081530665, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000549817267280851, 'l1_Layer_2': 0.0003114139634753381, 'l1_Layer_3': 0.00044350741524589235, 'n_units_Layer_1': 155, 'n_units_Layer_2': 145, 'n_units_Layer_3': 50}. Best is trial 196 with value: 1.4080976467825181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.40% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 10.02 | sMAPE for Test Set is: 24.84% | rMAE for Test Set is: 2.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:31:58,018]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:32:10,003]\u001b[0m Trial 211 finished with value: 1.399879178410358 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010029525807664552, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007326467876244691, 'dropout_rate_Layer_2': 0.11513726380785355, 'dropout_rate_Layer_3': 0.04762579135789653, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005388332740113786, 'l1_Layer_2': 0.0004040380693798095, 'l1_Layer_3': 8.811107269168619e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 150, 'n_units_Layer_3': 170}. Best is trial 211 with value: 1.399879178410358.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.40 | sMAPE for Validation Set is: 4.96% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 9.74 | sMAPE for Test Set is: 24.11% | rMAE for Test Set is: 2.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:32:49,180]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:32:54,350]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:32:59,590]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:33:04,225]\u001b[0m Trial 213 finished with value: 1.5700436306976513 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009919126485835675, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19215541239708236, 'dropout_rate_Layer_2': 0.10136544521939558, 'dropout_rate_Layer_3': 0.1374838451619002, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00534973838585625, 'l1_Layer_2': 0.015478887305481534, 'l1_Layer_3': 7.527387687566691e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 150, 'n_units_Layer_3': 50}. Best is trial 211 with value: 1.399879178410358.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.57 | sMAPE for Validation Set is: 5.54% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.37 | sMAPE for Test Set is: 10.75% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:33:09,246]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:33:09,693]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:33:15,504]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:33:18,066]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:33:32,575]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:33:45,446]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:33:54,304]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:34:00,266]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:34:12,535]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:34:19,276]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:34:29,755]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:34:34,786]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:34:41,987]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:34:51,999]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:34:57,262]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:35:11,756]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:35:14,332]\u001b[0m Trial 228 finished with value: 1.5397718575680053 and parameters: {'n_hidden': 3, 'learning_rate': 0.002181630807276889, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34749961542700847, 'dropout_rate_Layer_2': 0.39515950545250017, 'dropout_rate_Layer_3': 0.10372508026592875, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.1060964641665655e-05, 'l1_Layer_2': 0.0004917258991238626, 'l1_Layer_3': 0.00010954139569845092, 'n_units_Layer_1': 265, 'n_units_Layer_2': 160, 'n_units_Layer_3': 195}. Best is trial 211 with value: 1.399879178410358.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 5.41% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 9.88 | sMAPE for Test Set is: 24.41% | rMAE for Test Set is: 2.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:35:19,296]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:35:43,936]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:36:21,221]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:36:26,686]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:36:33,741]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:37:31,537]\u001b[0m Trial 237 finished with value: 1.493919801125979 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006544664374780146, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3803147079804472, 'dropout_rate_Layer_2': 0.04422037526908777, 'dropout_rate_Layer_3': 0.22574006882334327, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004850930819118288, 'l1_Layer_2': 0.0022429879376428207, 'l1_Layer_3': 0.0005843876946918545, 'n_units_Layer_1': 50, 'n_units_Layer_2': 300, 'n_units_Layer_3': 160}. Best is trial 211 with value: 1.399879178410358.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.30% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.62 | sMAPE for Test Set is: 18.46% | rMAE for Test Set is: 1.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:37:53,970]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:38:01,370]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:38:11,058]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:38:17,527]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:38:47,557]\u001b[0m Trial 240 finished with value: 1.516254633138966 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005301455096177656, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18959796502076767, 'dropout_rate_Layer_2': 0.06850573044462667, 'dropout_rate_Layer_3': 0.20620206387575574, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005973505073515299, 'l1_Layer_2': 0.0023444325181864126, 'l1_Layer_3': 0.0005607245425527566, 'n_units_Layer_1': 185, 'n_units_Layer_2': 80, 'n_units_Layer_3': 60}. Best is trial 211 with value: 1.399879178410358.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.52 | sMAPE for Validation Set is: 5.37% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 9.47 | sMAPE for Test Set is: 23.32% | rMAE for Test Set is: 1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:38:58,012]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:39:04,866]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:39:41,761]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:39:51,381]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:39:56,673]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:40:01,316]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:40:01,600]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:40:07,043]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:40:26,909]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:40:31,655]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:40:35,877]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:40:45,637]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:41:27,822]\u001b[0m Trial 254 finished with value: 1.3895806974627674 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015441630986517054, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.002689509823515163, 'dropout_rate_Layer_2': 0.06074612219661781, 'dropout_rate_Layer_3': 0.1956909072949783, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003754126954476251, 'l1_Layer_2': 0.0022390472438671423, 'l1_Layer_3': 0.0047971264653655435, 'n_units_Layer_1': 150, 'n_units_Layer_2': 75, 'n_units_Layer_3': 260}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.39 | sMAPE for Validation Set is: 4.90% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 9.22 | sMAPE for Test Set is: 22.61% | rMAE for Test Set is: 1.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:41:28,247]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:41:33,480]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:41:38,095]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:41:40,865]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:41:45,472]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:42:15,753]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:42:22,523]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:42:27,835]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:42:37,200]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:42:42,123]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:42:47,338]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:42:54,158]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:44:33,206]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:44:38,226]\u001b[0m Trial 264 finished with value: 1.5193200436162329 and parameters: {'n_hidden': 3, 'learning_rate': 0.0043021920152887475, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3230977361283492, 'dropout_rate_Layer_2': 0.22088245305775187, 'dropout_rate_Layer_3': 0.09633860061933879, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000517394778556431, 'l1_Layer_2': 0.0008610573357716617, 'l1_Layer_3': 0.00030979927878494715, 'n_units_Layer_1': 270, 'n_units_Layer_2': 265, 'n_units_Layer_3': 145}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.52 | sMAPE for Validation Set is: 5.44% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.92 | sMAPE for Test Set is: 19.27% | rMAE for Test Set is: 1.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:44:44,704]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:44:47,732]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:44:50,174]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:45:59,119]\u001b[0m Trial 276 finished with value: 1.4613260643042665 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012549477476361086, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3608187925140931, 'dropout_rate_Layer_2': 0.270752911988344, 'dropout_rate_Layer_3': 0.17917558209335516, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6085887193596684e-05, 'l1_Layer_2': 0.0008665253662583942, 'l1_Layer_3': 3.261234314892096e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 220, 'n_units_Layer_3': 185}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 5.17% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 10.00 | sMAPE for Test Set is: 24.78% | rMAE for Test Set is: 2.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:46:16,101]\u001b[0m Trial 275 finished with value: 1.4243278498001384 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015503472559047224, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.055390305985587904, 'dropout_rate_Layer_2': 0.061552825841448916, 'dropout_rate_Layer_3': 0.058280985531443216, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003108908189695792, 'l1_Layer_2': 0.0077060414811527984, 'l1_Layer_3': 0.006992531165661363, 'n_units_Layer_1': 100, 'n_units_Layer_2': 80, 'n_units_Layer_3': 245}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.42 | sMAPE for Validation Set is: 5.05% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.57 | sMAPE for Test Set is: 18.31% | rMAE for Test Set is: 1.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:46:20,926]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:46:27,944]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:46:43,094]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:46:50,157]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:46:53,021]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:46:57,499]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:47:15,376]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:47:20,293]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:47:25,151]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:47:51,754]\u001b[0m Trial 287 finished with value: 1.5074728390624401 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015453916476216901, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2817740108928316, 'dropout_rate_Layer_2': 0.2918965935605981, 'dropout_rate_Layer_3': 0.004926753936433791, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0069075659690839356, 'l1_Layer_2': 0.00011337852034559875, 'l1_Layer_3': 1.534195678949951e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 165, 'n_units_Layer_3': 290}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.35% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.92 | sMAPE for Test Set is: 16.73% | rMAE for Test Set is: 1.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:47:57,099]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:48:01,625]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:48:09,088]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:48:18,954]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:48:24,200]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:48:28,350]\u001b[0m Trial 285 finished with value: 1.4862591752437684 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013765973866298623, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28418239969340725, 'dropout_rate_Layer_2': 0.3167538885397699, 'dropout_rate_Layer_3': 0.01255451617537866, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006994890652352825, 'l1_Layer_2': 0.00011975722413286663, 'l1_Layer_3': 0.002804343169703957, 'n_units_Layer_1': 75, 'n_units_Layer_2': 170, 'n_units_Layer_3': 290}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.30% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.85 | sMAPE for Test Set is: 24.38% | rMAE for Test Set is: 2.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:48:30,965]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:48:50,861]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:48:59,939]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:49:27,167]\u001b[0m Trial 294 finished with value: 1.678466424302682 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007951896073534483, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15615018292116087, 'dropout_rate_Layer_2': 0.3571631745103637, 'dropout_rate_Layer_3': 0.14855574367702068, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 1.8209556195250387e-05, 'l1_Layer_2': 0.0019154141811381312, 'l1_Layer_3': 2.9000322666907567e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 215, 'n_units_Layer_3': 280}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.68 | sMAPE for Validation Set is: 5.90% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.29 | sMAPE for Test Set is: 20.15% | rMAE for Test Set is: 1.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:49:32,102]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:49:37,264]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:49:44,630]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:49:45,188]\u001b[0m Trial 297 finished with value: 1.7277396983496522 and parameters: {'n_hidden': 3, 'learning_rate': 0.001412088058393748, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3593765085876371, 'dropout_rate_Layer_2': 0.3579496909111888, 'dropout_rate_Layer_3': 0.1541865045985168, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 1.1334348119747539e-05, 'l1_Layer_2': 0.001649569020674913, 'l1_Layer_3': 2.6754116027945303e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 215, 'n_units_Layer_3': 275}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.73 | sMAPE for Validation Set is: 6.07% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.79 | sMAPE for Test Set is: 24.19% | rMAE for Test Set is: 2.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:49:50,463]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:49:53,081]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:50:00,242]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:50:05,160]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:50:10,275]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:50:12,619]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:50:27,259]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:50:34,950]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:50:35,079]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:50:42,437]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:50:47,122]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:50:56,938]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:51:02,089]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:51:26,288]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:51:44,157]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:51:48,667]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:51:53,165]\u001b[0m Trial 310 finished with value: 1.7008386300706768 and parameters: {'n_hidden': 3, 'learning_rate': 0.002312836736907461, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3652443938365187, 'dropout_rate_Layer_2': 0.25541914285717426, 'dropout_rate_Layer_3': 0.18107657267374722, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.5768064075639462e-05, 'l1_Layer_2': 0.0007246812309908922, 'l1_Layer_3': 9.364228011941982e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 185, 'n_units_Layer_3': 180}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.70 | sMAPE for Validation Set is: 5.99% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.08 | sMAPE for Test Set is: 27.83% | rMAE for Test Set is: 2.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:51:58,771]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:52:03,464]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:52:08,671]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:52:13,298]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:52:22,527]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:52:27,891]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:52:33,162]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:52:39,785]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:52:44,695]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:52:50,382]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:53:22,690]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:53:34,404]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:53:39,269]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:53:44,532]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:54:06,245]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:54:09,722]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:54:16,971]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:54:21,321]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:54:23,692]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:54:31,154]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:54:36,314]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:54:41,694]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:54:46,174]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:54:48,558]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:54:53,354]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:54:56,107]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:54:58,963]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:55:05,282]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:55:08,372]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:55:18,281]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:55:26,008]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:55:30,975]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:56:23,093]\u001b[0m Trial 349 finished with value: 1.5468933411727843 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016867056910776811, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30897932631690267, 'dropout_rate_Layer_2': 0.30692167115156127, 'dropout_rate_Layer_3': 0.21882128736115117, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023340759545627303, 'l1_Layer_2': 0.0003664024811165185, 'l1_Layer_3': 0.0013150239604226837, 'n_units_Layer_1': 205, 'n_units_Layer_2': 300, 'n_units_Layer_3': 215}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.55 | sMAPE for Validation Set is: 5.45% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.98 | sMAPE for Test Set is: 27.56% | rMAE for Test Set is: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:56:27,916]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:56:32,803]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:56:36,990]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:56:44,480]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:56:56,821]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:56:59,553]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:57:01,896]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:57:06,849]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:57:06,961]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:57:16,516]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:57:18,903]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:57:26,398]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:57:31,955]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:58:03,756]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:58:13,426]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:58:19,097]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:58:26,251]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:58:31,163]\u001b[0m Trial 362 finished with value: 1.4813146087577225 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034766877076268694, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28336213050979764, 'dropout_rate_Layer_2': 0.18697571826448878, 'dropout_rate_Layer_3': 0.2871761468090042, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005138920912169466, 'l1_Layer_2': 0.00033870753643163066, 'l1_Layer_3': 0.00023745055943349383, 'n_units_Layer_1': 50, 'n_units_Layer_2': 200, 'n_units_Layer_3': 50}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.27% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.54 | sMAPE for Test Set is: 23.52% | rMAE for Test Set is: 1.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:58:33,805]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:58:40,276]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:58:45,395]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:58:48,716]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:58:58,094]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:59:02,995]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:59:08,185]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:59:12,794]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:59:20,317]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:59:27,666]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:59:35,507]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:59:50,493]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:00:10,593]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:00:19,201]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:00:38,140]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:00:44,114]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:00:51,242]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:00:58,938]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:01:16,102]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:01:21,406]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:01:21,541]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:01:32,246]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:01:32,478]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:01:47,501]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:01:50,614]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:01:57,725]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:02:17,523]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:02:26,994]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:02:27,187]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:03:26,906]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:03:34,506]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:03:46,673]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:04:06,595]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:04:13,877]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:05:02,806]\u001b[0m Trial 398 finished with value: 1.5735538846998018 and parameters: {'n_hidden': 3, 'learning_rate': 0.005747355194263102, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23150532732112833, 'dropout_rate_Layer_2': 0.18758856814652636, 'dropout_rate_Layer_3': 0.24136296469263419, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004316116047622355, 'l1_Layer_2': 8.661963838643374e-05, 'l1_Layer_3': 0.00015168415999926898, 'n_units_Layer_1': 120, 'n_units_Layer_2': 250, 'n_units_Layer_3': 85}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.57 | sMAPE for Validation Set is: 5.56% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.16 | sMAPE for Test Set is: 12.70% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:05:33,079]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:05:48,006]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:05:58,101]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:06:02,568]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:06:22,599]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:06:28,389]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:06:37,952]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:06:42,607]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:06:59,794]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:07:02,269]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:07:12,018]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:07:15,333]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:07:24,250]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:07:29,319]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:07:34,416]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:07:37,384]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:07:40,033]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:07:44,825]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:07:51,853]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:07:52,420]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:08:10,558]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:08:15,888]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:08:22,562]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:08:24,511]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:08:29,049]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:08:38,471]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:09:10,368]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:09:15,723]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:09:20,656]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:09:37,870]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:09:57,451]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:10:10,203]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:10:35,318]\u001b[0m Trial 435 finished with value: 1.5199692729465124 and parameters: {'n_hidden': 3, 'learning_rate': 0.001245059218082976, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3704166392082233, 'dropout_rate_Layer_2': 0.03624707846082704, 'dropout_rate_Layer_3': 0.19573854462091506, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010417341584944794, 'l1_Layer_2': 0.0006033618102934343, 'l1_Layer_3': 4.8739811093170616e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 255, 'n_units_Layer_3': 265}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.52 | sMAPE for Validation Set is: 5.39% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.48 | sMAPE for Test Set is: 15.63% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:10:42,680]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:10:59,791]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:11:05,129]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:11:11,736]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:11:21,866]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:11:31,659]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:11:37,137]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.55 | sMAPE for Validation Set is: 5.47% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.52 | sMAPE for Test Set is: 23.49% | rMAE for Test Set is: 1.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:11:40,982]\u001b[0m Trial 440 finished with value: 1.5451014831745422 and parameters: {'n_hidden': 3, 'learning_rate': 0.001317264812721412, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37458635607363416, 'dropout_rate_Layer_2': 0.030405319395359894, 'dropout_rate_Layer_3': 0.08163064595131553, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006374888604987709, 'l1_Layer_2': 0.001573375407067339, 'l1_Layer_3': 5.184038024969161e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 165, 'n_units_Layer_3': 295}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:11:44,431]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:11:49,976]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:11:54,836]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:11:59,737]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:12:04,220]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:12:26,521]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:12:29,416]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:12:38,412]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:12:41,448]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:12:47,893]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:12:50,921]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:13:06,160]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:13:09,188]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:13:15,827]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:13:22,598]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:13:30,789]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:13:30,885]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:13:39,437]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:13:39,749]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:13:48,190]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:13:52,958]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:13:55,772]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:14:02,980]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:14:31,987]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:14:36,939]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:14:37,304]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:14:43,225]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:14:45,421]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:14:50,444]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:14:55,304]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:14:57,539]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:15:07,701]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:15:17,311]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:15:22,658]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:15:22,895]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:15:30,255]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:15:30,377]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:15:37,747]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:15:37,946]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:15:45,653]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:15:51,288]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:16:20,748]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:16:27,399]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:16:33,284]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:16:42,938]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:16:48,058]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:16:52,728]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:16:55,425]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:17:00,049]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:17:02,938]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:17:06,980]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:17:09,513]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:17:15,041]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:17:21,525]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:17:22,111]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:17:34,140]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:17:44,063]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:17:51,343]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:18:26,673]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:18:31,542]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:18:41,881]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:18:46,755]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:18:55,807]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:18:58,952]\u001b[0m Trial 504 finished with value: 1.4947252216996205 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006388600343523575, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31582379630672386, 'dropout_rate_Layer_2': 0.047813226085193214, 'dropout_rate_Layer_3': 0.06646082047955056, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0252006685536013, 'l1_Layer_2': 0.004103449000646546, 'l1_Layer_3': 2.1035106134479976e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 160, 'n_units_Layer_3': 270}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.29% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.42 | sMAPE for Test Set is: 15.47% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:19:03,937]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:19:10,882]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:19:16,318]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:19:21,487]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:19:52,918]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:19:59,962]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:20:03,323]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:20:20,837]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:20:42,694]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:21:20,332]\u001b[0m Trial 518 finished with value: 1.4969481720604711 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013499639486138344, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2769234625025426, 'dropout_rate_Layer_2': 0.2540818611472415, 'dropout_rate_Layer_3': 1.5732187586969468e-05, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00829287520597488, 'l1_Layer_2': 9.633259773850986e-05, 'l1_Layer_3': 7.495265974589904e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 160, 'n_units_Layer_3': 280}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.31% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.43 | sMAPE for Test Set is: 23.20% | rMAE for Test Set is: 1.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:21:24,462]\u001b[0m Trial 519 finished with value: 1.4933801995797753 and parameters: {'n_hidden': 3, 'learning_rate': 0.001255630949479226, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2760695984265774, 'dropout_rate_Layer_2': 0.2527134314689192, 'dropout_rate_Layer_3': 0.01017074312596791, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008409097421548396, 'l1_Layer_2': 9.640273238858243e-05, 'l1_Layer_3': 7.237415952724566e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 170, 'n_units_Layer_3': 280}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.29% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.35 | sMAPE for Test Set is: 23.01% | rMAE for Test Set is: 1.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:21:26,824]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:21:37,438]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:21:47,184]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:21:51,196]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:21:56,916]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:21:57,050]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:22:23,615]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:22:34,459]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:22:41,495]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:22:46,235]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:22:51,761]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:23:05,760]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:23:10,757]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:23:20,908]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:23:33,861]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:23:38,535]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:23:48,598]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:24:41,873]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:24:41,946]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:24:50,253]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:24:50,445]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:24:55,460]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:25:00,622]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:25:07,924]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:25:12,272]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:25:19,931]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:25:32,141]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:25:32,585]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:25:38,436]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:25:43,436]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:25:48,726]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:25:57,551]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:26:02,879]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:26:05,915]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:26:10,776]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:26:17,507]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:26:22,987]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:26:28,109]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:26:32,903]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:27:33,662]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:27:48,314]\u001b[0m Trial 560 finished with value: 1.4999910206368516 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007418568733021685, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3998084752043303, 'dropout_rate_Layer_2': 0.0582328240489681, 'dropout_rate_Layer_3': 0.03794058509878362, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07936414983578238, 'l1_Layer_2': 0.004062480373460388, 'l1_Layer_3': 3.8344300309214715e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 125, 'n_units_Layer_3': 290}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.33% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.90 | sMAPE for Test Set is: 16.71% | rMAE for Test Set is: 1.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:27:56,417]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:28:03,198]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:28:08,617]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:28:15,849]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:28:30,569]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:28:30,639]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:28:39,451]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:28:47,022]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:28:54,457]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:29:01,546]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:29:09,358]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:29:22,119]\u001b[0m Trial 567 finished with value: 1.45607727235478 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012821681539087054, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27574079493527726, 'dropout_rate_Layer_2': 0.27992691009518966, 'dropout_rate_Layer_3': 0.393298184064159, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007291378817471523, 'l1_Layer_2': 0.00010142019145128176, 'l1_Layer_3': 0.00031274597150656624, 'n_units_Layer_1': 60, 'n_units_Layer_2': 165, 'n_units_Layer_3': 295}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 5.17% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.32 | sMAPE for Test Set is: 17.68% | rMAE for Test Set is: 1.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:29:43,433]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:29:51,210]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:29:58,565]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:30:09,021]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:31:18,080]\u001b[0m Trial 578 finished with value: 1.511795576675422 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008592251766097699, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37363180463096646, 'dropout_rate_Layer_2': 0.028103943337058988, 'dropout_rate_Layer_3': 0.015065357268015205, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07375160311502749, 'l1_Layer_2': 0.002424921239158922, 'l1_Layer_3': 3.388233583140206e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 145, 'n_units_Layer_3': 95}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.34% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.86 | sMAPE for Test Set is: 19.11% | rMAE for Test Set is: 1.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:31:22,893]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:31:35,147]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:31:42,179]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:31:47,559]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:32:00,056]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:32:07,119]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:32:12,363]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:32:17,464]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:32:25,000]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:32:32,110]\u001b[0m Trial 573 finished with value: 1.487900606267279 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007345668744006948, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3921371572593659, 'dropout_rate_Layer_2': 0.011402379173950851, 'dropout_rate_Layer_3': 0.029962788416509747, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.051173889871237534, 'l1_Layer_2': 0.004047970851442312, 'l1_Layer_3': 2.4673018374404248e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 120, 'n_units_Layer_3': 85}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.27% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.81 | sMAPE for Test Set is: 16.44% | rMAE for Test Set is: 1.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:32:37,264]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:32:41,245]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:33:01,392]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:33:06,175]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:33:10,945]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:33:21,541]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:33:43,394]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:34:13,546]\u001b[0m Trial 596 finished with value: 1.54323411619641 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015631370571836751, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.274770793740419, 'dropout_rate_Layer_2': 0.271243178019118, 'dropout_rate_Layer_3': 0.3785238623618024, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00826034329379554, 'l1_Layer_2': 9.246814973875942e-05, 'l1_Layer_3': 3.0977900615479923e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 175, 'n_units_Layer_3': 295}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 5.48% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.81 | sMAPE for Test Set is: 16.49% | rMAE for Test Set is: 1.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:34:47,839]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:34:52,527]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:34:57,835]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:35:02,405]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:35:07,288]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:35:12,287]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:35:47,257]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:36:02,117]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:36:09,316]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:36:19,117]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:36:33,881]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:36:40,940]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:36:48,805]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:36:53,872]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:36:58,745]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:37:03,406]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:37:18,685]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:37:28,651]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:37:33,364]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:37:35,976]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:37:40,151]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:38:05,138]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:38:10,427]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:38:17,305]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:38:44,715]\u001b[0m Trial 618 finished with value: 1.520751657201813 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016333172054853436, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03364476616658024, 'dropout_rate_Layer_2': 0.038112666077166436, 'dropout_rate_Layer_3': 0.16102168610415174, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00814365177698424, 'l1_Layer_2': 0.0006119679055881298, 'l1_Layer_3': 1.6527304147787013e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 95, 'n_units_Layer_3': 85}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.52 | sMAPE for Validation Set is: 5.41% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.03 | sMAPE for Test Set is: 14.55% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:38:47,687]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:38:52,492]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:38:55,212]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:39:02,358]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:39:07,934]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:39:14,779]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:40:23,506]\u001b[0m Trial 625 finished with value: 1.4904574458337139 and parameters: {'n_hidden': 3, 'learning_rate': 0.002777421224784652, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35430315140648183, 'dropout_rate_Layer_2': 0.04610739405907091, 'dropout_rate_Layer_3': 0.13718275816407885, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021020872192809335, 'l1_Layer_2': 0.000841581443045613, 'l1_Layer_3': 4.043843761067088e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 225, 'n_units_Layer_3': 175}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.27% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.90 | sMAPE for Test Set is: 21.82% | rMAE for Test Set is: 1.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:40:30,655]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:40:35,639]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:40:40,845]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:40:47,891]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:40:55,390]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:40:55,441]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:41:04,733]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:41:09,861]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:41:26,952]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:41:34,005]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:41:39,073]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:41:46,079]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:41:51,295]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:41:58,424]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:42:05,780]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:42:11,089]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:42:15,958]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:42:21,227]\u001b[0m Trial 636 finished with value: 1.5317019321043839 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010414846637747347, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3431228701492658, 'dropout_rate_Layer_2': 0.040287306917040855, 'dropout_rate_Layer_3': 0.19881339238844456, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.8410520934531046e-05, 'l1_Layer_2': 0.001721819161937874, 'l1_Layer_3': 4.089126078795001e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 225, 'n_units_Layer_3': 180}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.41% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.81 | sMAPE for Test Set is: 21.68% | rMAE for Test Set is: 1.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:42:21,464]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:42:29,182]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:42:35,548]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:42:43,331]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:42:48,886]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:42:55,316]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:42:58,107]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:43:03,404]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:43:05,093]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:43:10,630]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:43:13,103]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:43:27,222]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:43:42,229]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:43:42,501]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:43:49,933]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:43:50,065]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:43:59,292]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:44:08,309]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:44:09,953]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:44:53,360]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:44:55,825]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:45:05,553]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:45:25,019]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:45:29,893]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:45:33,396]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:45:39,875]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:45:45,147]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:45:52,674]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:45:57,869]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:46:02,726]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:46:09,876]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:46:12,516]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:46:22,112]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:46:41,782]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:46:51,209]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:47:28,259]\u001b[0m Trial 680 finished with value: 1.6617291807906363 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024377172180642882, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2087926209453709, 'dropout_rate_Layer_2': 0.31807579455157897, 'dropout_rate_Layer_3': 0.22645046545246308, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.5695135629495774e-05, 'l1_Layer_2': 0.0005078044796781072, 'l1_Layer_3': 2.0604731209432292e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 175, 'n_units_Layer_3': 195}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.66 | sMAPE for Validation Set is: 5.92% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.46 | sMAPE for Test Set is: 23.37% | rMAE for Test Set is: 1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:48:32,426]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:48:37,115]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:48:44,284]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:48:49,781]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:48:54,231]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:49:01,747]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:49:13,773]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:49:21,101]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:49:40,962]\u001b[0m Trial 682 finished with value: 1.433331215057515 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009487384197854993, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04093797449200921, 'dropout_rate_Layer_2': 0.035085549586101064, 'dropout_rate_Layer_3': 0.06477837349961695, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0028229928176256407, 'l1_Layer_2': 0.0009538271659067267, 'l1_Layer_3': 0.0011806767197388064, 'n_units_Layer_1': 195, 'n_units_Layer_2': 95, 'n_units_Layer_3': 245}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 5.07% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.45 | sMAPE for Test Set is: 18.02% | rMAE for Test Set is: 1.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:49:45,850]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:49:48,298]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:49:50,825]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:49:57,738]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:50:23,054]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.68 | sMAPE for Validation Set is: 5.92% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.98 | sMAPE for Test Set is: 30.46% | rMAE for Test Set is: 2.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:50:26,595]\u001b[0m Trial 695 finished with value: 1.6832619883627862 and parameters: {'n_hidden': 3, 'learning_rate': 0.003338137237548881, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11130247863578005, 'dropout_rate_Layer_2': 0.2973152238230919, 'dropout_rate_Layer_3': 0.20489331007658057, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.29525354203073e-05, 'l1_Layer_2': 0.03563456697263567, 'l1_Layer_3': 0.00013821405763904743, 'n_units_Layer_1': 275, 'n_units_Layer_2': 220, 'n_units_Layer_3': 250}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:50:32,620]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:50:40,282]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:50:42,831]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:50:51,867]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:50:52,400]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:51:00,861]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:51:06,216]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:51:20,874]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:51:27,570]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:51:57,312]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:52:31,625]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:52:46,726]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:52:56,839]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:53:03,632]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:53:38,086]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:53:48,574]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:53:55,517]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:54:06,223]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:54:13,394]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:54:20,240]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:54:20,244]\u001b[0m Trial 709 finished with value: 1.42229356868751 and parameters: {'n_hidden': 3, 'learning_rate': 0.000917981161804399, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.031253834365650726, 'dropout_rate_Layer_2': 0.00854166146663976, 'dropout_rate_Layer_3': 0.04846799874942558, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003032151855251758, 'l1_Layer_2': 1.616440178832152e-05, 'l1_Layer_3': 0.0012337925150156712, 'n_units_Layer_1': 185, 'n_units_Layer_2': 105, 'n_units_Layer_3': 300}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.42 | sMAPE for Validation Set is: 5.03% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.30 | sMAPE for Test Set is: 20.18% | rMAE for Test Set is: 1.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:54:26,422]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:54:31,563]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:54:36,163]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:54:42,830]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:55:08,427]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:55:15,247]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:55:49,443]\u001b[0m Trial 719 finished with value: 1.450418572132814 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019758993993649757, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3538493250842771, 'dropout_rate_Layer_2': 0.15880737792017702, 'dropout_rate_Layer_3': 0.10967284340127285, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005438946116459446, 'l1_Layer_2': 0.0007698816440148034, 'l1_Layer_3': 3.3543712458757674e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 205, 'n_units_Layer_3': 85}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.45 | sMAPE for Validation Set is: 5.15% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.60 | sMAPE for Test Set is: 13.54% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:55:52,813]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:55:57,232]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:56:04,375]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:56:07,411]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:56:09,450]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:56:15,068]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:56:21,708]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:56:31,936]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:56:33,720]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:56:43,811]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:56:48,762]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:57:02,903]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:57:08,009]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:57:23,080]\u001b[0m Trial 735 finished with value: 1.5265879309954367 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013099035580997815, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37943394268627817, 'dropout_rate_Layer_2': 0.11523141163632504, 'dropout_rate_Layer_3': 0.18951240446885315, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021248140464762955, 'l1_Layer_2': 0.0006876365709433311, 'l1_Layer_3': 4.9527990443191325e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 140, 'n_units_Layer_3': 80}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.42% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 9.57 | sMAPE for Test Set is: 23.62% | rMAE for Test Set is: 1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:57:27,718]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:57:32,380]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:57:49,865]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:57:56,578]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:58:01,461]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:58:11,895]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:58:36,061]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:58:38,197]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:58:55,784]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:58:58,652]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:59:05,720]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:59:26,998]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:59:32,300]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:59:37,317]\u001b[0m Trial 751 finished with value: 1.5897562914143284 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009773183321198132, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14555464525881234, 'dropout_rate_Layer_2': 0.3992090669803611, 'dropout_rate_Layer_3': 0.17834929033130129, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017915599545047134, 'l1_Layer_2': 0.00046319774131966726, 'l1_Layer_3': 1.0104779309001606e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 110, 'n_units_Layer_3': 75}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.59 | sMAPE for Validation Set is: 5.64% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.97 | sMAPE for Test Set is: 27.55% | rMAE for Test Set is: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:59:40,026]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:59:44,439]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:59:44,865]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:59:52,180]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:00:04,822]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:00:14,917]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:00:19,863]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:00:26,276]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:00:32,146]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:00:41,848]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:00:51,468]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:00:51,774]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:00:59,177]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:01:04,004]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:01:04,399]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:01:17,168]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:01:22,578]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:02:53,247]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:02:58,259]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:02:58,521]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:03:22,813]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:03:40,255]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:03:47,313]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:03:57,612]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:04:04,467]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:04:17,127]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:04:43,629]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:04:48,517]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:04:53,555]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:05:01,018]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:05:06,348]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:05:10,984]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:05:15,406]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:05:32,637]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:05:35,757]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:05:38,112]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:05:42,507]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:05:45,568]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:05:50,362]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:05:50,539]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:05:58,204]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:05:58,525]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:06:06,353]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:06:09,256]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:06:11,751]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:06:16,141]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:06:16,360]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:06:23,102]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:06:25,653]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:06:29,556]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:06:29,999]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:06:43,254]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:07:07,380]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:07:12,927]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:07:17,441]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:07:37,909]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:07:44,681]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:07:58,078]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:08:03,215]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:08:09,537]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:08:12,446]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:08:19,613]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:08:24,283]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:08:32,711]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:08:37,548]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:09:06,236]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:09:11,388]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:09:25,865]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:09:34,099]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:09:41,652]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:09:48,894]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:09:52,992]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:10:02,901]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:10:10,142]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:10:15,965]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:10:16,431]\u001b[0m Trial 817 finished with value: 1.4934921988384238 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022387301705993163, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3883419649831407, 'dropout_rate_Layer_2': 0.22583580398393055, 'dropout_rate_Layer_3': 0.19171014750238477, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014000980797079354, 'l1_Layer_2': 0.0014414126392826134, 'l1_Layer_3': 0.0003727247905858013, 'n_units_Layer_1': 290, 'n_units_Layer_2': 200, 'n_units_Layer_3': 200}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.28% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.32 | sMAPE for Test Set is: 22.94% | rMAE for Test Set is: 1.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:10:25,426]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:10:33,034]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:10:40,012]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:10:47,285]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:11:09,062]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:11:09,531]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:11:15,296]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:11:22,090]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:11:27,479]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:11:27,690]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:11:38,514]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:11:38,828]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:11:48,736]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:11:49,283]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:11:56,669]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:12:01,260]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:12:06,713]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:12:11,389]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:12:11,436]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:12:20,444]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:12:20,605]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:12:36,548]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:12:41,108]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:12:41,392]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:12:47,804]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:12:52,143]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:12:59,196]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:13:00,102]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:13:04,981]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:13:06,693]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:13:14,709]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:13:17,518]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:13:24,351]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:13:24,853]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:13:30,405]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:13:37,947]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:13:42,848]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:13:47,878]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:13:54,560]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:13:59,650]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:15:03,615]\u001b[0m Trial 864 finished with value: 1.4499184499328586 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010618308653029917, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28928930929316854, 'dropout_rate_Layer_2': 0.03274705020740845, 'dropout_rate_Layer_3': 0.020086556981464408, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.018283698924306736, 'l1_Layer_2': 0.013566103668309947, 'l1_Layer_3': 0.0013477074270432153, 'n_units_Layer_1': 50, 'n_units_Layer_2': 195, 'n_units_Layer_3': 285}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.45 | sMAPE for Validation Set is: 5.14% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.00 | sMAPE for Test Set is: 19.44% | rMAE for Test Set is: 1.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:15:08,740]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:15:30,899]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:15:35,920]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:15:57,682]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:16:02,514]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:16:07,417]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:16:12,986]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:16:17,668]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:16:44,957]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:16:47,223]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:16:49,869]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:16:56,801]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:17:01,701]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:17:55,655]\u001b[0m Trial 884 finished with value: 1.4811784578923628 and parameters: {'n_hidden': 3, 'learning_rate': 0.000638335066426246, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3210429561670217, 'dropout_rate_Layer_2': 0.04553558871169788, 'dropout_rate_Layer_3': 0.058890686589668756, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.034145774227915364, 'l1_Layer_2': 0.010453365845078801, 'l1_Layer_3': 4.916283438469251e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 165, 'n_units_Layer_3': 285}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.24% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.01 | sMAPE for Test Set is: 16.95% | rMAE for Test Set is: 1.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:18:05,954]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:18:12,732]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:18:20,766]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:18:25,983]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:18:32,815]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:18:42,956]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:18:52,550]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:19:41,774]\u001b[0m Trial 892 finished with value: 1.4918015392665758 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031930560228898078, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34356344249652404, 'dropout_rate_Layer_2': 0.17945707125887927, 'dropout_rate_Layer_3': 0.1371600234086758, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00027009778770752476, 'l1_Layer_2': 0.0022486082191556403, 'l1_Layer_3': 0.0008848283189904622, 'n_units_Layer_1': 130, 'n_units_Layer_2': 255, 'n_units_Layer_3': 95}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.27% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 10.38 | sMAPE for Test Set is: 25.84% | rMAE for Test Set is: 2.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:19:51,912]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:20:08,610]\u001b[0m Trial 887 finished with value: 1.4489700147737115 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009297869150837061, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2820534655289628, 'dropout_rate_Layer_2': 0.040469252739870946, 'dropout_rate_Layer_3': 0.031051984629508686, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.013299415545461235, 'l1_Layer_2': 0.006878302288968311, 'l1_Layer_3': 0.0018872344874341848, 'n_units_Layer_1': 55, 'n_units_Layer_2': 205, 'n_units_Layer_3': 280}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.45 | sMAPE for Validation Set is: 5.14% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.44 | sMAPE for Test Set is: 20.57% | rMAE for Test Set is: 1.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:20:33,398]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:20:53,853]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:21:18,305]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:21:34,859]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:21:45,126]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:21:52,555]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:21:57,385]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:22:04,873]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:22:21,720]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:22:27,361]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:22:34,294]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:22:41,567]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:23:38,541]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:23:44,918]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:23:52,554]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:25:18,478]\u001b[0m Trial 904 finished with value: 1.4415296484016615 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006091277251206885, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2831504633960876, 'dropout_rate_Layer_2': 0.029914626700984562, 'dropout_rate_Layer_3': 0.02930799990110953, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.016388268241183224, 'l1_Layer_2': 0.00689573849866642, 'l1_Layer_3': 0.0038372216722249454, 'n_units_Layer_1': 50, 'n_units_Layer_2': 205, 'n_units_Layer_3': 265}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 5.11% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.60 | sMAPE for Test Set is: 20.98% | rMAE for Test Set is: 1.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:25:23,221]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:25:30,400]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:25:41,228]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:26:02,622]\u001b[0m Trial 910 finished with value: 1.47443926286875 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007162714889769752, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3085721879367997, 'dropout_rate_Layer_2': 0.037125906568409646, 'dropout_rate_Layer_3': 0.07872771390216628, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008921216209204198, 'l1_Layer_2': 0.011107905184529152, 'l1_Layer_3': 6.063217743318942e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 300, 'n_units_Layer_3': 275}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.24% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.86 | sMAPE for Test Set is: 16.56% | rMAE for Test Set is: 1.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:26:24,905]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:27:21,549]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:28:23,020]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:28:28,187]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:28:32,905]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:28:39,744]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:29:01,866]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:29:22,260]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:30:10,797]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:30:17,694]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:30:20,942]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:30:25,534]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:30:35,263]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:30:42,659]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:31:04,848]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:31:09,947]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:31:14,705]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:31:22,298]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:33:11,971]\u001b[0m Trial 925 finished with value: 1.435350001182414 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005718222623618934, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27141196704158527, 'dropout_rate_Layer_2': 0.025801440943933485, 'dropout_rate_Layer_3': 0.05892475314416239, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.014430297597461096, 'l1_Layer_2': 0.004532260834446085, 'l1_Layer_3': 0.001846216359176263, 'n_units_Layer_1': 60, 'n_units_Layer_2': 195, 'n_units_Layer_3': 280}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 5.09% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.14 | sMAPE for Test Set is: 19.79% | rMAE for Test Set is: 1.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:33:33,947]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:33:38,893]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:34:33,278]\u001b[0m Trial 933 finished with value: 1.4479755280404116 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007119891779116197, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2821972495595942, 'dropout_rate_Layer_2': 0.01659042211342296, 'dropout_rate_Layer_3': 0.02307030046941962, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.013048093121432923, 'l1_Layer_2': 0.0077320940282002044, 'l1_Layer_3': 0.004058689880429957, 'n_units_Layer_1': 55, 'n_units_Layer_2': 190, 'n_units_Layer_3': 270}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.45 | sMAPE for Validation Set is: 5.13% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.69 | sMAPE for Test Set is: 21.23% | rMAE for Test Set is: 1.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:34:38,598]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:35:30,086]\u001b[0m Trial 938 finished with value: 1.686266563138482 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030397783418559684, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38469425893141007, 'dropout_rate_Layer_2': 0.27564307506238384, 'dropout_rate_Layer_3': 0.18359964620415176, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00031375897190194627, 'l1_Layer_2': 0.001249067497734495, 'l1_Layer_3': 0.0007585035373238643, 'n_units_Layer_1': 135, 'n_units_Layer_2': 240, 'n_units_Layer_3': 230}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.69 | sMAPE for Validation Set is: 5.90% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.46 | sMAPE for Test Set is: 28.93% | rMAE for Test Set is: 2.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:35:34,773]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:35:42,447]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:36:01,717]\u001b[0m Trial 936 finished with value: 1.4323679398602394 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006663732117175637, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2622068286209164, 'dropout_rate_Layer_2': 0.02486878428545033, 'dropout_rate_Layer_3': 0.013094434485831311, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.013656735278940242, 'l1_Layer_2': 0.0044134800289765495, 'l1_Layer_3': 0.0032156982591300736, 'n_units_Layer_1': 60, 'n_units_Layer_2': 200, 'n_units_Layer_3': 280}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 5.08% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.33 | sMAPE for Test Set is: 20.29% | rMAE for Test Set is: 1.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:36:06,589]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:36:57,929]\u001b[0m Trial 943 finished with value: 1.51778148955695 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016370772123236695, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3473337531023404, 'dropout_rate_Layer_2': 0.17236316824195205, 'dropout_rate_Layer_3': 0.16671908133910177, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0105173436337619e-05, 'l1_Layer_2': 0.006619363096415743, 'l1_Layer_3': 2.7626786838605667e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 215, 'n_units_Layer_3': 70}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.52 | sMAPE for Validation Set is: 5.37% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 9.11 | sMAPE for Test Set is: 22.33% | rMAE for Test Set is: 1.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:37:09,800]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:37:24,822]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:37:31,545]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:37:52,128]\u001b[0m Trial 941 finished with value: 1.4388077354386757 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008565751755845533, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31141918276400504, 'dropout_rate_Layer_2': 0.03247307171060941, 'dropout_rate_Layer_3': 0.007038435962937736, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006216892400792736, 'l1_Layer_2': 0.011379601442674865, 'l1_Layer_3': 7.554379598056562e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 295, 'n_units_Layer_3': 270}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 5.10% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.08 | sMAPE for Test Set is: 17.11% | rMAE for Test Set is: 1.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:37:56,826]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:38:53,004]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:40:41,342]\u001b[0m Trial 949 finished with value: 1.426769592016103 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005904715665780907, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28100822364303674, 'dropout_rate_Layer_2': 0.013760369143176503, 'dropout_rate_Layer_3': 0.011906285630136928, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.021513925561201557, 'l1_Layer_2': 0.00422646667742965, 'l1_Layer_3': 0.003208719835666536, 'n_units_Layer_1': 60, 'n_units_Layer_2': 195, 'n_units_Layer_3': 275}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 5.06% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.30 | sMAPE for Test Set is: 20.20% | rMAE for Test Set is: 1.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:41:33,894]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:41:45,497]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:41:50,645]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:42:00,860]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:42:05,778]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:42:59,669]\u001b[0m Trial 951 finished with value: 1.4230612351907699 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006995967010858833, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28199222592463874, 'dropout_rate_Layer_2': 0.0012188331689656495, 'dropout_rate_Layer_3': 0.009646525436192155, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.025519763792214135, 'l1_Layer_2': 0.004037958639797454, 'l1_Layer_3': 0.002640616275767017, 'n_units_Layer_1': 65, 'n_units_Layer_2': 195, 'n_units_Layer_3': 265}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.42 | sMAPE for Validation Set is: 5.04% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.99 | sMAPE for Test Set is: 19.39% | rMAE for Test Set is: 1.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:43:06,768]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:43:47,468]\u001b[0m Trial 956 finished with value: 1.459937181486098 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010283561289926213, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3299205590975749, 'dropout_rate_Layer_2': 0.035448857475326036, 'dropout_rate_Layer_3': 0.003961480533866156, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006469877427371217, 'l1_Layer_2': 0.01322113567338134, 'l1_Layer_3': 0.00010812657054411182, 'n_units_Layer_1': 65, 'n_units_Layer_2': 300, 'n_units_Layer_3': 150}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 5.17% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.96 | sMAPE for Test Set is: 16.81% | rMAE for Test Set is: 1.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:43:54,392]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:43:59,573]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:44:17,768]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:45:30,567]\u001b[0m Trial 958 finished with value: 1.4403626590023715 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007122844734315458, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25348301283498054, 'dropout_rate_Layer_2': 0.0005755845406472217, 'dropout_rate_Layer_3': 0.009205874520325296, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.023249723196555012, 'l1_Layer_2': 0.004308520106185325, 'l1_Layer_3': 0.0028792444782824553, 'n_units_Layer_1': 70, 'n_units_Layer_2': 195, 'n_units_Layer_3': 260}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 5.10% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.01 | sMAPE for Test Set is: 19.45% | rMAE for Test Set is: 1.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:45:40,149]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:45:45,309]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:45:51,950]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:45:56,780]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:46:04,685]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:46:09,558]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:46:29,490]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:46:34,081]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:46:38,702]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:47:08,340]\u001b[0m Trial 962 finished with value: 1.4308859197787065 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006205873405078724, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2578771823095313, 'dropout_rate_Layer_2': 0.0003833215841631039, 'dropout_rate_Layer_3': 0.01201015798667588, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.021674729252590223, 'l1_Layer_2': 0.005739984595810282, 'l1_Layer_3': 0.002375076599968701, 'n_units_Layer_1': 60, 'n_units_Layer_2': 195, 'n_units_Layer_3': 260}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 5.07% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.17 | sMAPE for Test Set is: 19.86% | rMAE for Test Set is: 1.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:47:13,398]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:47:25,919]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:47:32,497]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:47:50,319]\u001b[0m Trial 972 finished with value: 1.4709635321654424 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011517449273297988, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3127485865565944, 'dropout_rate_Layer_2': 0.027126203929756267, 'dropout_rate_Layer_3': 0.018872143196145434, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007215067936776142, 'l1_Layer_2': 0.010001863186380943, 'l1_Layer_3': 8.46193357762704e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 300, 'n_units_Layer_3': 165}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.22% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.04 | sMAPE for Test Set is: 17.01% | rMAE for Test Set is: 1.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:47:55,273]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:48:00,594]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:48:05,368]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:48:14,728]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:48:19,608]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:48:40,686]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:49:18,005]\u001b[0m Trial 976 finished with value: 1.461976819011752 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010876103602381097, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0013736864585451188, 'dropout_rate_Layer_2': 0.08662993601027232, 'dropout_rate_Layer_3': 0.04565204258321466, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000883445045523946, 'l1_Layer_2': 0.014140482111197164, 'l1_Layer_3': 2.0849575373533706e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 60, 'n_units_Layer_3': 50}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 5.18% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.11 | sMAPE for Test Set is: 17.24% | rMAE for Test Set is: 1.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:49:42,734]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:49:48,000]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:49:55,609]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:50:00,524]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:50:55,623]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:51:12,343]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:51:17,504]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:51:22,470]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:52:02,627]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:52:14,671]\u001b[0m Trial 989 finished with value: 1.5019949520189229 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015610515824986142, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016694395804105068, 'dropout_rate_Layer_2': 0.10308595989094449, 'dropout_rate_Layer_3': 0.04227999822032304, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008777632576573685, 'l1_Layer_2': 0.012530382420668597, 'l1_Layer_3': 2.0860733979409525e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 60, 'n_units_Layer_3': 55}. Best is trial 254 with value: 1.3895806974627674.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.32% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.21 | sMAPE for Test Set is: 22.65% | rMAE for Test Set is: 1.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:52:19,370]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:52:26,675]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:52:31,531]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:52:36,275]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:52:42,013]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:52:46,504]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:53:00,849]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:53:01,388]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:53:07,650]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:53:10,211]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:53:14,691]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:53:17,200]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:53:21,944]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:53:24,643]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:53:29,349]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:53:34,237]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:53:41,187]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:53:46,248]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:54:13,782]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:54:19,203]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:54:26,594]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:54:34,096]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:54:41,238]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:54:48,720]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:54:55,727]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:55:02,766]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:55:10,723]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:55:18,050]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:55:28,002]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:55:33,172]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:55:43,276]\u001b[0m Trial 1012 finished with value: 1.3406999643199715 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008831162191256708, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.038688528678630735, 'dropout_rate_Layer_2': 0.18093947611331407, 'dropout_rate_Layer_3': 0.20710483844751001, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018969608949727188, 'l1_Layer_2': 0.0052890997580079145, 'l1_Layer_3': 5.675291002258548e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 180, 'n_units_Layer_3': 210}. Best is trial 1012 with value: 1.3406999643199715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.34 | sMAPE for Validation Set is: 4.77% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 4.23 | sMAPE for Test Set is: 10.42% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:55:45,828]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:55:50,618]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:55:55,325]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:56:00,663]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:56:03,297]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:56:08,020]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:56:20,078]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:56:25,134]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:56:32,249]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:57:07,458]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:57:15,109]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:57:22,427]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:57:29,333]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:57:34,559]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:58:36,226]\u001b[0m Trial 1029 finished with value: 1.3533354940849531 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006726871231872582, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011684915317548054, 'dropout_rate_Layer_2': 0.16523031527601945, 'dropout_rate_Layer_3': 0.2485960295444518, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004538860593692841, 'l1_Layer_2': 0.0036678371513615285, 'l1_Layer_3': 4.676752091907312e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 180, 'n_units_Layer_3': 210}. Best is trial 1012 with value: 1.3406999643199715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.35 | sMAPE for Validation Set is: 4.83% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 2.49 | sMAPE for Test Set is: 6.68% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:58:43,385]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:58:46,653]\u001b[0m Trial 1039 finished with value: 1.4577634011788965 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018316887028297913, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.025721542590951624, 'dropout_rate_Layer_2': 0.050343326105189115, 'dropout_rate_Layer_3': 0.009354787809131293, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0024830304397084383, 'l1_Layer_2': 0.013525296351013856, 'l1_Layer_3': 0.0009114997149747606, 'n_units_Layer_1': 260, 'n_units_Layer_2': 55, 'n_units_Layer_3': 75}. Best is trial 1012 with value: 1.3406999643199715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 5.16% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.81 | sMAPE for Test Set is: 18.93% | rMAE for Test Set is: 1.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:58:51,081]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:58:56,437]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:58:59,199]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:59:06,217]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:00:34,666]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:00:40,230]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:00:47,124]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:00:59,389]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:01:09,224]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:01:14,806]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:01:21,928]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:01:29,072]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:01:36,694]\u001b[0m Trial 1046 finished with value: 1.4303202544466298 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017632631207529052, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.044515384138250555, 'dropout_rate_Layer_2': 0.049045547346761045, 'dropout_rate_Layer_3': 0.02932111465564249, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0025234098747287563, 'l1_Layer_2': 0.015622726821882526, 'l1_Layer_3': 0.0009421131230704529, 'n_units_Layer_1': 245, 'n_units_Layer_2': 50, 'n_units_Layer_3': 75}. Best is trial 1012 with value: 1.3406999643199715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 5.07% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.67 | sMAPE for Test Set is: 18.56% | rMAE for Test Set is: 1.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:01:44,580]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:01:51,576]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:01:56,842]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:02:16,456]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:02:36,080]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:02:43,423]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:02:48,874]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:02:58,411]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:03:04,077]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:03:10,671]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:03:15,990]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:03:20,842]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:03:32,981]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:03:38,249]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:03:48,471]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:03:54,923]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:04:19,927]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:04:27,092]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:04:32,420]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:04:41,679]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:04:49,886]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:05:12,148]\u001b[0m Trial 1062 finished with value: 1.4012748381767415 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011350812321973432, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03899282986483009, 'dropout_rate_Layer_2': 0.06220925314006809, 'dropout_rate_Layer_3': 0.028066779550197034, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004985696663346707, 'l1_Layer_2': 0.010449372422151333, 'l1_Layer_3': 0.0004548589216062086, 'n_units_Layer_1': 245, 'n_units_Layer_2': 75, 'n_units_Layer_3': 80}. Best is trial 1012 with value: 1.3406999643199715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.40 | sMAPE for Validation Set is: 4.96% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.51 | sMAPE for Test Set is: 13.35% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:05:18,941]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:06:28,272]\u001b[0m Trial 1076 finished with value: 1.3574088507835202 and parameters: {'n_hidden': 3, 'learning_rate': 0.000789875853555006, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.004303885365766546, 'dropout_rate_Layer_2': 0.18105273646939393, 'dropout_rate_Layer_3': 0.2865956295185457, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017401237017348496, 'l1_Layer_2': 0.005528344409401313, 'l1_Layer_3': 4.4245200944745524e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 195, 'n_units_Layer_3': 215}. Best is trial 1012 with value: 1.3406999643199715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.36 | sMAPE for Validation Set is: 4.84% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 2.58 | sMAPE for Test Set is: 6.88% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:07:20,160]\u001b[0m Trial 1078 finished with value: 1.4299715480724526 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005288066468303565, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2561481069824117, 'dropout_rate_Layer_2': 0.0324654098031173, 'dropout_rate_Layer_3': 0.010911793068638384, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008751883624452134, 'l1_Layer_2': 8.851133195465262e-05, 'l1_Layer_3': 0.0021680029189488858, 'n_units_Layer_1': 60, 'n_units_Layer_2': 200, 'n_units_Layer_3': 270}. Best is trial 1012 with value: 1.3406999643199715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 5.08% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.77 | sMAPE for Test Set is: 21.46% | rMAE for Test Set is: 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:07:25,309]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:07:30,830]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:07:37,441]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:09:34,426]\u001b[0m Trial 1083 finished with value: 1.371859135166005 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008715400572600469, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01105645949403744, 'dropout_rate_Layer_2': 0.18428432840728354, 'dropout_rate_Layer_3': 0.3019103674963657, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0020969623024697233, 'l1_Layer_2': 0.0053330330826380215, 'l1_Layer_3': 4.6944077811118215e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 185, 'n_units_Layer_3': 220}. Best is trial 1012 with value: 1.3406999643199715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.37 | sMAPE for Validation Set is: 4.87% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 2.67 | sMAPE for Test Set is: 7.10% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:10:21,069]\u001b[0m Trial 1079 finished with value: 1.3358235728407706 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011406682141291223, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02072230976042195, 'dropout_rate_Layer_2': 0.07644703275329491, 'dropout_rate_Layer_3': 0.00818432566322181, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004066485858458836, 'l1_Layer_2': 0.016700413206168878, 'l1_Layer_3': 0.0017753504095810307, 'n_units_Layer_1': 245, 'n_units_Layer_2': 75, 'n_units_Layer_3': 85}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.34 | sMAPE for Validation Set is: 4.74% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 6.07 | sMAPE for Test Set is: 14.61% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:10:26,403]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:10:31,612]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:10:38,404]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:10:48,049]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:10:58,513]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:11:05,532]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:11:05,665]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:11:14,234]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:11:19,004]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:11:27,013]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:11:36,213]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:11:41,490]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:12:18,027]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:12:23,310]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:14:49,525]\u001b[0m Trial 1097 finished with value: 1.4164689612211019 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011894935411426624, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03252184662526114, 'dropout_rate_Layer_2': 0.06263030253618386, 'dropout_rate_Layer_3': 0.02544655692465162, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003951845960723891, 'l1_Layer_2': 0.02322471112790388, 'l1_Layer_3': 0.002758664792756801, 'n_units_Layer_1': 260, 'n_units_Layer_2': 75, 'n_units_Layer_3': 60}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.42 | sMAPE for Validation Set is: 5.02% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.09 | sMAPE for Test Set is: 17.12% | rMAE for Test Set is: 1.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:14:58,545]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:15:03,790]\u001b[0m Trial 1099 finished with value: 1.4446918649602425 and parameters: {'n_hidden': 3, 'learning_rate': 0.001438770799228189, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03554002527105139, 'dropout_rate_Layer_2': 0.05690458950668077, 'dropout_rate_Layer_3': 0.026196827936202552, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007633282517802567, 'l1_Layer_2': 0.010334303633605029, 'l1_Layer_3': 0.0026812833466334394, 'n_units_Layer_1': 260, 'n_units_Layer_2': 75, 'n_units_Layer_3': 60}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:15:03,941]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 5.13% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.51 | sMAPE for Test Set is: 18.18% | rMAE for Test Set is: 1.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:15:10,914]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:15:15,949]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:15:22,963]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:15:28,275]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:15:35,346]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:15:40,587]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:15:45,842]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:15:54,961]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:16:00,038]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:16:04,620]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:16:09,653]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:16:14,904]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:16:22,067]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:16:27,050]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:17:24,478]\u001b[0m Trial 1102 finished with value: 1.4128218627686386 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007179188312584305, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0028929043464114112, 'dropout_rate_Layer_2': 0.13878940828278657, 'dropout_rate_Layer_3': 0.301790992842151, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004871669221450888, 'l1_Layer_2': 0.00531080101449688, 'l1_Layer_3': 4.5936499680951084e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 185, 'n_units_Layer_3': 220}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.41 | sMAPE for Validation Set is: 5.01% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 2.70 | sMAPE for Test Set is: 7.20% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:17:29,524]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:18:16,649]\u001b[0m Trial 1117 finished with value: 1.3809570048774422 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008069742110956581, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0012587033952843954, 'dropout_rate_Layer_2': 0.15887571139039167, 'dropout_rate_Layer_3': 0.2999089758651705, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001958503523304186, 'l1_Layer_2': 0.005240968922977206, 'l1_Layer_3': 3.1563410528384354e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 185, 'n_units_Layer_3': 220}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.38 | sMAPE for Validation Set is: 4.92% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 2.66 | sMAPE for Test Set is: 7.06% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:18:31,316]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:18:36,974]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:18:41,398]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:18:46,722]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:18:56,617]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:19:03,215]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:19:12,970]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:19:18,898]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:19:24,182]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:19:30,722]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:19:36,559]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:20:55,003]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:21:04,775]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:21:47,148]\u001b[0m Trial 1120 finished with value: 1.4055785036619817 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015125828907731776, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03197148965775368, 'dropout_rate_Layer_2': 0.06089054950143991, 'dropout_rate_Layer_3': 0.02548591187016185, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007744907343730425, 'l1_Layer_2': 0.011460347833811295, 'l1_Layer_3': 0.002779651736928425, 'n_units_Layer_1': 265, 'n_units_Layer_2': 75, 'n_units_Layer_3': 60}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.41 | sMAPE for Validation Set is: 4.98% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.71 | sMAPE for Test Set is: 16.17% | rMAE for Test Set is: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:21:53,897]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:21:59,410]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:22:11,832]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:22:16,871]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:22:24,133]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:22:34,249]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:22:38,990]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:22:39,475]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:22:54,888]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:23:12,237]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:23:24,036]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:24:35,725]\u001b[0m Trial 1145 finished with value: 1.4305494517898205 and parameters: {'n_hidden': 3, 'learning_rate': 0.000865298135110209, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02857468772524386, 'dropout_rate_Layer_2': 0.16104567426093222, 'dropout_rate_Layer_3': 0.32353657368798766, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0029449538903773835, 'l1_Layer_2': 0.0037776714462085773, 'l1_Layer_3': 1.8580524290005695e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 170, 'n_units_Layer_3': 210}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 5.09% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 2.66 | sMAPE for Test Set is: 7.13% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:24:40,960]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:24:45,970]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:24:51,152]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:24:58,496]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:25:03,350]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:25:08,806]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:25:15,633]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:25:28,008]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:25:33,479]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:25:40,825]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:25:45,704]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:25:54,907]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:25:59,758]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:26:22,277]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:26:27,605]\u001b[0m Trial 1141 finished with value: 1.4527265064587584 and parameters: {'n_hidden': 3, 'learning_rate': 0.001410434439369506, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 6.657281154025837e-05, 'dropout_rate_Layer_2': 0.040283929246159075, 'dropout_rate_Layer_3': 0.041721449638831405, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011554400300776039, 'l1_Layer_2': 0.020285560750209437, 'l1_Layer_3': 0.0035922633869134683, 'n_units_Layer_1': 270, 'n_units_Layer_2': 65, 'n_units_Layer_3': 85}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.45 | sMAPE for Validation Set is: 5.14% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 15.93% | rMAE for Test Set is: 1.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:26:32,879]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:26:37,398]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:26:39,377]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:26:46,889]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:26:49,731]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:27:16,142]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:27:50,354]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:27:55,759]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:28:00,895]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:28:05,939]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:28:12,719]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:28:20,698]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:28:31,141]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:29:52,854]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:30:00,691]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:30:19,806]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:30:29,677]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:30:34,643]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:30:46,760]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:30:51,693]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:30:55,062]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:31:02,006]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:31:39,255]\u001b[0m Trial 1174 finished with value: 1.4754834491536162 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014301844003757876, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07118542248868046, 'dropout_rate_Layer_2': 0.041840950921384686, 'dropout_rate_Layer_3': 0.04438802437648452, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011267936750494182, 'l1_Layer_2': 0.021308871859507153, 'l1_Layer_3': 0.001871598478733155, 'n_units_Layer_1': 270, 'n_units_Layer_2': 65, 'n_units_Layer_3': 100}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.23% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.70 | sMAPE for Test Set is: 18.64% | rMAE for Test Set is: 1.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:31:47,115]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:31:52,525]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:31:59,026]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:32:02,248]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:32:07,218]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:32:07,391]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:32:16,550]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:32:16,932]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:32:24,292]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:32:36,122]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:35:22,195]\u001b[0m Trial 1191 finished with value: 1.3927183054456942 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008293818571197345, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027507447589115247, 'dropout_rate_Layer_2': 0.15814001605641004, 'dropout_rate_Layer_3': 0.33096635203073915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0025952426447625656, 'l1_Layer_2': 0.0036915292314775687, 'l1_Layer_3': 1.7026700960669465e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 160, 'n_units_Layer_3': 210}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.39 | sMAPE for Validation Set is: 4.97% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 2.55 | sMAPE for Test Set is: 6.81% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:35:22,740]\u001b[0m Trial 1194 finished with value: 1.4599946173298513 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012838034985326783, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06876515195656466, 'dropout_rate_Layer_2': 0.026196785478858113, 'dropout_rate_Layer_3': 0.017524526025695257, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003988713697759731, 'l1_Layer_2': 0.01202950522901516, 'l1_Layer_3': 0.00506741809726036, 'n_units_Layer_1': 245, 'n_units_Layer_2': 60, 'n_units_Layer_3': 85}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 5.16% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.82 | sMAPE for Test Set is: 21.60% | rMAE for Test Set is: 1.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:35:33,890]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:35:34,001]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:35:41,743]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:35:53,842]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:36:00,940]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:36:05,948]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:36:06,535]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:36:12,131]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:36:23,886]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:36:28,847]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:36:39,076]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:36:43,849]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:37:05,173]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:37:17,786]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:37:24,952]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:37:35,396]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:38:06,339]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:38:13,786]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:38:19,095]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:38:25,694]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:38:33,171]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:38:48,190]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:39:12,651]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:39:18,380]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:39:25,675]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:39:29,572]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:39:34,635]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:39:39,798]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:39:47,017]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:40:08,657]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:40:14,019]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:40:17,173]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:40:24,007]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:40:56,289]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:41:17,123]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:41:23,570]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:41:46,199]\u001b[0m Trial 1229 finished with value: 1.4574723846108775 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005898281151851753, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30611477937747866, 'dropout_rate_Layer_2': 0.000695408057964305, 'dropout_rate_Layer_3': 0.009748376854322439, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012037963207434086, 'l1_Layer_2': 0.0019007161573243293, 'l1_Layer_3': 6.332492300412848e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 130, 'n_units_Layer_3': 295}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 5.17% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.59 | sMAPE for Test Set is: 13.51% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:42:14,019]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:42:18,941]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:42:23,820]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:42:28,308]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:42:31,122]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:42:35,733]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:42:36,062]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:42:42,735]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:42:47,510]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:43:26,875]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:43:38,504]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:43:45,863]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:43:51,544]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:44:48,835]\u001b[0m Trial 1246 finished with value: 1.4647962519354438 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014841335703902497, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28888266677869984, 'dropout_rate_Layer_2': 0.014170931419551301, 'dropout_rate_Layer_3': 0.039266145073671065, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00878851160063434, 'l1_Layer_2': 0.029583586803520252, 'l1_Layer_3': 5.675212090431151e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 130, 'n_units_Layer_3': 285}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 5.19% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.95 | sMAPE for Test Set is: 16.77% | rMAE for Test Set is: 1.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:44:58,639]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:45:48,895]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:45:55,876]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:46:05,709]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:46:10,840]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:46:16,698]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:46:47,380]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:46:52,512]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:47:56,592]\u001b[0m Trial 1255 finished with value: 1.4582762952090647 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015892229408835414, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2817887704803231, 'dropout_rate_Layer_2': 0.008576514623267325, 'dropout_rate_Layer_3': 0.059178466077158286, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00877986172341071, 'l1_Layer_2': 0.05393411869593688, 'l1_Layer_3': 6.479671359887734e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 140, 'n_units_Layer_3': 300}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 5.16% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.22 | sMAPE for Test Set is: 17.44% | rMAE for Test Set is: 1.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:49:31,114]\u001b[0m Trial 1253 finished with value: 1.461301080967461 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009192624461314235, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05157358728049602, 'dropout_rate_Layer_2': 0.052945740160247126, 'dropout_rate_Layer_3': 0.0005246277328233642, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.023270592652041008, 'l1_Layer_2': 0.007134340111029137, 'l1_Layer_3': 0.008914801030890797, 'n_units_Layer_1': 270, 'n_units_Layer_2': 85, 'n_units_Layer_3': 65}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 5.18% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.44 | sMAPE for Test Set is: 20.60% | rMAE for Test Set is: 1.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:49:38,616]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:50:08,178]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:50:15,708]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:50:20,870]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:50:27,851]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:50:34,870]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:50:42,798]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:50:47,568]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:50:52,555]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:50:57,852]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:50:57,870]\u001b[0m Trial 1256 finished with value: 1.4510160077350764 and parameters: {'n_hidden': 3, 'learning_rate': 0.000679948326732661, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02194620984802769, 'dropout_rate_Layer_2': 0.11861401836062133, 'dropout_rate_Layer_3': 0.3153951929873883, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010624838050843993, 'l1_Layer_2': 0.009991741558043986, 'l1_Layer_3': 1.829738629305864e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 180, 'n_units_Layer_3': 235}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.45 | sMAPE for Validation Set is: 5.15% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 2.72 | sMAPE for Test Set is: 7.27% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:51:05,899]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:51:10,925]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:51:15,974]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:51:16,519]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:51:23,666]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:51:28,944]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:51:36,525]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:52:34,019]\u001b[0m Trial 1271 finished with value: 1.4871086504161912 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007444803300127764, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05400179600846143, 'dropout_rate_Layer_2': 0.14731610041441315, 'dropout_rate_Layer_3': 0.2945722801324181, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010353001590192758, 'l1_Layer_2': 0.020742487840316518, 'l1_Layer_3': 6.643640827328927e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 165, 'n_units_Layer_3': 250}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.26% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.73 | sMAPE for Test Set is: 7.28% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:52:54,020]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:53:00,892]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:53:21,522]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:53:26,774]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:53:33,237]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:53:38,579]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:53:50,383]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:53:57,841]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:54:02,898]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:54:08,056]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:55:31,853]\u001b[0m Trial 1286 finished with value: 1.475433461697186 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009060686451585513, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0010435280321725773, 'dropout_rate_Layer_2': 0.15855657982100144, 'dropout_rate_Layer_3': 0.35743095895317023, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.029742401716785438, 'l1_Layer_2': 0.012643916546488124, 'l1_Layer_3': 4.760537015131895e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 185, 'n_units_Layer_3': 235}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.25% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.06 | sMAPE for Test Set is: 8.01% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:55:44,152]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:55:56,197]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:56:03,022]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:56:10,445]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:56:34,867]\u001b[0m Trial 1276 finished with value: 1.4446932550471143 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010788747916455647, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012479319134216911, 'dropout_rate_Layer_2': 0.07474813771524488, 'dropout_rate_Layer_3': 0.008546871458416233, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02416134583032271, 'l1_Layer_2': 0.01277799510175181, 'l1_Layer_3': 0.004187165508201364, 'n_units_Layer_1': 270, 'n_units_Layer_2': 95, 'n_units_Layer_3': 75}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 5.11% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.34 | sMAPE for Test Set is: 15.26% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:56:39,912]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:56:43,188]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:56:50,682]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:57:02,944]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:57:08,135]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:57:18,030]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:57:22,722]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:57:28,351]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:57:35,109]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:57:38,114]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:57:45,424]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:57:48,083]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:57:54,955]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:57:55,395]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:58:01,360]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:58:03,370]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:58:10,618]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:58:15,787]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:58:20,880]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:58:23,236]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:58:35,314]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:59:17,135]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:59:24,123]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:59:29,352]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:59:34,984]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:59:58,863]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:00:28,624]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:00:35,211]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:00:40,556]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:00:47,515]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:00:52,717]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:00:57,794]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:01:02,267]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:01:11,951]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:01:17,672]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:01:24,547]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:01:29,669]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:01:29,772]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:01:36,700]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:01:39,374]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:01:44,017]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:01:48,693]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:02:00,965]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:02:08,224]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:02:13,276]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:02:18,569]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:02:38,550]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:02:53,462]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:02:58,611]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:03:05,246]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:03:40,218]\u001b[0m Trial 1336 finished with value: 1.4621385213827065 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008663827032392925, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017225275312965485, 'dropout_rate_Layer_2': 0.16349474287047158, 'dropout_rate_Layer_3': 0.27266858418631845, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0037843856081813815, 'l1_Layer_2': 0.006222698484907308, 'l1_Layer_3': 4.5026163377604243e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 70, 'n_units_Layer_3': 225}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 5.22% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 2.75 | sMAPE for Test Set is: 7.32% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 15:03:50,140]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:03:55,700]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:04:05,195]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:04:27,203]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:04:32,298]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:04:39,612]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:04:44,725]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:05:44,595]\u001b[0m Trial 1342 finished with value: 1.364214848455326 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005793798511739212, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016275368131135046, 'dropout_rate_Layer_2': 0.2075585855001387, 'dropout_rate_Layer_3': 0.27483900695370267, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002467146365330108, 'l1_Layer_2': 0.003169601679796652, 'l1_Layer_3': 5.6443817133106664e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 195, 'n_units_Layer_3': 225}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.36 | sMAPE for Validation Set is: 4.85% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 2.62 | sMAPE for Test Set is: 6.98% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 15:05:51,502]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:05:55,617]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:06:02,180]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:06:07,380]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:06:10,451]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:06:13,000]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:06:18,033]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:06:22,258]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:06:30,285]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:06:45,049]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:06:50,264]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:06:57,023]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:07:04,393]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:07:11,761]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:08:03,901]\u001b[0m Trial 1360 finished with value: 1.4619743596819303 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006175625183416092, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03121253722196498, 'dropout_rate_Layer_2': 0.10666955522672061, 'dropout_rate_Layer_3': 0.2560119313473141, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007731072039034576, 'l1_Layer_2': 0.004932364411094205, 'l1_Layer_3': 5.561538638758219e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 170, 'n_units_Layer_3': 220}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 5.19% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 2.70 | sMAPE for Test Set is: 7.20% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 15:08:10,604]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:08:20,496]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:08:25,584]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:08:35,731]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:08:41,059]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:09:00,345]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:09:03,521]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:09:08,379]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:09:42,527]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:09:47,735]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:09:54,461]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:10:02,216]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:10:08,979]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:10:16,399]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:10:39,521]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:10:41,948]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:10:51,421]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:11:03,729]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:11:08,354]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:11:51,010]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:11:57,921]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:11:59,922]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:12:07,592]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:12:55,997]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:13:02,376]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:13:07,783]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:13:13,315]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:13:18,358]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:13:35,122]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:13:47,320]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:13:54,599]\u001b[0m Trial 1389 finished with value: 1.4124372745625802 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007949853701101315, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01452864348320647, 'dropout_rate_Layer_2': 0.14911642621520352, 'dropout_rate_Layer_3': 0.3066919984399994, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002166873475524009, 'l1_Layer_2': 0.009372292825429797, 'l1_Layer_3': 9.654504220927681e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 195, 'n_units_Layer_3': 230}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.41 | sMAPE for Validation Set is: 5.01% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 2.66 | sMAPE for Test Set is: 7.12% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 15:13:59,296]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:14:09,418]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:14:14,838]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:14:36,385]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:14:43,667]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:14:48,824]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:14:49,119]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:14:55,245]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:15:00,014]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:15:02,396]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:15:07,306]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:15:51,339]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:16:20,773]\u001b[0m Trial 1406 finished with value: 1.403074285917442 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006851116607574872, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3227562002543931, 'dropout_rate_Layer_2': 0.012489011407495865, 'dropout_rate_Layer_3': 0.00459266439237202, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006280728385892169, 'l1_Layer_2': 0.00042450276090548624, 'l1_Layer_3': 2.9574454578426518e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 135, 'n_units_Layer_3': 290}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.40 | sMAPE for Validation Set is: 4.98% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.07 | sMAPE for Test Set is: 14.61% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 15:16:47,793]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:16:52,911]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:18:12,033]\u001b[0m Trial 1410 finished with value: 1.3898297008810985 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011261532962643934, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0006320069003555844, 'dropout_rate_Layer_2': 0.14980053464599963, 'dropout_rate_Layer_3': 0.2474614335982054, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004108344929568892, 'l1_Layer_2': 0.006069989026199978, 'l1_Layer_3': 8.483239557860407e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 190, 'n_units_Layer_3': 215}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.39 | sMAPE for Validation Set is: 4.93% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 2.61 | sMAPE for Test Set is: 6.99% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 15:19:08,031]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:19:28,837]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:19:33,398]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:19:42,836]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:19:48,283]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:20:09,745]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:20:14,978]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:20:24,930]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:20:29,630]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:20:39,232]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:20:57,263]\u001b[0m Trial 1412 finished with value: 1.4229898599273003 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012638823962455566, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03875558733950599, 'dropout_rate_Layer_2': 0.042873366857751234, 'dropout_rate_Layer_3': 0.014197626852912768, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005050899542620193, 'l1_Layer_2': 0.025444081513950476, 'l1_Layer_3': 0.001808905503036584, 'n_units_Layer_1': 260, 'n_units_Layer_2': 60, 'n_units_Layer_3': 70}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.42 | sMAPE for Validation Set is: 5.04% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.38 | sMAPE for Test Set is: 17.85% | rMAE for Test Set is: 1.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 15:21:01,790]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:21:02,113]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:21:10,011]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:21:17,553]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:21:29,852]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:21:37,414]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:21:44,685]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:21:45,273]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:22:34,140]\u001b[0m Trial 1431 finished with value: 1.435965578520542 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014007963122988144, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07818535972884347, 'dropout_rate_Layer_2': 0.1308549290096911, 'dropout_rate_Layer_3': 0.3297934345523204, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00202243017515613, 'l1_Layer_2': 1.7028988857937544e-05, 'l1_Layer_3': 3.7185465735622e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 185, 'n_units_Layer_3': 225}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 5.10% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.10 | sMAPE for Test Set is: 17.17% | rMAE for Test Set is: 1.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 15:22:35,064]\u001b[0m Trial 1432 finished with value: 1.4813631693788523 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009300680060430179, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027226785141834867, 'dropout_rate_Layer_2': 0.17021839606092257, 'dropout_rate_Layer_3': 0.2688836159987523, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001107357111721373, 'l1_Layer_2': 0.0044081963039231285, 'l1_Layer_3': 3.789354634283237e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 210, 'n_units_Layer_3': 225}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.26% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.42 | sMAPE for Test Set is: 15.56% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 15:22:40,611]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:22:59,584]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:23:01,954]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:23:06,716]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:23:09,811]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:23:14,890]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:23:19,112]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:23:24,187]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:23:29,298]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:23:37,134]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:23:43,733]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:23:48,753]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:23:53,956]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:23:59,102]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:24:04,071]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:24:04,175]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:24:13,082]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:24:13,100]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:24:20,853]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:24:20,962]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:24:27,581]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:24:31,935]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:24:37,308]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:25:17,729]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:25:25,141]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:25:30,039]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:25:30,171]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:25:38,434]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:25:38,785]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:25:48,495]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:25:48,639]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:25:57,472]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:25:57,773]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:26:04,055]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:26:05,654]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:26:13,844]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:26:23,690]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.45 | sMAPE for Validation Set is: 5.13% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.76 | sMAPE for Test Set is: 16.35% | rMAE for Test Set is: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 15:27:00,111]\u001b[0m Trial 1468 finished with value: 1.4451175716069826 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008712919253296609, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03639867892686824, 'dropout_rate_Layer_2': 0.15385806576884747, 'dropout_rate_Layer_3': 0.32466994664637533, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00286198221784406, 'l1_Layer_2': 1.0023922824163441e-05, 'l1_Layer_3': 5.298384155308412e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 175, 'n_units_Layer_3': 210}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:27:08,227]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:27:16,036]\u001b[0m Trial 1471 finished with value: 1.4663340926791928 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011483933722985897, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00562186024454854, 'dropout_rate_Layer_2': 0.18240576462226551, 'dropout_rate_Layer_3': 0.3281565120366093, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0030388646711416094, 'l1_Layer_2': 6.634291756205235e-05, 'l1_Layer_3': 3.0459325048475438e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 175, 'n_units_Layer_3': 210}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.22% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.69 | sMAPE for Test Set is: 16.17% | rMAE for Test Set is: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 15:27:17,938]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:27:25,977]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:27:31,048]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:27:35,555]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:27:35,911]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:27:42,261]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:27:47,248]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:27:47,629]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:27:56,552]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:27:57,049]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:28:05,061]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:28:05,233]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:29:24,870]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:29:25,179]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:29:33,046]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:29:33,543]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:29:39,160]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:29:43,451]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:29:48,528]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:29:51,296]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:29:53,658]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:29:59,027]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:30:03,905]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:30:23,370]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:30:28,003]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:30:53,059]\u001b[0m Trial 1494 finished with value: 1.443128581810708 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008774541460536269, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.035898835954239594, 'dropout_rate_Layer_2': 0.13534388688938068, 'dropout_rate_Layer_3': 0.2916799437779428, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001931933957135553, 'l1_Layer_2': 1.9838417588795793e-05, 'l1_Layer_3': 5.0436359666232645e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 160, 'n_units_Layer_3': 215}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 5.13% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.40 | sMAPE for Test Set is: 15.45% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 15:31:04,957]\u001b[0m Trial 1499 finished with value: 1.4688504424574653 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011329921998877064, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37179554460366304, 'dropout_rate_Layer_2': 0.044110574989735064, 'dropout_rate_Layer_3': 0.015702876183554544, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008247590616870436, 'l1_Layer_2': 0.011671397758023276, 'l1_Layer_3': 2.667259875022262e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 300, 'n_units_Layer_3': 275}. Best is trial 1079 with value: 1.3358235728407706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.21% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.16 | sMAPE for Test Set is: 17.31% | rMAE for Test Set is: 1.48\n",
      "for 2018-01-01, MAE is:0.77 & sMAPE is:2.93% & rMAE is:2.32 ||| daily mean of MAE & sMAPE & rMAE till now are :0.77 & 2.93% & 2.32\n",
      "for 2018-01-02, MAE is:5.21 & sMAPE is:16.65% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :2.99 & 9.79% & 1.62\n",
      "for 2018-01-03, MAE is:1.17 & sMAPE is:4.02% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.38 & 7.87% & 1.22\n",
      "WARNING:tensorflow:5 out of the last 28 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000025422637310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-04, MAE is:3.52 & sMAPE is:10.85% & rMAE is:2.36 ||| daily mean of MAE & sMAPE & rMAE till now are :2.67 & 8.61% & 1.50\n",
      "WARNING:tensorflow:6 out of the last 29 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000025427D40160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-05, MAE is:1.84 & sMAPE is:5.84% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :2.50 & 8.06% & 1.35\n",
      "for 2018-01-06, MAE is:1.23 & sMAPE is:3.82% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 7.35% & 1.17\n",
      "for 2018-01-07, MAE is:1.72 & sMAPE is:5.87% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :2.21 & 7.14% & 1.14\n",
      "for 2018-01-08, MAE is:4.02 & sMAPE is:12.11% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 7.76% & 1.08\n",
      "for 2018-01-09, MAE is:1.34 & sMAPE is:4.48% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.31 & 7.40% & 1.01\n",
      "for 2018-01-10, MAE is:9.95 & sMAPE is:25.93% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :3.08 & 9.25% & 1.00\n",
      "for 2018-01-11, MAE is:10.60 & sMAPE is:24.81% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :3.76 & 10.67% & 0.99\n",
      "for 2018-01-12, MAE is:3.87 & sMAPE is:10.36% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :3.77 & 10.64% & 0.98\n",
      "for 2018-01-13, MAE is:1.28 & sMAPE is:4.02% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :3.58 & 10.13% & 1.04\n",
      "for 2018-01-14, MAE is:0.99 & sMAPE is:3.28% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :3.39 & 9.64% & 1.02\n",
      "for 2018-01-15, MAE is:1.17 & sMAPE is:3.88% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.25 & 9.26% & 0.97\n",
      "for 2018-01-16, MAE is:2.76 & sMAPE is:8.27% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.22 & 9.20% & 1.01\n",
      "for 2018-01-17, MAE is:3.29 & sMAPE is:9.32% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.22 & 9.20% & 0.98\n",
      "for 2018-01-18, MAE is:4.89 & sMAPE is:13.76% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :3.31 & 9.46% & 0.96\n",
      "for 2018-01-19, MAE is:7.48 & sMAPE is:19.07% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :3.53 & 9.96% & 1.01\n",
      "for 2018-01-20, MAE is:2.14 & sMAPE is:6.59% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :3.46 & 9.79% & 1.04\n",
      "for 2018-01-21, MAE is:0.79 & sMAPE is:2.49% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 9.45% & 1.01\n",
      "for 2018-01-22, MAE is:8.09 & sMAPE is:21.20% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :3.55 & 9.98% & 1.00\n",
      "for 2018-01-23, MAE is:3.60 & sMAPE is:10.02% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :3.55 & 9.98% & 1.00\n",
      "for 2018-01-24, MAE is:1.58 & sMAPE is:5.45% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.47 & 9.79% & 0.97\n",
      "for 2018-01-25, MAE is:1.83 & sMAPE is:6.21% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :3.41 & 9.65% & 0.94\n",
      "for 2018-01-26, MAE is:2.08 & sMAPE is:6.46% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 9.53% & 0.92\n",
      "for 2018-01-27, MAE is:1.13 & sMAPE is:3.68% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :3.27 & 9.31% & 0.92\n",
      "for 2018-01-28, MAE is:0.57 & sMAPE is:2.00% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :3.18 & 9.05% & 0.89\n",
      "for 2018-01-29, MAE is:0.76 & sMAPE is:2.59% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :3.09 & 8.83% & 0.86\n",
      "for 2018-01-30, MAE is:2.06 & sMAPE is:6.04% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.06 & 8.73% & 0.85\n",
      "for 2018-01-31, MAE is:1.12 & sMAPE is:3.72% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :3.00 & 8.57% & 0.85\n",
      "for 2018-02-01, MAE is:1.81 & sMAPE is:5.95% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.96 & 8.49% & 0.87\n",
      "for 2018-02-02, MAE is:4.91 & sMAPE is:14.00% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.02 & 8.66% & 0.89\n",
      "for 2018-02-03, MAE is:1.61 & sMAPE is:4.54% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :2.98 & 8.54% & 0.88\n",
      "for 2018-02-04, MAE is:1.98 & sMAPE is:5.68% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :2.95 & 8.45% & 0.86\n",
      "for 2018-02-05, MAE is:11.18 & sMAPE is:25.72% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :3.18 & 8.93% & 0.86\n",
      "for 2018-02-06, MAE is:10.58 & sMAPE is:22.50% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :3.38 & 9.30% & 0.86\n",
      "for 2018-02-07, MAE is:9.19 & sMAPE is:19.97% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :3.53 & 9.58% & 0.85\n",
      "for 2018-02-08, MAE is:5.67 & sMAPE is:12.49% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.58 & 9.66% & 0.84\n",
      "for 2018-02-09, MAE is:0.77 & sMAPE is:2.39% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :3.51 & 9.47% & 0.83\n",
      "for 2018-02-10, MAE is:1.20 & sMAPE is:3.78% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.46 & 9.34% & 0.82\n",
      "for 2018-02-11, MAE is:1.38 & sMAPE is:4.52% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.41 & 9.22% & 0.81\n",
      "for 2018-02-12, MAE is:0.76 & sMAPE is:2.35% & rMAE is:0.06 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 9.06% & 0.79\n",
      "for 2018-02-13, MAE is:5.02 & sMAPE is:13.10% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :3.38 & 9.15% & 0.79\n",
      "for 2018-02-14, MAE is:3.56 & sMAPE is:9.33% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :3.39 & 9.16% & 0.78\n",
      "for 2018-02-15, MAE is:1.17 & sMAPE is:3.61% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :3.34 & 9.04% & 0.76\n",
      "for 2018-02-16, MAE is:3.00 & sMAPE is:8.09% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 9.02% & 0.76\n",
      "for 2018-02-17, MAE is:4.65 & sMAPE is:12.46% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :3.36 & 9.09% & 0.76\n",
      "for 2018-02-18, MAE is:1.85 & sMAPE is:4.84% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 9.00% & 0.75\n",
      "for 2018-02-19, MAE is:4.69 & sMAPE is:11.04% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.36 & 9.04% & 0.75\n",
      "for 2018-02-20, MAE is:9.49 & sMAPE is:22.67% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :3.48 & 9.31% & 0.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-02-21, MAE is:4.08 & sMAPE is:9.31% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :3.49 & 9.31% & 0.76\n",
      "for 2018-02-22, MAE is:7.18 & sMAPE is:16.71% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.56 & 9.45% & 0.75\n",
      "for 2018-02-23, MAE is:3.92 & sMAPE is:8.94% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :3.56 & 9.44% & 0.75\n",
      "for 2018-02-24, MAE is:2.14 & sMAPE is:5.75% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :3.54 & 9.37% & 0.75\n",
      "for 2018-02-25, MAE is:2.31 & sMAPE is:6.05% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :3.52 & 9.31% & 0.75\n",
      "for 2018-02-26, MAE is:8.67 & sMAPE is:18.65% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :3.61 & 9.48% & 0.76\n",
      "for 2018-02-27, MAE is:2.44 & sMAPE is:5.92% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.59 & 9.42% & 0.76\n",
      "for 2018-02-28, MAE is:2.62 & sMAPE is:6.32% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :3.57 & 9.36% & 0.76\n",
      "for 2018-03-01, MAE is:2.54 & sMAPE is:6.49% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :3.55 & 9.31% & 0.75\n",
      "for 2018-03-02, MAE is:5.27 & sMAPE is:11.13% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :3.58 & 9.34% & 0.76\n",
      "for 2018-03-03, MAE is:1.96 & sMAPE is:4.74% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.56 & 9.27% & 0.75\n",
      "for 2018-03-04, MAE is:3.12 & sMAPE is:7.87% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.55 & 9.25% & 0.76\n",
      "for 2018-03-05, MAE is:13.29 & sMAPE is:26.26% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :3.70 & 9.51% & 0.78\n",
      "for 2018-03-06, MAE is:8.69 & sMAPE is:17.93% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :3.78 & 9.64% & 0.78\n",
      "for 2018-03-07, MAE is:7.86 & sMAPE is:16.92% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :3.84 & 9.75% & 0.79\n",
      "for 2018-03-08, MAE is:1.81 & sMAPE is:4.41% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :3.81 & 9.67% & 0.79\n",
      "for 2018-03-09, MAE is:3.54 & sMAPE is:8.74% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :3.81 & 9.66% & 0.79\n",
      "for 2018-03-10, MAE is:1.37 & sMAPE is:3.59% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.77 & 9.57% & 0.78\n",
      "for 2018-03-11, MAE is:0.76 & sMAPE is:2.11% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :3.73 & 9.47% & 0.77\n",
      "for 2018-03-12, MAE is:6.03 & sMAPE is:14.58% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :3.76 & 9.54% & 0.77\n",
      "for 2018-03-13, MAE is:3.19 & sMAPE is:7.72% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 9.51% & 0.77\n",
      "for 2018-03-14, MAE is:9.27 & sMAPE is:19.84% & rMAE is:6.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.83 & 9.65% & 0.84\n",
      "for 2018-03-15, MAE is:1.29 & sMAPE is:3.41% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :3.79 & 9.57% & 0.84\n",
      "for 2018-03-16, MAE is:0.96 & sMAPE is:2.51% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :3.76 & 9.48% & 0.83\n",
      "for 2018-03-17, MAE is:0.89 & sMAPE is:2.39% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :3.72 & 9.38% & 0.83\n",
      "for 2018-03-18, MAE is:1.14 & sMAPE is:3.04% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 9.30% & 0.83\n",
      "for 2018-03-19, MAE is:5.43 & sMAPE is:12.84% & rMAE is:2.66 ||| daily mean of MAE & sMAPE & rMAE till now are :3.71 & 9.35% & 0.86\n",
      "for 2018-03-20, MAE is:5.17 & sMAPE is:11.79% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :3.72 & 9.38% & 0.87\n",
      "for 2018-03-21, MAE is:3.35 & sMAPE is:8.00% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.72 & 9.36% & 0.86\n",
      "for 2018-03-22, MAE is:3.10 & sMAPE is:7.90% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.71 & 9.34% & 0.87\n",
      "for 2018-03-23, MAE is:4.77 & sMAPE is:10.75% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :3.73 & 9.36% & 0.87\n",
      "for 2018-03-24, MAE is:1.81 & sMAPE is:4.53% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :3.70 & 9.30% & 0.87\n",
      "for 2018-03-25, MAE is:1.79 & sMAPE is:4.55% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 9.24% & 0.87\n",
      "for 2018-03-26, MAE is:8.42 & sMAPE is:18.13% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.74 & 9.35% & 0.88\n",
      "for 2018-03-27, MAE is:5.30 & sMAPE is:11.32% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 9.37% & 0.88\n",
      "for 2018-03-28, MAE is:1.06 & sMAPE is:2.74% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :3.72 & 9.29% & 0.87\n",
      "for 2018-03-29, MAE is:2.72 & sMAPE is:6.91% & rMAE is:3.06 ||| daily mean of MAE & sMAPE & rMAE till now are :3.71 & 9.27% & 0.90\n",
      "for 2018-03-30, MAE is:0.82 & sMAPE is:2.03% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 9.19% & 0.89\n",
      "for 2018-03-31, MAE is:1.55 & sMAPE is:3.96% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :3.66 & 9.13% & 0.89\n",
      "for 2018-04-01, MAE is:1.09 & sMAPE is:2.83% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :3.63 & 9.06% & 0.89\n",
      "for 2018-04-02, MAE is:1.32 & sMAPE is:3.38% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :3.60 & 9.00% & 0.88\n",
      "for 2018-04-03, MAE is:3.04 & sMAPE is:7.32% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :3.60 & 8.98% & 0.88\n",
      "for 2018-04-04, MAE is:3.06 & sMAPE is:7.21% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :3.59 & 8.96% & 0.88\n",
      "for 2018-04-05, MAE is:2.67 & sMAPE is:6.67% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :3.58 & 8.94% & 0.89\n",
      "for 2018-04-06, MAE is:2.24 & sMAPE is:5.51% & rMAE is:2.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.57 & 8.90% & 0.91\n",
      "for 2018-04-07, MAE is:1.32 & sMAPE is:3.45% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :3.54 & 8.84% & 0.92\n",
      "for 2018-04-08, MAE is:1.49 & sMAPE is:3.82% & rMAE is:2.37 ||| daily mean of MAE & sMAPE & rMAE till now are :3.52 & 8.79% & 0.93\n",
      "for 2018-04-09, MAE is:4.36 & sMAPE is:9.96% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :3.53 & 8.80% & 0.93\n",
      "for 2018-04-10, MAE is:0.94 & sMAPE is:2.42% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.51 & 8.74% & 0.93\n",
      "for 2018-04-11, MAE is:1.29 & sMAPE is:3.35% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.48 & 8.69% & 0.92\n",
      "for 2018-04-12, MAE is:1.12 & sMAPE is:2.88% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :3.46 & 8.63% & 0.92\n",
      "for 2018-04-13, MAE is:1.76 & sMAPE is:4.54% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :3.44 & 8.59% & 0.93\n",
      "for 2018-04-14, MAE is:1.96 & sMAPE is:5.09% & rMAE is:2.81 ||| daily mean of MAE & sMAPE & rMAE till now are :3.43 & 8.56% & 0.94\n",
      "for 2018-04-15, MAE is:2.10 & sMAPE is:5.41% & rMAE is:5.94 ||| daily mean of MAE & sMAPE & rMAE till now are :3.42 & 8.53% & 0.99\n",
      "for 2018-04-16, MAE is:5.49 & sMAPE is:12.66% & rMAE is:3.32 ||| daily mean of MAE & sMAPE & rMAE till now are :3.44 & 8.57% & 1.01\n",
      "for 2018-04-17, MAE is:2.53 & sMAPE is:6.13% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :3.43 & 8.54% & 1.01\n",
      "for 2018-04-18, MAE is:3.11 & sMAPE is:7.25% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :3.42 & 8.53% & 1.01\n",
      "for 2018-04-19, MAE is:3.05 & sMAPE is:7.60% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :3.42 & 8.52% & 1.01\n",
      "for 2018-04-20, MAE is:1.88 & sMAPE is:5.21% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :3.41 & 8.49% & 1.01\n",
      "for 2018-04-21, MAE is:3.25 & sMAPE is:10.26% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.41 & 8.51% & 1.00\n",
      "for 2018-04-22, MAE is:2.10 & sMAPE is:6.08% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.39 & 8.49% & 1.00\n",
      "for 2018-04-23, MAE is:2.89 & sMAPE is:8.89% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.39 & 8.49% & 0.99\n",
      "for 2018-04-24, MAE is:1.66 & sMAPE is:5.07% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :3.37 & 8.46% & 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-04-25, MAE is:1.30 & sMAPE is:3.55% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :3.36 & 8.42% & 0.98\n",
      "for 2018-04-26, MAE is:1.57 & sMAPE is:4.31% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :3.34 & 8.38% & 0.97\n",
      "for 2018-04-27, MAE is:1.57 & sMAPE is:4.24% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 8.35% & 0.98\n",
      "for 2018-04-28, MAE is:0.93 & sMAPE is:2.63% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :3.31 & 8.30% & 0.98\n",
      "for 2018-04-29, MAE is:0.60 & sMAPE is:1.70% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.28 & 8.24% & 0.97\n",
      "for 2018-04-30, MAE is:3.50 & sMAPE is:11.14% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :3.28 & 8.27% & 0.97\n",
      "for 2018-05-01, MAE is:2.61 & sMAPE is:8.66% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.28 & 8.27% & 0.97\n",
      "for 2018-05-02, MAE is:5.24 & sMAPE is:14.99% & rMAE is:5.37 ||| daily mean of MAE & sMAPE & rMAE till now are :3.30 & 8.33% & 1.00\n",
      "for 2018-05-03, MAE is:1.71 & sMAPE is:4.74% & rMAE is:2.45 ||| daily mean of MAE & sMAPE & rMAE till now are :3.28 & 8.30% & 1.02\n",
      "for 2018-05-04, MAE is:1.84 & sMAPE is:5.01% & rMAE is:2.72 ||| daily mean of MAE & sMAPE & rMAE till now are :3.27 & 8.27% & 1.03\n",
      "for 2018-05-05, MAE is:3.00 & sMAPE is:9.34% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :3.27 & 8.28% & 1.03\n",
      "for 2018-05-06, MAE is:8.33 & sMAPE is:32.27% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :3.31 & 8.47% & 1.03\n",
      "for 2018-05-07, MAE is:6.04 & sMAPE is:21.60% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 8.57% & 1.03\n",
      "for 2018-05-08, MAE is:5.95 & sMAPE is:21.88% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 8.68% & 1.03\n",
      "for 2018-05-09, MAE is:6.63 & sMAPE is:30.53% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :3.38 & 8.85% & 1.03\n",
      "for 2018-05-10, MAE is:7.68 & sMAPE is:57.78% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :3.41 & 9.22% & 1.02\n",
      "for 2018-05-11, MAE is:13.30 & sMAPE is:67.64% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.48 & 9.67% & 1.03\n",
      "for 2018-05-12, MAE is:2.75 & sMAPE is:9.29% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :3.48 & 9.67% & 1.03\n",
      "for 2018-05-13, MAE is:7.82 & sMAPE is:37.72% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :3.51 & 9.88% & 1.03\n",
      "for 2018-05-14, MAE is:12.35 & sMAPE is:43.65% & rMAE is:4.95 ||| daily mean of MAE & sMAPE & rMAE till now are :3.58 & 10.13% & 1.06\n",
      "for 2018-05-15, MAE is:2.34 & sMAPE is:6.85% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :3.57 & 10.10% & 1.06\n",
      "for 2018-05-16, MAE is:2.90 & sMAPE is:8.74% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :3.56 & 10.09% & 1.05\n",
      "for 2018-05-17, MAE is:7.57 & sMAPE is:33.36% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :3.59 & 10.26% & 1.05\n",
      "for 2018-05-18, MAE is:7.81 & sMAPE is:32.33% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :3.62 & 10.42% & 1.05\n",
      "for 2018-05-19, MAE is:2.29 & sMAPE is:6.66% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :3.61 & 10.40% & 1.05\n",
      "for 2018-05-20, MAE is:7.37 & sMAPE is:27.07% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 10.52% & 1.05\n",
      "for 2018-05-21, MAE is:10.26 & sMAPE is:38.52% & rMAE is:3.14 ||| daily mean of MAE & sMAPE & rMAE till now are :3.69 & 10.71% & 1.06\n",
      "for 2018-05-22, MAE is:7.35 & sMAPE is:20.74% & rMAE is:2.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.71 & 10.78% & 1.07\n",
      "for 2018-05-23, MAE is:3.31 & sMAPE is:8.55% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :3.71 & 10.77% & 1.07\n",
      "for 2018-05-24, MAE is:2.90 & sMAPE is:7.63% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.70 & 10.75% & 1.06\n",
      "for 2018-05-25, MAE is:3.33 & sMAPE is:8.69% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.70 & 10.73% & 1.06\n",
      "for 2018-05-26, MAE is:2.69 & sMAPE is:6.99% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :3.70 & 10.71% & 1.05\n",
      "for 2018-05-27, MAE is:2.16 & sMAPE is:5.73% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :3.69 & 10.67% & 1.05\n",
      "for 2018-05-28, MAE is:3.44 & sMAPE is:9.04% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 10.66% & 1.04\n",
      "for 2018-05-29, MAE is:3.74 & sMAPE is:9.24% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 10.65% & 1.05\n",
      "for 2018-05-30, MAE is:3.45 & sMAPE is:8.66% & rMAE is:2.27 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 10.64% & 1.05\n",
      "for 2018-05-31, MAE is:2.98 & sMAPE is:7.19% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 10.62% & 1.05\n",
      "for 2018-06-01, MAE is:3.86 & sMAPE is:9.35% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 10.61% & 1.05\n",
      "for 2018-06-02, MAE is:2.78 & sMAPE is:6.80% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 10.58% & 1.05\n",
      "for 2018-06-03, MAE is:3.71 & sMAPE is:9.09% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 10.57% & 1.05\n",
      "for 2018-06-04, MAE is:5.21 & sMAPE is:12.72% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 10.59% & 1.05\n",
      "for 2018-06-05, MAE is:5.41 & sMAPE is:12.53% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :3.69 & 10.60% & 1.06\n",
      "for 2018-06-06, MAE is:6.31 & sMAPE is:14.49% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :3.71 & 10.63% & 1.06\n",
      "for 2018-06-07, MAE is:6.30 & sMAPE is:14.15% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :3.73 & 10.65% & 1.06\n",
      "for 2018-06-08, MAE is:5.21 & sMAPE is:11.37% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :3.74 & 10.65% & 1.06\n",
      "for 2018-06-09, MAE is:5.16 & sMAPE is:11.83% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 10.66% & 1.06\n",
      "for 2018-06-10, MAE is:3.38 & sMAPE is:7.55% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :3.74 & 10.64% & 1.06\n",
      "for 2018-06-11, MAE is:5.98 & sMAPE is:13.68% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.76 & 10.66% & 1.06\n",
      "for 2018-06-12, MAE is:4.85 & sMAPE is:10.81% & rMAE is:4.37 ||| daily mean of MAE & sMAPE & rMAE till now are :3.76 & 10.66% & 1.08\n",
      "for 2018-06-13, MAE is:5.39 & sMAPE is:12.12% & rMAE is:7.83 ||| daily mean of MAE & sMAPE & rMAE till now are :3.77 & 10.67% & 1.12\n",
      "for 2018-06-14, MAE is:5.22 & sMAPE is:11.90% & rMAE is:2.50 ||| daily mean of MAE & sMAPE & rMAE till now are :3.78 & 10.68% & 1.13\n",
      "for 2018-06-15, MAE is:4.72 & sMAPE is:10.92% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :3.79 & 10.68% & 1.13\n",
      "for 2018-06-16, MAE is:3.72 & sMAPE is:8.89% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :3.79 & 10.67% & 1.14\n",
      "for 2018-06-17, MAE is:2.91 & sMAPE is:6.97% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :3.78 & 10.64% & 1.14\n",
      "for 2018-06-18, MAE is:3.46 & sMAPE is:8.06% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :3.78 & 10.63% & 1.14\n",
      "for 2018-06-19, MAE is:2.67 & sMAPE is:6.43% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :3.77 & 10.60% & 1.13\n",
      "for 2018-06-20, MAE is:2.54 & sMAPE is:6.01% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :3.77 & 10.58% & 1.13\n",
      "for 2018-06-21, MAE is:3.50 & sMAPE is:8.50% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :3.77 & 10.57% & 1.13\n",
      "for 2018-06-22, MAE is:3.00 & sMAPE is:7.49% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :3.76 & 10.55% & 1.13\n",
      "for 2018-06-23, MAE is:2.54 & sMAPE is:6.36% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 10.52% & 1.13\n",
      "for 2018-06-24, MAE is:3.49 & sMAPE is:8.42% & rMAE is:2.54 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 10.51% & 1.13\n",
      "for 2018-06-25, MAE is:5.54 & sMAPE is:12.94% & rMAE is:3.81 ||| daily mean of MAE & sMAPE & rMAE till now are :3.76 & 10.53% & 1.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-06-26, MAE is:5.92 & sMAPE is:13.67% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.77 & 10.54% & 1.15\n",
      "for 2018-06-27, MAE is:5.62 & sMAPE is:12.68% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :3.78 & 10.56% & 1.15\n",
      "for 2018-06-28, MAE is:4.81 & sMAPE is:10.70% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :3.79 & 10.56% & 1.15\n",
      "for 2018-06-29, MAE is:5.91 & sMAPE is:13.44% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :3.80 & 10.57% & 1.15\n",
      "for 2018-06-30, MAE is:5.57 & sMAPE is:12.76% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :3.81 & 10.58% & 1.15\n",
      "for 2018-07-01, MAE is:5.49 & sMAPE is:12.74% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :3.82 & 10.60% & 1.16\n",
      "for 2018-07-02, MAE is:7.99 & sMAPE is:17.52% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :3.84 & 10.63% & 1.16\n",
      "for 2018-07-03, MAE is:7.35 & sMAPE is:15.78% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :3.86 & 10.66% & 1.16\n",
      "for 2018-07-04, MAE is:7.48 & sMAPE is:15.90% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :3.88 & 10.69% & 1.17\n",
      "for 2018-07-05, MAE is:7.42 & sMAPE is:15.64% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 10.72% & 1.17\n",
      "for 2018-07-06, MAE is:6.60 & sMAPE is:14.20% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 10.74% & 1.18\n",
      "for 2018-07-07, MAE is:5.56 & sMAPE is:12.29% & rMAE is:3.02 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 10.74% & 1.19\n",
      "for 2018-07-08, MAE is:6.50 & sMAPE is:14.14% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :3.94 & 10.76% & 1.19\n",
      "for 2018-07-09, MAE is:7.06 & sMAPE is:15.11% & rMAE is:10.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 10.78% & 1.24\n",
      "for 2018-07-10, MAE is:8.42 & sMAPE is:17.94% & rMAE is:9.21 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 10.82% & 1.28\n",
      "for 2018-07-11, MAE is:9.42 & sMAPE is:20.06% & rMAE is:9.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 10.87% & 1.32\n",
      "for 2018-07-12, MAE is:9.24 & sMAPE is:19.50% & rMAE is:9.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 10.92% & 1.37\n",
      "for 2018-07-13, MAE is:10.25 & sMAPE is:21.45% & rMAE is:3.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 10.97% & 1.38\n",
      "for 2018-07-14, MAE is:8.62 & sMAPE is:18.17% & rMAE is:2.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 11.01% & 1.38\n",
      "for 2018-07-15, MAE is:8.69 & sMAPE is:18.34% & rMAE is:3.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 11.04% & 1.39\n",
      "for 2018-07-16, MAE is:8.11 & sMAPE is:16.53% & rMAE is:2.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 11.07% & 1.40\n",
      "for 2018-07-17, MAE is:8.67 & sMAPE is:17.93% & rMAE is:5.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 11.11% & 1.42\n",
      "for 2018-07-18, MAE is:8.30 & sMAPE is:17.23% & rMAE is:8.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 11.14% & 1.46\n",
      "for 2018-07-19, MAE is:8.90 & sMAPE is:18.53% & rMAE is:7.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 11.17% & 1.48\n",
      "for 2018-07-20, MAE is:9.60 & sMAPE is:19.74% & rMAE is:13.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 11.22% & 1.55\n",
      "for 2018-07-21, MAE is:9.23 & sMAPE is:19.11% & rMAE is:7.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 11.26% & 1.58\n",
      "for 2018-07-22, MAE is:8.83 & sMAPE is:18.28% & rMAE is:8.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.27 & 11.29% & 1.61\n",
      "for 2018-07-23, MAE is:10.34 & sMAPE is:21.08% & rMAE is:8.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 11.34% & 1.65\n",
      "for 2018-07-24, MAE is:10.82 & sMAPE is:22.19% & rMAE is:6.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 11.39% & 1.67\n",
      "for 2018-07-25, MAE is:10.95 & sMAPE is:22.55% & rMAE is:5.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 11.45% & 1.69\n",
      "for 2018-07-26, MAE is:9.20 & sMAPE is:18.83% & rMAE is:6.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 11.48% & 1.71\n",
      "for 2018-07-27, MAE is:9.57 & sMAPE is:19.75% & rMAE is:21.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 11.52% & 1.81\n",
      "for 2018-07-28, MAE is:6.43 & sMAPE is:13.47% & rMAE is:2.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 11.53% & 1.82\n",
      "for 2018-07-29, MAE is:8.47 & sMAPE is:18.22% & rMAE is:3.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 11.56% & 1.82\n",
      "for 2018-07-30, MAE is:7.87 & sMAPE is:16.08% & rMAE is:5.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 11.58% & 1.84\n",
      "for 2018-07-31, MAE is:8.70 & sMAPE is:17.84% & rMAE is:8.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 11.61% & 1.87\n",
      "for 2018-08-01, MAE is:9.13 & sMAPE is:18.65% & rMAE is:13.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 11.65% & 1.92\n",
      "for 2018-08-02, MAE is:9.49 & sMAPE is:19.59% & rMAE is:17.13 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 11.68% & 2.00\n",
      "for 2018-08-03, MAE is:8.42 & sMAPE is:17.08% & rMAE is:11.09 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 11.71% & 2.04\n",
      "for 2018-08-04, MAE is:6.54 & sMAPE is:13.49% & rMAE is:4.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 11.72% & 2.05\n",
      "for 2018-08-05, MAE is:6.39 & sMAPE is:13.71% & rMAE is:3.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 11.73% & 2.06\n",
      "for 2018-08-06, MAE is:8.74 & sMAPE is:18.22% & rMAE is:14.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 11.76% & 2.12\n",
      "for 2018-08-07, MAE is:8.36 & sMAPE is:17.34% & rMAE is:7.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 11.78% & 2.14\n",
      "for 2018-08-08, MAE is:6.44 & sMAPE is:13.36% & rMAE is:2.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 11.79% & 2.14\n",
      "for 2018-08-09, MAE is:7.56 & sMAPE is:15.93% & rMAE is:3.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 11.81% & 2.15\n",
      "for 2018-08-10, MAE is:4.11 & sMAPE is:8.79% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 11.79% & 2.14\n",
      "for 2018-08-11, MAE is:4.08 & sMAPE is:8.83% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 11.78% & 2.14\n",
      "for 2018-08-12, MAE is:3.76 & sMAPE is:8.41% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 11.76% & 2.13\n",
      "for 2018-08-13, MAE is:7.11 & sMAPE is:15.51% & rMAE is:2.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 11.78% & 2.13\n",
      "for 2018-08-14, MAE is:6.78 & sMAPE is:14.58% & rMAE is:2.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 11.79% & 2.13\n",
      "for 2018-08-15, MAE is:7.16 & sMAPE is:15.38% & rMAE is:4.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 11.81% & 2.15\n",
      "for 2018-08-16, MAE is:7.19 & sMAPE is:15.39% & rMAE is:5.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 11.83% & 2.16\n",
      "for 2018-08-17, MAE is:6.46 & sMAPE is:13.85% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 11.83% & 2.16\n",
      "for 2018-08-18, MAE is:4.92 & sMAPE is:10.89% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 11.83% & 2.16\n",
      "for 2018-08-19, MAE is:3.78 & sMAPE is:8.50% & rMAE is:2.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 11.82% & 2.16\n",
      "for 2018-08-20, MAE is:6.23 & sMAPE is:13.36% & rMAE is:8.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 11.82% & 2.19\n",
      "for 2018-08-21, MAE is:6.28 & sMAPE is:13.44% & rMAE is:11.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 11.83% & 2.23\n",
      "for 2018-08-22, MAE is:4.95 & sMAPE is:10.56% & rMAE is:3.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 11.82% & 2.23\n",
      "for 2018-08-23, MAE is:7.50 & sMAPE is:16.11% & rMAE is:10.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 11.84% & 2.27\n",
      "for 2018-08-24, MAE is:6.24 & sMAPE is:13.25% & rMAE is:6.09 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 11.85% & 2.29\n",
      "for 2018-08-25, MAE is:6.01 & sMAPE is:12.64% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 11.85% & 2.28\n",
      "for 2018-08-26, MAE is:6.88 & sMAPE is:14.70% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 11.86% & 2.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-08-27, MAE is:6.74 & sMAPE is:14.62% & rMAE is:2.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 11.88% & 2.28\n",
      "for 2018-08-28, MAE is:10.60 & sMAPE is:21.52% & rMAE is:2.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 11.92% & 2.28\n",
      "for 2018-08-29, MAE is:10.87 & sMAPE is:21.47% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 11.95% & 2.28\n",
      "for 2018-08-30, MAE is:8.86 & sMAPE is:17.71% & rMAE is:2.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 11.98% & 2.28\n",
      "for 2018-08-31, MAE is:11.59 & sMAPE is:22.52% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 12.02% & 2.28\n",
      "for 2018-09-01, MAE is:11.62 & sMAPE is:22.60% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.84 & 12.07% & 2.28\n",
      "for 2018-09-02, MAE is:9.75 & sMAPE is:18.94% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 12.09% & 2.27\n",
      "for 2018-09-03, MAE is:12.51 & sMAPE is:23.94% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 12.14% & 2.27\n",
      "for 2018-09-04, MAE is:10.97 & sMAPE is:20.92% & rMAE is:3.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 12.18% & 2.27\n",
      "for 2018-09-05, MAE is:12.47 & sMAPE is:23.71% & rMAE is:4.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 12.22% & 2.28\n",
      "for 2018-09-06, MAE is:12.17 & sMAPE is:23.25% & rMAE is:3.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 12.27% & 2.29\n",
      "for 2018-09-07, MAE is:9.98 & sMAPE is:19.06% & rMAE is:9.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 12.30% & 2.31\n",
      "for 2018-09-08, MAE is:8.42 & sMAPE is:16.75% & rMAE is:2.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 12.31% & 2.32\n",
      "for 2018-09-09, MAE is:7.44 & sMAPE is:14.83% & rMAE is:2.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 12.32% & 2.32\n",
      "for 2018-09-10, MAE is:9.82 & sMAPE is:19.29% & rMAE is:3.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 12.35% & 2.32\n",
      "for 2018-09-11, MAE is:6.35 & sMAPE is:12.90% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 12.35% & 2.32\n",
      "for 2018-09-12, MAE is:7.27 & sMAPE is:14.86% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 12.36% & 2.31\n",
      "for 2018-09-13, MAE is:9.23 & sMAPE is:18.82% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 12.39% & 2.31\n",
      "for 2018-09-14, MAE is:8.60 & sMAPE is:17.62% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 12.41% & 2.31\n",
      "for 2018-09-15, MAE is:3.79 & sMAPE is:8.05% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 12.39% & 2.31\n",
      "for 2018-09-16, MAE is:3.41 & sMAPE is:7.69% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 12.37% & 2.30\n",
      "for 2018-09-17, MAE is:6.50 & sMAPE is:13.87% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 12.38% & 2.29\n",
      "for 2018-09-18, MAE is:2.52 & sMAPE is:5.62% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 12.35% & 2.29\n",
      "for 2018-09-19, MAE is:2.61 & sMAPE is:6.17% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 12.33% & 2.28\n",
      "for 2018-09-20, MAE is:4.07 & sMAPE is:10.12% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 12.32% & 2.27\n",
      "for 2018-09-21, MAE is:6.21 & sMAPE is:20.24% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 12.35% & 2.26\n",
      "for 2018-09-22, MAE is:10.26 & sMAPE is:54.18% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 12.51% & 2.26\n",
      "for 2018-09-23, MAE is:9.85 & sMAPE is:33.50% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.09 & 12.59% & 2.25\n",
      "for 2018-09-24, MAE is:7.13 & sMAPE is:27.32% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 12.64% & 2.25\n",
      "for 2018-09-25, MAE is:2.43 & sMAPE is:6.44% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.09 & 12.62% & 2.24\n",
      "for 2018-09-26, MAE is:8.31 & sMAPE is:32.35% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 12.69% & 2.23\n",
      "for 2018-09-27, MAE is:7.08 & sMAPE is:23.04% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 12.73% & 2.23\n",
      "for 2018-09-28, MAE is:5.60 & sMAPE is:14.93% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 12.74% & 2.22\n",
      "for 2018-09-29, MAE is:5.21 & sMAPE is:14.50% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 12.75% & 2.22\n",
      "for 2018-09-30, MAE is:6.39 & sMAPE is:19.39% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 12.77% & 2.21\n",
      "for 2018-10-01, MAE is:6.91 & sMAPE is:16.45% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 12.78% & 2.21\n",
      "for 2018-10-02, MAE is:4.35 & sMAPE is:9.92% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 12.77% & 2.20\n",
      "for 2018-10-03, MAE is:3.25 & sMAPE is:7.32% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 12.75% & 2.19\n",
      "for 2018-10-04, MAE is:4.50 & sMAPE is:9.90% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 12.74% & 2.19\n",
      "for 2018-10-05, MAE is:3.70 & sMAPE is:8.27% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 12.73% & 2.18\n",
      "for 2018-10-06, MAE is:3.91 & sMAPE is:8.75% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 12.71% & 2.17\n",
      "for 2018-10-07, MAE is:3.38 & sMAPE is:7.59% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 12.69% & 2.17\n",
      "for 2018-10-08, MAE is:2.59 & sMAPE is:5.75% & rMAE is:2.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.09 & 12.67% & 2.17\n",
      "for 2018-10-09, MAE is:1.68 & sMAPE is:3.92% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 12.64% & 2.16\n",
      "for 2018-10-10, MAE is:2.17 & sMAPE is:5.09% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 12.61% & 2.16\n",
      "for 2018-10-11, MAE is:2.43 & sMAPE is:6.38% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 12.59% & 2.15\n",
      "for 2018-10-12, MAE is:2.14 & sMAPE is:5.24% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 12.56% & 2.15\n",
      "for 2018-10-13, MAE is:6.22 & sMAPE is:18.71% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 12.59% & 2.14\n",
      "for 2018-10-14, MAE is:15.00 & sMAPE is:75.72% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.09 & 12.81% & 2.14\n",
      "for 2018-10-15, MAE is:17.44 & sMAPE is:68.34% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.13 & 13.00% & 2.13\n",
      "for 2018-10-16, MAE is:5.60 & sMAPE is:14.42% & rMAE is:2.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.13 & 13.00% & 2.13\n",
      "for 2018-10-17, MAE is:2.00 & sMAPE is:5.19% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 12.98% & 2.13\n",
      "for 2018-10-18, MAE is:1.54 & sMAPE is:3.85% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 12.95% & 2.12\n",
      "for 2018-10-19, MAE is:0.99 & sMAPE is:2.53% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.09 & 12.91% & 2.12\n",
      "for 2018-10-20, MAE is:2.23 & sMAPE is:5.69% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 12.88% & 2.11\n",
      "for 2018-10-21, MAE is:2.65 & sMAPE is:6.76% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 12.86% & 2.10\n",
      "for 2018-10-22, MAE is:5.22 & sMAPE is:15.64% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 12.87% & 2.10\n",
      "for 2018-10-23, MAE is:5.31 & sMAPE is:18.21% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 12.89% & 2.10\n",
      "for 2018-10-24, MAE is:5.85 & sMAPE is:14.50% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 12.90% & 2.09\n",
      "for 2018-10-25, MAE is:3.83 & sMAPE is:8.89% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 12.88% & 2.09\n",
      "for 2018-10-26, MAE is:5.38 & sMAPE is:12.13% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 12.88% & 2.09\n",
      "for 2018-10-27, MAE is:1.74 & sMAPE is:3.94% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 12.85% & 2.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-10-28, MAE is:2.10 & sMAPE is:4.80% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 12.82% & 2.08\n",
      "for 2018-10-29, MAE is:2.47 & sMAPE is:5.55% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 12.80% & 2.07\n",
      "for 2018-10-30, MAE is:1.65 & sMAPE is:3.83% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 12.77% & 2.06\n",
      "for 2018-10-31, MAE is:2.65 & sMAPE is:6.26% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 12.75% & 2.06\n",
      "for 2018-11-01, MAE is:3.89 & sMAPE is:9.15% & rMAE is:2.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 12.74% & 2.07\n",
      "for 2018-11-02, MAE is:2.17 & sMAPE is:4.99% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 12.71% & 2.06\n",
      "for 2018-11-03, MAE is:2.46 & sMAPE is:5.81% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 12.69% & 2.06\n",
      "for 2018-11-04, MAE is:2.49 & sMAPE is:5.92% & rMAE is:2.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 12.67% & 2.06\n",
      "for 2018-11-05, MAE is:3.40 & sMAPE is:7.74% & rMAE is:2.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 12.65% & 2.06\n",
      "for 2018-11-06, MAE is:4.80 & sMAPE is:10.55% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 12.64% & 2.06\n",
      "for 2018-11-07, MAE is:3.48 & sMAPE is:7.83% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 12.63% & 2.06\n",
      "for 2018-11-08, MAE is:3.43 & sMAPE is:7.65% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.98 & 12.61% & 2.06\n",
      "for 2018-11-09, MAE is:3.19 & sMAPE is:7.22% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.98 & 12.60% & 2.06\n",
      "for 2018-11-10, MAE is:1.03 & sMAPE is:2.43% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 12.56% & 2.05\n",
      "for 2018-11-11, MAE is:1.75 & sMAPE is:4.35% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 12.54% & 2.05\n",
      "for 2018-11-12, MAE is:5.01 & sMAPE is:11.48% & rMAE is:3.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 12.53% & 2.05\n",
      "for 2018-11-13, MAE is:5.35 & sMAPE is:11.69% & rMAE is:6.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 12.53% & 2.07\n",
      "for 2018-11-14, MAE is:5.94 & sMAPE is:12.82% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 12.53% & 2.06\n",
      "for 2018-11-15, MAE is:3.52 & sMAPE is:7.74% & rMAE is:4.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 12.52% & 2.07\n",
      "for 2018-11-16, MAE is:3.42 & sMAPE is:7.59% & rMAE is:3.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 12.50% & 2.08\n",
      "for 2018-11-17, MAE is:3.57 & sMAPE is:8.00% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 12.49% & 2.07\n",
      "for 2018-11-18, MAE is:3.59 & sMAPE is:7.83% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 12.47% & 2.07\n",
      "for 2018-11-19, MAE is:4.94 & sMAPE is:10.29% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 12.47% & 2.07\n",
      "for 2018-11-20, MAE is:4.30 & sMAPE is:9.18% & rMAE is:4.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 12.46% & 2.07\n",
      "for 2018-11-21, MAE is:5.89 & sMAPE is:11.95% & rMAE is:2.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 12.46% & 2.07\n",
      "for 2018-11-22, MAE is:7.62 & sMAPE is:15.60% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 12.46% & 2.07\n",
      "for 2018-11-23, MAE is:6.36 & sMAPE is:12.74% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 12.47% & 2.07\n",
      "for 2018-11-24, MAE is:3.96 & sMAPE is:8.45% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 12.45% & 2.07\n",
      "for 2018-11-25, MAE is:3.41 & sMAPE is:7.15% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 12.44% & 2.07\n",
      "for 2018-11-26, MAE is:19.62 & sMAPE is:30.69% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 12.49% & 2.06\n",
      "for 2018-11-27, MAE is:14.26 & sMAPE is:21.97% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 12.52% & 2.06\n",
      "for 2018-11-28, MAE is:4.23 & sMAPE is:8.30% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 12.51% & 2.06\n",
      "for 2018-11-29, MAE is:2.28 & sMAPE is:4.90% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 12.49% & 2.05\n",
      "for 2018-11-30, MAE is:2.08 & sMAPE is:4.51% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 12.46% & 2.05\n",
      "for 2018-12-01, MAE is:3.45 & sMAPE is:7.74% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 12.45% & 2.04\n",
      "for 2018-12-02, MAE is:2.24 & sMAPE is:5.09% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 12.43% & 2.04\n",
      "for 2018-12-03, MAE is:2.78 & sMAPE is:5.91% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.98 & 12.41% & 2.03\n",
      "for 2018-12-04, MAE is:1.21 & sMAPE is:2.60% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 12.38% & 2.03\n",
      "for 2018-12-05, MAE is:6.31 & sMAPE is:12.90% & rMAE is:2.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 12.38% & 2.03\n",
      "for 2018-12-06, MAE is:6.68 & sMAPE is:13.33% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.98 & 12.38% & 2.03\n",
      "for 2018-12-07, MAE is:2.75 & sMAPE is:5.66% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 12.36% & 2.02\n",
      "for 2018-12-08, MAE is:2.17 & sMAPE is:4.90% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 12.34% & 2.02\n",
      "for 2018-12-09, MAE is:2.02 & sMAPE is:4.61% & rMAE is:3.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 12.32% & 2.03\n",
      "for 2018-12-10, MAE is:2.79 & sMAPE is:6.05% & rMAE is:2.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 12.30% & 2.03\n",
      "for 2018-12-11, MAE is:6.15 & sMAPE is:12.75% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 12.30% & 2.03\n",
      "for 2018-12-12, MAE is:14.96 & sMAPE is:26.55% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.98 & 12.34% & 2.03\n",
      "for 2018-12-13, MAE is:9.56 & sMAPE is:16.75% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 12.35% & 2.03\n",
      "for 2018-12-14, MAE is:11.12 & sMAPE is:19.70% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 12.38% & 2.02\n",
      "for 2018-12-15, MAE is:4.22 & sMAPE is:8.44% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 12.36% & 2.02\n",
      "for 2018-12-16, MAE is:3.92 & sMAPE is:8.07% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 12.35% & 2.01\n",
      "for 2018-12-17, MAE is:19.03 & sMAPE is:31.60% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 12.41% & 2.01\n",
      "for 2018-12-18, MAE is:10.90 & sMAPE is:19.17% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 12.43% & 2.01\n",
      "for 2018-12-19, MAE is:5.26 & sMAPE is:10.35% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 12.42% & 2.01\n",
      "for 2018-12-20, MAE is:7.01 & sMAPE is:13.88% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 12.42% & 2.00\n",
      "for 2018-12-21, MAE is:5.34 & sMAPE is:10.60% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 12.42% & 2.00\n",
      "for 2018-12-22, MAE is:5.06 & sMAPE is:10.25% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 12.41% & 2.00\n",
      "for 2018-12-23, MAE is:6.71 & sMAPE is:13.35% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 12.42% & 2.00\n",
      "for 2018-12-24, MAE is:3.42 & sMAPE is:6.93% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 12.40% & 2.00\n",
      "for 2018-12-25, MAE is:4.61 & sMAPE is:9.69% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 12.39% & 1.99\n",
      "for 2018-12-26, MAE is:7.06 & sMAPE is:14.88% & rMAE is:2.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 12.40% & 1.99\n",
      "for 2018-12-27, MAE is:6.44 & sMAPE is:13.18% & rMAE is:2.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 12.40% & 2.00\n",
      "for 2018-12-28, MAE is:6.63 & sMAPE is:13.10% & rMAE is:3.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 12.40% & 2.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-12-29, MAE is:3.45 & sMAPE is:7.08% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 12.39% & 2.00\n",
      "for 2018-12-30, MAE is:5.23 & sMAPE is:10.73% & rMAE is:2.87 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 12.38% & 2.00\n",
      "for 2018-12-31, MAE is:3.39 & sMAPE is:7.05% & rMAE is:2.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 12.37% & 2.00\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3 (PC Version - Run on Laptop)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:03:39,110]\u001b[0m A new study created in RDB with name: NO_2_2019\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.55 | sMAPE for Validation Set is: 26.50% | rMAE for Validation Set is: 2.18\n",
      "MAE for Test Set is: 6.78 | sMAPE for Test Set is: 17.77% | rMAE for Test Set is: 2.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:04:14,957]\u001b[0m Trial 1 finished with value: 10.547939076157254 and parameters: {'n_hidden': 4, 'learning_rate': 0.0570875050377252, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3548846430070889, 'dropout_rate_Layer_2': 0.1933016533829971, 'dropout_rate_Layer_3': 0.04426312629963772, 'dropout_rate_Layer_4': 0.11089483774295741, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.5756930117558895e-05, 'l1_Layer_2': 0.00012139973958484372, 'l1_Layer_3': 0.0016230749960663557, 'l1_Layer_4': 1.260562028109552e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 125, 'n_units_Layer_3': 290, 'n_units_Layer_4': 60}. Best is trial 1 with value: 10.547939076157254.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:04:28,886]\u001b[0m Trial 0 finished with value: 7.666279910893858 and parameters: {'n_hidden': 3, 'learning_rate': 0.003685385566929304, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18059923680923695, 'dropout_rate_Layer_2': 0.23748155576021565, 'dropout_rate_Layer_3': 0.042754354008455134, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011659949835521118, 'l1_Layer_2': 0.04160790076103205, 'l1_Layer_3': 1.1267262814855772e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 85, 'n_units_Layer_3': 65}. Best is trial 0 with value: 7.666279910893858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.67 | sMAPE for Validation Set is: 18.59% | rMAE for Validation Set is: 1.59\n",
      "MAE for Test Set is: 4.33 | sMAPE for Test Set is: 10.86% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:04:58,799]\u001b[0m Trial 3 finished with value: 5.496115465705844 and parameters: {'n_hidden': 4, 'learning_rate': 0.08351572290523697, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3859450440154013, 'dropout_rate_Layer_2': 0.07190068132193543, 'dropout_rate_Layer_3': 0.13692282945825537, 'dropout_rate_Layer_4': 0.1444749388005826, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.06853609010958651, 'l1_Layer_2': 6.23238992709957e-05, 'l1_Layer_3': 0.010210601818081234, 'l1_Layer_4': 0.0010884371308648492, 'n_units_Layer_1': 85, 'n_units_Layer_2': 80, 'n_units_Layer_3': 285, 'n_units_Layer_4': 50}. Best is trial 3 with value: 5.496115465705844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.50 | sMAPE for Validation Set is: 13.54% | rMAE for Validation Set is: 1.14\n",
      "MAE for Test Set is: 3.08 | sMAPE for Test Set is: 8.12% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:05:03,387]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.69 | sMAPE for Validation Set is: 21.57% | rMAE for Validation Set is: 1.80\n",
      "MAE for Test Set is: 5.89 | sMAPE for Test Set is: 15.44% | rMAE for Test Set is: 1.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:05:22,270]\u001b[0m Trial 5 finished with value: 8.685505615230824 and parameters: {'n_hidden': 4, 'learning_rate': 0.04780049603489198, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32633770305639676, 'dropout_rate_Layer_2': 0.0314825244644446, 'dropout_rate_Layer_3': 0.37882473749583734, 'dropout_rate_Layer_4': 0.015170524331332836, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.6145913202797623e-05, 'l1_Layer_2': 0.00019106508715589077, 'l1_Layer_3': 0.0002415557023672048, 'l1_Layer_4': 0.00014522588671497398, 'n_units_Layer_1': 175, 'n_units_Layer_2': 75, 'n_units_Layer_3': 185, 'n_units_Layer_4': 235}. Best is trial 3 with value: 5.496115465705844.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:05:39,495]\u001b[0m Trial 6 finished with value: 16.47353383700941 and parameters: {'n_hidden': 3, 'learning_rate': 0.005334483448209729, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024226534682204415, 'dropout_rate_Layer_2': 0.3905738561142442, 'dropout_rate_Layer_3': 0.34370025416495337, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.000105391632451091, 'l1_Layer_2': 0.0695970706428775, 'l1_Layer_3': 0.05788334988682181, 'n_units_Layer_1': 240, 'n_units_Layer_2': 165, 'n_units_Layer_3': 105}. Best is trial 3 with value: 5.496115465705844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.47 | sMAPE for Validation Set is: 44.72% | rMAE for Validation Set is: 3.41\n",
      "MAE for Test Set is: 11.73 | sMAPE for Test Set is: 33.44% | rMAE for Test Set is: 3.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:05:46,976]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:05:52,226]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:05:57,075]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:06:01,553]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.00 | sMAPE for Validation Set is: 12.14% | rMAE for Validation Set is: 1.03\n",
      "MAE for Test Set is: 3.08 | sMAPE for Test Set is: 7.71% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:06:02,034]\u001b[0m Trial 2 finished with value: 4.996774094988293 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016260634740799657, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33145587412277344, 'dropout_rate_Layer_2': 0.19250604218845313, 'dropout_rate_Layer_3': 0.11847799325757907, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.241879925672624e-05, 'l1_Layer_2': 0.0690097641597299, 'l1_Layer_3': 0.00023603068915194124, 'n_units_Layer_1': 115, 'n_units_Layer_2': 105, 'n_units_Layer_3': 295}. Best is trial 2 with value: 4.996774094988293.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:06:11,321]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:06:11,513]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:06:18,041]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:06:24,983]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:06:32,257]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:06:59,726]\u001b[0m Trial 14 finished with value: 4.206717115327632 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018447304042424765, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23224475442921677, 'dropout_rate_Layer_2': 0.16830979785363318, 'dropout_rate_Layer_3': 0.39998875932763633, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004475359850924828, 'l1_Layer_2': 0.0032778115113730613, 'l1_Layer_3': 0.004044650748525622, 'n_units_Layer_1': 130, 'n_units_Layer_2': 235, 'n_units_Layer_3': 55}. Best is trial 14 with value: 4.206717115327632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.21 | sMAPE for Validation Set is: 10.38% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 3.95 | sMAPE for Test Set is: 9.85% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:07:04,971]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:07:16,811]\u001b[0m Trial 17 finished with value: 7.934691729723187 and parameters: {'n_hidden': 4, 'learning_rate': 0.034286140783726146, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1195161989870198, 'dropout_rate_Layer_2': 0.20900546122225708, 'dropout_rate_Layer_3': 0.3648266843083781, 'dropout_rate_Layer_4': 0.13853014958604817, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 3.082370056501479e-05, 'l1_Layer_2': 0.0012250495255754586, 'l1_Layer_3': 0.004776896067524209, 'l1_Layer_4': 0.011589873459822115, 'n_units_Layer_1': 195, 'n_units_Layer_2': 190, 'n_units_Layer_3': 200, 'n_units_Layer_4': 125}. Best is trial 14 with value: 4.206717115327632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.93 | sMAPE for Validation Set is: 19.31% | rMAE for Validation Set is: 1.64\n",
      "MAE for Test Set is: 4.62 | sMAPE for Test Set is: 11.62% | rMAE for Test Set is: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:07:22,606]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:07:39,752]\u001b[0m Trial 21 finished with value: 8.825666540863349 and parameters: {'n_hidden': 3, 'learning_rate': 0.00556776799078511, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19096989798253527, 'dropout_rate_Layer_2': 0.025924305729682698, 'dropout_rate_Layer_3': 0.02194669420567932, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.160361336027835e-05, 'l1_Layer_2': 0.0003386635854054366, 'l1_Layer_3': 0.00011006596340093272, 'n_units_Layer_1': 155, 'n_units_Layer_2': 285, 'n_units_Layer_3': 215}. Best is trial 14 with value: 4.206717115327632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.83 | sMAPE for Validation Set is: 21.78% | rMAE for Validation Set is: 1.83\n",
      "MAE for Test Set is: 6.33 | sMAPE for Test Set is: 16.38% | rMAE for Test Set is: 1.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:07:44,271]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:07:52,304]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:07:56,921]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:08:03,933]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:08:39,326]\u001b[0m Trial 19 finished with value: 3.1407040282379093 and parameters: {'n_hidden': 3, 'learning_rate': 0.005282258038790488, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16062797616859076, 'dropout_rate_Layer_2': 0.19909368289955598, 'dropout_rate_Layer_3': 0.2538736724753979, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5544549293583714e-05, 'l1_Layer_2': 5.9192467793418366e-05, 'l1_Layer_3': 0.019366575865277336, 'n_units_Layer_1': 255, 'n_units_Layer_2': 240, 'n_units_Layer_3': 110}. Best is trial 19 with value: 3.1407040282379093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.14 | sMAPE for Validation Set is: 8.15% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 2.19 | sMAPE for Test Set is: 5.78% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:08:48,295]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:09:10,967]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:09:16,357]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:09:28,314]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:09:40,002]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:11:14,713]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:11:19,556]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:11:19,782]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:11:24,603]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:11:26,607]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:11:31,251]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:11:34,403]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:11:39,084]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:11:46,060]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:11:46,505]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:11:52,026]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:11:56,518]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:12:01,113]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:12:04,278]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:12:08,945]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:12:13,203]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:12:15,796]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:12:18,828]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:12:19,171]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:12:28,059]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:14:12,294]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:14:37,737]\u001b[0m Trial 52 finished with value: 4.451871773384138 and parameters: {'n_hidden': 3, 'learning_rate': 0.0077060281021819055, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11183456879618053, 'dropout_rate_Layer_2': 0.16894675646852086, 'dropout_rate_Layer_3': 0.05859962151154499, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0007973265102739409, 'l1_Layer_2': 0.030965856900123264, 'l1_Layer_3': 0.0003904631814162691, 'n_units_Layer_1': 270, 'n_units_Layer_2': 70, 'n_units_Layer_3': 115}. Best is trial 19 with value: 3.1407040282379093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 11.21% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 3.31 | sMAPE for Test Set is: 8.69% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:14:47,091]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:14:50,044]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:14:53,352]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:15:12,050]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:15:22,391]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:15:32,061]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:15:41,893]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:15:46,770]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:15:46,818]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:15:57,079]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:16:02,542]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:16:09,656]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:16:19,161]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:16:29,201]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:16:34,159]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:16:38,657]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:16:44,376]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:16:56,689]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:17:11,329]\u001b[0m Trial 68 finished with value: 2.775005891744873 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025596970114693976, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15094789166290604, 'dropout_rate_Layer_2': 0.1412813013665507, 'dropout_rate_Layer_3': 0.16131892021184277, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004218213902451355, 'l1_Layer_2': 0.00016945154413677846, 'l1_Layer_3': 5.802684724768345e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 90, 'n_units_Layer_3': 280}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.78 | sMAPE for Validation Set is: 7.31% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.86 | sMAPE for Test Set is: 4.92% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:17:19,327]\u001b[0m Trial 72 finished with value: 4.2192005133673245 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022574866746193547, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3352673560884171, 'dropout_rate_Layer_2': 0.26261057963902446, 'dropout_rate_Layer_3': 0.30154942310323857, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011145287715505835, 'l1_Layer_2': 3.410604463010261e-05, 'l1_Layer_3': 1.0681189548731325e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 165, 'n_units_Layer_3': 165}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.22 | sMAPE for Validation Set is: 10.49% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 3.59 | sMAPE for Test Set is: 9.52% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:17:33,336]\u001b[0m Trial 73 finished with value: 3.3336349206885374 and parameters: {'n_hidden': 3, 'learning_rate': 0.006162053448210624, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1840605880065114, 'dropout_rate_Layer_2': 0.1530911984596637, 'dropout_rate_Layer_3': 0.1724112511298514, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004975329931384769, 'l1_Layer_2': 0.00012791899563314882, 'l1_Layer_3': 0.0001770943897119464, 'n_units_Layer_1': 50, 'n_units_Layer_2': 80, 'n_units_Layer_3': 270}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.33 | sMAPE for Validation Set is: 8.62% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 2.75 | sMAPE for Test Set is: 7.24% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:17:40,692]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:17:53,419]\u001b[0m Trial 74 finished with value: 2.9314445523665165 and parameters: {'n_hidden': 3, 'learning_rate': 0.005402145696413384, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18664822110332935, 'dropout_rate_Layer_2': 0.15374627987777328, 'dropout_rate_Layer_3': 0.147372243542758, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004680671265688933, 'l1_Layer_2': 0.00010717156945337288, 'l1_Layer_3': 1.7500631928138152e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 85, 'n_units_Layer_3': 245}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.93 | sMAPE for Validation Set is: 7.62% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 2.00 | sMAPE for Test Set is: 5.24% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:17:53,608]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:18:01,908]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:18:06,822]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:18:13,638]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:18:14,095]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:18:28,372]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:18:36,438]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:18:38,488]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:18:43,641]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:18:48,369]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:18:48,577]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:19:00,467]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:19:15,667]\u001b[0m Trial 87 finished with value: 3.139809021372591 and parameters: {'n_hidden': 3, 'learning_rate': 0.008403333026308498, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16558841512047362, 'dropout_rate_Layer_2': 0.1668323922838887, 'dropout_rate_Layer_3': 0.1380325790507102, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0068121903050373574, 'l1_Layer_2': 0.0002999348111514274, 'l1_Layer_3': 5.762042126240533e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 50, 'n_units_Layer_3': 250}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.14 | sMAPE for Validation Set is: 8.07% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 2.06 | sMAPE for Test Set is: 5.42% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:19:20,314]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:19:26,954]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:19:49,085]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:20:03,708]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:20:08,919]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:20:18,923]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:20:19,035]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:20:27,290]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:20:27,486]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:20:43,736]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:20:57,444]\u001b[0m Trial 98 finished with value: 2.899665596258707 and parameters: {'n_hidden': 3, 'learning_rate': 0.007254973004611792, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23080377613634678, 'dropout_rate_Layer_2': 0.15920773090897242, 'dropout_rate_Layer_3': 0.15197589423346008, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0021057515526980855, 'l1_Layer_2': 0.0009205347476734361, 'l1_Layer_3': 2.2417916263301647e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 65, 'n_units_Layer_3': 200}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.90 | sMAPE for Validation Set is: 7.65% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.15 | sMAPE for Test Set is: 5.57% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:21:00,684]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:21:05,486]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:21:19,397]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:21:40,477]\u001b[0m Trial 104 finished with value: 3.3138684397702782 and parameters: {'n_hidden': 3, 'learning_rate': 0.015820706908320555, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26057441179522556, 'dropout_rate_Layer_2': 0.22939771956651833, 'dropout_rate_Layer_3': 0.091106410605892, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006818755421946356, 'l1_Layer_2': 0.0003871552421597812, 'l1_Layer_3': 2.7246305088543702e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 90, 'n_units_Layer_3': 250}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.31 | sMAPE for Validation Set is: 8.53% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 2.05 | sMAPE for Test Set is: 5.39% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:21:50,291]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:21:55,503]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:22:01,929]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:22:16,816]\u001b[0m Trial 108 finished with value: 8.005867790771818 and parameters: {'n_hidden': 3, 'learning_rate': 0.019272393445772338, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011301279106449097, 'dropout_rate_Layer_2': 0.38354282658275396, 'dropout_rate_Layer_3': 0.3808647424294776, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002081429852163104, 'l1_Layer_2': 0.00953372251897738, 'l1_Layer_3': 0.002388399695079684, 'n_units_Layer_1': 50, 'n_units_Layer_2': 225, 'n_units_Layer_3': 120}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.01 | sMAPE for Validation Set is: 19.54% | rMAE for Validation Set is: 1.66\n",
      "MAE for Test Set is: 4.57 | sMAPE for Test Set is: 11.55% | rMAE for Test Set is: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:22:23,664]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:22:34,728]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:22:41,554]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:22:44,659]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:22:49,433]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:23:06,674]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:23:17,621]\u001b[0m Trial 113 finished with value: 3.428097650511971 and parameters: {'n_hidden': 3, 'learning_rate': 0.014162119872063146, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3536380339699092, 'dropout_rate_Layer_2': 0.2420491622059246, 'dropout_rate_Layer_3': 0.29294496817901466, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002247278560851927, 'l1_Layer_2': 6.396255709337967e-05, 'l1_Layer_3': 1.0421596608584373e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 100, 'n_units_Layer_3': 160}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.43 | sMAPE for Validation Set is: 8.83% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 2.43 | sMAPE for Test Set is: 6.48% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:23:17,820]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:23:25,571]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:23:26,128]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:23:34,843]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:23:40,891]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:23:46,204]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:23:47,800]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:23:56,237]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:24:00,641]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:24:05,281]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:24:15,334]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:24:20,185]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.22 | sMAPE for Validation Set is: 17.68% | rMAE for Validation Set is: 1.49\n",
      "MAE for Test Set is: 5.00 | sMAPE for Test Set is: 13.42% | rMAE for Test Set is: 1.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:24:21,493]\u001b[0m Trial 126 finished with value: 7.216644368882064 and parameters: {'n_hidden': 3, 'learning_rate': 0.018155602268716375, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0043549468412203895, 'dropout_rate_Layer_2': 0.3866324338861914, 'dropout_rate_Layer_3': 0.3906781000113822, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016490357193401967, 'l1_Layer_2': 0.008704607805048002, 'l1_Layer_3': 0.0025306332196484505, 'n_units_Layer_1': 60, 'n_units_Layer_2': 225, 'n_units_Layer_3': 110}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:24:28,017]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:24:40,309]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:24:42,914]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:24:47,980]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:24:55,083]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:25:01,942]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:25:09,419]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:25:15,321]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:25:24,184]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.00 | sMAPE for Validation Set is: 7.85% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 2.12 | sMAPE for Test Set is: 5.61% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:25:39,070]\u001b[0m Trial 136 finished with value: 3.0037526272661856 and parameters: {'n_hidden': 3, 'learning_rate': 0.01434472657717996, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3894855741561013, 'dropout_rate_Layer_2': 0.13009802541589902, 'dropout_rate_Layer_3': 0.28264224933190835, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018346490964443645, 'l1_Layer_2': 0.007731625703648601, 'l1_Layer_3': 5.4325448784499294e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 120, 'n_units_Layer_3': 210}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:25:51,282]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:25:51,847]\u001b[0m Trial 138 finished with value: 7.563795858663776 and parameters: {'n_hidden': 3, 'learning_rate': 0.001724391758378334, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2448830889378802, 'dropout_rate_Layer_2': 0.2796340836663227, 'dropout_rate_Layer_3': 0.2169509170863101, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007738246451715133, 'l1_Layer_2': 0.045872579630683905, 'l1_Layer_3': 1.2241479392971987e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 155, 'n_units_Layer_3': 240}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.56 | sMAPE for Validation Set is: 18.28% | rMAE for Validation Set is: 1.57\n",
      "MAE for Test Set is: 4.17 | sMAPE for Test Set is: 10.39% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:25:57,478]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:26:01,601]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:26:02,168]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:26:08,985]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:26:11,695]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:26:14,418]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:26:18,909]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:26:23,686]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:26:28,954]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.67 | sMAPE for Validation Set is: 16.11% | rMAE for Validation Set is: 1.38\n",
      "MAE for Test Set is: 3.68 | sMAPE for Test Set is: 9.13% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:26:31,311]\u001b[0m Trial 146 finished with value: 6.67406412195671 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014531742678018434, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2026632950560397, 'dropout_rate_Layer_2': 0.3658148656240595, 'dropout_rate_Layer_3': 0.2275492022813595, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03955635986659142, 'l1_Layer_2': 2.1543132047824058e-05, 'l1_Layer_3': 2.5008647714002206e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 95, 'n_units_Layer_3': 285}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:26:35,775]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:26:42,749]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:26:48,286]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:26:51,267]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:26:55,794]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:26:56,188]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:27:02,556]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:27:09,995]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:27:14,570]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:27:20,182]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:27:27,191]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:27:31,947]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:27:42,198]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:27:47,085]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:27:50,198]\u001b[0m Trial 156 finished with value: 3.079683361586246 and parameters: {'n_hidden': 3, 'learning_rate': 0.05397537797815678, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2519336681808473, 'dropout_rate_Layer_2': 0.1932083598143424, 'dropout_rate_Layer_3': 0.313975494835675, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017707058354507493, 'l1_Layer_2': 0.04276469890855001, 'l1_Layer_3': 0.00042122398743598826, 'n_units_Layer_1': 115, 'n_units_Layer_2': 205, 'n_units_Layer_3': 65}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.08 | sMAPE for Validation Set is: 8.03% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 2.46 | sMAPE for Test Set is: 6.46% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:27:54,317]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:28:02,262]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:28:08,792]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:28:13,888]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:28:19,215]\u001b[0m Trial 166 finished with value: 3.963350073731812 and parameters: {'n_hidden': 3, 'learning_rate': 0.09178605893959561, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2524290050974334, 'dropout_rate_Layer_2': 0.17436293873794384, 'dropout_rate_Layer_3': 0.3057989610606685, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022891442140924196, 'l1_Layer_2': 0.08343881598042725, 'l1_Layer_3': 0.0003880577819480106, 'n_units_Layer_1': 95, 'n_units_Layer_2': 210, 'n_units_Layer_3': 65}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.96 | sMAPE for Validation Set is: 10.16% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 2.69 | sMAPE for Test Set is: 7.09% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:28:26,564]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:28:43,796]\u001b[0m Trial 170 finished with value: 2.930241698304146 and parameters: {'n_hidden': 3, 'learning_rate': 0.0055643623519844995, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2003979229044533, 'dropout_rate_Layer_2': 0.14102396365496186, 'dropout_rate_Layer_3': 0.19714670361817202, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0028776755423681757, 'l1_Layer_2': 0.00013440906418403801, 'l1_Layer_3': 0.00011652023994889905, 'n_units_Layer_1': 115, 'n_units_Layer_2': 70, 'n_units_Layer_3': 295}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.93 | sMAPE for Validation Set is: 7.65% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 1.92 | sMAPE for Test Set is: 5.07% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:28:51,203]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:28:57,605]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:29:01,004]\u001b[0m Trial 172 finished with value: 2.873998447538977 and parameters: {'n_hidden': 3, 'learning_rate': 0.005064919853525533, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23912674179253474, 'dropout_rate_Layer_2': 0.1415467735333255, 'dropout_rate_Layer_3': 0.1425192124813615, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0038400915355278806, 'l1_Layer_2': 0.00010566425459202124, 'l1_Layer_3': 0.00022317632772374908, 'n_units_Layer_1': 115, 'n_units_Layer_2': 80, 'n_units_Layer_3': 295}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.87 | sMAPE for Validation Set is: 7.58% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.02 | sMAPE for Test Set is: 5.33% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:29:14,793]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:29:20,180]\u001b[0m Trial 175 finished with value: 7.894112034563245 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010919627686730045, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1958550005848689, 'dropout_rate_Layer_2': 0.3655681564785005, 'dropout_rate_Layer_3': 0.16733691065858952, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.051998076354347736, 'l1_Layer_2': 1.1765408157595372e-05, 'l1_Layer_3': 5.3366147369447276e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 95, 'n_units_Layer_3': 155}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.89 | sMAPE for Validation Set is: 19.21% | rMAE for Validation Set is: 1.63\n",
      "MAE for Test Set is: 4.66 | sMAPE for Test Set is: 11.73% | rMAE for Test Set is: 1.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:29:25,276]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:29:32,456]\u001b[0m Trial 177 finished with value: 4.427998047496576 and parameters: {'n_hidden': 3, 'learning_rate': 0.00367077579274374, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19662288994644736, 'dropout_rate_Layer_2': 0.3520469897196137, 'dropout_rate_Layer_3': 0.23735132089356656, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00841142162603022, 'l1_Layer_2': 1.3154207715021664e-05, 'l1_Layer_3': 4.7596792455118144e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 95, 'n_units_Layer_3': 155}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 10.96% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 2.62 | sMAPE for Test Set is: 6.65% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:29:46,715]\u001b[0m Trial 179 finished with value: 2.858122402596074 and parameters: {'n_hidden': 3, 'learning_rate': 0.019591766882241613, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38616334471808206, 'dropout_rate_Layer_2': 0.10418562690077063, 'dropout_rate_Layer_3': 0.2755881005425147, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0053458600099691314, 'l1_Layer_2': 0.009671573071478664, 'l1_Layer_3': 4.033512731501366e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 120, 'n_units_Layer_3': 210}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.86 | sMAPE for Validation Set is: 7.54% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.94 | sMAPE for Test Set is: 5.17% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:29:49,698]\u001b[0m Trial 180 finished with value: 4.79180974862651 and parameters: {'n_hidden': 3, 'learning_rate': 0.003916062225493512, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16002575920054507, 'dropout_rate_Layer_2': 0.3493386602346208, 'dropout_rate_Layer_3': 0.24224697221431024, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009880456205901778, 'l1_Layer_2': 1.0778801972360954e-05, 'l1_Layer_3': 0.00010097514110026038, 'n_units_Layer_1': 95, 'n_units_Layer_2': 100, 'n_units_Layer_3': 190}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.79 | sMAPE for Validation Set is: 11.59% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 2.95 | sMAPE for Test Set is: 7.44% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:29:59,700]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:30:06,664]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:30:19,049]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:30:19,251]\u001b[0m Trial 182 finished with value: 3.165522954299685 and parameters: {'n_hidden': 3, 'learning_rate': 0.004317217992319822, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21462666226686206, 'dropout_rate_Layer_2': 0.1721347671275024, 'dropout_rate_Layer_3': 0.11418849880421805, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00139818368848327, 'l1_Layer_2': 9.662261802718218e-05, 'l1_Layer_3': 0.00017590004807335182, 'n_units_Layer_1': 110, 'n_units_Layer_2': 65, 'n_units_Layer_3': 280}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.17 | sMAPE for Validation Set is: 8.35% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 2.29 | sMAPE for Test Set is: 6.12% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:30:26,957]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:30:27,224]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:30:36,577]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:31:08,577]\u001b[0m Trial 189 finished with value: 3.8594160675869307 and parameters: {'n_hidden': 3, 'learning_rate': 0.07737549898415079, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24912130998707654, 'dropout_rate_Layer_2': 0.1772412607859185, 'dropout_rate_Layer_3': 0.2837906004863985, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.003222188859696435, 'l1_Layer_2': 0.09809300117299655, 'l1_Layer_3': 0.00034862118039136734, 'n_units_Layer_1': 105, 'n_units_Layer_2': 140, 'n_units_Layer_3': 60}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:31:08,586]\u001b[0m Trial 187 finished with value: 4.67719992644738 and parameters: {'n_hidden': 3, 'learning_rate': 0.08665477007285666, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2461919115039144, 'dropout_rate_Layer_2': 0.17601463534227052, 'dropout_rate_Layer_3': 0.28123226246403266, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.003612369542035845, 'l1_Layer_2': 0.08899379464088433, 'l1_Layer_3': 1.083863176143571e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 120, 'n_units_Layer_3': 50}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 9.83% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 2.92 | sMAPE for Test Set is: 7.39% | rMAE for Test Set is: 0.88\n",
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 11.67% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 3.28 | sMAPE for Test Set is: 8.64% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:31:19,757]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:31:41,181]\u001b[0m Trial 192 finished with value: 2.8603913032009616 and parameters: {'n_hidden': 3, 'learning_rate': 0.02533527046112703, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3915909168438415, 'dropout_rate_Layer_2': 0.12347271569315091, 'dropout_rate_Layer_3': 0.26400666266957684, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.020290894444410183, 'l1_Layer_2': 0.01003854730672532, 'l1_Layer_3': 5.079350706103476e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 135, 'n_units_Layer_3': 215}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.86 | sMAPE for Validation Set is: 7.52% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.96 | sMAPE for Test Set is: 5.20% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:31:46,809]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:31:51,952]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:31:58,750]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:32:03,814]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:32:11,482]\u001b[0m Trial 190 finished with value: 5.528138424999444 and parameters: {'n_hidden': 3, 'learning_rate': 0.04801436328652368, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39407403190700585, 'dropout_rate_Layer_2': 0.05879312604494155, 'dropout_rate_Layer_3': 0.17371415576624488, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.004748929696582764, 'l1_Layer_2': 0.026721229446436793, 'l1_Layer_3': 0.00027061494584351605, 'n_units_Layer_1': 135, 'n_units_Layer_2': 145, 'n_units_Layer_3': 95}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 13.59% | rMAE for Validation Set is: 1.14\n",
      "MAE for Test Set is: 6.34 | sMAPE for Test Set is: 16.04% | rMAE for Test Set is: 1.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:32:16,500]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:32:23,601]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:32:28,407]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:32:35,612]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:32:43,410]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:32:47,888]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:32:50,753]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:32:57,577]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:33:02,798]\u001b[0m Trial 197 finished with value: 6.07210455850072 and parameters: {'n_hidden': 3, 'learning_rate': 0.05088169998459118, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3946403301031914, 'dropout_rate_Layer_2': 0.06534174173876792, 'dropout_rate_Layer_3': 0.17738668098748778, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.010325646969892695, 'l1_Layer_2': 0.026200544957147336, 'l1_Layer_3': 0.000323354437502484, 'n_units_Layer_1': 125, 'n_units_Layer_2': 50, 'n_units_Layer_3': 90}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.07 | sMAPE for Validation Set is: 14.69% | rMAE for Validation Set is: 1.26\n",
      "MAE for Test Set is: 3.21 | sMAPE for Test Set is: 8.04% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:33:07,875]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:33:12,464]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:33:19,532]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:33:24,263]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:33:31,826]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:33:39,542]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:33:44,479]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:33:51,404]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:33:56,072]\u001b[0m Trial 210 finished with value: 2.915119861686252 and parameters: {'n_hidden': 3, 'learning_rate': 0.006924533877725351, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05179798807679477, 'dropout_rate_Layer_2': 0.10475604881553782, 'dropout_rate_Layer_3': 0.204218516621666, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003580062121391813, 'l1_Layer_2': 0.00013040284402892545, 'l1_Layer_3': 0.006924856609312874, 'n_units_Layer_1': 235, 'n_units_Layer_2': 60, 'n_units_Layer_3': 80}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.92 | sMAPE for Validation Set is: 7.73% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.36 | sMAPE for Test Set is: 6.35% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:33:58,920]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:34:03,814]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:34:08,992]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:34:09,129]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:34:16,265]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:34:40,295]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:34:40,347]\u001b[0m Trial 221 finished with value: 2.9152936513996655 and parameters: {'n_hidden': 3, 'learning_rate': 0.011311977174725214, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0006084779254491302, 'dropout_rate_Layer_2': 0.08145433660525464, 'dropout_rate_Layer_3': 0.14989426867701183, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012199733647029782, 'l1_Layer_2': 0.06902692888345816, 'l1_Layer_3': 0.023042860856282252, 'n_units_Layer_1': 225, 'n_units_Layer_2': 55, 'n_units_Layer_3': 60}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.92 | sMAPE for Validation Set is: 7.67% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 1.99 | sMAPE for Test Set is: 5.23% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:34:46,376]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:34:51,376]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:34:55,943]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:35:00,743]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:35:16,141]\u001b[0m Trial 227 finished with value: 2.8730114113329948 and parameters: {'n_hidden': 3, 'learning_rate': 0.030559474815899552, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39787021690661206, 'dropout_rate_Layer_2': 0.07636111966083108, 'dropout_rate_Layer_3': 0.2663994923275233, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.013142883970791155, 'l1_Layer_2': 0.01779448977387557, 'l1_Layer_3': 0.00042624814390002027, 'n_units_Layer_1': 50, 'n_units_Layer_2': 55, 'n_units_Layer_3': 275}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.87 | sMAPE for Validation Set is: 7.53% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.96 | sMAPE for Test Set is: 5.17% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:35:20,916]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:35:27,563]\u001b[0m Trial 223 finished with value: 2.7967174495309863 and parameters: {'n_hidden': 3, 'learning_rate': 0.007568797529609137, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3908255086584462, 'dropout_rate_Layer_2': 0.06309297366931638, 'dropout_rate_Layer_3': 0.2576943386816805, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015536806531033107, 'l1_Layer_2': 0.017405466490368088, 'l1_Layer_3': 0.0002457580792882905, 'n_units_Layer_1': 50, 'n_units_Layer_2': 60, 'n_units_Layer_3': 195}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.80 | sMAPE for Validation Set is: 7.36% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.92 | sMAPE for Test Set is: 5.12% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:35:30,315]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:35:34,631]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:35:38,008]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:35:42,035]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:35:42,298]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:35:49,249]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:35:49,806]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:35:55,481]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:36:04,891]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:36:11,941]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:36:17,684]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:36:17,901]\u001b[0m Trial 238 finished with value: 4.5378304693019595 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033844478496986774, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21234612372882408, 'dropout_rate_Layer_2': 0.3621270308344592, 'dropout_rate_Layer_3': 0.24987463345171676, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002118294797171576, 'l1_Layer_2': 7.041462740595989e-05, 'l1_Layer_3': 5.794696930535636e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 65, 'n_units_Layer_3': 80}. Best is trial 68 with value: 2.775005891744873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 11.18% | rMAE for Validation Set is: 0.94\n",
      "MAE for Test Set is: 2.93 | sMAPE for Test Set is: 7.41% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:36:25,176]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:36:27,835]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:36:30,253]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:36:34,698]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:36:38,108]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:36:42,053]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:36:45,589]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:36:49,666]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:36:52,544]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:37:19,569]\u001b[0m Trial 251 finished with value: 2.7202838967587915 and parameters: {'n_hidden': 3, 'learning_rate': 0.004006302268780185, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1737881081990272, 'dropout_rate_Layer_2': 0.005552791398133056, 'dropout_rate_Layer_3': 0.2701272554239122, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0074985222084782335, 'l1_Layer_2': 0.0006287046731441122, 'l1_Layer_3': 0.09763647677182345, 'n_units_Layer_1': 80, 'n_units_Layer_2': 70, 'n_units_Layer_3': 80}. Best is trial 251 with value: 2.7202838967587915.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.72 | sMAPE for Validation Set is: 7.18% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 1.91 | sMAPE for Test Set is: 5.06% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:37:24,744]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:37:48,451]\u001b[0m Trial 250 finished with value: 3.15513283557288 and parameters: {'n_hidden': 3, 'learning_rate': 0.004016193854467736, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2884334781996359, 'dropout_rate_Layer_2': 0.22135041493903232, 'dropout_rate_Layer_3': 0.2619166468326696, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004925586400199481, 'l1_Layer_2': 0.023460954612521026, 'l1_Layer_3': 0.0007805855384010598, 'n_units_Layer_1': 80, 'n_units_Layer_2': 150, 'n_units_Layer_3': 150}. Best is trial 251 with value: 2.7202838967587915.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.16 | sMAPE for Validation Set is: 8.12% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 2.17 | sMAPE for Test Set is: 5.64% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:37:53,844]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:38:00,689]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:38:18,339]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:38:30,486]\u001b[0m Trial 256 finished with value: 2.730645840163559 and parameters: {'n_hidden': 3, 'learning_rate': 0.006500239725694884, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08363968661413701, 'dropout_rate_Layer_2': 0.12179380032668648, 'dropout_rate_Layer_3': 0.29366311694572295, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021500486136026235, 'l1_Layer_2': 0.00026224065000741216, 'l1_Layer_3': 0.09894725283663977, 'n_units_Layer_1': 85, 'n_units_Layer_2': 65, 'n_units_Layer_3': 75}. Best is trial 251 with value: 2.7202838967587915.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.73 | sMAPE for Validation Set is: 7.24% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.91 | sMAPE for Test Set is: 5.05% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:38:41,023]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:38:45,509]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:38:50,130]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:38:53,020]\u001b[0m Trial 257 finished with value: 2.6105727016548426 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027567337355857585, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17548133284039874, 'dropout_rate_Layer_2': 0.048392310209481273, 'dropout_rate_Layer_3': 0.22264676022488664, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000605368720884035, 'l1_Layer_2': 0.0019637036903287033, 'l1_Layer_3': 0.0008195105895784576, 'n_units_Layer_1': 85, 'n_units_Layer_2': 75, 'n_units_Layer_3': 85}. Best is trial 257 with value: 2.6105727016548426.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.61 | sMAPE for Validation Set is: 6.94% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 1.94 | sMAPE for Test Set is: 5.20% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:38:57,995]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:39:03,182]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:39:07,763]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:39:14,427]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:39:29,728]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:39:37,512]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:39:46,921]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:39:49,447]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:39:56,700]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:40:01,574]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:40:13,866]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.74 | sMAPE for Validation Set is: 7.30% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.95 | sMAPE for Test Set is: 5.14% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:40:23,133]\u001b[0m Trial 271 finished with value: 2.74248063653985 and parameters: {'n_hidden': 3, 'learning_rate': 0.009264507981672828, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3700544121990435, 'dropout_rate_Layer_2': 0.04846025337466288, 'dropout_rate_Layer_3': 0.24913821686243148, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002249342639019646, 'l1_Layer_2': 0.00032192828738809805, 'l1_Layer_3': 0.0009043381550192185, 'n_units_Layer_1': 100, 'n_units_Layer_2': 50, 'n_units_Layer_3': 100}. Best is trial 257 with value: 2.6105727016548426.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:40:39,017]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:40:43,861]\u001b[0m Trial 274 finished with value: 2.8095772453926124 and parameters: {'n_hidden': 3, 'learning_rate': 0.007576342243311536, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3458881323971929, 'dropout_rate_Layer_2': 0.1284730223189759, 'dropout_rate_Layer_3': 0.24787702335662062, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.013071430195987936, 'l1_Layer_2': 0.0008873213235778146, 'l1_Layer_3': 3.271489912135709e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 140, 'n_units_Layer_3': 195}. Best is trial 257 with value: 2.6105727016548426.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.81 | sMAPE for Validation Set is: 7.41% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.00 | sMAPE for Test Set is: 5.33% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:40:48,978]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:40:55,574]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:40:57,819]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:41:03,334]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:41:07,694]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:41:15,022]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:41:25,243]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:41:30,050]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:41:34,869]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:41:35,502]\u001b[0m Trial 278 finished with value: 3.424961595766149 and parameters: {'n_hidden': 3, 'learning_rate': 0.00413425630091371, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26008316088492855, 'dropout_rate_Layer_2': 0.1506408480604142, 'dropout_rate_Layer_3': 0.33764131893389043, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012066470109803851, 'l1_Layer_2': 0.010912598328982885, 'l1_Layer_3': 0.0001025048863632367, 'n_units_Layer_1': 105, 'n_units_Layer_2': 110, 'n_units_Layer_3': 165}. Best is trial 257 with value: 2.6105727016548426.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.42 | sMAPE for Validation Set is: 8.77% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 2.77 | sMAPE for Test Set is: 7.34% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:41:43,422]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:41:49,924]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:42:19,268]\u001b[0m Trial 287 finished with value: 2.652410251876717 and parameters: {'n_hidden': 3, 'learning_rate': 0.004119828670766315, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12080720367982341, 'dropout_rate_Layer_2': 0.08474580133071442, 'dropout_rate_Layer_3': 0.2928581869082941, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0036769829336371898, 'l1_Layer_2': 0.00027133402196607737, 'l1_Layer_3': 0.0015363774944692815, 'n_units_Layer_1': 75, 'n_units_Layer_2': 50, 'n_units_Layer_3': 95}. Best is trial 257 with value: 2.6105727016548426.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.65 | sMAPE for Validation Set is: 7.07% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.92 | sMAPE for Test Set is: 5.10% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:42:24,022]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:42:29,513]\u001b[0m Trial 288 finished with value: 3.563697988760538 and parameters: {'n_hidden': 3, 'learning_rate': 0.00458585748810211, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34777787367918817, 'dropout_rate_Layer_2': 0.1463424639390856, 'dropout_rate_Layer_3': 0.3480891546441347, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015099601432682316, 'l1_Layer_2': 0.0124817434617138, 'l1_Layer_3': 0.00013978640857104107, 'n_units_Layer_1': 80, 'n_units_Layer_2': 105, 'n_units_Layer_3': 160}. Best is trial 257 with value: 2.6105727016548426.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.56 | sMAPE for Validation Set is: 9.09% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 2.28 | sMAPE for Test Set is: 5.92% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:42:32,389]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:42:42,012]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:42:58,927]\u001b[0m Trial 290 finished with value: 3.9522494830232753 and parameters: {'n_hidden': 3, 'learning_rate': 0.004491975873923665, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2771117302985702, 'dropout_rate_Layer_2': 0.14300492035424867, 'dropout_rate_Layer_3': 0.3385631746072394, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00043844382042464375, 'l1_Layer_2': 0.010158430142824915, 'l1_Layer_3': 8.118001630777538e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 100, 'n_units_Layer_3': 165}. Best is trial 257 with value: 2.6105727016548426.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.95 | sMAPE for Validation Set is: 9.94% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 2.79 | sMAPE for Test Set is: 7.31% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:43:03,923]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:43:09,124]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:43:13,901]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:43:18,580]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:43:23,491]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:43:28,626]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:43:33,114]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:43:37,953]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:43:43,346]\u001b[0m Trial 296 finished with value: 3.418204001163859 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013002294931649119, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35253724345478765, 'dropout_rate_Layer_2': 0.22633594233103183, 'dropout_rate_Layer_3': 0.33070824306958974, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011361685158148705, 'l1_Layer_2': 0.0032137505275084202, 'l1_Layer_3': 1.777277793735784e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 200, 'n_units_Layer_3': 220}. Best is trial 257 with value: 2.6105727016548426.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:43:43,407]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.42 | sMAPE for Validation Set is: 8.73% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 2.32 | sMAPE for Test Set is: 6.01% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:44:07,735]\u001b[0m Trial 303 finished with value: 3.1242137420110865 and parameters: {'n_hidden': 3, 'learning_rate': 0.005612076437017399, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02318019645045279, 'dropout_rate_Layer_2': 0.020836942750441782, 'dropout_rate_Layer_3': 0.1371101028423672, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013976625324791047, 'l1_Layer_2': 0.08059546511511967, 'l1_Layer_3': 0.028119733339093688, 'n_units_Layer_1': 225, 'n_units_Layer_2': 55, 'n_units_Layer_3': 275}. Best is trial 257 with value: 2.6105727016548426.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.12 | sMAPE for Validation Set is: 8.19% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 2.11 | sMAPE for Test Set is: 5.60% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:44:18,324]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:44:20,413]\u001b[0m Trial 304 finished with value: 2.9966874365566833 and parameters: {'n_hidden': 3, 'learning_rate': 0.005797803210119471, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023447247209602878, 'dropout_rate_Layer_2': 0.0782762758434233, 'dropout_rate_Layer_3': 0.14326013035601715, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013055471035815507, 'l1_Layer_2': 0.07745064405279042, 'l1_Layer_3': 0.027049997009108807, 'n_units_Layer_1': 220, 'n_units_Layer_2': 50, 'n_units_Layer_3': 275}. Best is trial 257 with value: 2.6105727016548426.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.00 | sMAPE for Validation Set is: 7.85% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 1.96 | sMAPE for Test Set is: 5.15% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:44:27,277]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:44:27,694]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:44:37,852]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:44:42,693]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:44:52,832]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:44:59,663]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:45:03,077]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:45:19,504]\u001b[0m Trial 312 finished with value: 2.577128201987268 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013844394211023903, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3565011713296432, 'dropout_rate_Layer_2': 0.3062435590109054, 'dropout_rate_Layer_3': 0.24152524975197573, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.303653440079033e-05, 'l1_Layer_2': 0.0031436967650149586, 'l1_Layer_3': 1.4708572975565313e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 195, 'n_units_Layer_3': 230}. Best is trial 312 with value: 2.577128201987268.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.58 | sMAPE for Validation Set is: 6.87% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 2.04 | sMAPE for Test Set is: 5.51% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:45:29,075]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:45:32,246]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:45:37,106]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:45:41,883]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:45:47,225]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:46:08,923]\u001b[0m Trial 314 finished with value: 2.9008189865019958 and parameters: {'n_hidden': 3, 'learning_rate': 0.016158120904817084, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0346075431947451, 'dropout_rate_Layer_2': 0.019913025342868495, 'dropout_rate_Layer_3': 0.13728536882198067, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.014941588269622875, 'l1_Layer_2': 0.060069056018126905, 'l1_Layer_3': 0.026903014482418688, 'n_units_Layer_1': 235, 'n_units_Layer_2': 70, 'n_units_Layer_3': 260}. Best is trial 312 with value: 2.577128201987268.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.90 | sMAPE for Validation Set is: 7.61% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.02 | sMAPE for Test Set is: 5.30% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:46:11,614]\u001b[0m Trial 320 finished with value: 2.8034352449065483 and parameters: {'n_hidden': 3, 'learning_rate': 0.007562545715403725, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.031053174365729498, 'dropout_rate_Layer_2': 0.0768226730036332, 'dropout_rate_Layer_3': 0.15915275548147784, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009967979841235329, 'l1_Layer_2': 0.05767398266789163, 'l1_Layer_3': 2.2289226699838087e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 70, 'n_units_Layer_3': 265}. Best is trial 312 with value: 2.577128201987268.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.80 | sMAPE for Validation Set is: 7.40% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.91 | sMAPE for Test Set is: 5.02% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:46:53,347]\u001b[0m Trial 322 finished with value: 2.4776613505947744 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014105134444255378, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2154411253344479, 'dropout_rate_Layer_2': 0.30576353613030915, 'dropout_rate_Layer_3': 0.23971722696219694, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.489773485749999e-05, 'l1_Layer_2': 0.0023901905645972426, 'l1_Layer_3': 2.9300588988203262e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 160, 'n_units_Layer_3': 250}. Best is trial 322 with value: 2.4776613505947744.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.48 | sMAPE for Validation Set is: 6.61% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 1.86 | sMAPE for Test Set is: 4.92% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:47:18,717]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:47:28,297]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:47:40,142]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:47:50,198]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:47:53,305]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:48:00,193]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:48:04,940]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.92 | sMAPE for Validation Set is: 7.67% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 1.94 | sMAPE for Test Set is: 5.12% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:48:05,952]\u001b[0m Trial 321 finished with value: 2.915885835750587 and parameters: {'n_hidden': 3, 'learning_rate': 0.0052828138046616905, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02741318378153825, 'dropout_rate_Layer_2': 0.03421929820215154, 'dropout_rate_Layer_3': 0.1405122145046528, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02368757501590534, 'l1_Layer_2': 0.039422490727298094, 'l1_Layer_3': 0.019176336457539998, 'n_units_Layer_1': 230, 'n_units_Layer_2': 70, 'n_units_Layer_3': 265}. Best is trial 322 with value: 2.4776613505947744.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:48:12,269]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:48:24,658]\u001b[0m Trial 331 finished with value: 4.095523978300823 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011625213457171456, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34726878881135537, 'dropout_rate_Layer_2': 0.2911006501727251, 'dropout_rate_Layer_3': 0.23833808332641915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.831141544300104e-05, 'l1_Layer_2': 0.00010861677622330642, 'l1_Layer_3': 3.0525515184508684e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 205, 'n_units_Layer_3': 235}. Best is trial 322 with value: 2.4776613505947744.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.10 | sMAPE for Validation Set is: 10.60% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 3.63 | sMAPE for Test Set is: 9.58% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:48:29,695]\u001b[0m Trial 332 finished with value: 4.190686106166805 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014914560380576759, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34201507935301634, 'dropout_rate_Layer_2': 2.4072399064878347e-05, 'dropout_rate_Layer_3': 0.21983252710585227, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.0020795763986584e-05, 'l1_Layer_2': 0.00011633211841484623, 'l1_Layer_3': 3.819464921717723e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 245, 'n_units_Layer_3': 235}. Best is trial 322 with value: 2.4776613505947744.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 10.79% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 3.69 | sMAPE for Test Set is: 10.12% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:48:34,717]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:48:39,840]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:48:40,082]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:48:44,928]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:48:45,238]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:48:57,062]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:48:57,478]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:49:50,788]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:50:13,134]\u001b[0m Trial 342 finished with value: 2.5256578176913984 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009036854136601271, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20772426333333693, 'dropout_rate_Layer_2': 0.23711287227769393, 'dropout_rate_Layer_3': 0.18627038186239592, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011152852728280778, 'l1_Layer_2': 0.0006261336799551159, 'l1_Layer_3': 0.00016186352799682412, 'n_units_Layer_1': 155, 'n_units_Layer_2': 190, 'n_units_Layer_3': 185}. Best is trial 322 with value: 2.4776613505947744.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.53 | sMAPE for Validation Set is: 6.72% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 1.90 | sMAPE for Test Set is: 5.06% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:50:18,456]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:50:20,624]\u001b[0m Trial 340 finished with value: 2.852448205308541 and parameters: {'n_hidden': 3, 'learning_rate': 0.005270931941093408, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012695900189702236, 'dropout_rate_Layer_2': 0.048754243933268625, 'dropout_rate_Layer_3': 0.14242955544461688, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01841925292219535, 'l1_Layer_2': 0.050552050422680996, 'l1_Layer_3': 0.029384895101532017, 'n_units_Layer_1': 225, 'n_units_Layer_2': 70, 'n_units_Layer_3': 270}. Best is trial 322 with value: 2.4776613505947744.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.85 | sMAPE for Validation Set is: 7.51% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.94 | sMAPE for Test Set is: 5.09% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:50:25,093]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:50:27,889]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:50:33,274]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:50:37,465]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:51:24,343]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:51:29,762]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:51:36,243]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:52:18,662]\u001b[0m Trial 349 finished with value: 2.830338569531006 and parameters: {'n_hidden': 3, 'learning_rate': 0.005213447135170677, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02206790583823709, 'dropout_rate_Layer_2': 0.0257973191345966, 'dropout_rate_Layer_3': 0.15775101011931297, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02023305573801204, 'l1_Layer_2': 0.03032552011231552, 'l1_Layer_3': 0.03698657195646828, 'n_units_Layer_1': 230, 'n_units_Layer_2': 80, 'n_units_Layer_3': 260}. Best is trial 322 with value: 2.4776613505947744.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.83 | sMAPE for Validation Set is: 7.43% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.91 | sMAPE for Test Set is: 5.02% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:52:50,140]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:52:55,686]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:52:57,453]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:53:02,985]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:53:13,141]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:53:18,471]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:53:33,322]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:54:05,006]\u001b[0m Trial 355 finished with value: 3.024824023797303 and parameters: {'n_hidden': 3, 'learning_rate': 0.006846695928235156, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17865375819285806, 'dropout_rate_Layer_2': 0.0032724370123773036, 'dropout_rate_Layer_3': 0.1478220638735478, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.018097052197938217, 'l1_Layer_2': 0.03639709740034923, 'l1_Layer_3': 0.028370453312973033, 'n_units_Layer_1': 235, 'n_units_Layer_2': 70, 'n_units_Layer_3': 240}. Best is trial 322 with value: 2.4776613505947744.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.02 | sMAPE for Validation Set is: 7.96% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 2.04 | sMAPE for Test Set is: 5.37% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:54:15,471]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:54:29,938]\u001b[0m Trial 360 finished with value: 2.781893711773821 and parameters: {'n_hidden': 3, 'learning_rate': 0.004361034268978435, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010058262828308533, 'dropout_rate_Layer_2': 0.013971879058036157, 'dropout_rate_Layer_3': 0.12754275417849498, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01544789489559537, 'l1_Layer_2': 0.051793047541345005, 'l1_Layer_3': 0.04518383358017606, 'n_units_Layer_1': 240, 'n_units_Layer_2': 75, 'n_units_Layer_3': 255}. Best is trial 322 with value: 2.4776613505947744.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.78 | sMAPE for Validation Set is: 7.36% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.88 | sMAPE for Test Set is: 4.97% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:55:01,306]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:55:13,990]\u001b[0m Trial 362 finished with value: 2.9718672036325464 and parameters: {'n_hidden': 3, 'learning_rate': 0.005750022952622952, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3103516275777911, 'dropout_rate_Layer_2': 0.00774629087033803, 'dropout_rate_Layer_3': 0.14586324442865836, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01418052405735215, 'l1_Layer_2': 0.039201932574872415, 'l1_Layer_3': 0.028723435505702728, 'n_units_Layer_1': 240, 'n_units_Layer_2': 70, 'n_units_Layer_3': 240}. Best is trial 322 with value: 2.4776613505947744.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.97 | sMAPE for Validation Set is: 7.74% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 2.04 | sMAPE for Test Set is: 5.33% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:55:18,357]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:55:24,069]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:55:30,777]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:56:22,457]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:56:58,995]\u001b[0m Trial 364 finished with value: 2.7840096851878102 and parameters: {'n_hidden': 3, 'learning_rate': 0.0041269820406656076, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011919680175818933, 'dropout_rate_Layer_2': 0.011216998159505772, 'dropout_rate_Layer_3': 0.1287888360572834, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.013581662357097362, 'l1_Layer_2': 0.04121588486756502, 'l1_Layer_3': 0.03730669968604862, 'n_units_Layer_1': 260, 'n_units_Layer_2': 70, 'n_units_Layer_3': 240}. Best is trial 322 with value: 2.4776613505947744.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.78 | sMAPE for Validation Set is: 7.37% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.94 | sMAPE for Test Set is: 5.13% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:57:06,539]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:58:12,746]\u001b[0m Trial 369 finished with value: 2.8167147567329907 and parameters: {'n_hidden': 3, 'learning_rate': 0.004450073919469932, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012503796060277534, 'dropout_rate_Layer_2': 0.0005138816712001401, 'dropout_rate_Layer_3': 0.12974863369044157, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.017479347822082044, 'l1_Layer_2': 0.03911659220309832, 'l1_Layer_3': 0.037943897587272575, 'n_units_Layer_1': 240, 'n_units_Layer_2': 70, 'n_units_Layer_3': 245}. Best is trial 322 with value: 2.4776613505947744.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.82 | sMAPE for Validation Set is: 7.41% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.89 | sMAPE for Test Set is: 4.96% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:58:18,367]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:58:23,285]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:58:28,305]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:59:02,016]\u001b[0m Trial 371 finished with value: 2.783307956290645 and parameters: {'n_hidden': 3, 'learning_rate': 0.003730995836457046, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012945563073025506, 'dropout_rate_Layer_2': 0.0007898321637242519, 'dropout_rate_Layer_3': 0.12820625122503226, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.017122766098628454, 'l1_Layer_2': 0.03739188255682619, 'l1_Layer_3': 0.03515432841493602, 'n_units_Layer_1': 240, 'n_units_Layer_2': 70, 'n_units_Layer_3': 230}. Best is trial 322 with value: 2.4776613505947744.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.78 | sMAPE for Validation Set is: 7.32% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.95 | sMAPE for Test Set is: 5.09% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:59:53,286]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:59:58,681]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:00:03,120]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:00:07,781]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:00:13,523]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:00:50,442]\u001b[0m Trial 375 finished with value: 2.7998137327279458 and parameters: {'n_hidden': 3, 'learning_rate': 0.003827904925431073, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012415448759984689, 'dropout_rate_Layer_2': 0.004290156093695596, 'dropout_rate_Layer_3': 0.12813144957978462, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.015167870314957688, 'l1_Layer_2': 0.034257879854318454, 'l1_Layer_3': 0.040275585594704275, 'n_units_Layer_1': 240, 'n_units_Layer_2': 65, 'n_units_Layer_3': 245}. Best is trial 322 with value: 2.4776613505947744.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.80 | sMAPE for Validation Set is: 7.38% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.96 | sMAPE for Test Set is: 5.12% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:01:42,057]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:01:46,687]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:02:26,182]\u001b[0m Trial 381 finished with value: 2.775096591979653 and parameters: {'n_hidden': 3, 'learning_rate': 0.003847730133565342, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016290319944270264, 'dropout_rate_Layer_2': 0.017673751665678285, 'dropout_rate_Layer_3': 0.1266858897733592, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01277033397149506, 'l1_Layer_2': 0.054353516920817066, 'l1_Layer_3': 0.04897103601017941, 'n_units_Layer_1': 240, 'n_units_Layer_2': 65, 'n_units_Layer_3': 225}. Best is trial 322 with value: 2.4776613505947744.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.78 | sMAPE for Validation Set is: 7.33% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.88 | sMAPE for Test Set is: 4.95% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:02:48,391]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:02:53,322]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:03:08,176]\u001b[0m Trial 384 finished with value: 2.8919247342310364 and parameters: {'n_hidden': 3, 'learning_rate': 0.004520424703422393, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024079266349433092, 'dropout_rate_Layer_2': 0.015588699078854497, 'dropout_rate_Layer_3': 0.13374657629175535, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.019753981887584107, 'l1_Layer_2': 0.03581720395871927, 'l1_Layer_3': 0.028965155057623922, 'n_units_Layer_1': 235, 'n_units_Layer_2': 65, 'n_units_Layer_3': 230}. Best is trial 322 with value: 2.4776613505947744.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.89 | sMAPE for Validation Set is: 7.62% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 1.94 | sMAPE for Test Set is: 5.07% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:03:47,430]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:04:48,353]\u001b[0m Trial 389 finished with value: 2.4933842131723014 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006762869886600114, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21932617225126863, 'dropout_rate_Layer_2': 0.29985183321275877, 'dropout_rate_Layer_3': 0.15008758782696519, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0025116959646807e-05, 'l1_Layer_2': 0.001643373156440537, 'l1_Layer_3': 1.882923225356676e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 185, 'n_units_Layer_3': 300}. Best is trial 322 with value: 2.4776613505947744.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.49 | sMAPE for Validation Set is: 6.63% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 1.79 | sMAPE for Test Set is: 4.79% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:05:07,996]\u001b[0m Trial 388 finished with value: 2.811587006055665 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038906295205732425, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010247969831457121, 'dropout_rate_Layer_2': 0.00017348567552193128, 'dropout_rate_Layer_3': 0.12558464624473187, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.020567640821060287, 'l1_Layer_2': 0.0238091646480195, 'l1_Layer_3': 0.028636361950113504, 'n_units_Layer_1': 235, 'n_units_Layer_2': 65, 'n_units_Layer_3': 230}. Best is trial 322 with value: 2.4776613505947744.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.81 | sMAPE for Validation Set is: 7.43% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.87 | sMAPE for Test Set is: 4.92% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:05:42,167]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:07:13,389]\u001b[0m Trial 391 finished with value: 2.852200810309895 and parameters: {'n_hidden': 3, 'learning_rate': 0.004170559041911433, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009831844602955442, 'dropout_rate_Layer_2': 0.009894079051121623, 'dropout_rate_Layer_3': 0.12865737905285912, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01696704220600634, 'l1_Layer_2': 0.026440824773358036, 'l1_Layer_3': 0.04442180479624936, 'n_units_Layer_1': 240, 'n_units_Layer_2': 75, 'n_units_Layer_3': 220}. Best is trial 322 with value: 2.4776613505947744.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.85 | sMAPE for Validation Set is: 7.50% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.95 | sMAPE for Test Set is: 5.13% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:07:27,463]\u001b[0m Trial 392 finished with value: 2.762033367609844 and parameters: {'n_hidden': 3, 'learning_rate': 0.003930050819380618, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007749443904188269, 'dropout_rate_Layer_2': 0.011327467611602604, 'dropout_rate_Layer_3': 0.12551427876992113, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.023322578504186255, 'l1_Layer_2': 0.014417076194969371, 'l1_Layer_3': 0.03266377193213734, 'n_units_Layer_1': 240, 'n_units_Layer_2': 70, 'n_units_Layer_3': 225}. Best is trial 322 with value: 2.4776613505947744.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.76 | sMAPE for Validation Set is: 7.25% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 2.12 | sMAPE for Test Set is: 5.55% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:07:42,636]\u001b[0m Trial 394 finished with value: 2.824506753090374 and parameters: {'n_hidden': 3, 'learning_rate': 0.0333700248127018, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39360237727281333, 'dropout_rate_Layer_2': 0.12015239574795872, 'dropout_rate_Layer_3': 0.24683759446007092, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.022005111603635663, 'l1_Layer_2': 0.011920418429241625, 'l1_Layer_3': 7.162033191599321e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 145, 'n_units_Layer_3': 170}. Best is trial 322 with value: 2.4776613505947744.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.82 | sMAPE for Validation Set is: 7.47% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.32 | sMAPE for Test Set is: 6.18% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:08:09,109]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:08:33,929]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:09:32,860]\u001b[0m Trial 396 finished with value: 2.454780728594995 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007493609448617313, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17546572946939648, 'dropout_rate_Layer_2': 0.30047312982108065, 'dropout_rate_Layer_3': 0.14633455074360213, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.599983619704307e-05, 'l1_Layer_2': 0.0014087554850744123, 'l1_Layer_3': 1.7996011363707103e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 180, 'n_units_Layer_3': 295}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.45 | sMAPE for Validation Set is: 6.57% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 1.78 | sMAPE for Test Set is: 4.77% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:09:40,177]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:09:48,151]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:09:50,765]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:10:03,116]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:10:20,743]\u001b[0m Trial 400 finished with value: 2.578466816809813 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019469546615563764, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16648360625764833, 'dropout_rate_Layer_2': 0.05293176256711316, 'dropout_rate_Layer_3': 0.19997078252244627, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.017880681633653802, 'l1_Layer_2': 0.00017817049777841266, 'l1_Layer_3': 0.0005101215991106644, 'n_units_Layer_1': 105, 'n_units_Layer_2': 75, 'n_units_Layer_3': 300}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.58 | sMAPE for Validation Set is: 6.87% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.85 | sMAPE for Test Set is: 4.96% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:10:54,729]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:10:59,290]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:11:12,610]\u001b[0m Trial 405 finished with value: 2.9514975920025415 and parameters: {'n_hidden': 3, 'learning_rate': 0.037430537761248245, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39931089728464986, 'dropout_rate_Layer_2': 0.052396414567624214, 'dropout_rate_Layer_3': 0.20650914447968313, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.021301676799195236, 'l1_Layer_2': 0.015089240976993082, 'l1_Layer_3': 8.812705451108168e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 155, 'n_units_Layer_3': 175}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.95 | sMAPE for Validation Set is: 7.74% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 2.00 | sMAPE for Test Set is: 5.28% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:12:13,011]\u001b[0m Trial 403 finished with value: 2.8211387323578414 and parameters: {'n_hidden': 3, 'learning_rate': 0.004119748105082099, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.002708548977281207, 'dropout_rate_Layer_2': 0.00029458391598404974, 'dropout_rate_Layer_3': 0.11382423025567318, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.019432611797923983, 'l1_Layer_2': 0.031359769332975004, 'l1_Layer_3': 0.04389844327137857, 'n_units_Layer_1': 230, 'n_units_Layer_2': 60, 'n_units_Layer_3': 225}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.82 | sMAPE for Validation Set is: 7.45% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.92 | sMAPE for Test Set is: 5.04% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:13:14,711]\u001b[0m Trial 406 finished with value: 2.806937699646479 and parameters: {'n_hidden': 3, 'learning_rate': 0.004062525644097098, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0323296744286599, 'dropout_rate_Layer_2': 0.005504051937061033, 'dropout_rate_Layer_3': 0.1428748636375075, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.015507298769751404, 'l1_Layer_2': 0.054527674184614947, 'l1_Layer_3': 0.027905719882527928, 'n_units_Layer_1': 250, 'n_units_Layer_2': 80, 'n_units_Layer_3': 225}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.81 | sMAPE for Validation Set is: 7.41% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.90 | sMAPE for Test Set is: 5.00% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:14:45,305]\u001b[0m Trial 408 finished with value: 2.9139831506917377 and parameters: {'n_hidden': 3, 'learning_rate': 0.004000892261870848, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.032564122679467136, 'dropout_rate_Layer_2': 0.02575176479303002, 'dropout_rate_Layer_3': 0.10890324763700128, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.016039612229348063, 'l1_Layer_2': 0.011498843273346835, 'l1_Layer_3': 0.053040446222489115, 'n_units_Layer_1': 255, 'n_units_Layer_2': 80, 'n_units_Layer_3': 225}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.91 | sMAPE for Validation Set is: 7.67% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.00 | sMAPE for Test Set is: 5.24% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:14:50,632]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:15:04,975]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:15:14,703]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:15:52,173]\u001b[0m Trial 407 finished with value: 2.7249019441835483 and parameters: {'n_hidden': 3, 'learning_rate': 0.003998987686161167, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0010960425405470327, 'dropout_rate_Layer_2': 6.912567633051217e-06, 'dropout_rate_Layer_3': 0.12039765618602044, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01492011846913858, 'l1_Layer_2': 0.031622745157697495, 'l1_Layer_3': 0.048002868823297636, 'n_units_Layer_1': 255, 'n_units_Layer_2': 70, 'n_units_Layer_3': 225}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.72 | sMAPE for Validation Set is: 7.22% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 1.86 | sMAPE for Test Set is: 4.89% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:16:07,009]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:16:36,118]\u001b[0m Trial 414 finished with value: 2.513629561669333 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005287066215135938, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17734375259656182, 'dropout_rate_Layer_2': 0.24272013769041803, 'dropout_rate_Layer_3': 0.1469580372421299, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.429275920986924e-05, 'l1_Layer_2': 0.00026894810484627335, 'l1_Layer_3': 0.00017963565615029483, 'n_units_Layer_1': 180, 'n_units_Layer_2': 165, 'n_units_Layer_3': 260}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.51 | sMAPE for Validation Set is: 6.70% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 1.83 | sMAPE for Test Set is: 4.86% | rMAE for Test Set is: 0.55\n",
      "MAE for Validation Set is: 2.86 | sMAPE for Validation Set is: 7.52% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.98 | sMAPE for Test Set is: 5.19% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:17:01,973]\u001b[0m Trial 413 finished with value: 2.8631727634373103 and parameters: {'n_hidden': 3, 'learning_rate': 0.004029345014259005, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0003017103087315869, 'dropout_rate_Layer_2': 0.002611141951215262, 'dropout_rate_Layer_3': 0.10452855761120183, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01184446492116338, 'l1_Layer_2': 0.029403788787816337, 'l1_Layer_3': 0.06124159132715478, 'n_units_Layer_1': 255, 'n_units_Layer_2': 80, 'n_units_Layer_3': 225}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:17:12,068]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:17:32,285]\u001b[0m Trial 415 finished with value: 2.5212689426802166 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015616123976815567, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2010489294749163, 'dropout_rate_Layer_2': 0.03716962273587624, 'dropout_rate_Layer_3': 0.25951853807019365, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00639472676599316, 'l1_Layer_2': 0.0003203483138281408, 'l1_Layer_3': 0.0004967682752545795, 'n_units_Layer_1': 95, 'n_units_Layer_2': 80, 'n_units_Layer_3': 300}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.52 | sMAPE for Validation Set is: 6.73% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 1.81 | sMAPE for Test Set is: 4.86% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:18:01,278]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:18:25,814]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:18:30,693]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:18:52,003]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:19:22,275]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:19:22,777]\u001b[0m Trial 420 finished with value: 2.62038659632095 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016039346795619757, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16098155698494904, 'dropout_rate_Layer_2': 0.03855738481389291, 'dropout_rate_Layer_3': 0.2594450031756135, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007083467857181067, 'l1_Layer_2': 0.0002735035992348887, 'l1_Layer_3': 0.000514435020953705, 'n_units_Layer_1': 95, 'n_units_Layer_2': 80, 'n_units_Layer_3': 295}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.62 | sMAPE for Validation Set is: 6.99% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 1.82 | sMAPE for Test Set is: 4.91% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:19:30,334]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:19:34,705]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:20:23,677]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:21:24,851]\u001b[0m Trial 427 finished with value: 2.6044683540333584 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012156737009812236, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15574071161859943, 'dropout_rate_Layer_2': 0.02210590141977094, 'dropout_rate_Layer_3': 0.259520359605063, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00961801335964254, 'l1_Layer_2': 0.00028915781429210706, 'l1_Layer_3': 0.0006247328237428039, 'n_units_Layer_1': 110, 'n_units_Layer_2': 60, 'n_units_Layer_3': 290}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.60 | sMAPE for Validation Set is: 6.95% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 1.81 | sMAPE for Test Set is: 4.88% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:21:32,349]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:21:39,792]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:21:44,015]\u001b[0m Trial 426 finished with value: 2.7973304929679994 and parameters: {'n_hidden': 3, 'learning_rate': 0.004280368353885214, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.028020553781392454, 'dropout_rate_Layer_2': 0.01452749030465144, 'dropout_rate_Layer_3': 0.12085246049871577, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.011424008731221328, 'l1_Layer_2': 0.008914678334535377, 'l1_Layer_3': 0.048911483331044336, 'n_units_Layer_1': 245, 'n_units_Layer_2': 70, 'n_units_Layer_3': 235}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.80 | sMAPE for Validation Set is: 7.41% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.90 | sMAPE for Test Set is: 5.01% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:21:45,394]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:21:51,912]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:21:52,371]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:22:04,256]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:22:04,665]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:23:21,168]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:23:25,723]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:23:35,519]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:24:11,636]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:24:24,956]\u001b[0m Trial 439 finished with value: 2.624864150230223 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009012729666018361, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16921200925907282, 'dropout_rate_Layer_2': 0.02370190921021253, 'dropout_rate_Layer_3': 0.25787238936488677, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.011951048694861936, 'l1_Layer_2': 0.00021600242991446402, 'l1_Layer_3': 0.0007764087751826485, 'n_units_Layer_1': 110, 'n_units_Layer_2': 70, 'n_units_Layer_3': 295}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.62 | sMAPE for Validation Set is: 7.00% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 2.00 | sMAPE for Test Set is: 5.31% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:24:31,731]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:25:16,085]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:25:23,237]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:25:28,442]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:25:40,807]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:25:50,225]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:25:55,181]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:26:17,168]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:26:22,801]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:26:29,481]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:26:47,493]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:27:15,050]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:27:20,081]\u001b[0m Trial 451 finished with value: 2.568491602019447 and parameters: {'n_hidden': 3, 'learning_rate': 0.002287575544314407, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18111601600595978, 'dropout_rate_Layer_2': 0.03087694568311192, 'dropout_rate_Layer_3': 0.25619988567940505, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005611320836497921, 'l1_Layer_2': 0.00013650479783550455, 'l1_Layer_3': 0.00027873620423619514, 'n_units_Layer_1': 105, 'n_units_Layer_2': 65, 'n_units_Layer_3': 285}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.57 | sMAPE for Validation Set is: 6.83% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.88 | sMAPE for Test Set is: 5.03% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:27:38,903]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:27:51,541]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:27:58,298]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:28:38,504]\u001b[0m Trial 457 finished with value: 2.680738888186449 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007050421169578929, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1811226873041898, 'dropout_rate_Layer_2': 0.007146934132731757, 'dropout_rate_Layer_3': 0.21296149650649526, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0088667600029157, 'l1_Layer_2': 0.00015176837558532438, 'l1_Layer_3': 0.0002989486329328579, 'n_units_Layer_1': 100, 'n_units_Layer_2': 80, 'n_units_Layer_3': 285}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.68 | sMAPE for Validation Set is: 7.15% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 1.89 | sMAPE for Test Set is: 5.06% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:29:30,388]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:29:32,901]\u001b[0m Trial 454 finished with value: 2.866465291612863 and parameters: {'n_hidden': 3, 'learning_rate': 0.004244426030388915, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0448824784657496, 'dropout_rate_Layer_2': 0.018903425014406408, 'dropout_rate_Layer_3': 0.14093987696693833, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.023082551897623246, 'l1_Layer_2': 0.055730348377416895, 'l1_Layer_3': 0.026414990779275945, 'n_units_Layer_1': 240, 'n_units_Layer_2': 60, 'n_units_Layer_3': 245}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.87 | sMAPE for Validation Set is: 7.54% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.96 | sMAPE for Test Set is: 5.15% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:29:59,607]\u001b[0m Trial 459 finished with value: 2.7344637443144677 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023188914125859494, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35601780436974917, 'dropout_rate_Layer_2': 0.022240069513618843, 'dropout_rate_Layer_3': 0.2977304478506781, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008988390619192594, 'l1_Layer_2': 0.0005827679714755002, 'l1_Layer_3': 6.597645784855724e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 195, 'n_units_Layer_3': 165}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.73 | sMAPE for Validation Set is: 7.26% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.88 | sMAPE for Test Set is: 4.95% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:30:14,103]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:30:23,618]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:30:23,925]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:30:33,810]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:30:46,492]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:31:05,770]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:31:14,976]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:31:22,690]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:31:25,113]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:31:30,277]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:31:39,867]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:31:47,207]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:31:52,748]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:31:59,142]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:32:09,391]\u001b[0m Trial 469 finished with value: 2.472485535673145 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007994368939093828, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22688009831613717, 'dropout_rate_Layer_2': 0.24356274278579848, 'dropout_rate_Layer_3': 0.15476665384049149, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6117134452936162e-05, 'l1_Layer_2': 0.0010025780928408997, 'l1_Layer_3': 0.00017251017099480104, 'n_units_Layer_1': 180, 'n_units_Layer_2': 175, 'n_units_Layer_3': 250}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.47 | sMAPE for Validation Set is: 6.61% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 1.79 | sMAPE for Test Set is: 4.78% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:32:19,143]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:32:26,848]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:32:38,704]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:33:22,440]\u001b[0m Trial 475 finished with value: 2.534793142189083 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009255614393485955, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.062047662205631626, 'dropout_rate_Layer_2': 0.019267143912703292, 'dropout_rate_Layer_3': 0.2567260934968697, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0038494721459065096, 'l1_Layer_2': 0.0002327465459672453, 'l1_Layer_3': 0.0005952646567702183, 'n_units_Layer_1': 110, 'n_units_Layer_2': 90, 'n_units_Layer_3': 285}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.53 | sMAPE for Validation Set is: 6.78% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 1.90 | sMAPE for Test Set is: 5.15% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:33:28,164]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:34:04,966]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:34:19,665]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:34:24,561]\u001b[0m Trial 480 finished with value: 2.5033740151661066 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007084961898624828, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22699117667605787, 'dropout_rate_Layer_2': 0.32738452784807776, 'dropout_rate_Layer_3': 0.12514130448286231, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5540664743301013e-05, 'l1_Layer_2': 0.0011908056319541286, 'l1_Layer_3': 6.017656614425195e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 175, 'n_units_Layer_3': 300}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.50 | sMAPE for Validation Set is: 6.70% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 1.88 | sMAPE for Test Set is: 5.06% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:34:31,961]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:34:36,580]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:34:49,084]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:34:52,339]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:35:01,837]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:35:06,226]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:35:13,460]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:35:26,426]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:35:28,221]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:35:32,920]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:36:06,939]\u001b[0m Trial 493 finished with value: 2.720360849227763 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009324123368468155, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.057691621726414, 'dropout_rate_Layer_2': 0.001138434792849679, 'dropout_rate_Layer_3': 0.2837902850330804, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008351709464814358, 'l1_Layer_2': 0.00022561504753187942, 'l1_Layer_3': 0.0003996783115573006, 'n_units_Layer_1': 105, 'n_units_Layer_2': 75, 'n_units_Layer_3': 300}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.72 | sMAPE for Validation Set is: 7.22% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 1.90 | sMAPE for Test Set is: 5.08% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:36:24,376]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:36:29,554]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:36:37,122]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:36:41,964]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:36:42,481]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:36:54,907]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:37:04,925]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:37:53,630]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:37:54,155]\u001b[0m Trial 501 finished with value: 2.574327034177727 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006064210395154043, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03497436418404647, 'dropout_rate_Layer_2': 0.00018837688653437767, 'dropout_rate_Layer_3': 0.1763982487949679, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008562556220736857, 'l1_Layer_2': 0.00024010731940841395, 'l1_Layer_3': 0.00025812005342758183, 'n_units_Layer_1': 120, 'n_units_Layer_2': 75, 'n_units_Layer_3': 295}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.57 | sMAPE for Validation Set is: 6.88% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.91 | sMAPE for Test Set is: 5.10% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:38:03,587]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:38:11,542]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:38:41,224]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:38:51,282]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:39:01,335]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:39:12,964]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:39:22,605]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:39:42,260]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:39:52,516]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:40:46,624]\u001b[0m Trial 512 finished with value: 2.8463979740870955 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036875945887057076, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05288100367627429, 'dropout_rate_Layer_2': 0.015988289261465727, 'dropout_rate_Layer_3': 0.12923677296677719, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01362006050554874, 'l1_Layer_2': 0.04700500237101466, 'l1_Layer_3': 0.0243370799011607, 'n_units_Layer_1': 145, 'n_units_Layer_2': 55, 'n_units_Layer_3': 255}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.85 | sMAPE for Validation Set is: 7.50% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.88 | sMAPE for Test Set is: 4.93% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:40:53,057]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:41:03,485]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:41:25,516]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:41:35,185]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:41:40,245]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:41:45,086]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:41:57,424]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:42:01,798]\u001b[0m Trial 513 finished with value: 2.8427951281563524 and parameters: {'n_hidden': 3, 'learning_rate': 0.005263295833802767, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.051340220781597834, 'dropout_rate_Layer_2': 0.025400112896016427, 'dropout_rate_Layer_3': 0.1424085584696622, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01247422883805634, 'l1_Layer_2': 0.02183919726218611, 'l1_Layer_3': 0.04174010819784239, 'n_units_Layer_1': 255, 'n_units_Layer_2': 70, 'n_units_Layer_3': 260}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.84 | sMAPE for Validation Set is: 7.50% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.89 | sMAPE for Test Set is: 4.97% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:42:04,051]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:42:16,720]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:42:28,778]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:42:50,422]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:42:58,093]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:43:05,709]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:43:11,063]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:43:15,733]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:43:25,604]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:43:27,460]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:43:29,869]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:43:49,989]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:43:57,582]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:44:04,528]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:44:12,279]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:44:21,432]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:44:29,016]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:44:29,232]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:44:39,687]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:44:49,609]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:45:12,287]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:45:17,064]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:45:23,795]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:45:31,447]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:45:41,489]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:45:51,320]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:45:56,389]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:46:08,112]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:46:15,287]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:46:23,541]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:46:30,094]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:47:09,238]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:47:16,581]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:47:36,718]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:47:42,176]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:47:46,450]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:47:51,760]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:48:11,767]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:48:19,282]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:48:48,804]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:49:17,904]\u001b[0m Trial 562 finished with value: 2.505765468412715 and parameters: {'n_hidden': 3, 'learning_rate': 0.000545539130166281, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18568855138228085, 'dropout_rate_Layer_2': 0.2503184304674766, 'dropout_rate_Layer_3': 0.11670266932665838, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.086340659801433e-05, 'l1_Layer_2': 0.00017299792493264703, 'l1_Layer_3': 0.0002069405135959435, 'n_units_Layer_1': 180, 'n_units_Layer_2': 175, 'n_units_Layer_3': 285}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.51 | sMAPE for Validation Set is: 6.69% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 1.91 | sMAPE for Test Set is: 5.08% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:49:23,024]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:49:43,585]\u001b[0m Trial 553 finished with value: 2.8316320001524034 and parameters: {'n_hidden': 3, 'learning_rate': 0.005134004352502695, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0074685306730109735, 'dropout_rate_Layer_2': 0.007457104646865914, 'dropout_rate_Layer_3': 0.16201796584410827, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.011230247359386264, 'l1_Layer_2': 0.06572502421846388, 'l1_Layer_3': 0.04280407198807078, 'n_units_Layer_1': 230, 'n_units_Layer_2': 65, 'n_units_Layer_3': 235}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.83 | sMAPE for Validation Set is: 7.44% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.00 | sMAPE for Test Set is: 5.26% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:49:58,216]\u001b[0m Trial 564 finished with value: 2.6648992309712387 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018174226532286298, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17321688749159256, 'dropout_rate_Layer_2': 0.036437956321850935, 'dropout_rate_Layer_3': 0.28116792833691423, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0036793376364287864, 'l1_Layer_2': 0.00017577420036611298, 'l1_Layer_3': 0.0013411998250909675, 'n_units_Layer_1': 95, 'n_units_Layer_2': 85, 'n_units_Layer_3': 90}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.66 | sMAPE for Validation Set is: 7.08% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.94 | sMAPE for Test Set is: 5.13% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:50:10,161]\u001b[0m Trial 565 finished with value: 2.944611692659459 and parameters: {'n_hidden': 3, 'learning_rate': 0.023119258043424493, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3872290987128588, 'dropout_rate_Layer_2': 0.21537621433266252, 'dropout_rate_Layer_3': 0.2572368681897216, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015806786040569266, 'l1_Layer_2': 0.022622842308919262, 'l1_Layer_3': 4.984597356077326e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 155, 'n_units_Layer_3': 215}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.94 | sMAPE for Validation Set is: 7.71% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 2.18 | sMAPE for Test Set is: 5.79% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:50:15,246]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:50:32,844]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:50:37,071]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:50:37,629]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:50:42,248]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:50:44,536]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:50:52,274]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:50:54,633]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:51:01,777]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:51:41,254]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:51:46,210]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:51:56,247]\u001b[0m Trial 576 finished with value: 2.7703312082042015 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020161767291952096, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17466830610527317, 'dropout_rate_Layer_2': 0.010104635585066798, 'dropout_rate_Layer_3': 0.2958517310361541, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01521915486761604, 'l1_Layer_2': 0.00413531749028428, 'l1_Layer_3': 0.0019093222152791222, 'n_units_Layer_1': 70, 'n_units_Layer_2': 75, 'n_units_Layer_3': 290}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.77 | sMAPE for Validation Set is: 7.33% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.90 | sMAPE for Test Set is: 5.01% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:52:12,682]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:52:51,686]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:52:56,655]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:53:09,030]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:53:14,838]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:53:19,775]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:53:24,436]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:53:29,207]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:53:33,999]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:53:41,369]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:53:51,580]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:54:01,536]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:54:13,144]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:54:18,116]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:54:24,952]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:54:30,498]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:54:36,100]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:54:40,299]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:54:52,752]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:55:12,380]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:55:17,554]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:55:29,677]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:55:34,123]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:55:44,533]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:55:51,107]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:56:01,297]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:56:08,710]\u001b[0m Trial 591 finished with value: 2.824872582531508 and parameters: {'n_hidden': 3, 'learning_rate': 0.005201373185418395, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019074466835809895, 'dropout_rate_Layer_2': 0.0005301296730403989, 'dropout_rate_Layer_3': 0.12243320225860518, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.022652761123985593, 'l1_Layer_2': 0.028115033702383396, 'l1_Layer_3': 0.062458217606887495, 'n_units_Layer_1': 250, 'n_units_Layer_2': 65, 'n_units_Layer_3': 235}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.82 | sMAPE for Validation Set is: 7.45% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.95 | sMAPE for Test Set is: 5.14% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:56:15,665]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:56:16,477]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:56:23,597]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:56:28,498]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:56:30,494]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:56:32,859]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:56:37,919]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:56:52,754]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:57:12,878]\u001b[0m Trial 614 finished with value: 2.789549696396627 and parameters: {'n_hidden': 3, 'learning_rate': 0.006142871379650346, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38332261389774114, 'dropout_rate_Layer_2': 0.11222584769621115, 'dropout_rate_Layer_3': 0.3184926025288441, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005724103818440389, 'l1_Layer_2': 0.006077025354822812, 'l1_Layer_3': 1.9342810235987612e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 65, 'n_units_Layer_3': 210}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.79 | sMAPE for Validation Set is: 7.36% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.98 | sMAPE for Test Set is: 5.26% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:57:19,671]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:57:24,665]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:57:31,889]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:57:51,663]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:57:57,096]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:58:16,608]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:58:26,172]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:58:36,059]\u001b[0m Trial 613 finished with value: 2.799153621911558 and parameters: {'n_hidden': 3, 'learning_rate': 0.0039117265984434805, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.025447385934837675, 'dropout_rate_Layer_2': 0.02468683016795832, 'dropout_rate_Layer_3': 0.10787570900097483, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010468467134843739, 'l1_Layer_2': 0.0465809579997961, 'l1_Layer_3': 0.09438773217026203, 'n_units_Layer_1': 235, 'n_units_Layer_2': 65, 'n_units_Layer_3': 230}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.80 | sMAPE for Validation Set is: 7.40% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.89 | sMAPE for Test Set is: 4.96% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:58:40,525]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:58:43,246]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:58:53,137]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:58:55,942]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:59:07,812]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:59:30,606]\u001b[0m Trial 628 finished with value: 3.1078947123380125 and parameters: {'n_hidden': 3, 'learning_rate': 0.007971262005443926, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2035243031369123, 'dropout_rate_Layer_2': 0.2720054209599734, 'dropout_rate_Layer_3': 0.1673036194564999, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.301993328004521e-05, 'l1_Layer_2': 0.0028742624364383462, 'l1_Layer_3': 0.014789071275698413, 'n_units_Layer_1': 295, 'n_units_Layer_2': 195, 'n_units_Layer_3': 280}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.11 | sMAPE for Validation Set is: 8.06% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 2.03 | sMAPE for Test Set is: 5.34% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 00:59:35,429]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:59:50,084]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 00:59:52,963]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:00:00,102]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:00:00,530]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:00:05,943]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:00:13,258]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:00:13,530]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:00:21,172]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:00:26,020]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:00:26,135]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:00:31,636]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:00:35,751]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:00:51,355]\u001b[0m Trial 639 finished with value: 2.7949617807736384 and parameters: {'n_hidden': 3, 'learning_rate': 0.004528586550572262, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3996667793419777, 'dropout_rate_Layer_2': 0.0980892128699038, 'dropout_rate_Layer_3': 0.34902104041556203, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005353803372475711, 'l1_Layer_2': 0.01365200258508882, 'l1_Layer_3': 4.432317264674721e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 85, 'n_units_Layer_3': 220}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.79 | sMAPE for Validation Set is: 7.38% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.00 | sMAPE for Test Set is: 5.31% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:00:58,097]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:01:03,859]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:01:10,472]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:01:16,338]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:01:20,452]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:01:27,940]\u001b[0m Trial 643 finished with value: 2.678021042813136 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037860999073072474, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2175871211546677, 'dropout_rate_Layer_2': 0.07106415881676138, 'dropout_rate_Layer_3': 0.24152253293300918, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010645105160413641, 'l1_Layer_2': 0.005496041026451792, 'l1_Layer_3': 0.0010087230739054083, 'n_units_Layer_1': 95, 'n_units_Layer_2': 90, 'n_units_Layer_3': 95}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.68 | sMAPE for Validation Set is: 7.13% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.89 | sMAPE for Test Set is: 5.08% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:01:28,225]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:01:35,648]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:01:37,414]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:01:40,113]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:01:44,928]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:01:52,567]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:01:57,897]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:02:02,638]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:02:07,244]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:02:15,450]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:02:19,546]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:02:27,519]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:02:41,906]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:02:49,752]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:02:50,161]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:02:55,771]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:03:00,153]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:03:04,678]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:03:14,638]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:03:17,483]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:03:21,909]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:03:25,026]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:03:32,370]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:03:39,101]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:03:46,722]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:03:48,981]\u001b[0m Trial 671 finished with value: 2.70406469997747 and parameters: {'n_hidden': 3, 'learning_rate': 0.008316522341276038, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38877987682590776, 'dropout_rate_Layer_2': 0.1939476896726531, 'dropout_rate_Layer_3': 0.30787253111588764, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0026115173141110465, 'l1_Layer_2': 0.0011143919066729589, 'l1_Layer_3': 0.0001426897009023624, 'n_units_Layer_1': 85, 'n_units_Layer_2': 95, 'n_units_Layer_3': 260}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.70 | sMAPE for Validation Set is: 7.19% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 2.03 | sMAPE for Test Set is: 5.42% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:03:54,257]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:04:01,334]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.89 | sMAPE for Validation Set is: 7.60% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.00 | sMAPE for Test Set is: 5.35% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:04:10,988]\u001b[0m Trial 674 finished with value: 2.8916622391137774 and parameters: {'n_hidden': 3, 'learning_rate': 0.01055961147305824, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39976645742803846, 'dropout_rate_Layer_2': 0.13104643373697933, 'dropout_rate_Layer_3': 0.23007869750256443, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009888577270070413, 'l1_Layer_2': 0.013298262804782777, 'l1_Layer_3': 5.174564729082593e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 95, 'n_units_Layer_3': 215}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:04:13,829]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:04:15,879]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:04:20,439]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:04:26,031]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:04:53,357]\u001b[0m Trial 680 finished with value: 2.66467299732194 and parameters: {'n_hidden': 3, 'learning_rate': 0.004418649864693725, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03279184265951958, 'dropout_rate_Layer_2': 0.031494619306891215, 'dropout_rate_Layer_3': 0.2314845900497111, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005961092976178603, 'l1_Layer_2': 0.005480804156806058, 'l1_Layer_3': 0.0017405402470202101, 'n_units_Layer_1': 285, 'n_units_Layer_2': 95, 'n_units_Layer_3': 90}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.66 | sMAPE for Validation Set is: 7.11% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.84 | sMAPE for Test Set is: 4.85% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:05:17,091]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:05:22,358]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:06:28,658]\u001b[0m Trial 683 finished with value: 2.8302057316138978 and parameters: {'n_hidden': 3, 'learning_rate': 0.004322454399889113, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00800044462222409, 'dropout_rate_Layer_2': 0.019081344540918803, 'dropout_rate_Layer_3': 0.15705612462861795, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.014405088671813499, 'l1_Layer_2': 0.034035204292586954, 'l1_Layer_3': 0.053881884350254414, 'n_units_Layer_1': 250, 'n_units_Layer_2': 190, 'n_units_Layer_3': 260}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.83 | sMAPE for Validation Set is: 7.49% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.86 | sMAPE for Test Set is: 4.89% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:06:33,319]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:06:46,106]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:06:55,617]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:07:20,198]\u001b[0m Trial 685 finished with value: 2.7513160874013347 and parameters: {'n_hidden': 3, 'learning_rate': 0.003711143736547609, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008710575010629471, 'dropout_rate_Layer_2': 0.007113572638119396, 'dropout_rate_Layer_3': 0.14545253302476532, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.024196192784910867, 'l1_Layer_2': 0.017933368330769462, 'l1_Layer_3': 0.01924449934736179, 'n_units_Layer_1': 260, 'n_units_Layer_2': 70, 'n_units_Layer_3': 225}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.75 | sMAPE for Validation Set is: 7.29% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.92 | sMAPE for Test Set is: 5.06% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:07:33,738]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:07:43,263]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:07:48,016]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:07:52,436]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:07:57,874]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:07:58,074]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:08:03,769]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:08:08,439]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:08:11,373]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:08:16,192]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:08:21,378]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:08:23,623]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:08:28,342]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:08:45,876]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:09:00,316]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:09:05,635]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:09:28,248]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:09:34,799]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:09:40,591]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:09:47,626]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:09:54,821]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:10:01,849]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:10:07,230]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:10:12,275]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:10:51,151]\u001b[0m Trial 702 finished with value: 2.8075380089207513 and parameters: {'n_hidden': 3, 'learning_rate': 0.003961460028059645, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008247006154873516, 'dropout_rate_Layer_2': 0.032155418554839596, 'dropout_rate_Layer_3': 0.17689705804916475, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01220738726188809, 'l1_Layer_2': 0.02704139414031292, 'l1_Layer_3': 0.03132371985487863, 'n_units_Layer_1': 265, 'n_units_Layer_2': 65, 'n_units_Layer_3': 215}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.81 | sMAPE for Validation Set is: 7.43% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.86 | sMAPE for Test Set is: 4.88% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:11:03,390]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:11:13,821]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:11:18,496]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:11:25,821]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:11:40,109]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:11:48,390]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:11:55,152]\u001b[0m Trial 714 finished with value: 2.7782190456692284 and parameters: {'n_hidden': 3, 'learning_rate': 0.004501863576424941, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00011377973134358012, 'dropout_rate_Layer_2': 0.007544289531403958, 'dropout_rate_Layer_3': 0.12234201419613433, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.05027001711224989, 'l1_Layer_2': 0.026527542453257575, 'l1_Layer_3': 0.030268064735984226, 'n_units_Layer_1': 230, 'n_units_Layer_2': 195, 'n_units_Layer_3': 255}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.78 | sMAPE for Validation Set is: 7.35% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.88 | sMAPE for Test Set is: 4.94% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:11:55,373]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:12:05,335]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:12:10,747]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:12:11,126]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:12:18,869]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:12:23,658]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:12:33,435]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:12:43,365]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:12:57,652]\u001b[0m Trial 730 finished with value: 13.061545193368493 and parameters: {'n_hidden': 3, 'learning_rate': 0.032116172598832385, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15349116023460824, 'dropout_rate_Layer_2': 0.1988471698499724, 'dropout_rate_Layer_3': 0.2207095150186238, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 9.136484728363868e-05, 'l1_Layer_2': 0.0016994216210669381, 'l1_Layer_3': 0.00021988115897006338, 'n_units_Layer_1': 190, 'n_units_Layer_2': 185, 'n_units_Layer_3': 220}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.06 | sMAPE for Validation Set is: 33.71% | rMAE for Validation Set is: 2.70\n",
      "MAE for Test Set is: 8.71 | sMAPE for Test Set is: 23.53% | rMAE for Test Set is: 2.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:13:04,854]\u001b[0m Trial 729 finished with value: 2.646749013202816 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027242889722371858, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1777755692220015, 'dropout_rate_Layer_2': 0.24160773571826158, 'dropout_rate_Layer_3': 0.2681907766748074, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008808148201842675, 'l1_Layer_2': 0.00020789123878509365, 'l1_Layer_3': 0.0006942971066449203, 'n_units_Layer_1': 100, 'n_units_Layer_2': 105, 'n_units_Layer_3': 290}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.65 | sMAPE for Validation Set is: 7.04% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.91 | sMAPE for Test Set is: 5.03% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:13:10,537]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:13:17,709]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:13:24,434]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:13:27,166]\u001b[0m Trial 733 finished with value: 3.0515611714002584 and parameters: {'n_hidden': 3, 'learning_rate': 0.023787486857448772, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38954819683915715, 'dropout_rate_Layer_2': 0.15362784097440624, 'dropout_rate_Layer_3': 0.25861993737463285, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.026457083469732585, 'l1_Layer_2': 0.009615221747598057, 'l1_Layer_3': 5.724376460384781e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 140, 'n_units_Layer_3': 195}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.05 | sMAPE for Validation Set is: 7.92% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 2.52 | sMAPE for Test Set is: 6.68% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:13:29,268]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:13:33,912]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:13:39,681]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:13:44,443]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:13:49,860]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:13:59,718]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:14:02,032]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:14:14,504]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:14:21,344]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:14:48,235]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:14:55,621]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:14:59,009]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:15:03,443]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:15:11,146]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:15:18,384]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:15:37,923]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:15:38,605]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:15:43,115]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:15:52,347]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:15:57,699]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:16:04,479]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:16:12,274]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:16:34,905]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:16:39,898]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:16:48,699]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:16:51,785]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:16:56,088]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:16:59,043]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:17:01,890]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:17:04,261]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:17:09,170]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:17:13,566]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:17:13,927]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:17:19,366]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:17:21,811]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:17:28,672]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:17:41,166]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:17:49,000]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:17:51,310]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:17:58,454]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:17:58,773]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:18:04,390]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:18:04,419]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:18:13,572]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:18:16,685]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:18:48,206]\u001b[0m Trial 781 finished with value: 2.5043450330045194 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005493328481798192, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2183478312281678, 'dropout_rate_Layer_2': 0.2177136558497217, 'dropout_rate_Layer_3': 0.1093751330333792, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.0468487247538864e-05, 'l1_Layer_2': 0.0002446675558453921, 'l1_Layer_3': 0.0005003495964033849, 'n_units_Layer_1': 180, 'n_units_Layer_2': 155, 'n_units_Layer_3': 280}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.50 | sMAPE for Validation Set is: 6.67% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 1.91 | sMAPE for Test Set is: 5.13% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:18:53,327]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:19:32,678]\u001b[0m Trial 780 finished with value: 2.818721232716154 and parameters: {'n_hidden': 3, 'learning_rate': 0.00536352652696638, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0220044295313001, 'dropout_rate_Layer_2': 0.013229661284804886, 'dropout_rate_Layer_3': 0.10891208623627788, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03264366360166937, 'l1_Layer_2': 0.05240534726452455, 'l1_Layer_3': 0.024641710336064476, 'n_units_Layer_1': 250, 'n_units_Layer_2': 60, 'n_units_Layer_3': 230}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.82 | sMAPE for Validation Set is: 7.40% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.09 | sMAPE for Test Set is: 5.53% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:19:45,280]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:19:49,851]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:19:54,828]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:20:02,601]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:20:06,947]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:20:13,991]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:20:34,485]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:20:53,630]\u001b[0m Trial 791 finished with value: 2.5848843842778124 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008076045366154019, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21648837240602217, 'dropout_rate_Layer_2': 0.1849093546378083, 'dropout_rate_Layer_3': 0.11437850171510203, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.16112847593056e-05, 'l1_Layer_2': 0.00016926465261624557, 'l1_Layer_3': 0.0002990990411573586, 'n_units_Layer_1': 200, 'n_units_Layer_2': 155, 'n_units_Layer_3': 280}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.58 | sMAPE for Validation Set is: 6.88% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 1.87 | sMAPE for Test Set is: 5.00% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:20:59,453]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:21:03,973]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:21:14,097]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:21:21,512]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:21:23,834]\u001b[0m Trial 787 finished with value: 2.7962913968531997 and parameters: {'n_hidden': 3, 'learning_rate': 0.005790725199222896, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.022708974051557036, 'dropout_rate_Layer_2': 0.01498423223759119, 'dropout_rate_Layer_3': 0.11158784838604333, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03430615628729567, 'l1_Layer_2': 0.045312243709366457, 'l1_Layer_3': 0.01776524682812674, 'n_units_Layer_1': 255, 'n_units_Layer_2': 60, 'n_units_Layer_3': 235}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.80 | sMAPE for Validation Set is: 7.37% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.88 | sMAPE for Test Set is: 4.93% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:21:31,337]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:21:33,498]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:21:43,545]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:21:50,458]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:21:56,250]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:22:00,292]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:22:10,933]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:22:18,035]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:22:20,560]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:22:27,752]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:22:37,932]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:22:42,389]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:22:45,062]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:22:47,656]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:22:52,624]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:22:59,590]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:23:04,763]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:23:12,103]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:23:19,670]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:23:26,743]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:23:34,406]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:23:39,069]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:23:46,501]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:23:53,907]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:24:04,505]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:24:11,963]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:24:16,429]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:24:26,955]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:24:53,566]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:25:32,875]\u001b[0m Trial 813 finished with value: 2.7713552744472936 and parameters: {'n_hidden': 3, 'learning_rate': 0.0066652601614413205, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012335914898993276, 'dropout_rate_Layer_2': 2.1379902731211153e-05, 'dropout_rate_Layer_3': 0.093909871493974, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02249510056448715, 'l1_Layer_2': 0.0732746653340888, 'l1_Layer_3': 0.028310186180048356, 'n_units_Layer_1': 285, 'n_units_Layer_2': 55, 'n_units_Layer_3': 245}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.77 | sMAPE for Validation Set is: 7.32% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.92 | sMAPE for Test Set is: 5.06% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:25:38,157]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:25:43,166]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:25:52,759]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:26:05,263]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:26:15,040]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:26:22,369]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:26:44,670]\u001b[0m Trial 833 finished with value: 2.9988236925988225 and parameters: {'n_hidden': 3, 'learning_rate': 0.004529544621924943, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33005580740511953, 'dropout_rate_Layer_2': 0.06029852113394911, 'dropout_rate_Layer_3': 0.2139277044124005, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010818895864969466, 'l1_Layer_2': 0.001736868926949148, 'l1_Layer_3': 0.0014194971690610644, 'n_units_Layer_1': 55, 'n_units_Layer_2': 170, 'n_units_Layer_3': 215}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.00 | sMAPE for Validation Set is: 7.86% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 2.10 | sMAPE for Test Set is: 5.60% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:26:59,031]\u001b[0m Trial 834 finished with value: 2.993420551351551 and parameters: {'n_hidden': 3, 'learning_rate': 0.011700777306931585, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20362879112716528, 'dropout_rate_Layer_2': 0.2771560626506344, 'dropout_rate_Layer_3': 0.13286265186633522, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.022999682361071527, 'l1_Layer_2': 6.297738879422897e-05, 'l1_Layer_3': 0.00010536357005332366, 'n_units_Layer_1': 175, 'n_units_Layer_2': 200, 'n_units_Layer_3': 270}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.99 | sMAPE for Validation Set is: 7.77% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 2.10 | sMAPE for Test Set is: 5.51% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:27:09,339]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:27:14,296]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:27:17,059]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:27:21,350]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:27:31,048]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:27:31,383]\u001b[0m Trial 830 finished with value: 2.7783871275175436 and parameters: {'n_hidden': 3, 'learning_rate': 0.006499736982219115, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012632754150985505, 'dropout_rate_Layer_2': 2.109934835231933e-05, 'dropout_rate_Layer_3': 0.09900043766116906, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.022096257145964242, 'l1_Layer_2': 0.08641045680583372, 'l1_Layer_3': 0.02250894262278665, 'n_units_Layer_1': 280, 'n_units_Layer_2': 55, 'n_units_Layer_3': 245}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.78 | sMAPE for Validation Set is: 7.35% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.86 | sMAPE for Test Set is: 4.89% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:27:38,498]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:28:25,062]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:28:32,451]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:28:38,492]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:28:57,841]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:29:02,975]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:29:14,949]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:29:24,702]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:29:44,562]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:29:54,071]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:29:57,238]\u001b[0m Trial 842 finished with value: 2.7748511491985073 and parameters: {'n_hidden': 3, 'learning_rate': 0.007009539299295127, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026495353468648244, 'dropout_rate_Layer_2': 0.0012295862520940969, 'dropout_rate_Layer_3': 0.09036024757714033, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.023486567912748182, 'l1_Layer_2': 0.09365294109116903, 'l1_Layer_3': 0.018068380048795428, 'n_units_Layer_1': 280, 'n_units_Layer_2': 60, 'n_units_Layer_3': 250}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.77 | sMAPE for Validation Set is: 7.36% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.90 | sMAPE for Test Set is: 4.98% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:30:01,065]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:30:05,961]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:30:21,099]\u001b[0m Trial 854 finished with value: 2.8884834986425645 and parameters: {'n_hidden': 3, 'learning_rate': 0.025492475628826297, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38072692179834594, 'dropout_rate_Layer_2': 0.04272701225213857, 'dropout_rate_Layer_3': 0.26350590372080407, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.016004394935133524, 'l1_Layer_2': 0.012647833151238254, 'l1_Layer_3': 0.00042415814303663175, 'n_units_Layer_1': 65, 'n_units_Layer_2': 55, 'n_units_Layer_3': 300}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.89 | sMAPE for Validation Set is: 7.59% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.01 | sMAPE for Test Set is: 5.30% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:30:30,799]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:30:35,614]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:30:50,645]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:31:10,751]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:31:19,928]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:31:29,895]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:31:37,016]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:31:47,233]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:31:52,560]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:32:12,085]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:32:21,800]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:32:28,448]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:32:35,465]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:32:39,207]\u001b[0m Trial 857 finished with value: 2.773959588178709 and parameters: {'n_hidden': 3, 'learning_rate': 0.002309207403183226, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014606534383048401, 'dropout_rate_Layer_2': 0.0002811477877625243, 'dropout_rate_Layer_3': 0.09158005278317814, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03969859915428244, 'l1_Layer_2': 0.072800194292672, 'l1_Layer_3': 0.016314061451855745, 'n_units_Layer_1': 280, 'n_units_Layer_2': 60, 'n_units_Layer_3': 250}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.77 | sMAPE for Validation Set is: 7.35% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.87 | sMAPE for Test Set is: 4.95% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:32:43,801]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:32:48,296]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:32:50,777]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:32:56,060]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:33:00,657]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:33:10,090]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:33:15,089]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:33:20,555]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:33:32,860]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:33:40,019]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:33:44,624]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:33:50,324]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:33:54,392]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:34:02,045]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:34:02,523]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:34:07,341]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:34:16,655]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:34:17,193]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:34:24,876]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:34:30,083]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:34:35,079]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:34:44,336]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:34:47,128]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:34:53,697]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:34:59,635]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:35:04,245]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:35:11,333]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:35:29,019]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:35:33,990]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:35:43,757]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:35:50,669]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:36:00,625]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:36:07,695]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:36:13,359]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:36:18,141]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:36:23,184]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:36:28,198]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:36:32,533]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:36:42,281]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:36:47,328]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:36:52,556]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:36:57,155]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:36:57,336]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:37:05,346]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:37:09,538]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:37:15,150]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:37:15,265]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:37:21,806]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:37:24,537]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:37:29,865]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:37:41,784]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:37:51,634]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:37:59,187]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:38:10,799]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:38:48,204]\u001b[0m Trial 920 finished with value: 2.496675632084326 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005853278282156416, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20107692301896063, 'dropout_rate_Layer_2': 0.2607609213119972, 'dropout_rate_Layer_3': 0.08750444602203522, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3321963522845464e-05, 'l1_Layer_2': 0.0037319877832547713, 'l1_Layer_3': 7.938696820081827e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 180, 'n_units_Layer_3': 265}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.50 | sMAPE for Validation Set is: 6.67% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 1.80 | sMAPE for Test Set is: 4.80% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:38:53,599]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:39:00,431]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:39:00,622]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:39:08,550]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:39:10,707]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:39:20,730]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:39:25,212]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:39:28,086]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:39:49,730]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:39:53,099]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:39:56,912]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:39:57,631]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:40:02,121]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:40:04,640]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:40:10,021]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:40:12,533]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:40:31,683]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:40:36,661]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:40:43,936]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:40:51,076]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:41:06,122]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:41:11,316]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:41:11,488]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:41:19,369]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:41:19,896]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:41:27,643]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:41:29,766]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:41:39,731]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:41:47,320]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:41:49,842]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:41:54,320]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:42:01,873]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:42:08,804]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:42:16,193]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:42:22,139]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:42:29,086]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:42:41,623]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:42:46,552]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:42:49,258]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:42:53,933]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:42:56,632]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:42:59,607]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:43:01,603]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:43:06,502]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:43:11,702]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:43:16,663]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:43:20,590]\u001b[0m Trial 966 finished with value: 2.9422457137986933 and parameters: {'n_hidden': 3, 'learning_rate': 0.023232924836562942, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3810209893048685, 'dropout_rate_Layer_2': 0.02051080741056402, 'dropout_rate_Layer_3': 0.266479051047761, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01627095296755133, 'l1_Layer_2': 0.013424015085388962, 'l1_Layer_3': 0.000472820158893621, 'n_units_Layer_1': 70, 'n_units_Layer_2': 55, 'n_units_Layer_3': 290}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.94 | sMAPE for Validation Set is: 7.74% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 1.99 | sMAPE for Test Set is: 5.30% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:43:21,037]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:43:26,017]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:43:30,698]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:43:36,307]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:43:40,962]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:43:45,620]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:43:51,092]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:43:57,526]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:44:03,355]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:44:17,837]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:44:27,431]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:44:30,296]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:44:32,286]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:44:37,050]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:44:41,742]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:44:41,978]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:44:54,976]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:45:02,591]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:45:09,770]\u001b[0m Trial 987 finished with value: 2.7093580996479623 and parameters: {'n_hidden': 3, 'learning_rate': 0.003968295854510427, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16560180058348442, 'dropout_rate_Layer_2': 0.3942065937635972, 'dropout_rate_Layer_3': 0.24697489010392362, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024933819258961027, 'l1_Layer_2': 0.00016129046678900632, 'l1_Layer_3': 0.0004316461133932948, 'n_units_Layer_1': 90, 'n_units_Layer_2': 60, 'n_units_Layer_3': 60}. Best is trial 396 with value: 2.454780728594995.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.71 | sMAPE for Validation Set is: 7.20% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 2.39 | sMAPE for Test Set is: 6.58% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:45:17,018]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:45:20,135]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:45:24,897]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:45:25,258]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:45:32,616]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:45:33,262]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:45:40,307]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:45:40,537]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:45:53,509]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:45:53,893]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:46:01,837]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:46:02,195]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:46:11,641]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:46:17,050]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:46:26,936]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:46:31,343]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:46:36,517]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:46:39,291]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:46:48,401]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:46:51,768]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:47:06,008]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:47:17,907]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:47:22,811]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:47:34,911]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:47:40,508]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:47:43,241]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:47:47,953]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:47:57,575]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:48:02,508]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:48:09,899]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:48:17,383]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:48:20,299]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:48:24,617]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:48:27,873]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:48:41,989]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:48:44,733]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:48:49,088]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:48:52,068]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:48:56,264]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:49:03,878]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:49:23,862]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:49:31,249]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:49:35,880]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:49:36,320]\u001b[0m Trial 1029 finished with value: 2.447419146203906 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009300915829280504, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18539684309904758, 'dropout_rate_Layer_2': 0.24586846859108044, 'dropout_rate_Layer_3': 0.14731450283162353, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.465186158907805e-05, 'l1_Layer_2': 0.00023240431337567298, 'l1_Layer_3': 1.772339016001017e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 165, 'n_units_Layer_3': 255}. Best is trial 1029 with value: 2.447419146203906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.45 | sMAPE for Validation Set is: 6.52% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 1.78 | sMAPE for Test Set is: 4.75% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:49:43,682]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:49:48,793]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:49:53,113]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:49:53,249]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:50:01,212]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:50:08,214]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:50:12,503]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:50:20,077]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:50:22,683]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:50:27,582]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:50:32,884]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:50:40,025]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:50:43,173]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:50:49,665]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:50:57,715]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:51:04,913]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:51:14,903]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:51:21,664]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:51:31,950]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:51:37,091]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:51:40,031]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:51:49,725]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:51:54,637]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:52:01,444]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:52:07,052]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:52:07,114]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:52:14,105]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:52:16,350]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:52:19,251]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:52:23,285]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:52:30,721]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:52:53,377]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:52:58,587]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:53:19,966]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:53:25,021]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:54:04,745]\u001b[0m Trial 1069 finished with value: 2.6943768897669274 and parameters: {'n_hidden': 3, 'learning_rate': 0.003294296503755383, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02463902700519652, 'dropout_rate_Layer_2': 0.2741190840560836, 'dropout_rate_Layer_3': 0.24679838744394073, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006073702816596651, 'l1_Layer_2': 0.0015037224345994258, 'l1_Layer_3': 0.014175333955290135, 'n_units_Layer_1': 105, 'n_units_Layer_2': 60, 'n_units_Layer_3': 95}. Best is trial 1029 with value: 2.447419146203906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.69 | sMAPE for Validation Set is: 7.17% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 1.84 | sMAPE for Test Set is: 4.84% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:54:13,912]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:54:22,205]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:54:29,346]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:54:33,806]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:54:43,658]\u001b[0m Trial 1063 finished with value: 2.9076024836090917 and parameters: {'n_hidden': 3, 'learning_rate': 0.005269929792325213, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03376051842034843, 'dropout_rate_Layer_2': 0.007826096899374612, 'dropout_rate_Layer_3': 0.14933364226597942, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01795033856457406, 'l1_Layer_2': 0.02599402293817699, 'l1_Layer_3': 4.9812605209599867e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 100, 'n_units_Layer_3': 240}. Best is trial 1029 with value: 2.447419146203906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.91 | sMAPE for Validation Set is: 7.68% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 1.96 | sMAPE for Test Set is: 5.23% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:54:43,889]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:54:53,189]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:54:55,125]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:55:02,514]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:55:07,586]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:55:11,995]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:55:12,506]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:55:19,507]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:55:21,905]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:55:27,694]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:55:32,626]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:55:34,916]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:55:39,771]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:55:44,238]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:55:49,421]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:55:51,724]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:55:56,143]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:55:56,237]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:56:02,221]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:56:04,366]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:56:08,785]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:56:28,550]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:56:28,760]\u001b[0m Trial 1096 finished with value: 2.6142272638697417 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005499325682583128, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1852260217924016, 'dropout_rate_Layer_2': 0.26949173172495416, 'dropout_rate_Layer_3': 0.2828179437681864, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.92060079502352e-05, 'l1_Layer_2': 0.0002972474163257824, 'l1_Layer_3': 1.8997341576952352e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 155, 'n_units_Layer_3': 235}. Best is trial 1029 with value: 2.447419146203906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.61 | sMAPE for Validation Set is: 6.93% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 1.90 | sMAPE for Test Set is: 5.07% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:56:36,624]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:56:39,297]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:56:42,465]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:56:44,450]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:56:49,167]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:56:56,290]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:57:03,928]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:57:13,765]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:57:24,111]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:57:28,571]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:57:33,656]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:57:38,296]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:57:41,748]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:57:50,645]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:57:54,141]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:58:18,699]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:58:23,488]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:58:28,270]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:58:33,451]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:58:40,454]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:58:47,370]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.74 | sMAPE for Validation Set is: 7.24% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.89 | sMAPE for Test Set is: 4.95% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:58:49,536]\u001b[0m Trial 1103 finished with value: 2.736065213915578 and parameters: {'n_hidden': 3, 'learning_rate': 0.0046048506884028605, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01422641528166686, 'dropout_rate_Layer_2': 0.0078058819038061234, 'dropout_rate_Layer_3': 0.09967241178598642, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014092468284894851, 'l1_Layer_2': 0.06460923237623573, 'l1_Layer_3': 0.04097069682684074, 'n_units_Layer_1': 255, 'n_units_Layer_2': 70, 'n_units_Layer_3': 230}. Best is trial 1029 with value: 2.447419146203906.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:58:55,550]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:58:59,740]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:59:00,451]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:59:08,005]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:59:08,531]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:59:15,904]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:59:16,437]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:59:23,880]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:59:23,987]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:59:32,609]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:59:37,395]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:59:41,918]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:59:52,056]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:59:56,983]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:00:06,586]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:00:29,186]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:00:39,194]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:00:48,891]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:00:53,411]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:01:01,018]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:01:05,725]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:01:15,797]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:01:22,248]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:01:22,827]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:01:27,811]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:01:30,228]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:01:32,795]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:01:37,423]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:01:37,951]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:01:45,291]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:01:45,786]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:01:53,408]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:02:02,743]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:02:10,401]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:02:19,803]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:02:27,153]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:02:32,270]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:02:39,266]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:02:44,875]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:02:52,079]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:02:54,777]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:02:59,800]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:03:04,203]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:03:20,960]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:03:26,655]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:03:31,357]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:03:48,655]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:04:02,561]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:04:25,330]\u001b[0m Trial 1166 finished with value: 2.59528588165784 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022322933484347084, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03629287962066481, 'dropout_rate_Layer_2': 0.295485997862381, 'dropout_rate_Layer_3': 0.2883611271528094, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0070728974096784854, 'l1_Layer_2': 0.0002247594752941035, 'l1_Layer_3': 0.0005857611997404874, 'n_units_Layer_1': 80, 'n_units_Layer_2': 80, 'n_units_Layer_3': 290}. Best is trial 1029 with value: 2.447419146203906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.60 | sMAPE for Validation Set is: 6.92% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 1.80 | sMAPE for Test Set is: 4.84% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:04:30,061]\u001b[0m Trial 1168 finished with value: 2.513865532777385 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005096093350243915, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19778284496183773, 'dropout_rate_Layer_2': 0.2485484654188393, 'dropout_rate_Layer_3': 0.08844202251784858, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1858467813943982e-05, 'l1_Layer_2': 0.00030433019462846006, 'l1_Layer_3': 3.92549419046092e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 165, 'n_units_Layer_3': 270}. Best is trial 1029 with value: 2.447419146203906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.51 | sMAPE for Validation Set is: 6.73% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 1.84 | sMAPE for Test Set is: 4.93% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:04:34,903]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:04:41,660]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:04:51,539]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:05:06,629]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:05:10,814]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:05:15,424]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:05:25,293]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:05:26,383]\u001b[0m Trial 1174 finished with value: 2.8546636854292515 and parameters: {'n_hidden': 3, 'learning_rate': 0.04081518300253391, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12353068750194926, 'dropout_rate_Layer_2': 0.026348160537069665, 'dropout_rate_Layer_3': 0.23708297432134223, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.017370154779506024, 'l1_Layer_2': 0.012581081741721576, 'l1_Layer_3': 5.652236646154334e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 185, 'n_units_Layer_3': 275}. Best is trial 1029 with value: 2.447419146203906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.85 | sMAPE for Validation Set is: 7.49% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.91 | sMAPE for Test Set is: 5.09% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:05:32,834]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:05:32,945]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:05:41,997]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:05:44,517]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:05:50,019]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:05:52,506]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:05:59,567]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:06:06,883]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:06:11,830]\u001b[0m Trial 1183 finished with value: 2.759644995206339 and parameters: {'n_hidden': 3, 'learning_rate': 0.04853212980795666, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24520842381365218, 'dropout_rate_Layer_2': 0.10321045529184396, 'dropout_rate_Layer_3': 0.2153197404054106, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.024184333179705718, 'l1_Layer_2': 0.005428723521766986, 'l1_Layer_3': 5.185654899446732e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 180, 'n_units_Layer_3': 260}. Best is trial 1029 with value: 2.447419146203906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.76 | sMAPE for Validation Set is: 7.30% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.91 | sMAPE for Test Set is: 5.10% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:06:14,016]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:06:18,802]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:06:21,618]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:06:26,656]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:06:33,521]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:06:34,237]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:06:41,471]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:06:41,679]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:06:50,614]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:06:50,853]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:06:59,195]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:07:04,600]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:07:13,571]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:07:21,367]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:07:21,744]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:07:44,362]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:07:54,782]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:08:02,896]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:08:22,642]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:09:19,023]\u001b[0m Trial 1202 finished with value: 2.85944194620548 and parameters: {'n_hidden': 3, 'learning_rate': 0.005311700162994104, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00021364268296593728, 'dropout_rate_Layer_2': 0.013224505005751439, 'dropout_rate_Layer_3': 0.10818245347231566, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.042171022785836246, 'l1_Layer_2': 0.06636881437637815, 'l1_Layer_3': 0.021517393589313174, 'n_units_Layer_1': 260, 'n_units_Layer_2': 70, 'n_units_Layer_3': 230}. Best is trial 1029 with value: 2.447419146203906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.86 | sMAPE for Validation Set is: 7.54% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.12 | sMAPE for Test Set is: 5.51% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:09:28,466]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:09:34,239]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:09:38,808]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:09:46,715]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:09:53,049]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:09:56,572]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:10:03,790]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:10:05,706]\u001b[0m Trial 1206 finished with value: 2.429027547907341 and parameters: {'n_hidden': 3, 'learning_rate': 0.000879720199777761, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020841071527138072, 'dropout_rate_Layer_2': 0.048378124193103084, 'dropout_rate_Layer_3': 0.2854009425616025, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001315556644233185, 'l1_Layer_2': 0.0001498331010960839, 'l1_Layer_3': 0.0006145929017438969, 'n_units_Layer_1': 100, 'n_units_Layer_2': 65, 'n_units_Layer_3': 290}. Best is trial 1206 with value: 2.429027547907341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.43 | sMAPE for Validation Set is: 6.51% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 1.77 | sMAPE for Test Set is: 4.78% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:10:13,334]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:10:13,735]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:10:21,623]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:10:28,630]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:10:28,677]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:10:38,334]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:10:48,838]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:10:57,798]\u001b[0m Trial 1219 finished with value: 2.935631886514205 and parameters: {'n_hidden': 3, 'learning_rate': 0.04121779843834216, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2126755448366866, 'dropout_rate_Layer_2': 0.012426906036901345, 'dropout_rate_Layer_3': 0.21847721930185235, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.019073596827335653, 'l1_Layer_2': 0.017060982444845663, 'l1_Layer_3': 2.1056675583735543e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 170, 'n_units_Layer_3': 245}. Best is trial 1206 with value: 2.429027547907341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.94 | sMAPE for Validation Set is: 7.70% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 2.01 | sMAPE for Test Set is: 5.33% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:11:01,083]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:11:07,475]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:11:18,010]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:11:24,842]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:11:34,947]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:11:44,972]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:12:10,361]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:12:12,997]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:12:22,776]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:12:29,658]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:12:39,384]\u001b[0m Trial 1230 finished with value: 2.7550203869995458 and parameters: {'n_hidden': 3, 'learning_rate': 0.006852344838679205, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18308116589764634, 'dropout_rate_Layer_2': 0.10494025707064808, 'dropout_rate_Layer_3': 0.2522555894848241, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005736540074514687, 'l1_Layer_2': 0.00875286425070041, 'l1_Layer_3': 5.7348536139061004e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 160, 'n_units_Layer_3': 265}. Best is trial 1206 with value: 2.429027547907341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.76 | sMAPE for Validation Set is: 7.29% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.88 | sMAPE for Test Set is: 5.02% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:12:42,756]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:12:47,019]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:12:50,268]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:12:54,911]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:12:59,452]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:13:02,446]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:13:07,107]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:13:09,139]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:13:16,509]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:13:21,573]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:13:31,316]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:13:39,084]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:13:51,847]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:14:41,476]\u001b[0m Trial 1247 finished with value: 2.6809916071119253 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009045800495460186, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04009134200613127, 'dropout_rate_Layer_2': 0.05013757331545605, 'dropout_rate_Layer_3': 0.2722680385759554, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008314187796086513, 'l1_Layer_2': 0.00031801791374987896, 'l1_Layer_3': 0.0007381056994823347, 'n_units_Layer_1': 100, 'n_units_Layer_2': 90, 'n_units_Layer_3': 285}. Best is trial 1206 with value: 2.429027547907341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.68 | sMAPE for Validation Set is: 7.13% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 2.06 | sMAPE for Test Set is: 5.46% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:14:50,705]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:15:00,155]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:15:00,554]\u001b[0m Trial 1242 finished with value: 2.5137756110436427 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011138900749277404, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04194141955582675, 'dropout_rate_Layer_2': 0.05137109748817588, 'dropout_rate_Layer_3': 0.2732787887570791, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00883298712870449, 'l1_Layer_2': 0.0003561400403759296, 'l1_Layer_3': 0.0005966307266957924, 'n_units_Layer_1': 100, 'n_units_Layer_2': 90, 'n_units_Layer_3': 300}. Best is trial 1206 with value: 2.429027547907341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.51 | sMAPE for Validation Set is: 6.72% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 1.76 | sMAPE for Test Set is: 4.73% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:15:08,714]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:15:25,940]\u001b[0m Trial 1251 finished with value: 2.5552289716891075 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005212234338276636, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.198064334644535, 'dropout_rate_Layer_2': 0.24824774630209206, 'dropout_rate_Layer_3': 0.08821313187120375, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.514022235369553e-05, 'l1_Layer_2': 0.00013468505150708004, 'l1_Layer_3': 4.053464846702833e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 165, 'n_units_Layer_3': 270}. Best is trial 1206 with value: 2.429027547907341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.56 | sMAPE for Validation Set is: 6.79% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.85 | sMAPE for Test Set is: 4.93% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:15:38,215]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:15:41,242]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:15:44,281]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:15:51,369]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:16:00,803]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:16:09,038]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:16:18,286]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:16:18,580]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:16:25,491]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:16:31,041]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:16:36,037]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:16:43,218]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:16:45,653]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:16:50,530]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:16:52,896]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:16:58,067]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:17:00,318]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:17:05,353]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:17:10,417]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:17:14,995]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:17:17,361]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:17:38,298]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:17:38,314]\u001b[0m Trial 1274 finished with value: 2.8547676537600757 and parameters: {'n_hidden': 3, 'learning_rate': 0.009135796415283672, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18341266465072958, 'dropout_rate_Layer_2': 0.36065897097175537, 'dropout_rate_Layer_3': 0.20852749572617482, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009128881926262017, 'l1_Layer_2': 0.014368728821397756, 'l1_Layer_3': 3.6893180687480325e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225}. Best is trial 1206 with value: 2.429027547907341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.85 | sMAPE for Validation Set is: 7.51% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.97 | sMAPE for Test Set is: 5.26% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:17:47,323]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:17:57,314]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:18:02,069]\u001b[0m Trial 1276 finished with value: 2.8757877702331185 and parameters: {'n_hidden': 3, 'learning_rate': 0.008474984941614552, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1792003568594321, 'dropout_rate_Layer_2': 0.38641803231741156, 'dropout_rate_Layer_3': 0.2082804498597585, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02591460313729807, 'l1_Layer_2': 0.01571842983034941, 'l1_Layer_3': 3.61783257528129e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 50, 'n_units_Layer_3': 240}. Best is trial 1206 with value: 2.429027547907341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.88 | sMAPE for Validation Set is: 7.60% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 1.91 | sMAPE for Test Set is: 5.10% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:18:04,286]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:18:10,043]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:18:14,729]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:18:21,884]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:18:37,210]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:18:46,457]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:18:51,598]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:18:56,509]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:19:03,391]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:19:03,628]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:19:12,186]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:19:19,602]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:19:27,041]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:19:34,417]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:19:39,034]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:19:51,409]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:20:29,180]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:20:39,312]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:20:43,617]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:20:50,580]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:20:55,865]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:21:08,752]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:21:18,364]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:21:22,850]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:21:33,214]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:21:33,689]\u001b[0m Trial 1295 finished with value: 2.80547444162422 and parameters: {'n_hidden': 3, 'learning_rate': 0.003626085142775837, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02459787981596747, 'dropout_rate_Layer_2': 0.01835034250510831, 'dropout_rate_Layer_3': 0.03348569465335868, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01698575586299575, 'l1_Layer_2': 0.038497090064454134, 'l1_Layer_3': 0.03172650673808462, 'n_units_Layer_1': 255, 'n_units_Layer_2': 80, 'n_units_Layer_3': 270}. Best is trial 1206 with value: 2.429027547907341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.81 | sMAPE for Validation Set is: 7.40% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.89 | sMAPE for Test Set is: 5.00% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:21:41,276]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:21:43,768]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:21:46,750]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:21:49,121]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:21:53,968]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:21:58,950]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:22:01,910]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:22:09,060]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:22:11,682]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:22:16,949]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:22:26,050]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:22:31,878]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:22:36,249]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:22:36,651]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:22:45,838]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:22:46,305]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:22:53,198]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:23:00,914]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:23:06,180]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:23:06,303]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:23:15,553]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:23:20,876]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:23:23,803]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:23:30,843]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:23:40,718]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:23:45,798]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:23:52,912]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:23:58,032]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:23:58,494]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:24:04,657]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:24:11,991]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:24:14,698]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:24:19,433]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:24:29,622]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:24:36,821]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:25:01,115]\u001b[0m Trial 1339 finished with value: 2.5358974832485064 and parameters: {'n_hidden': 3, 'learning_rate': 0.001143636236651005, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16676051747488382, 'dropout_rate_Layer_2': 0.23936332251893458, 'dropout_rate_Layer_3': 0.1691716051680325, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.728967160301215e-05, 'l1_Layer_2': 0.0017013656379225776, 'l1_Layer_3': 7.632188573832794e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 195, 'n_units_Layer_3': 155}. Best is trial 1206 with value: 2.429027547907341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.54 | sMAPE for Validation Set is: 6.77% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.77 | sMAPE for Test Set is: 4.73% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:25:06,608]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:25:11,579]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:25:14,129]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:25:20,808]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:25:28,037]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:25:33,706]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:25:40,680]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:25:45,726]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:25:52,787]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:25:57,643]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:26:05,172]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:26:10,292]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:26:20,078]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:26:49,796]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:26:57,249]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:27:01,802]\u001b[0m Trial 1344 finished with value: 2.950589629764663 and parameters: {'n_hidden': 3, 'learning_rate': 0.003624119156174075, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019081721509865018, 'dropout_rate_Layer_2': 4.50565535737798e-05, 'dropout_rate_Layer_3': 0.16346114575263931, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.012993733920031348, 'l1_Layer_2': 0.03702976487094788, 'l1_Layer_3': 0.09953898852154867, 'n_units_Layer_1': 250, 'n_units_Layer_2': 75, 'n_units_Layer_3': 265}. Best is trial 1206 with value: 2.429027547907341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.95 | sMAPE for Validation Set is: 7.76% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 1.98 | sMAPE for Test Set is: 5.19% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:27:06,981]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:27:22,227]\u001b[0m Trial 1358 finished with value: 2.8373259417038383 and parameters: {'n_hidden': 3, 'learning_rate': 0.009661165771977683, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16674152871393075, 'dropout_rate_Layer_2': 0.1033161014744088, 'dropout_rate_Layer_3': 0.24106912365438699, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015265845389688143, 'l1_Layer_2': 0.014161943317229062, 'l1_Layer_3': 7.133705564936998e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 55, 'n_units_Layer_3': 210}. Best is trial 1206 with value: 2.429027547907341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.84 | sMAPE for Validation Set is: 7.47% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.03 | sMAPE for Test Set is: 5.36% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:27:28,807]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:27:33,774]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:27:39,680]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:27:46,385]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:27:51,682]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:28:11,114]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:28:16,686]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:28:23,095]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:28:43,900]\u001b[0m Trial 1367 finished with value: 2.854163366589466 and parameters: {'n_hidden': 3, 'learning_rate': 0.009832858034690608, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18683239780779162, 'dropout_rate_Layer_2': 0.30949211108796015, 'dropout_rate_Layer_3': 0.11111370652699708, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.018497928460393404, 'l1_Layer_2': 0.014488137050675181, 'l1_Layer_3': 7.520533741701715e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 55, 'n_units_Layer_3': 210}. Best is trial 1206 with value: 2.429027547907341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.85 | sMAPE for Validation Set is: 7.54% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.99 | sMAPE for Test Set is: 5.31% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:28:53,545]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:28:58,109]\u001b[0m Trial 1356 finished with value: 2.6881439210849103 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008162666873276921, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.037845837970725896, 'dropout_rate_Layer_2': 0.05684403527386081, 'dropout_rate_Layer_3': 0.3007201782850248, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008925649477838494, 'l1_Layer_2': 0.030548252397350383, 'l1_Layer_3': 0.0008157867651457265, 'n_units_Layer_1': 95, 'n_units_Layer_2': 85, 'n_units_Layer_3': 280}. Best is trial 1206 with value: 2.429027547907341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.69 | sMAPE for Validation Set is: 7.15% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 1.89 | sMAPE for Test Set is: 5.06% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:29:05,569]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:29:17,488]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:29:24,776]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:29:35,023]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:29:47,294]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:29:59,334]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:30:06,506]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:30:13,624]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:30:48,510]\u001b[0m Trial 1378 finished with value: 2.566956376088176 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017842979235205383, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1921334699164887, 'dropout_rate_Layer_2': 0.2804139204218548, 'dropout_rate_Layer_3': 0.1518477767477018, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.89686947660261e-05, 'l1_Layer_2': 0.0007656273260191885, 'l1_Layer_3': 0.00027698469571393707, 'n_units_Layer_1': 130, 'n_units_Layer_2': 190, 'n_units_Layer_3': 170}. Best is trial 1206 with value: 2.429027547907341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.57 | sMAPE for Validation Set is: 6.80% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.88 | sMAPE for Test Set is: 4.97% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:31:00,332]\u001b[0m Trial 1369 finished with value: 2.8667558269926956 and parameters: {'n_hidden': 3, 'learning_rate': 0.004340437320941875, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03288035005756376, 'dropout_rate_Layer_2': 0.020782162080432237, 'dropout_rate_Layer_3': 0.17894635903343806, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.044087115774590006, 'l1_Layer_2': 0.04579677741004249, 'l1_Layer_3': 0.010961929929218685, 'n_units_Layer_1': 265, 'n_units_Layer_2': 65, 'n_units_Layer_3': 235}. Best is trial 1206 with value: 2.429027547907341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.87 | sMAPE for Validation Set is: 7.50% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.04 | sMAPE for Test Set is: 5.35% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:31:24,356]\u001b[0m Trial 1380 finished with value: 2.8065799252325374 and parameters: {'n_hidden': 3, 'learning_rate': 0.007396365731027538, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14940627145330584, 'dropout_rate_Layer_2': 0.2789659828423028, 'dropout_rate_Layer_3': 0.06433696305987574, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02047867880952449, 'l1_Layer_2': 0.007305464476151273, 'l1_Layer_3': 6.946990812888544e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 55, 'n_units_Layer_3': 200}. Best is trial 1206 with value: 2.429027547907341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.81 | sMAPE for Validation Set is: 7.42% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.89 | sMAPE for Test Set is: 5.05% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:31:34,659]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:31:56,451]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:32:19,098]\u001b[0m Trial 1383 finished with value: 2.80792886956 and parameters: {'n_hidden': 3, 'learning_rate': 0.007197466958049229, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12661221999384256, 'dropout_rate_Layer_2': 0.2969502943006962, 'dropout_rate_Layer_3': 0.07302598089410586, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02089244734725119, 'l1_Layer_2': 0.0067162555847731405, 'l1_Layer_3': 7.256377916824486e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 60, 'n_units_Layer_3': 190}. Best is trial 1206 with value: 2.429027547907341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.81 | sMAPE for Validation Set is: 7.42% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.93 | sMAPE for Test Set is: 5.13% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:32:26,755]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:32:48,273]\u001b[0m Trial 1379 finished with value: 2.763712418199251 and parameters: {'n_hidden': 3, 'learning_rate': 0.004764339631588056, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007049299876005655, 'dropout_rate_Layer_2': 0.008168104782523786, 'dropout_rate_Layer_3': 0.11492882651665365, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010517338143840966, 'l1_Layer_2': 0.03349386595009665, 'l1_Layer_3': 0.023884905210992787, 'n_units_Layer_1': 280, 'n_units_Layer_2': 90, 'n_units_Layer_3': 230}. Best is trial 1206 with value: 2.429027547907341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.76 | sMAPE for Validation Set is: 7.31% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.88 | sMAPE for Test Set is: 4.93% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:32:55,613]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:33:10,865]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:33:20,974]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:33:25,903]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:33:54,874]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:33:59,850]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:34:04,659]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:34:26,987]\u001b[0m Trial 1393 finished with value: 2.7819254851652033 and parameters: {'n_hidden': 3, 'learning_rate': 0.007261110433000596, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12233753252916571, 'dropout_rate_Layer_2': 0.30226551715244704, 'dropout_rate_Layer_3': 0.1047993803990136, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.019247938962244793, 'l1_Layer_2': 0.00551097315972062, 'l1_Layer_3': 6.766345754593482e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 60, 'n_units_Layer_3': 195}. Best is trial 1206 with value: 2.429027547907341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.78 | sMAPE for Validation Set is: 7.36% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.92 | sMAPE for Test Set is: 5.12% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:34:38,996]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:34:56,304]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:35:06,593]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:35:15,551]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:35:20,243]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:35:23,303]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:35:28,743]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:35:33,199]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:35:40,394]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:35:45,684]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:35:53,322]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:35:53,531]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:36:02,099]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:36:07,442]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:36:12,265]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:36:12,497]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:36:18,768]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:36:27,924]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:36:35,433]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:36:40,343]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:36:44,912]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:36:45,471]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:36:53,918]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:36:56,628]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:37:01,417]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:37:07,970]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:37:11,451]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:37:15,502]\u001b[0m Trial 1417 finished with value: 2.7796484187905794 and parameters: {'n_hidden': 3, 'learning_rate': 0.009368488575688214, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1272934475736582, 'dropout_rate_Layer_2': 0.2577181452234131, 'dropout_rate_Layer_3': 0.10181031201164434, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02113726014753924, 'l1_Layer_2': 0.009567993634336735, 'l1_Layer_3': 6.486864185839722e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 50, 'n_units_Layer_3': 200}. Best is trial 1206 with value: 2.429027547907341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.78 | sMAPE for Validation Set is: 7.38% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.88 | sMAPE for Test Set is: 5.03% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:37:21,255]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:37:28,175]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:37:37,794]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:37:53,536]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:37:58,041]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:37:58,386]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:38:06,171]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:38:08,560]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:38:16,625]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:38:21,613]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:38:23,304]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:38:35,798]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:38:36,271]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:38:43,616]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:38:46,455]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:38:51,677]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:38:59,187]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:39:04,004]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:39:09,311]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:39:11,794]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:39:17,022]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:39:22,126]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:39:26,884]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:39:31,953]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:39:36,739]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:39:41,248]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:39:47,051]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:39:54,071]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:39:58,413]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:40:01,168]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:40:06,344]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:40:06,677]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:40:15,911]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:40:22,753]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:40:25,774]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:40:37,531]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:40:45,171]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:40:52,071]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:40:54,862]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:41:04,688]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:41:07,333]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:41:21,747]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:41:29,153]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:41:36,967]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:41:44,273]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:42:03,789]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:42:33,693]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:42:38,886]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:42:42,987]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:42:46,249]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:42:53,523]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:43:00,699]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:43:05,899]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:43:11,099]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:43:18,295]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:43:25,664]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:43:44,783]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:43:50,343]\u001b[0m Trial 1478 finished with value: 2.5756214049630546 and parameters: {'n_hidden': 3, 'learning_rate': 0.03827737154999754, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14475708241147645, 'dropout_rate_Layer_2': 0.23791412698293285, 'dropout_rate_Layer_3': 0.17766388844127118, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.641314577835637e-05, 'l1_Layer_2': 0.0011039895574510605, 'l1_Layer_3': 3.248060733916276e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 195, 'n_units_Layer_3': 295}. Best is trial 1206 with value: 2.429027547907341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.58 | sMAPE for Validation Set is: 6.88% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.92 | sMAPE for Test Set is: 5.19% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:43:50,765]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:43:57,967]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:43:58,644]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:44:04,532]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:44:09,014]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:44:11,806]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:44:16,733]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:44:19,553]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:44:24,145]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:44:24,190]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:44:33,186]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:44:33,509]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:44:46,667]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:44:49,252]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:44:52,282]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:44:59,266]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:45:06,339]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:45:25,750]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:45:28,998]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:45:39,120]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:45:40,885]\u001b[0m Trial 1495 finished with value: 2.5648330920501796 and parameters: {'n_hidden': 3, 'learning_rate': 0.00189457979139397, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17698417574574032, 'dropout_rate_Layer_2': 0.038763809834079045, 'dropout_rate_Layer_3': 0.2607862181286979, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0070795831451332236, 'l1_Layer_2': 0.00033811009201024033, 'l1_Layer_3': 0.0005670325958338781, 'n_units_Layer_1': 100, 'n_units_Layer_2': 70, 'n_units_Layer_3': 295}. Best is trial 1206 with value: 2.429027547907341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.56 | sMAPE for Validation Set is: 6.80% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.91 | sMAPE for Test Set is: 5.09% | rMAE for Test Set is: 0.58\n",
      "for 2019-01-01, MAE is:1.36 & sMAPE is:2.85% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :1.36 & 2.85% & 0.88\n",
      "for 2019-01-02, MAE is:2.45 & sMAPE is:4.88% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :1.90 & 3.86% & 1.26\n",
      "for 2019-01-03, MAE is:4.98 & sMAPE is:8.53% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :2.93 & 5.42% & 1.14\n",
      "for 2019-01-04, MAE is:2.36 & sMAPE is:4.46% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :2.79 & 5.18% & 1.11\n",
      "for 2019-01-05, MAE is:2.87 & sMAPE is:5.71% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :2.80 & 5.29% & 1.22\n",
      "for 2019-01-06, MAE is:2.07 & sMAPE is:4.11% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :2.68 & 5.09% & 1.26\n",
      "for 2019-01-07, MAE is:1.95 & sMAPE is:3.71% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :2.58 & 4.89% & 1.18\n",
      "for 2019-01-08, MAE is:0.92 & sMAPE is:1.86% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :2.37 & 4.51% & 1.10\n",
      "for 2019-01-09, MAE is:1.31 & sMAPE is:2.56% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 4.30% & 1.16\n",
      "for 2019-01-10, MAE is:8.67 & sMAPE is:14.29% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :2.89 & 5.30% & 1.17\n",
      "for 2019-01-11, MAE is:1.64 & sMAPE is:3.27% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.78 & 5.11% & 1.18\n",
      "for 2019-01-12, MAE is:2.19 & sMAPE is:4.50% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.73 & 5.06% & 1.21\n",
      "for 2019-01-13, MAE is:1.34 & sMAPE is:2.78% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :2.62 & 4.89% & 1.17\n",
      "for 2019-01-14, MAE is:1.51 & sMAPE is:2.95% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 4.75% & 1.13\n",
      "for 2019-01-15, MAE is:1.78 & sMAPE is:3.39% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 4.66% & 1.10\n",
      "for 2019-01-16, MAE is:2.01 & sMAPE is:3.94% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 4.61% & 1.09\n",
      "for 2019-01-17, MAE is:1.38 & sMAPE is:2.58% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 4.49% & 1.04\n",
      "for 2019-01-18, MAE is:8.92 & sMAPE is:14.82% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :2.76 & 5.07% & 1.02\n",
      "for 2019-01-19, MAE is:1.88 & sMAPE is:3.36% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :2.72 & 4.98% & 0.99\n",
      "for 2019-01-20, MAE is:4.17 & sMAPE is:7.56% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :2.79 & 5.11% & 0.97\n",
      "for 2019-01-21, MAE is:12.53 & sMAPE is:18.68% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :3.25 & 5.75% & 0.96\n",
      "for 2019-01-22, MAE is:5.23 & sMAPE is:8.03% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :3.34 & 5.86% & 0.94\n",
      "for 2019-01-23, MAE is:11.48 & sMAPE is:16.62% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :3.70 & 6.32% & 0.93\n",
      "for 2019-01-24, MAE is:18.35 & sMAPE is:23.27% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 7.03% & 0.92\n",
      "for 2019-01-25, MAE is:6.18 & sMAPE is:8.98% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 7.11% & 0.92\n",
      "for 2019-01-26, MAE is:1.75 & sMAPE is:3.25% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 6.96% & 0.93\n",
      "for 2019-01-27, MAE is:1.50 & sMAPE is:2.93% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 6.81% & 0.91\n",
      "for 2019-01-28, MAE is:2.01 & sMAPE is:3.55% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 6.69% & 0.88\n",
      "for 2019-01-29, MAE is:6.53 & sMAPE is:10.49% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 6.83% & 0.92\n",
      "for 2019-01-30, MAE is:3.66 & sMAPE is:6.41% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 6.81% & 0.90\n",
      "for 2019-01-31, MAE is:1.80 & sMAPE is:3.23% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 6.70% & 0.87\n",
      "for 2019-02-01, MAE is:1.95 & sMAPE is:3.51% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 6.60% & 0.85\n",
      "for 2019-02-02, MAE is:1.13 & sMAPE is:2.20% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.94 & 6.46% & 0.84\n",
      "for 2019-02-03, MAE is:1.30 & sMAPE is:2.54% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :3.86 & 6.35% & 0.84\n",
      "for 2019-02-04, MAE is:1.75 & sMAPE is:3.35% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :3.80 & 6.26% & 0.83\n",
      "for 2019-02-05, MAE is:1.37 & sMAPE is:2.62% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :3.73 & 6.16% & 0.81\n",
      "for 2019-02-06, MAE is:2.29 & sMAPE is:4.32% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :3.69 & 6.11% & 0.81\n",
      "for 2019-02-07, MAE is:1.93 & sMAPE is:3.77% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 6.05% & 0.80\n",
      "for 2019-02-08, MAE is:1.50 & sMAPE is:3.12% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :3.59 & 5.97% & 0.78\n",
      "for 2019-02-09, MAE is:2.08 & sMAPE is:4.45% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.55 & 5.94% & 0.78\n",
      "for 2019-02-10, MAE is:1.65 & sMAPE is:3.58% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.51 & 5.88% & 0.77\n",
      "for 2019-02-11, MAE is:1.68 & sMAPE is:3.45% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.46 & 5.82% & 0.76\n",
      "for 2019-02-12, MAE is:0.97 & sMAPE is:2.02% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.40 & 5.73% & 0.75\n",
      "for 2019-02-13, MAE is:1.04 & sMAPE is:2.25% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 5.65% & 0.74\n",
      "for 2019-02-14, MAE is:1.20 & sMAPE is:2.66% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :3.30 & 5.59% & 0.73\n",
      "for 2019-02-15, MAE is:1.08 & sMAPE is:2.49% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :3.25 & 5.52% & 0.72\n",
      "for 2019-02-16, MAE is:1.45 & sMAPE is:3.51% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :3.22 & 5.48% & 0.71\n",
      "for 2019-02-17, MAE is:1.05 & sMAPE is:2.46% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :3.17 & 5.41% & 0.70\n",
      "for 2019-02-18, MAE is:1.47 & sMAPE is:3.40% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.14 & 5.37% & 0.69\n",
      "for 2019-02-19, MAE is:1.24 & sMAPE is:2.91% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :3.10 & 5.32% & 0.68\n",
      "for 2019-02-20, MAE is:1.38 & sMAPE is:3.24% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :3.06 & 5.28% & 0.68\n",
      "for 2019-02-21, MAE is:1.05 & sMAPE is:2.38% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :3.03 & 5.23% & 0.68\n",
      "for 2019-02-22, MAE is:1.20 & sMAPE is:2.78% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :2.99 & 5.18% & 0.71\n",
      "for 2019-02-23, MAE is:1.22 & sMAPE is:3.04% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :2.96 & 5.14% & 0.72\n",
      "for 2019-02-24, MAE is:2.34 & sMAPE is:5.78% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :2.95 & 5.15% & 0.74\n",
      "for 2019-02-25, MAE is:1.43 & sMAPE is:3.43% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :2.92 & 5.12% & 0.73\n",
      "for 2019-02-26, MAE is:1.06 & sMAPE is:2.55% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :2.89 & 5.08% & 0.74\n",
      "for 2019-02-27, MAE is:1.75 & sMAPE is:4.28% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :2.87 & 5.06% & 0.74\n",
      "for 2019-02-28, MAE is:3.42 & sMAPE is:8.46% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :2.88 & 5.12% & 0.76\n",
      "for 2019-03-01, MAE is:1.77 & sMAPE is:4.02% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :2.86 & 5.10% & 0.77\n",
      "for 2019-03-02, MAE is:1.71 & sMAPE is:4.04% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :2.84 & 5.08% & 0.77\n",
      "for 2019-03-03, MAE is:1.66 & sMAPE is:4.10% & rMAE is:3.46 ||| daily mean of MAE & sMAPE & rMAE till now are :2.82 & 5.07% & 0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-03-04, MAE is:0.84 & sMAPE is:2.04% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :2.79 & 5.02% & 0.82\n",
      "for 2019-03-05, MAE is:2.48 & sMAPE is:5.72% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :2.79 & 5.03% & 0.83\n",
      "for 2019-03-06, MAE is:1.87 & sMAPE is:4.25% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :2.77 & 5.02% & 0.82\n",
      "for 2019-03-07, MAE is:2.30 & sMAPE is:5.28% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :2.76 & 5.02% & 0.83\n",
      "for 2019-03-08, MAE is:1.01 & sMAPE is:2.37% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.74 & 4.98% & 0.82\n",
      "for 2019-03-09, MAE is:0.80 & sMAPE is:1.89% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :2.71 & 4.94% & 0.82\n",
      "for 2019-03-10, MAE is:1.08 & sMAPE is:2.52% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.69 & 4.90% & 0.82\n",
      "for 2019-03-11, MAE is:1.07 & sMAPE is:2.33% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.66 & 4.87% & 0.81\n",
      "for 2019-03-12, MAE is:1.60 & sMAPE is:3.54% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :2.65 & 4.85% & 0.81\n",
      "for 2019-03-13, MAE is:1.15 & sMAPE is:2.66% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.63 & 4.82% & 0.81\n",
      "for 2019-03-14, MAE is:1.17 & sMAPE is:2.74% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :2.61 & 4.79% & 0.80\n",
      "for 2019-03-15, MAE is:1.09 & sMAPE is:2.59% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :2.59 & 4.76% & 0.81\n",
      "for 2019-03-16, MAE is:1.32 & sMAPE is:3.27% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :2.57 & 4.74% & 0.81\n",
      "for 2019-03-17, MAE is:0.49 & sMAPE is:1.21% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 4.69% & 0.80\n",
      "for 2019-03-18, MAE is:1.16 & sMAPE is:2.79% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 4.67% & 0.79\n",
      "for 2019-03-19, MAE is:2.89 & sMAPE is:6.06% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 4.69% & 0.80\n",
      "for 2019-03-20, MAE is:1.34 & sMAPE is:3.21% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 4.67% & 0.81\n",
      "for 2019-03-21, MAE is:1.25 & sMAPE is:3.08% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :2.50 & 4.65% & 0.81\n",
      "for 2019-03-22, MAE is:2.61 & sMAPE is:6.23% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :2.50 & 4.67% & 0.81\n",
      "for 2019-03-23, MAE is:0.86 & sMAPE is:2.29% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 4.64% & 0.80\n",
      "for 2019-03-24, MAE is:1.00 & sMAPE is:2.65% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 4.61% & 0.80\n",
      "for 2019-03-25, MAE is:1.41 & sMAPE is:3.60% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :2.45 & 4.60% & 0.80\n",
      "for 2019-03-26, MAE is:1.28 & sMAPE is:3.24% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :2.44 & 4.59% & 0.79\n",
      "for 2019-03-27, MAE is:1.26 & sMAPE is:3.14% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :2.42 & 4.57% & 0.79\n",
      "for 2019-03-28, MAE is:2.94 & sMAPE is:7.51% & rMAE is:3.60 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 4.60% & 0.82\n",
      "for 2019-03-29, MAE is:1.93 & sMAPE is:4.79% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :2.42 & 4.61% & 0.83\n",
      "for 2019-03-30, MAE is:0.91 & sMAPE is:2.44% & rMAE is:2.29 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 4.58% & 0.84\n",
      "for 2019-03-31, MAE is:2.49 & sMAPE is:6.70% & rMAE is:4.54 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 4.60% & 0.89\n",
      "for 2019-04-01, MAE is:1.98 & sMAPE is:4.92% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 4.61% & 0.89\n",
      "for 2019-04-02, MAE is:1.08 & sMAPE is:2.84% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :2.39 & 4.59% & 0.89\n",
      "for 2019-04-03, MAE is:3.19 & sMAPE is:8.22% & rMAE is:2.76 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 4.63% & 0.91\n",
      "for 2019-04-04, MAE is:1.61 & sMAPE is:4.14% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :2.39 & 4.62% & 0.91\n",
      "for 2019-04-05, MAE is:1.02 & sMAPE is:2.61% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :2.37 & 4.60% & 0.91\n",
      "for 2019-04-06, MAE is:3.70 & sMAPE is:9.73% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :2.39 & 4.66% & 0.93\n",
      "for 2019-04-07, MAE is:1.57 & sMAPE is:3.99% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :2.38 & 4.65% & 0.93\n",
      "for 2019-04-08, MAE is:1.07 & sMAPE is:2.58% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :2.36 & 4.63% & 0.93\n",
      "for 2019-04-09, MAE is:2.91 & sMAPE is:6.97% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :2.37 & 4.65% & 0.92\n",
      "for 2019-04-10, MAE is:3.06 & sMAPE is:7.03% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :2.38 & 4.67% & 0.92\n",
      "for 2019-04-11, MAE is:4.64 & sMAPE is:10.20% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 4.73% & 0.92\n",
      "for 2019-04-12, MAE is:2.43 & sMAPE is:5.18% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 4.73% & 0.91\n",
      "for 2019-04-13, MAE is:2.53 & sMAPE is:5.94% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 4.75% & 0.91\n",
      "for 2019-04-14, MAE is:2.13 & sMAPE is:5.07% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 4.75% & 0.91\n",
      "for 2019-04-15, MAE is:1.89 & sMAPE is:4.24% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :2.39 & 4.74% & 0.91\n",
      "for 2019-04-16, MAE is:2.66 & sMAPE is:6.09% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 4.76% & 0.91\n",
      "for 2019-04-17, MAE is:1.37 & sMAPE is:3.18% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :2.39 & 4.74% & 0.91\n",
      "for 2019-04-18, MAE is:3.33 & sMAPE is:7.99% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 4.77% & 0.91\n",
      "for 2019-04-19, MAE is:1.55 & sMAPE is:3.76% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :2.39 & 4.76% & 0.91\n",
      "for 2019-04-20, MAE is:1.21 & sMAPE is:2.94% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :2.38 & 4.75% & 0.90\n",
      "for 2019-04-21, MAE is:1.07 & sMAPE is:2.63% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :2.37 & 4.73% & 0.90\n",
      "for 2019-04-22, MAE is:0.69 & sMAPE is:1.75% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :2.35 & 4.70% & 0.89\n",
      "for 2019-04-23, MAE is:1.35 & sMAPE is:3.35% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :2.34 & 4.69% & 0.89\n",
      "for 2019-04-24, MAE is:1.91 & sMAPE is:4.81% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :2.34 & 4.69% & 0.88\n",
      "for 2019-04-25, MAE is:1.87 & sMAPE is:4.67% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :2.33 & 4.69% & 0.88\n",
      "for 2019-04-26, MAE is:1.87 & sMAPE is:4.67% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :2.33 & 4.69% & 0.88\n",
      "for 2019-04-27, MAE is:5.42 & sMAPE is:15.52% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :2.36 & 4.78% & 0.88\n",
      "for 2019-04-28, MAE is:2.97 & sMAPE is:8.48% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :2.36 & 4.81% & 0.88\n",
      "for 2019-04-29, MAE is:2.64 & sMAPE is:6.65% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :2.36 & 4.83% & 0.88\n",
      "for 2019-04-30, MAE is:1.46 & sMAPE is:3.74% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :2.36 & 4.82% & 0.88\n",
      "for 2019-05-01, MAE is:2.48 & sMAPE is:6.90% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :2.36 & 4.84% & 0.88\n",
      "for 2019-05-02, MAE is:1.83 & sMAPE is:5.06% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :2.35 & 4.84% & 0.88\n",
      "for 2019-05-03, MAE is:1.36 & sMAPE is:3.46% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :2.34 & 4.83% & 0.87\n",
      "for 2019-05-04, MAE is:1.08 & sMAPE is:2.61% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :2.33 & 4.81% & 0.87\n",
      "for 2019-05-05, MAE is:1.84 & sMAPE is:4.60% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.33 & 4.81% & 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-05-06, MAE is:1.11 & sMAPE is:2.63% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.32 & 4.79% & 0.86\n",
      "for 2019-05-07, MAE is:1.44 & sMAPE is:3.37% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :2.31 & 4.78% & 0.85\n",
      "for 2019-05-08, MAE is:1.88 & sMAPE is:4.43% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.31 & 4.78% & 0.85\n",
      "for 2019-05-09, MAE is:3.58 & sMAPE is:8.55% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :2.32 & 4.81% & 0.85\n",
      "for 2019-05-10, MAE is:1.00 & sMAPE is:2.33% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :2.31 & 4.79% & 0.84\n",
      "for 2019-05-11, MAE is:1.30 & sMAPE is:3.17% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :2.30 & 4.77% & 0.84\n",
      "for 2019-05-12, MAE is:0.98 & sMAPE is:2.39% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 4.76% & 0.85\n",
      "for 2019-05-13, MAE is:1.48 & sMAPE is:3.54% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 4.75% & 0.85\n",
      "for 2019-05-14, MAE is:0.95 & sMAPE is:2.25% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 4.73% & 0.85\n",
      "for 2019-05-15, MAE is:1.56 & sMAPE is:3.77% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :2.27 & 4.72% & 0.86\n",
      "for 2019-05-16, MAE is:1.35 & sMAPE is:3.48% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :2.26 & 4.71% & 0.85\n",
      "for 2019-05-17, MAE is:2.31 & sMAPE is:5.84% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :2.26 & 4.72% & 0.85\n",
      "for 2019-05-18, MAE is:2.59 & sMAPE is:6.77% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :2.27 & 4.74% & 0.85\n",
      "for 2019-05-19, MAE is:2.15 & sMAPE is:5.72% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :2.27 & 4.74% & 0.85\n",
      "for 2019-05-20, MAE is:3.55 & sMAPE is:8.74% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 4.77% & 0.85\n",
      "for 2019-05-21, MAE is:2.40 & sMAPE is:6.19% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 4.78% & 0.85\n",
      "for 2019-05-22, MAE is:2.61 & sMAPE is:7.05% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 4.80% & 0.85\n",
      "for 2019-05-23, MAE is:2.03 & sMAPE is:5.38% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 4.80% & 0.85\n",
      "for 2019-05-24, MAE is:2.17 & sMAPE is:5.59% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 4.81% & 0.85\n",
      "for 2019-05-25, MAE is:1.12 & sMAPE is:3.15% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :2.27 & 4.80% & 0.85\n",
      "for 2019-05-26, MAE is:4.82 & sMAPE is:16.90% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 4.88% & 0.85\n",
      "for 2019-05-27, MAE is:4.16 & sMAPE is:11.68% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :2.30 & 4.92% & 0.85\n",
      "for 2019-05-28, MAE is:1.54 & sMAPE is:4.14% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 4.92% & 0.85\n",
      "for 2019-05-29, MAE is:0.96 & sMAPE is:2.63% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 4.90% & 0.84\n",
      "for 2019-05-30, MAE is:3.82 & sMAPE is:11.84% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 4.95% & 0.84\n",
      "for 2019-05-31, MAE is:2.05 & sMAPE is:5.78% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 4.96% & 0.84\n",
      "for 2019-06-01, MAE is:2.73 & sMAPE is:8.11% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.30 & 4.98% & 0.84\n",
      "for 2019-06-02, MAE is:4.07 & sMAPE is:12.84% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :2.31 & 5.03% & 0.85\n",
      "for 2019-06-03, MAE is:4.74 & sMAPE is:14.91% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :2.32 & 5.09% & 0.85\n",
      "for 2019-06-04, MAE is:2.23 & sMAPE is:6.22% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :2.32 & 5.10% & 0.85\n",
      "for 2019-06-05, MAE is:2.24 & sMAPE is:7.47% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.32 & 5.11% & 0.85\n",
      "for 2019-06-06, MAE is:1.30 & sMAPE is:4.41% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :2.32 & 5.11% & 0.84\n",
      "for 2019-06-07, MAE is:1.61 & sMAPE is:5.41% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :2.31 & 5.11% & 0.84\n",
      "for 2019-06-08, MAE is:12.95 & sMAPE is:65.92% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :2.38 & 5.49% & 0.84\n",
      "for 2019-06-09, MAE is:18.23 & sMAPE is:97.34% & rMAE is:4.15 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 6.07% & 0.86\n",
      "for 2019-06-10, MAE is:3.20 & sMAPE is:10.20% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 6.09% & 0.86\n",
      "for 2019-06-11, MAE is:0.75 & sMAPE is:2.46% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :2.47 & 6.07% & 0.85\n",
      "for 2019-06-12, MAE is:1.44 & sMAPE is:4.55% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 6.06% & 0.85\n",
      "for 2019-06-13, MAE is:2.39 & sMAPE is:7.96% & rMAE is:2.60 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 6.07% & 0.86\n",
      "for 2019-06-14, MAE is:1.60 & sMAPE is:5.07% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 6.07% & 0.86\n",
      "for 2019-06-15, MAE is:1.53 & sMAPE is:5.65% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :2.45 & 6.06% & 0.86\n",
      "for 2019-06-16, MAE is:1.72 & sMAPE is:6.08% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :2.45 & 6.07% & 0.86\n",
      "for 2019-06-17, MAE is:1.97 & sMAPE is:6.45% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :2.45 & 6.07% & 0.86\n",
      "for 2019-06-18, MAE is:2.16 & sMAPE is:6.90% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :2.44 & 6.07% & 0.86\n",
      "for 2019-06-19, MAE is:1.38 & sMAPE is:4.30% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :2.44 & 6.06% & 0.87\n",
      "for 2019-06-20, MAE is:0.81 & sMAPE is:2.62% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 6.04% & 0.86\n",
      "for 2019-06-21, MAE is:1.91 & sMAPE is:6.38% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 6.04% & 0.86\n",
      "for 2019-06-22, MAE is:2.51 & sMAPE is:8.32% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 6.06% & 0.86\n",
      "for 2019-06-23, MAE is:2.74 & sMAPE is:10.09% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 6.08% & 0.87\n",
      "for 2019-06-24, MAE is:2.42 & sMAPE is:7.84% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 6.09% & 0.87\n",
      "for 2019-06-25, MAE is:2.28 & sMAPE is:7.42% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 6.10% & 0.87\n",
      "for 2019-06-26, MAE is:2.07 & sMAPE is:6.62% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :2.42 & 6.10% & 0.87\n",
      "for 2019-06-27, MAE is:2.92 & sMAPE is:10.88% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 6.13% & 0.88\n",
      "for 2019-06-28, MAE is:2.42 & sMAPE is:8.26% & rMAE is:2.65 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 6.14% & 0.89\n",
      "for 2019-06-29, MAE is:1.67 & sMAPE is:5.77% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :2.42 & 6.14% & 0.89\n",
      "for 2019-06-30, MAE is:4.97 & sMAPE is:21.59% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :2.44 & 6.22% & 0.89\n",
      "for 2019-07-01, MAE is:2.14 & sMAPE is:8.15% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :2.44 & 6.23% & 0.88\n",
      "for 2019-07-02, MAE is:1.51 & sMAPE is:5.59% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 6.23% & 0.88\n",
      "for 2019-07-03, MAE is:0.68 & sMAPE is:2.37% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :2.42 & 6.21% & 0.88\n",
      "for 2019-07-04, MAE is:1.08 & sMAPE is:3.88% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 6.20% & 0.88\n",
      "for 2019-07-05, MAE is:2.33 & sMAPE is:8.20% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 6.21% & 0.88\n",
      "for 2019-07-06, MAE is:1.17 & sMAPE is:4.13% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 6.20% & 0.88\n",
      "for 2019-07-07, MAE is:1.55 & sMAPE is:5.52% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 6.19% & 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-07-08, MAE is:0.93 & sMAPE is:3.05% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.39 & 6.18% & 0.87\n",
      "for 2019-07-09, MAE is:3.72 & sMAPE is:11.83% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 6.21% & 0.87\n",
      "for 2019-07-10, MAE is:1.51 & sMAPE is:4.70% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 6.20% & 0.87\n",
      "for 2019-07-11, MAE is:2.74 & sMAPE is:8.15% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 6.21% & 0.86\n",
      "for 2019-07-12, MAE is:2.92 & sMAPE is:8.30% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 6.22% & 0.86\n",
      "for 2019-07-13, MAE is:3.30 & sMAPE is:9.44% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 6.24% & 0.86\n",
      "for 2019-07-14, MAE is:2.34 & sMAPE is:6.58% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 6.24% & 0.86\n",
      "for 2019-07-15, MAE is:1.03 & sMAPE is:2.80% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 6.22% & 0.85\n",
      "for 2019-07-16, MAE is:0.81 & sMAPE is:2.20% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :2.39 & 6.20% & 0.85\n",
      "for 2019-07-17, MAE is:1.94 & sMAPE is:5.19% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :2.39 & 6.19% & 0.85\n",
      "for 2019-07-18, MAE is:1.97 & sMAPE is:5.25% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :2.39 & 6.19% & 0.85\n",
      "for 2019-07-19, MAE is:1.63 & sMAPE is:4.41% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :2.38 & 6.18% & 0.85\n",
      "for 2019-07-20, MAE is:0.89 & sMAPE is:2.46% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :2.38 & 6.16% & 0.85\n",
      "for 2019-07-21, MAE is:1.14 & sMAPE is:3.24% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :2.37 & 6.15% & 0.85\n",
      "for 2019-07-22, MAE is:0.62 & sMAPE is:1.69% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :2.36 & 6.13% & 0.85\n",
      "for 2019-07-23, MAE is:2.41 & sMAPE is:6.66% & rMAE is:3.05 ||| daily mean of MAE & sMAPE & rMAE till now are :2.36 & 6.13% & 0.86\n",
      "for 2019-07-24, MAE is:2.12 & sMAPE is:5.72% & rMAE is:4.90 ||| daily mean of MAE & sMAPE & rMAE till now are :2.36 & 6.13% & 0.88\n",
      "for 2019-07-25, MAE is:3.06 & sMAPE is:8.18% & rMAE is:4.90 ||| daily mean of MAE & sMAPE & rMAE till now are :2.36 & 6.14% & 0.90\n",
      "for 2019-07-26, MAE is:0.39 & sMAPE is:1.01% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :2.35 & 6.11% & 0.90\n",
      "for 2019-07-27, MAE is:0.92 & sMAPE is:2.48% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :2.35 & 6.09% & 0.90\n",
      "for 2019-07-28, MAE is:3.35 & sMAPE is:9.73% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :2.35 & 6.11% & 0.90\n",
      "for 2019-07-29, MAE is:3.26 & sMAPE is:8.63% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.36 & 6.12% & 0.90\n",
      "for 2019-07-30, MAE is:1.52 & sMAPE is:3.90% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :2.35 & 6.11% & 0.90\n",
      "for 2019-07-31, MAE is:2.42 & sMAPE is:6.39% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :2.35 & 6.11% & 0.91\n",
      "for 2019-08-01, MAE is:1.58 & sMAPE is:4.13% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :2.35 & 6.10% & 0.91\n",
      "for 2019-08-02, MAE is:1.02 & sMAPE is:2.60% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :2.34 & 6.09% & 0.91\n",
      "for 2019-08-03, MAE is:0.74 & sMAPE is:1.92% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :2.33 & 6.07% & 0.91\n",
      "for 2019-08-04, MAE is:1.44 & sMAPE is:3.74% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :2.33 & 6.06% & 0.90\n",
      "for 2019-08-05, MAE is:0.72 & sMAPE is:1.83% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :2.32 & 6.04% & 0.90\n",
      "for 2019-08-06, MAE is:1.68 & sMAPE is:4.28% & rMAE is:3.16 ||| daily mean of MAE & sMAPE & rMAE till now are :2.32 & 6.03% & 0.91\n",
      "for 2019-08-07, MAE is:0.69 & sMAPE is:1.80% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.31 & 6.01% & 0.92\n",
      "for 2019-08-08, MAE is:0.78 & sMAPE is:2.08% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :2.31 & 5.99% & 0.91\n",
      "for 2019-08-09, MAE is:1.35 & sMAPE is:3.67% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :2.30 & 5.98% & 0.91\n",
      "for 2019-08-10, MAE is:1.76 & sMAPE is:5.21% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :2.30 & 5.98% & 0.91\n",
      "for 2019-08-11, MAE is:5.57 & sMAPE is:22.08% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :2.31 & 6.05% & 0.91\n",
      "for 2019-08-12, MAE is:1.71 & sMAPE is:4.80% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :2.31 & 6.05% & 0.91\n",
      "for 2019-08-13, MAE is:0.85 & sMAPE is:2.36% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :2.30 & 6.03% & 0.90\n",
      "for 2019-08-14, MAE is:1.63 & sMAPE is:4.87% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :2.30 & 6.02% & 0.90\n",
      "for 2019-08-15, MAE is:1.31 & sMAPE is:4.14% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.30 & 6.02% & 0.90\n",
      "for 2019-08-16, MAE is:1.36 & sMAPE is:4.12% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 6.01% & 0.89\n",
      "for 2019-08-17, MAE is:3.17 & sMAPE is:12.41% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :2.30 & 6.04% & 0.89\n",
      "for 2019-08-18, MAE is:1.11 & sMAPE is:3.37% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 6.02% & 0.89\n",
      "for 2019-08-19, MAE is:1.97 & sMAPE is:6.09% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 6.02% & 0.89\n",
      "for 2019-08-20, MAE is:1.25 & sMAPE is:3.72% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 6.01% & 0.89\n",
      "for 2019-08-21, MAE is:0.49 & sMAPE is:1.45% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 5.99% & 0.89\n",
      "for 2019-08-22, MAE is:0.91 & sMAPE is:2.78% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :2.27 & 5.98% & 0.89\n",
      "for 2019-08-23, MAE is:1.52 & sMAPE is:4.83% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :2.27 & 5.98% & 0.89\n",
      "for 2019-08-24, MAE is:1.11 & sMAPE is:3.59% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :2.26 & 5.97% & 0.88\n",
      "for 2019-08-25, MAE is:1.48 & sMAPE is:4.60% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :2.26 & 5.96% & 0.89\n",
      "for 2019-08-26, MAE is:1.15 & sMAPE is:3.54% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :2.26 & 5.95% & 0.88\n",
      "for 2019-08-27, MAE is:2.43 & sMAPE is:7.21% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :2.26 & 5.96% & 0.89\n",
      "for 2019-08-28, MAE is:1.11 & sMAPE is:3.38% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 5.94% & 0.89\n",
      "for 2019-08-29, MAE is:1.19 & sMAPE is:3.62% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 5.94% & 0.89\n",
      "for 2019-08-30, MAE is:0.75 & sMAPE is:2.49% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 5.92% & 0.89\n",
      "for 2019-08-31, MAE is:1.02 & sMAPE is:3.51% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 5.91% & 0.89\n",
      "for 2019-09-01, MAE is:1.28 & sMAPE is:4.24% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 5.90% & 0.89\n",
      "for 2019-09-02, MAE is:1.44 & sMAPE is:4.81% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 5.90% & 0.88\n",
      "for 2019-09-03, MAE is:3.34 & sMAPE is:10.62% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 5.92% & 0.88\n",
      "for 2019-09-04, MAE is:2.34 & sMAPE is:7.28% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 5.92% & 0.88\n",
      "for 2019-09-05, MAE is:2.36 & sMAPE is:7.75% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 5.93% & 0.88\n",
      "for 2019-09-06, MAE is:1.70 & sMAPE is:5.74% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 5.93% & 0.88\n",
      "for 2019-09-07, MAE is:1.83 & sMAPE is:6.34% & rMAE is:2.82 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 5.93% & 0.89\n",
      "for 2019-09-08, MAE is:3.07 & sMAPE is:10.32% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 5.95% & 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-09-09, MAE is:3.11 & sMAPE is:10.04% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 5.97% & 0.90\n",
      "for 2019-09-10, MAE is:1.14 & sMAPE is:3.68% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 5.96% & 0.89\n",
      "for 2019-09-11, MAE is:0.97 & sMAPE is:3.33% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 5.95% & 0.89\n",
      "for 2019-09-12, MAE is:1.21 & sMAPE is:4.21% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 5.94% & 0.89\n",
      "for 2019-09-13, MAE is:1.72 & sMAPE is:5.95% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 5.94% & 0.89\n",
      "for 2019-09-14, MAE is:2.11 & sMAPE is:7.73% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 5.95% & 0.89\n",
      "for 2019-09-15, MAE is:4.01 & sMAPE is:18.41% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 6.00% & 0.89\n",
      "for 2019-09-16, MAE is:6.03 & sMAPE is:28.64% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 6.08% & 0.89\n",
      "for 2019-09-17, MAE is:3.83 & sMAPE is:14.08% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 6.11% & 0.89\n",
      "for 2019-09-18, MAE is:1.03 & sMAPE is:3.65% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 6.10% & 0.89\n",
      "for 2019-09-19, MAE is:0.65 & sMAPE is:2.23% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 6.09% & 0.89\n",
      "for 2019-09-20, MAE is:1.00 & sMAPE is:3.54% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 6.08% & 0.89\n",
      "for 2019-09-21, MAE is:2.54 & sMAPE is:8.82% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 6.09% & 0.89\n",
      "for 2019-09-22, MAE is:1.95 & sMAPE is:6.73% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 6.09% & 0.89\n",
      "for 2019-09-23, MAE is:0.81 & sMAPE is:2.71% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 6.08% & 0.89\n",
      "for 2019-09-24, MAE is:1.12 & sMAPE is:3.61% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 6.07% & 0.89\n",
      "for 2019-09-25, MAE is:1.69 & sMAPE is:5.45% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 6.07% & 0.89\n",
      "for 2019-09-26, MAE is:1.75 & sMAPE is:5.71% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 6.07% & 0.88\n",
      "for 2019-09-27, MAE is:2.61 & sMAPE is:8.29% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 6.08% & 0.88\n",
      "for 2019-09-28, MAE is:1.18 & sMAPE is:3.81% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 6.07% & 0.88\n",
      "for 2019-09-29, MAE is:2.55 & sMAPE is:8.45% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 6.08% & 0.88\n",
      "for 2019-09-30, MAE is:1.94 & sMAPE is:6.06% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 6.08% & 0.89\n",
      "for 2019-10-01, MAE is:2.42 & sMAPE is:7.38% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 6.08% & 0.89\n",
      "for 2019-10-02, MAE is:2.58 & sMAPE is:7.61% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 6.09% & 0.89\n",
      "for 2019-10-03, MAE is:2.62 & sMAPE is:7.50% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 6.09% & 0.89\n",
      "for 2019-10-04, MAE is:2.13 & sMAPE is:5.94% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 6.09% & 0.88\n",
      "for 2019-10-05, MAE is:1.96 & sMAPE is:5.49% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 6.09% & 0.88\n",
      "for 2019-10-06, MAE is:0.52 & sMAPE is:1.45% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :2.21 & 6.07% & 0.88\n",
      "for 2019-10-07, MAE is:5.75 & sMAPE is:14.04% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 6.10% & 0.88\n",
      "for 2019-10-08, MAE is:2.68 & sMAPE is:7.24% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 6.10% & 0.88\n",
      "for 2019-10-09, MAE is:3.29 & sMAPE is:8.75% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 6.11% & 0.88\n",
      "for 2019-10-10, MAE is:3.29 & sMAPE is:9.58% & rMAE is:2.52 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 6.13% & 0.89\n",
      "for 2019-10-11, MAE is:1.07 & sMAPE is:3.18% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 6.12% & 0.88\n",
      "for 2019-10-12, MAE is:3.75 & sMAPE is:11.79% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 6.14% & 0.89\n",
      "for 2019-10-13, MAE is:1.31 & sMAPE is:3.89% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 6.13% & 0.89\n",
      "for 2019-10-14, MAE is:0.96 & sMAPE is:2.81% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 6.12% & 0.88\n",
      "for 2019-10-15, MAE is:1.98 & sMAPE is:5.84% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 6.11% & 0.88\n",
      "for 2019-10-16, MAE is:0.81 & sMAPE is:2.34% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 6.10% & 0.88\n",
      "for 2019-10-17, MAE is:2.63 & sMAPE is:7.59% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 6.11% & 0.89\n",
      "for 2019-10-18, MAE is:2.16 & sMAPE is:6.03% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 6.11% & 0.89\n",
      "for 2019-10-19, MAE is:1.27 & sMAPE is:3.59% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 6.10% & 0.89\n",
      "for 2019-10-20, MAE is:2.59 & sMAPE is:7.23% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 6.10% & 0.89\n",
      "for 2019-10-21, MAE is:1.26 & sMAPE is:3.34% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 6.09% & 0.88\n",
      "for 2019-10-22, MAE is:2.50 & sMAPE is:6.83% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 6.10% & 0.88\n",
      "for 2019-10-23, MAE is:2.35 & sMAPE is:6.43% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 6.10% & 0.88\n",
      "for 2019-10-24, MAE is:1.61 & sMAPE is:4.40% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 6.09% & 0.88\n",
      "for 2019-10-25, MAE is:1.53 & sMAPE is:4.29% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 6.08% & 0.89\n",
      "for 2019-10-26, MAE is:1.84 & sMAPE is:5.19% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 6.08% & 0.89\n",
      "for 2019-10-27, MAE is:1.01 & sMAPE is:2.67% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :2.21 & 6.07% & 0.89\n",
      "for 2019-10-28, MAE is:3.03 & sMAPE is:7.85% & rMAE is:2.19 ||| daily mean of MAE & sMAPE & rMAE till now are :2.21 & 6.08% & 0.90\n",
      "for 2019-10-29, MAE is:1.36 & sMAPE is:3.45% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :2.21 & 6.07% & 0.90\n",
      "for 2019-10-30, MAE is:0.97 & sMAPE is:2.45% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :2.21 & 6.06% & 0.89\n",
      "for 2019-10-31, MAE is:2.19 & sMAPE is:5.62% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :2.21 & 6.05% & 0.89\n",
      "for 2019-11-01, MAE is:1.54 & sMAPE is:4.03% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :2.21 & 6.05% & 0.89\n",
      "for 2019-11-02, MAE is:1.34 & sMAPE is:3.62% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :2.20 & 6.04% & 0.90\n",
      "for 2019-11-03, MAE is:2.00 & sMAPE is:5.34% & rMAE is:2.14 ||| daily mean of MAE & sMAPE & rMAE till now are :2.20 & 6.04% & 0.90\n",
      "for 2019-11-04, MAE is:1.37 & sMAPE is:3.37% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :2.20 & 6.03% & 0.90\n",
      "for 2019-11-05, MAE is:3.06 & sMAPE is:7.26% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :2.20 & 6.03% & 0.90\n",
      "for 2019-11-06, MAE is:12.29 & sMAPE is:24.11% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 6.09% & 0.90\n",
      "for 2019-11-07, MAE is:2.39 & sMAPE is:5.25% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 6.09% & 0.90\n",
      "for 2019-11-08, MAE is:5.22 & sMAPE is:11.17% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 6.10% & 0.90\n",
      "for 2019-11-09, MAE is:1.51 & sMAPE is:3.62% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 6.10% & 0.90\n",
      "for 2019-11-10, MAE is:3.29 & sMAPE is:7.77% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 6.10% & 0.90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-11-11, MAE is:1.62 & sMAPE is:3.73% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 6.09% & 0.90\n",
      "for 2019-11-12, MAE is:3.09 & sMAPE is:7.39% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 6.10% & 0.90\n",
      "for 2019-11-13, MAE is:4.29 & sMAPE is:9.17% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 6.11% & 0.90\n",
      "for 2019-11-14, MAE is:3.77 & sMAPE is:8.01% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :2.26 & 6.11% & 0.90\n",
      "for 2019-11-15, MAE is:1.48 & sMAPE is:3.53% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.26 & 6.11% & 0.90\n",
      "for 2019-11-16, MAE is:1.66 & sMAPE is:4.20% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 6.10% & 0.90\n",
      "for 2019-11-17, MAE is:0.80 & sMAPE is:1.93% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 6.09% & 0.90\n",
      "for 2019-11-18, MAE is:1.50 & sMAPE is:3.57% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 6.08% & 0.90\n",
      "for 2019-11-19, MAE is:1.55 & sMAPE is:3.82% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 6.07% & 0.90\n",
      "for 2019-11-20, MAE is:4.91 & sMAPE is:11.39% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 6.09% & 0.90\n",
      "for 2019-11-21, MAE is:2.05 & sMAPE is:5.00% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 6.09% & 0.90\n",
      "for 2019-11-22, MAE is:1.94 & sMAPE is:4.83% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 6.08% & 0.90\n",
      "for 2019-11-23, MAE is:1.02 & sMAPE is:2.68% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 6.07% & 0.90\n",
      "for 2019-11-24, MAE is:1.67 & sMAPE is:4.31% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 6.07% & 0.90\n",
      "for 2019-11-25, MAE is:2.92 & sMAPE is:7.03% & rMAE is:2.90 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 6.07% & 0.91\n",
      "for 2019-11-26, MAE is:4.16 & sMAPE is:9.47% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 6.08% & 0.91\n",
      "for 2019-11-27, MAE is:1.34 & sMAPE is:3.17% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 6.07% & 0.91\n",
      "for 2019-11-28, MAE is:1.13 & sMAPE is:2.79% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 6.06% & 0.91\n",
      "for 2019-11-29, MAE is:2.61 & sMAPE is:6.45% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 6.06% & 0.91\n",
      "for 2019-11-30, MAE is:1.71 & sMAPE is:4.12% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 6.06% & 0.91\n",
      "for 2019-12-01, MAE is:1.22 & sMAPE is:2.93% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 6.05% & 0.91\n",
      "for 2019-12-02, MAE is:3.21 & sMAPE is:7.32% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 6.05% & 0.91\n",
      "for 2019-12-03, MAE is:5.02 & sMAPE is:10.50% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 6.06% & 0.91\n",
      "for 2019-12-04, MAE is:2.91 & sMAPE is:7.17% & rMAE is:3.01 ||| daily mean of MAE & sMAPE & rMAE till now are :2.26 & 6.07% & 0.92\n",
      "for 2019-12-05, MAE is:1.78 & sMAPE is:4.53% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :2.26 & 6.06% & 0.92\n",
      "for 2019-12-06, MAE is:0.79 & sMAPE is:2.08% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 6.05% & 0.92\n",
      "for 2019-12-07, MAE is:0.70 & sMAPE is:1.85% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 6.04% & 0.92\n",
      "for 2019-12-08, MAE is:0.67 & sMAPE is:1.76% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 6.03% & 0.91\n",
      "for 2019-12-09, MAE is:1.35 & sMAPE is:3.45% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 6.02% & 0.91\n",
      "for 2019-12-10, MAE is:3.20 & sMAPE is:7.41% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 6.02% & 0.91\n",
      "for 2019-12-11, MAE is:3.01 & sMAPE is:8.11% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 6.03% & 0.91\n",
      "for 2019-12-12, MAE is:1.61 & sMAPE is:4.04% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 6.02% & 0.92\n",
      "for 2019-12-13, MAE is:1.03 & sMAPE is:2.76% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 6.01% & 0.92\n",
      "for 2019-12-14, MAE is:1.22 & sMAPE is:3.40% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 6.01% & 0.92\n",
      "for 2019-12-15, MAE is:1.63 & sMAPE is:4.33% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 6.00% & 0.92\n",
      "for 2019-12-16, MAE is:2.31 & sMAPE is:5.87% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 6.00% & 0.92\n",
      "for 2019-12-17, MAE is:1.59 & sMAPE is:4.08% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 5.99% & 0.92\n",
      "for 2019-12-18, MAE is:1.97 & sMAPE is:5.19% & rMAE is:3.37 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 5.99% & 0.93\n",
      "for 2019-12-19, MAE is:0.84 & sMAPE is:2.24% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 5.98% & 0.93\n",
      "for 2019-12-20, MAE is:1.44 & sMAPE is:4.01% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 5.98% & 0.93\n",
      "for 2019-12-21, MAE is:1.01 & sMAPE is:2.83% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 5.97% & 0.93\n",
      "for 2019-12-22, MAE is:1.89 & sMAPE is:5.26% & rMAE is:3.86 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 5.97% & 0.94\n",
      "for 2019-12-23, MAE is:0.71 & sMAPE is:1.95% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 5.95% & 0.93\n",
      "for 2019-12-24, MAE is:0.92 & sMAPE is:2.52% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :2.21 & 5.94% & 0.93\n",
      "for 2019-12-25, MAE is:0.63 & sMAPE is:1.77% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :2.21 & 5.93% & 0.93\n",
      "for 2019-12-26, MAE is:1.56 & sMAPE is:4.28% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :2.21 & 5.93% & 0.93\n",
      "for 2019-12-27, MAE is:1.12 & sMAPE is:2.98% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :2.20 & 5.92% & 0.93\n",
      "for 2019-12-28, MAE is:0.73 & sMAPE is:2.07% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :2.20 & 5.91% & 0.93\n",
      "for 2019-12-29, MAE is:1.04 & sMAPE is:3.12% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :2.20 & 5.90% & 0.93\n",
      "for 2019-12-30, MAE is:0.52 & sMAPE is:1.53% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :2.19 & 5.89% & 0.93\n",
      "for 2019-12-31, MAE is:0.77 & sMAPE is:2.35% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :2.19 & 5.88% & 0.93\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3 (PC Version - Run on Laptop)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:44:18,499]\u001b[0m A new study created in RDB with name: NO_2_2020\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:45:12,220]\u001b[0m Trial 1 finished with value: 2.2005944818003 and parameters: {'n_hidden': 3, 'learning_rate': 0.009626259150123415, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3075661901168214, 'dropout_rate_Layer_2': 0.27472072708152634, 'dropout_rate_Layer_3': 0.28998503621401345, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.014482498609053639, 'l1_Layer_2': 1.6162986381134546e-05, 'l1_Layer_3': 0.00491464502477845, 'n_units_Layer_1': 195, 'n_units_Layer_2': 170, 'n_units_Layer_3': 95}. Best is trial 1 with value: 2.2005944818003.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.20 | sMAPE for Validation Set is: 5.69% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 17.19 | sMAPE for Test Set is: 111.40% | rMAE for Test Set is: 5.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:45:21,088]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:45:26,584]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:45:31,810]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:45:48,478]\u001b[0m Trial 0 finished with value: 2.1498392997240887 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032726889101891677, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07411105860289893, 'dropout_rate_Layer_2': 0.16808309769687063, 'dropout_rate_Layer_3': 0.024654642129889305, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00044115837451523076, 'l1_Layer_2': 0.02416671670626459, 'l1_Layer_3': 0.00017610998834230842, 'n_units_Layer_1': 260, 'n_units_Layer_2': 100, 'n_units_Layer_3': 185}. Best is trial 0 with value: 2.1498392997240887.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.15 | sMAPE for Validation Set is: 5.55% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 13.60 | sMAPE for Test Set is: 102.65% | rMAE for Test Set is: 4.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:45:56,080]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:46:31,597]\u001b[0m Trial 7 finished with value: 3.9162622348778293 and parameters: {'n_hidden': 3, 'learning_rate': 0.061663189308145766, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09013226128012049, 'dropout_rate_Layer_2': 0.3918957110394187, 'dropout_rate_Layer_3': 0.1916172274258214, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.04517205672520991, 'l1_Layer_2': 0.046767665097033215, 'l1_Layer_3': 1.9131253404989063e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 195, 'n_units_Layer_3': 50}. Best is trial 0 with value: 2.1498392997240887.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.92 | sMAPE for Validation Set is: 10.00% | rMAE for Validation Set is: 1.18\n",
      "MAE for Test Set is: 20.49 | sMAPE for Test Set is: 117.90% | rMAE for Test Set is: 6.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:46:40,696]\u001b[0m Trial 5 finished with value: 3.7435502304755564 and parameters: {'n_hidden': 4, 'learning_rate': 0.057960361035470156, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12818019127741415, 'dropout_rate_Layer_2': 0.1635189326513753, 'dropout_rate_Layer_3': 0.32801304546014604, 'dropout_rate_Layer_4': 0.34880831837594967, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0018482109525584098, 'l1_Layer_2': 0.0026953993716596573, 'l1_Layer_3': 0.02177464637644487, 'l1_Layer_4': 0.0020060627139742685, 'n_units_Layer_1': 220, 'n_units_Layer_2': 285, 'n_units_Layer_3': 270, 'n_units_Layer_4': 170}. Best is trial 0 with value: 2.1498392997240887.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 9.33% | rMAE for Validation Set is: 1.13\n",
      "MAE for Test Set is: 21.09 | sMAPE for Test Set is: 119.01% | rMAE for Test Set is: 6.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:46:51,511]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:46:55,724]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:47:01,363]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:47:25,496]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:48:59,814]\u001b[0m Trial 13 finished with value: 1.940978977462655 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005528222377365879, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12548068345451666, 'dropout_rate_Layer_2': 0.047536108434008066, 'dropout_rate_Layer_3': 0.034393141154106924, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.011786303073258416, 'l1_Layer_2': 0.0065805374835164404, 'l1_Layer_3': 0.004230392819154221, 'n_units_Layer_1': 295, 'n_units_Layer_2': 230, 'n_units_Layer_3': 55}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.07% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 10.32 | sMAPE for Test Set is: 92.75% | rMAE for Test Set is: 3.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:49:09,593]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:49:19,190]\u001b[0m Trial 15 finished with value: 5.812320331603677 and parameters: {'n_hidden': 3, 'learning_rate': 0.08650383804883308, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2301253427993959, 'dropout_rate_Layer_2': 0.3975594742836312, 'dropout_rate_Layer_3': 0.2999208180334989, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 2.8644853027220775e-05, 'l1_Layer_2': 0.0017619362381210517, 'l1_Layer_3': 5.0339086558603926e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 175, 'n_units_Layer_3': 130}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 15.11% | rMAE for Validation Set is: 1.76\n",
      "MAE for Test Set is: 22.54 | sMAPE for Test Set is: 122.34% | rMAE for Test Set is: 7.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:49:24,871]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:49:30,020]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:49:34,299]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:49:39,592]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:49:46,558]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:49:56,764]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:50:04,693]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:50:09,671]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:50:14,013]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:50:21,022]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:50:24,327]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:50:28,950]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:50:41,722]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:50:46,108]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:50:55,886]\u001b[0m Trial 10 finished with value: 2.339945245233106 and parameters: {'n_hidden': 4, 'learning_rate': 0.001997006779951556, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19162789820535164, 'dropout_rate_Layer_2': 0.11361563727795763, 'dropout_rate_Layer_3': 0.238324025962828, 'dropout_rate_Layer_4': 0.11593081000456902, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.8870972298975324e-05, 'l1_Layer_2': 3.53176509558283e-05, 'l1_Layer_3': 0.013749548292080416, 'l1_Layer_4': 0.0024457981328387533, 'n_units_Layer_1': 120, 'n_units_Layer_2': 255, 'n_units_Layer_3': 90, 'n_units_Layer_4': 180}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.34 | sMAPE for Validation Set is: 6.03% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 18.72 | sMAPE for Test Set is: 115.11% | rMAE for Test Set is: 5.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:51:11,409]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:51:35,765]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:51:40,615]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:51:50,371]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:51:55,233]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:52:18,040]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:52:22,774]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:52:34,575]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:52:42,057]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:52:45,138]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:52:52,353]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:52:57,585]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:53:02,193]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:53:16,899]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:53:21,187]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:53:31,794]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:53:51,593]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:55:00,796]\u001b[0m Trial 48 finished with value: 2.089238842514862 and parameters: {'n_hidden': 3, 'learning_rate': 0.002709111168212841, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3480269978146854, 'dropout_rate_Layer_2': 0.2167551498452785, 'dropout_rate_Layer_3': 0.2186870912545429, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02950419135904272, 'l1_Layer_2': 0.03667475432218756, 'l1_Layer_3': 0.004065771617221155, 'n_units_Layer_1': 100, 'n_units_Layer_2': 160, 'n_units_Layer_3': 50}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 5.50% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.33 | sMAPE for Test Set is: 63.98% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:55:05,900]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:55:08,781]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:55:16,171]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:55:20,330]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:55:27,722]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:55:32,868]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:55:40,311]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:55:45,005]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:55:55,134]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:56:05,385]\u001b[0m Trial 30 finished with value: 2.4265552504058214 and parameters: {'n_hidden': 3, 'learning_rate': 0.004097738866740605, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013150889335083172, 'dropout_rate_Layer_2': 0.1789757371975406, 'dropout_rate_Layer_3': 0.37834944174989454, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.014968358825761975, 'l1_Layer_2': 3.291065411551215e-05, 'l1_Layer_3': 0.013765590799584481, 'n_units_Layer_1': 240, 'n_units_Layer_2': 95, 'n_units_Layer_3': 175}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.43 | sMAPE for Validation Set is: 6.31% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 13.26 | sMAPE for Test Set is: 101.06% | rMAE for Test Set is: 4.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:56:07,802]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:56:11,993]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:56:17,373]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:56:32,164]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:56:39,272]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:56:41,960]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:56:47,348]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:56:49,731]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:56:59,300]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:57:11,926]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:57:16,654]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:57:33,672]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:57:58,235]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:58:01,568]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:58:06,063]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:58:16,265]\u001b[0m Trial 70 finished with value: 2.2101685435279124 and parameters: {'n_hidden': 4, 'learning_rate': 0.009700798331405466, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10914397346095721, 'dropout_rate_Layer_2': 0.12367016082888622, 'dropout_rate_Layer_3': 0.36825952909279164, 'dropout_rate_Layer_4': 0.05595058300109132, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0008706424593256298, 'l1_Layer_2': 0.0025351138506491586, 'l1_Layer_3': 0.012741365366272236, 'l1_Layer_4': 0.004527692978498754, 'n_units_Layer_1': 290, 'n_units_Layer_2': 300, 'n_units_Layer_3': 50, 'n_units_Layer_4': 235}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.21 | sMAPE for Validation Set is: 5.70% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 18.28 | sMAPE for Test Set is: 113.28% | rMAE for Test Set is: 5.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:58:18,945]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:58:23,521]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:58:51,312]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.23 | sMAPE for Validation Set is: 5.83% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 1.68 | sMAPE for Test Set is: 27.97% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:59:12,854]\u001b[0m Trial 77 finished with value: 2.2317221473803954 and parameters: {'n_hidden': 3, 'learning_rate': 0.002579332361417188, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.321076908442883, 'dropout_rate_Layer_2': 0.23199236213447522, 'dropout_rate_Layer_3': 0.354187494623865, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0262966665371127, 'l1_Layer_2': 0.04888858368462251, 'l1_Layer_3': 0.00012005283870156829, 'n_units_Layer_1': 80, 'n_units_Layer_2': 120, 'n_units_Layer_3': 55}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:59:19,794]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:59:42,755]\u001b[0m Trial 78 finished with value: 2.2122640481785467 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030251779468318087, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3263067644217869, 'dropout_rate_Layer_2': 0.23188881392568098, 'dropout_rate_Layer_3': 0.022987464898309898, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02427387807832506, 'l1_Layer_2': 0.047010924144754294, 'l1_Layer_3': 0.00012084844266618148, 'n_units_Layer_1': 85, 'n_units_Layer_2': 125, 'n_units_Layer_3': 60}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.21 | sMAPE for Validation Set is: 5.76% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 2.90 | sMAPE for Test Set is: 87.47% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:00:08,740]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:00:11,132]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:00:24,495]\u001b[0m Trial 83 finished with value: 2.540533346144181 and parameters: {'n_hidden': 3, 'learning_rate': 0.027650215638472867, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20818112051348822, 'dropout_rate_Layer_2': 0.03803067639476496, 'dropout_rate_Layer_3': 0.27417063013684223, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.007231307621176181, 'l1_Layer_2': 7.962282567739057e-05, 'l1_Layer_3': 0.009158918552712095, 'n_units_Layer_1': 60, 'n_units_Layer_2': 175, 'n_units_Layer_3': 200}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.54 | sMAPE for Validation Set is: 6.58% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 17.66 | sMAPE for Test Set is: 112.66% | rMAE for Test Set is: 5.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:00:31,383]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:00:34,540]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:00:41,118]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:00:46,899]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:00:52,713]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:00:57,057]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:01:00,459]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:01:30,154]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:01:34,457]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:01:54,135]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:01:56,286]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:02:01,599]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:02:04,483]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:02:11,344]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:02:11,649]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:02:19,199]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:02:36,480]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:02:43,385]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:02:50,715]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:02:53,973]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:02:58,570]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:03:06,066]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:03:10,510]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:03:22,711]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:03:28,615]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:03:52,404]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:03:57,895]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:04:07,257]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:04:12,673]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:04:12,993]\u001b[0m Trial 105 finished with value: 2.4112734548295234 and parameters: {'n_hidden': 3, 'learning_rate': 0.010924722915748643, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009588644400680777, 'dropout_rate_Layer_2': 0.11555512135195092, 'dropout_rate_Layer_3': 0.39565523063008157, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.007842302870734976, 'l1_Layer_2': 0.00013487768297405135, 'l1_Layer_3': 0.03329217209545547, 'n_units_Layer_1': 140, 'n_units_Layer_2': 280, 'n_units_Layer_3': 300}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.41 | sMAPE for Validation Set is: 6.21% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 19.84 | sMAPE for Test Set is: 116.70% | rMAE for Test Set is: 6.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:04:20,484]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:04:27,896]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:04:32,226]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:04:32,900]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:04:52,431]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:05:07,273]\u001b[0m Trial 118 finished with value: 2.8762538269955797 and parameters: {'n_hidden': 3, 'learning_rate': 0.025826029582847118, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14499029782776415, 'dropout_rate_Layer_2': 0.3002225812527294, 'dropout_rate_Layer_3': 0.2931697421896727, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2577595397772289e-05, 'l1_Layer_2': 0.005804595474715312, 'l1_Layer_3': 0.061395591929518455, 'n_units_Layer_1': 300, 'n_units_Layer_2': 155, 'n_units_Layer_3': 195}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.88 | sMAPE for Validation Set is: 7.29% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 14.37 | sMAPE for Test Set is: 104.48% | rMAE for Test Set is: 4.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:05:24,238]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:05:26,874]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:05:28,961]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:05:33,674]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:05:38,873]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:05:43,734]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:05:44,098]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:05:55,758]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:07:14,107]\u001b[0m Trial 128 finished with value: 2.241414207275575 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016459504331689033, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2743879572363447, 'dropout_rate_Layer_2': 0.11147809032863913, 'dropout_rate_Layer_3': 0.36991523547386296, 'dropout_rate_Layer_4': 0.11113328735623276, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00011180883155670813, 'l1_Layer_2': 0.0002358481624355619, 'l1_Layer_3': 0.00276463002656219, 'l1_Layer_4': 0.00016674624909492248, 'n_units_Layer_1': 185, 'n_units_Layer_2': 270, 'n_units_Layer_3': 130, 'n_units_Layer_4': 110}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.24 | sMAPE for Validation Set is: 5.83% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 16.19 | sMAPE for Test Set is: 108.56% | rMAE for Test Set is: 5.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:07:21,391]\u001b[0m Trial 127 finished with value: 2.120823022093853 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027518338621511573, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38732115541697854, 'dropout_rate_Layer_2': 0.24486586593115478, 'dropout_rate_Layer_3': 0.19968031764884875, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07073095917992246, 'l1_Layer_2': 0.054838966798974334, 'l1_Layer_3': 0.00010262473645382263, 'n_units_Layer_1': 110, 'n_units_Layer_2': 120, 'n_units_Layer_3': 195}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 5.58% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 2.86 | sMAPE for Test Set is: 50.34% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:07:35,470]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:07:40,697]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:07:45,990]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:07:56,095]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:08:01,439]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:08:08,324]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:08:15,587]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:08:16,269]\u001b[0m Trial 130 finished with value: 2.1178514103649717 and parameters: {'n_hidden': 3, 'learning_rate': 0.002244364262708194, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39859207475076586, 'dropout_rate_Layer_2': 0.2480096453085162, 'dropout_rate_Layer_3': 0.3875824182655934, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08297434506366295, 'l1_Layer_2': 0.0721532260477468, 'l1_Layer_3': 4.265355938549525e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 90, 'n_units_Layer_3': 190}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 5.67% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 1.67 | sMAPE for Test Set is: 35.17% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:08:27,857]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:08:40,470]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:08:54,790]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:09:07,065]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:09:07,483]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:09:19,941]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:09:37,923]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:09:45,448]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:09:52,016]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:09:59,481]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:10:09,211]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:10:13,890]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:10:16,286]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:10:21,540]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:10:51,436]\u001b[0m Trial 151 finished with value: 2.681352835713818 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029699814147484396, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22686756584877626, 'dropout_rate_Layer_2': 0.011615846936376207, 'dropout_rate_Layer_3': 0.03964509847511484, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00035253361959360557, 'l1_Layer_2': 3.18656596425942e-05, 'l1_Layer_3': 0.0034190223311221096, 'n_units_Layer_1': 180, 'n_units_Layer_2': 90, 'n_units_Layer_3': 275}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.68 | sMAPE for Validation Set is: 7.22% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 16.03 | sMAPE for Test Set is: 108.91% | rMAE for Test Set is: 5.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:10:55,420]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:11:05,464]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:11:08,506]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:11:14,808]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:11:17,886]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:11:25,315]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:11:28,731]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:11:50,174]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:12:14,843]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:12:19,829]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:12:42,119]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:12:57,650]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:08,161]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:17,765]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:24,771]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:32,563]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:42,103]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:44,776]\u001b[0m Trial 157 finished with value: 2.0822044108300237 and parameters: {'n_hidden': 3, 'learning_rate': 0.012482908799826237, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14079999570623045, 'dropout_rate_Layer_2': 0.2512768597186177, 'dropout_rate_Layer_3': 0.3964911317080247, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0002670408047455454, 'l1_Layer_2': 0.002074381844429599, 'l1_Layer_3': 0.0003991944319124362, 'n_units_Layer_1': 130, 'n_units_Layer_2': 240, 'n_units_Layer_3': 115}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 5.38% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 17.40 | sMAPE for Test Set is: 111.22% | rMAE for Test Set is: 5.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:13:49,397]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:51,754]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:56,793]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:14:05,647]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:14:08,141]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:14:17,870]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:14:20,407]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:14:27,178]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:14:27,425]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:14:35,343]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:14:37,283]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:14:44,606]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:14:45,155]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:14:50,965]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:14:55,739]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:15:00,489]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:15:05,831]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:15:10,151]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:15:15,478]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:15:20,298]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:15:27,468]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:15:30,290]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:15:40,190]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:15:44,985]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:15:50,550]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:15:57,318]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:16:07,397]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:16:19,788]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:16:24,725]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:16:30,052]\u001b[0m Trial 195 finished with value: 2.137596790404293 and parameters: {'n_hidden': 4, 'learning_rate': 0.0025016009305331302, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1438410590234494, 'dropout_rate_Layer_2': 0.05915082642044353, 'dropout_rate_Layer_3': 0.3780284886410745, 'dropout_rate_Layer_4': 0.11421776707708559, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 1.5263757318191508e-05, 'l1_Layer_2': 0.00020638515057849548, 'l1_Layer_3': 0.0010754161625223125, 'l1_Layer_4': 0.00011687312631956833, 'n_units_Layer_1': 190, 'n_units_Layer_2': 200, 'n_units_Layer_3': 150, 'n_units_Layer_4': 170}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.14 | sMAPE for Validation Set is: 5.57% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 16.21 | sMAPE for Test Set is: 108.72% | rMAE for Test Set is: 5.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:16:35,444]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:16:37,867]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:16:40,295]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:16:45,056]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:16:55,203]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:17:05,352]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:17:10,797]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:17:15,506]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:17:22,415]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:17:25,621]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:17:30,106]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:17:45,326]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:17:52,475]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:18:09,748]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:18:16,887]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:18:21,974]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:18:32,173]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:18:54,356]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:19:00,283]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:19:07,003]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:19:12,467]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:19:14,989]\u001b[0m Trial 212 finished with value: 2.1665537933175565 and parameters: {'n_hidden': 3, 'learning_rate': 0.00334039215582941, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03451937005540767, 'dropout_rate_Layer_2': 0.1673045500528591, 'dropout_rate_Layer_3': 0.3996250843837785, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00047791054087078, 'l1_Layer_2': 0.0001724197224860842, 'l1_Layer_3': 0.003035823505969018, 'n_units_Layer_1': 140, 'n_units_Layer_2': 255, 'n_units_Layer_3': 175}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.17 | sMAPE for Validation Set is: 5.66% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 17.32 | sMAPE for Test Set is: 110.82% | rMAE for Test Set is: 5.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:19:19,184]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:19:22,959]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:19:36,295]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:19:39,045]\u001b[0m Trial 225 finished with value: 2.015110308347024 and parameters: {'n_hidden': 3, 'learning_rate': 0.006147431713194852, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2564121752280775, 'dropout_rate_Layer_2': 0.3698298080794808, 'dropout_rate_Layer_3': 0.26599601848894344, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.023742124107051708, 'l1_Layer_2': 0.00506911039783844, 'l1_Layer_3': 0.07131026159675953, 'n_units_Layer_1': 240, 'n_units_Layer_2': 130, 'n_units_Layer_3': 240}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.02 | sMAPE for Validation Set is: 5.29% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 15.77 | sMAPE for Test Set is: 109.12% | rMAE for Test Set is: 4.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:19:59,231]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:19:59,571]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:20:10,209]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:20:15,884]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:20:25,521]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:20:28,043]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:20:45,294]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:20:57,187]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:21:02,286]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:21:07,238]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:21:14,707]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:21:20,113]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:21:26,961]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:21:37,389]\u001b[0m Trial 233 finished with value: 2.129663109122264 and parameters: {'n_hidden': 4, 'learning_rate': 0.003840377560744017, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1303532064109054, 'dropout_rate_Layer_2': 0.05445410880148714, 'dropout_rate_Layer_3': 0.32071590881160683, 'dropout_rate_Layer_4': 0.0881046782895259, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.6985593327866652e-05, 'l1_Layer_2': 0.0004287938867580614, 'l1_Layer_3': 0.00027762114602320354, 'l1_Layer_4': 0.003912458345903025, 'n_units_Layer_1': 280, 'n_units_Layer_2': 290, 'n_units_Layer_3': 245, 'n_units_Layer_4': 170}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 5.56% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 16.00 | sMAPE for Test Set is: 108.05% | rMAE for Test Set is: 5.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:21:41,517]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:21:44,715]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:21:53,786]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:01,785]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:08,478]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:13,364]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:16,623]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:21,045]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:23,766]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:28,223]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:33,728]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:37,840]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:41,006]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:43,133]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:48,380]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:50,720]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:55,788]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:23:00,541]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:23:00,790]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:23:06,746]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:23:09,100]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:23:20,804]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:23:35,906]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:23:45,800]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:23:52,969]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:23:55,895]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:24:13,412]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:24:15,782]\u001b[0m Trial 261 finished with value: 2.1585673619027026 and parameters: {'n_hidden': 3, 'learning_rate': 0.001438463017888066, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3870801814009374, 'dropout_rate_Layer_2': 0.2552662852045696, 'dropout_rate_Layer_3': 0.16831393063799188, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03795108943631847, 'l1_Layer_2': 7.67223754381426e-05, 'l1_Layer_3': 0.00010217197539701855, 'n_units_Layer_1': 95, 'n_units_Layer_2': 105, 'n_units_Layer_3': 195}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.16 | sMAPE for Validation Set is: 5.50% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 12.64 | sMAPE for Test Set is: 100.46% | rMAE for Test Set is: 3.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:24:20,256]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:24:23,003]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:24:25,466]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:24:27,846]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:24:35,318]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:24:44,786]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:24:52,337]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:25:15,080]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:25:18,784]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:25:20,939]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:25:25,470]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:25:25,632]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:25:32,154]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:25:41,627]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:25:46,291]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:25:57,032]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:26:06,853]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:26:16,860]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:26:26,544]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:26:31,658]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:26:36,253]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:26:43,452]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:26:43,790]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:26:51,308]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:26:56,388]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:27:00,702]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:27:02,634]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:27:11,955]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:27:14,691]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:27:19,307]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:27:24,407]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:27:31,420]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:27:31,946]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:27:37,064]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:27:46,607]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:27:53,667]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:28:07,068]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:28:13,703]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:28:41,785]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:28:48,119]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:29:01,490]\u001b[0m Trial 308 finished with value: 4.048297066120239 and parameters: {'n_hidden': 3, 'learning_rate': 0.0915745012098062, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34908688325229775, 'dropout_rate_Layer_2': 0.3465108187442439, 'dropout_rate_Layer_3': 0.13657519896691164, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00031566177540588486, 'l1_Layer_2': 0.0022793060328575076, 'l1_Layer_3': 0.028132765050556133, 'n_units_Layer_1': 255, 'n_units_Layer_2': 260, 'n_units_Layer_3': 255}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.05 | sMAPE for Validation Set is: 10.61% | rMAE for Validation Set is: 1.22\n",
      "MAE for Test Set is: 17.23 | sMAPE for Test Set is: 111.79% | rMAE for Test Set is: 5.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:29:13,556]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:29:33,181]\u001b[0m Trial 309 finished with value: 6.761428688367208 and parameters: {'n_hidden': 3, 'learning_rate': 0.0659501630725099, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.037328237616770864, 'dropout_rate_Layer_2': 0.0007082426781684693, 'dropout_rate_Layer_3': 0.27088031009408803, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.061777916132583245, 'l1_Layer_2': 0.0008043997436405265, 'l1_Layer_3': 0.00039666130339930956, 'n_units_Layer_1': 240, 'n_units_Layer_2': 175, 'n_units_Layer_3': 265}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.76 | sMAPE for Validation Set is: 18.39% | rMAE for Validation Set is: 2.05\n",
      "MAE for Test Set is: 16.83 | sMAPE for Test Set is: 109.96% | rMAE for Test Set is: 5.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:29:47,530]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:29:53,430]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:30:02,799]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:30:14,804]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:30:22,195]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:30:27,893]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:30:37,854]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:30:44,351]\u001b[0m Trial 311 finished with value: 2.44656837081554 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009444440772201245, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.305663205357522, 'dropout_rate_Layer_2': 0.33373179246606016, 'dropout_rate_Layer_3': 0.10933526513824693, 'dropout_rate_Layer_4': 0.24392928466484923, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0008681450330604675, 'l1_Layer_2': 0.0002039934895074335, 'l1_Layer_3': 0.06225771722474805, 'l1_Layer_4': 0.01996078035499386, 'n_units_Layer_1': 105, 'n_units_Layer_2': 115, 'n_units_Layer_3': 135, 'n_units_Layer_4': 55}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.45 | sMAPE for Validation Set is: 6.25% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 17.81 | sMAPE for Test Set is: 112.40% | rMAE for Test Set is: 5.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:31:31,912]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:31:46,680]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:32:27,329]\u001b[0m Trial 320 finished with value: 2.099973492498061 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022582427824076336, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1866510224763076, 'dropout_rate_Layer_2': 0.2385579125891728, 'dropout_rate_Layer_3': 0.34942804510292674, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.07740378835528451, 'l1_Layer_2': 0.027985670641207636, 'l1_Layer_3': 0.0008935499451299725, 'n_units_Layer_1': 90, 'n_units_Layer_2': 170, 'n_units_Layer_3': 195}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.10 | sMAPE for Validation Set is: 5.41% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.25 | sMAPE for Test Set is: 96.08% | rMAE for Test Set is: 3.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:32:39,741]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:32:46,367]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:32:51,755]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:33:12,028]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:33:18,588]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:33:18,894]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:33:25,693]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:33:26,084]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:33:33,530]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:33:37,834]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:33:45,233]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:33:55,649]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:34:25,294]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:34:35,916]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:34:36,026]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:34:46,680]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:34:51,094]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:34:56,911]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:35:12,072]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:35:23,493]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:35:51,496]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:35:56,020]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:36:05,906]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:36:16,160]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:36:41,973]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:36:49,833]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:36:56,716]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:37:06,766]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:37:11,273]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:37:38,310]\u001b[0m Trial 346 finished with value: 2.0904448544468512 and parameters: {'n_hidden': 3, 'learning_rate': 0.003928166368848332, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17714846328575304, 'dropout_rate_Layer_2': 0.18699062022053423, 'dropout_rate_Layer_3': 0.39915492996872937, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0814791377592148, 'l1_Layer_2': 0.04037737430857159, 'l1_Layer_3': 0.0015254018750459387, 'n_units_Layer_1': 135, 'n_units_Layer_2': 165, 'n_units_Layer_3': 235}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 5.41% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 13.51 | sMAPE for Test Set is: 102.61% | rMAE for Test Set is: 4.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:38:00,679]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:38:15,646]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:39:10,650]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:40:03,226]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:40:25,560]\u001b[0m Trial 352 finished with value: 2.035278760361272 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019849650639096406, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16580965686198176, 'dropout_rate_Layer_2': 0.014440417314090244, 'dropout_rate_Layer_3': 0.31199634354129546, 'dropout_rate_Layer_4': 0.185572522984814, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.132265596954482e-05, 'l1_Layer_2': 0.005798664659488403, 'l1_Layer_3': 0.035728949650201444, 'l1_Layer_4': 0.0028729038760689305, 'n_units_Layer_1': 240, 'n_units_Layer_2': 270, 'n_units_Layer_3': 215, 'n_units_Layer_4': 140}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 5.41% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.36 | sMAPE for Test Set is: 86.38% | rMAE for Test Set is: 2.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:40:50,266]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:40:50,462]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:41:03,417]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:41:13,949]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:41:18,344]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:41:24,082]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:41:35,587]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:41:36,090]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:41:48,061]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:41:48,470]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:42:10,109]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:42:10,249]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:42:37,927]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:42:38,016]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:42:59,715]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:43:24,779]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:43:44,743]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:44:06,297]\u001b[0m Trial 371 finished with value: 2.0889452435317657 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026277860953097835, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1916730683193482, 'dropout_rate_Layer_2': 0.08366658778190528, 'dropout_rate_Layer_3': 0.38040076183310273, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.06561569668685233, 'l1_Layer_2': 0.03202523729460607, 'l1_Layer_3': 0.0009743975604108885, 'n_units_Layer_1': 155, 'n_units_Layer_2': 165, 'n_units_Layer_3': 230}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 5.38% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.90 | sMAPE for Test Set is: 95.22% | rMAE for Test Set is: 3.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:44:38,919]\u001b[0m Trial 376 finished with value: 2.946258038959467 and parameters: {'n_hidden': 3, 'learning_rate': 0.04173305156564269, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2900571814473098, 'dropout_rate_Layer_2': 0.09910524614490512, 'dropout_rate_Layer_3': 0.2682413527952994, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004766112780673755, 'l1_Layer_2': 0.006201498903743418, 'l1_Layer_3': 0.0045888658973657894, 'n_units_Layer_1': 170, 'n_units_Layer_2': 285, 'n_units_Layer_3': 145}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.95 | sMAPE for Validation Set is: 7.53% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 17.50 | sMAPE for Test Set is: 111.56% | rMAE for Test Set is: 5.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:44:48,845]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:45:11,020]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:45:28,396]\u001b[0m Trial 379 finished with value: 4.306479185422263 and parameters: {'n_hidden': 3, 'learning_rate': 0.08035897498389145, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35144599747808714, 'dropout_rate_Layer_2': 0.3497219287258362, 'dropout_rate_Layer_3': 0.14587257479861335, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002882987353546676, 'l1_Layer_2': 0.002620688705264346, 'l1_Layer_3': 0.029747731338481086, 'n_units_Layer_1': 230, 'n_units_Layer_2': 255, 'n_units_Layer_3': 265}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 11.17% | rMAE for Validation Set is: 1.30\n",
      "MAE for Test Set is: 18.79 | sMAPE for Test Set is: 114.65% | rMAE for Test Set is: 5.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:45:38,300]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:45:43,777]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:45:58,379]\u001b[0m Trial 382 finished with value: 3.545740587138598 and parameters: {'n_hidden': 3, 'learning_rate': 0.03377411788681299, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31970811114648845, 'dropout_rate_Layer_2': 0.34294611906876193, 'dropout_rate_Layer_3': 0.04738025412000465, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.074511016644915e-05, 'l1_Layer_2': 0.001346179242800433, 'l1_Layer_3': 0.0036507553795997946, 'n_units_Layer_1': 190, 'n_units_Layer_2': 275, 'n_units_Layer_3': 250}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 9.06% | rMAE for Validation Set is: 1.07\n",
      "MAE for Test Set is: 19.54 | sMAPE for Test Set is: 116.40% | rMAE for Test Set is: 6.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:46:03,660]\u001b[0m Trial 375 finished with value: 2.0307630698241335 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025734403895064286, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18965503409042603, 'dropout_rate_Layer_2': 0.1013989238557517, 'dropout_rate_Layer_3': 0.3842980595870726, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.06817780008187153, 'l1_Layer_2': 0.06333242584694018, 'l1_Layer_3': 0.004516072374854488, 'n_units_Layer_1': 115, 'n_units_Layer_2': 170, 'n_units_Layer_3': 255}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 5.28% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 13.64 | sMAPE for Test Set is: 102.84% | rMAE for Test Set is: 4.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:46:17,584]\u001b[0m Trial 383 finished with value: 2.352835182939384 and parameters: {'n_hidden': 3, 'learning_rate': 0.02889500214776202, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23812880649571413, 'dropout_rate_Layer_2': 0.0022109603343248158, 'dropout_rate_Layer_3': 0.3664292774380873, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.01732303063965812, 'l1_Layer_2': 0.09619283812773687, 'l1_Layer_3': 0.008726789909739179, 'n_units_Layer_1': 60, 'n_units_Layer_2': 165, 'n_units_Layer_3': 190}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.35 | sMAPE for Validation Set is: 5.98% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 18.01 | sMAPE for Test Set is: 112.92% | rMAE for Test Set is: 5.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:46:27,848]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:46:39,501]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:46:45,269]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:46:46,969]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:46:54,344]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:47:46,991]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:47:57,228]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:48:21,988]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:48:41,601]\u001b[0m Trial 389 finished with value: 2.0799078623631373 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025359571064714525, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19259106555450248, 'dropout_rate_Layer_2': 0.09564257830670779, 'dropout_rate_Layer_3': 0.3667158560418342, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.042911722221441115, 'l1_Layer_2': 0.05758543664875347, 'l1_Layer_3': 0.002629641530710718, 'n_units_Layer_1': 130, 'n_units_Layer_2': 165, 'n_units_Layer_3': 255}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 5.40% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.27 | sMAPE for Test Set is: 99.30% | rMAE for Test Set is: 3.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:49:18,703]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:49:24,419]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:49:28,750]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:49:38,890]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:49:56,111]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:50:08,364]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:51:13,678]\u001b[0m Trial 397 finished with value: 2.0921407098432714 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027304241506027147, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20404299760439687, 'dropout_rate_Layer_2': 0.09648943096177878, 'dropout_rate_Layer_3': 0.3785032690940468, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.047698496851779064, 'l1_Layer_2': 0.05732126470443523, 'l1_Layer_3': 0.004139912780236302, 'n_units_Layer_1': 115, 'n_units_Layer_2': 155, 'n_units_Layer_3': 260}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 5.39% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 14.04 | sMAPE for Test Set is: 104.15% | rMAE for Test Set is: 4.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:51:25,461]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:51:55,381]\u001b[0m Trial 400 finished with value: 2.1145893368108317 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025404232619637944, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19833031638120993, 'dropout_rate_Layer_2': 0.0930289164192492, 'dropout_rate_Layer_3': 0.3810227605595866, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.04662554178402171, 'l1_Layer_2': 0.05904279297333524, 'l1_Layer_3': 0.0032723517347652423, 'n_units_Layer_1': 115, 'n_units_Layer_2': 155, 'n_units_Layer_3': 255}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.11 | sMAPE for Validation Set is: 5.48% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 13.22 | sMAPE for Test Set is: 102.00% | rMAE for Test Set is: 4.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:52:52,249]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:52:57,104]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:53:34,320]\u001b[0m Trial 402 finished with value: 2.0049055441797776 and parameters: {'n_hidden': 3, 'learning_rate': 0.002744665670210788, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05089138613378247, 'dropout_rate_Layer_2': 0.07229759214290028, 'dropout_rate_Layer_3': 0.36255517808280485, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03272320035813081, 'l1_Layer_2': 0.0701686017662604, 'l1_Layer_3': 0.008924425774333061, 'n_units_Layer_1': 115, 'n_units_Layer_2': 145, 'n_units_Layer_3': 255}. Best is trial 13 with value: 1.940978977462655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 5.21% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.06 | sMAPE for Test Set is: 95.50% | rMAE for Test Set is: 3.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:53:44,700]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:54:31,940]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:54:44,388]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:54:54,426]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:55:01,848]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:55:22,149]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:55:36,654]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:55:56,725]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:56:36,730]\u001b[0m Trial 407 finished with value: 1.927197182440447 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025778000849743057, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03488649426842483, 'dropout_rate_Layer_2': 0.10150086657733716, 'dropout_rate_Layer_3': 0.3456168562664592, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03479443096107245, 'l1_Layer_2': 0.07921050661524812, 'l1_Layer_3': 0.00805883435357405, 'n_units_Layer_1': 120, 'n_units_Layer_2': 155, 'n_units_Layer_3': 260}. Best is trial 407 with value: 1.927197182440447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.05% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.78 | sMAPE for Test Set is: 94.55% | rMAE for Test Set is: 3.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:56:41,388]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:57:30,159]\u001b[0m Trial 416 finished with value: 1.9443082984466127 and parameters: {'n_hidden': 3, 'learning_rate': 0.003643472171039226, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010979084526425934, 'dropout_rate_Layer_2': 0.10254552376390345, 'dropout_rate_Layer_3': 0.33511906844953276, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010048890319810629, 'l1_Layer_2': 4.6502459874101815e-05, 'l1_Layer_3': 5.893485181598876e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 165, 'n_units_Layer_3': 190}. Best is trial 407 with value: 1.927197182440447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.11% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 12.20 | sMAPE for Test Set is: 98.61% | rMAE for Test Set is: 3.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:57:35,855]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:57:44,867]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:59:04,128]\u001b[0m Trial 414 finished with value: 1.9110506651166208 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028694883239328796, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04050535691631786, 'dropout_rate_Layer_2': 0.0841907769889536, 'dropout_rate_Layer_3': 0.35671207659812804, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.028889653981686983, 'l1_Layer_2': 0.054615082437343046, 'l1_Layer_3': 0.007965842134284126, 'n_units_Layer_1': 200, 'n_units_Layer_2': 140, 'n_units_Layer_3': 260}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 5.02% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.56 | sMAPE for Test Set is: 97.14% | rMAE for Test Set is: 3.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:01:01,524]\u001b[0m Trial 419 finished with value: 2.00972433417869 and parameters: {'n_hidden': 3, 'learning_rate': 0.002542870260542187, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.040314848854847804, 'dropout_rate_Layer_2': 0.09779134811578233, 'dropout_rate_Layer_3': 0.3645033363087075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03190027624654829, 'l1_Layer_2': 0.07100549395514992, 'l1_Layer_3': 0.007305812756029774, 'n_units_Layer_1': 180, 'n_units_Layer_2': 155, 'n_units_Layer_3': 265}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 5.21% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 13.31 | sMAPE for Test Set is: 102.14% | rMAE for Test Set is: 4.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:01:04,552]\u001b[0m Trial 420 finished with value: 1.9355065418488486 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028939235441405886, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03428780529039873, 'dropout_rate_Layer_2': 0.07494205418190344, 'dropout_rate_Layer_3': 0.35738179159894273, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03160950101513493, 'l1_Layer_2': 0.0729552886167724, 'l1_Layer_3': 0.00919707953752089, 'n_units_Layer_1': 125, 'n_units_Layer_2': 140, 'n_units_Layer_3': 265}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.11% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.87 | sMAPE for Test Set is: 91.33% | rMAE for Test Set is: 3.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:01:12,401]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:01:19,788]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:01:36,743]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:01:47,271]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:02:19,600]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:02:34,700]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:02:46,681]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:02:58,973]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:03:04,654]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:04:31,148]\u001b[0m Trial 426 finished with value: 1.9255172983894138 and parameters: {'n_hidden': 3, 'learning_rate': 0.002829066346065965, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020200361221556294, 'dropout_rate_Layer_2': 0.09470648347320468, 'dropout_rate_Layer_3': 0.3616734574849995, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03120184760684945, 'l1_Layer_2': 0.07451539290066496, 'l1_Layer_3': 0.007563013199347528, 'n_units_Layer_1': 185, 'n_units_Layer_2': 150, 'n_units_Layer_3': 275}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.06% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.00 | sMAPE for Test Set is: 95.21% | rMAE for Test Set is: 3.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:04:36,451]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:04:43,455]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:04:50,594]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:05:37,839]\u001b[0m Trial 431 finished with value: 2.0092816242026217 and parameters: {'n_hidden': 3, 'learning_rate': 0.002316730627169093, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04168748505630345, 'dropout_rate_Layer_2': 0.10038040246884108, 'dropout_rate_Layer_3': 0.35579077719242513, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03081614057102154, 'l1_Layer_2': 0.06375961870398722, 'l1_Layer_3': 0.008457981113748498, 'n_units_Layer_1': 180, 'n_units_Layer_2': 135, 'n_units_Layer_3': 260}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 5.21% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 13.02 | sMAPE for Test Set is: 101.52% | rMAE for Test Set is: 4.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:05:43,335]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:05:45,014]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:05:50,819]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:05:55,349]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:06:02,622]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:06:05,380]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:06:12,582]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:06:13,139]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:07:09,917]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:07:15,598]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:07:41,780]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:07:49,307]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:08:01,703]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:08:14,447]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:08:22,012]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:08:29,294]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:08:39,832]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:08:46,753]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:09:04,424]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:09:26,640]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:09:33,852]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:09:39,912]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:09:59,027]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:10:03,617]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:10:13,606]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:10:20,977]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:10:31,367]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:10:36,354]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:11:07,948]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:12:13,070]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:12:20,547]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:12:25,719]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:12:33,025]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:12:47,093]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:13:39,804]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:14:05,049]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:14:24,314]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:14:27,256]\u001b[0m Trial 470 finished with value: 1.9808552086331102 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018514820143004267, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.037551830080381404, 'dropout_rate_Layer_2': 0.19653400006249583, 'dropout_rate_Layer_3': 0.3612087496395799, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0807223875035244, 'l1_Layer_2': 0.011539476490876995, 'l1_Layer_3': 0.005300557559270787, 'n_units_Layer_1': 100, 'n_units_Layer_2': 160, 'n_units_Layer_3': 180}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.98 | sMAPE for Validation Set is: 5.15% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 17.69 | sMAPE for Test Set is: 111.93% | rMAE for Test Set is: 5.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:14:29,946]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:14:37,188]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:14:47,489]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:15:09,418]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:15:16,499]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:15:21,518]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:15:27,410]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:15:34,761]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:15:41,876]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:15:49,454]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:15:56,499]\u001b[0m Trial 480 finished with value: 2.2086215585037317 and parameters: {'n_hidden': 3, 'learning_rate': 0.01189845763518511, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3988442591866621, 'dropout_rate_Layer_2': 0.32483374956814537, 'dropout_rate_Layer_3': 0.17169840385115648, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2580998312684321e-05, 'l1_Layer_2': 0.012112173820695692, 'l1_Layer_3': 0.0022092959773813785, 'n_units_Layer_1': 210, 'n_units_Layer_2': 205, 'n_units_Layer_3': 240}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.21 | sMAPE for Validation Set is: 5.79% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.39 | sMAPE for Test Set is: 117.94% | rMAE for Test Set is: 6.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:15:59,740]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:16:06,350]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:16:13,992]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:16:24,711]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:16:41,382]\u001b[0m Trial 484 finished with value: 2.0135043002773263 and parameters: {'n_hidden': 3, 'learning_rate': 0.002610035033531966, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10338900888558804, 'dropout_rate_Layer_2': 0.08511915511498214, 'dropout_rate_Layer_3': 0.3420660649620309, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.04640796174524188, 'l1_Layer_2': 0.0688969568989466, 'l1_Layer_3': 0.006934937386702231, 'n_units_Layer_1': 190, 'n_units_Layer_2': 175, 'n_units_Layer_3': 270}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 5.24% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.64 | sMAPE for Test Set is: 82.63% | rMAE for Test Set is: 2.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:16:46,880]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:16:52,126]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:16:56,861]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:17:06,343]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:17:06,513]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:17:15,292]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:17:19,644]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:17:24,352]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:17:30,266]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:17:34,959]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:17:42,275]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:17:49,271]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:17:52,431]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:18:11,519]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:18:16,828]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:18:23,759]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:18:24,251]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:19:46,705]\u001b[0m Trial 506 finished with value: 2.0103790498001843 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009483343887457849, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.050113430549245414, 'dropout_rate_Layer_2': 0.2655454427404406, 'dropout_rate_Layer_3': 0.38848266501305423, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002869287262272777, 'l1_Layer_2': 0.014568668080765833, 'l1_Layer_3': 0.0021901113926407916, 'n_units_Layer_1': 50, 'n_units_Layer_2': 205, 'n_units_Layer_3': 180}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:19:46,841]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 5.20% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 16.34 | sMAPE for Test Set is: 109.08% | rMAE for Test Set is: 5.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:19:55,533]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:20:07,215]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:20:16,800]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:20:20,159]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:20:22,396]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:20:24,510]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:20:29,351]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:20:52,434]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:21:14,048]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:21:28,737]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:21:56,306]\u001b[0m Trial 515 finished with value: 1.9843782172655928 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008495370375242372, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05487159219799727, 'dropout_rate_Layer_2': 0.2692042663991597, 'dropout_rate_Layer_3': 0.2864291817306123, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09180515190421618, 'l1_Layer_2': 0.013398676431794073, 'l1_Layer_3': 0.0018864055420530514, 'n_units_Layer_1': 60, 'n_units_Layer_2': 225, 'n_units_Layer_3': 185}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.98 | sMAPE for Validation Set is: 5.14% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 15.80 | sMAPE for Test Set is: 107.82% | rMAE for Test Set is: 4.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:22:01,571]\u001b[0m Trial 519 finished with value: 4.725184678187806 and parameters: {'n_hidden': 3, 'learning_rate': 0.08798909996941896, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30326613677075925, 'dropout_rate_Layer_2': 0.1988536316455782, 'dropout_rate_Layer_3': 0.19572216144243038, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0028738748705105528, 'l1_Layer_2': 0.022160913993802763, 'l1_Layer_3': 0.002273103826165654, 'n_units_Layer_1': 55, 'n_units_Layer_2': 225, 'n_units_Layer_3': 205}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 12.46% | rMAE for Validation Set is: 1.43\n",
      "MAE for Test Set is: 20.62 | sMAPE for Test Set is: 118.06% | rMAE for Test Set is: 6.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:22:03,623]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:22:41,153]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:22:53,061]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:22:58,978]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:23:19,087]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:23:28,369]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:23:31,596]\u001b[0m Trial 522 finished with value: 1.9794013300421522 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008290394901289545, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08053327513604804, 'dropout_rate_Layer_2': 0.27275441057009847, 'dropout_rate_Layer_3': 0.28840803364061296, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.098057654055071, 'l1_Layer_2': 0.013735200593796317, 'l1_Layer_3': 0.000630525526139226, 'n_units_Layer_1': 50, 'n_units_Layer_2': 230, 'n_units_Layer_3': 180}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.98 | sMAPE for Validation Set is: 5.13% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 15.80 | sMAPE for Test Set is: 108.11% | rMAE for Test Set is: 4.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:23:36,687]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:23:44,629]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:23:51,093]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:24:01,262]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:24:11,406]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:24:24,162]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:24:48,914]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:24:59,144]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:25:06,484]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:25:16,628]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:25:23,177]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:25:58,500]\u001b[0m Trial 537 finished with value: 2.1973596686801877 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029052981957368622, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1266671445174335, 'dropout_rate_Layer_2': 0.02929479175438168, 'dropout_rate_Layer_3': 0.3822160725977992, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4701141185897438e-05, 'l1_Layer_2': 6.394912586417465e-05, 'l1_Layer_3': 0.005647105993808358, 'n_units_Layer_1': 90, 'n_units_Layer_2': 115, 'n_units_Layer_3': 250}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.20 | sMAPE for Validation Set is: 5.64% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 18.97 | sMAPE for Test Set is: 115.75% | rMAE for Test Set is: 5.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:26:02,653]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:26:08,351]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:26:12,831]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:27:12,364]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:28:48,352]\u001b[0m Trial 542 finished with value: 2.0522809663697994 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017970030813835437, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19085744312753816, 'dropout_rate_Layer_2': 0.20454720630495274, 'dropout_rate_Layer_3': 0.3382063759509293, 'dropout_rate_Layer_4': 0.11492907613239613, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0010675443797604615, 'l1_Layer_2': 0.0006459206562162532, 'l1_Layer_3': 0.0003404075070421361, 'l1_Layer_4': 0.002690032915723868, 'n_units_Layer_1': 95, 'n_units_Layer_2': 215, 'n_units_Layer_3': 175, 'n_units_Layer_4': 240}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 5.29% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 15.90 | sMAPE for Test Set is: 108.53% | rMAE for Test Set is: 4.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:28:52,923]\u001b[0m Trial 544 finished with value: 1.9439335095016652 and parameters: {'n_hidden': 3, 'learning_rate': 0.000628003371182837, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03957407384414328, 'dropout_rate_Layer_2': 0.30982612919460584, 'dropout_rate_Layer_3': 0.26938325261453305, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07944438650208299, 'l1_Layer_2': 0.004053208099859258, 'l1_Layer_3': 0.00033721471983859516, 'n_units_Layer_1': 85, 'n_units_Layer_2': 235, 'n_units_Layer_3': 165}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.07% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 12.93 | sMAPE for Test Set is: 100.74% | rMAE for Test Set is: 4.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:28:55,534]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:29:17,473]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:29:20,870]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:29:25,523]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:29:28,363]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:29:35,816]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:29:45,417]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:29:55,692]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:30:17,202]\u001b[0m Trial 550 finished with value: 2.0744173255579432 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016242521229016275, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18203680011707019, 'dropout_rate_Layer_2': 0.2272841660471866, 'dropout_rate_Layer_3': 0.34896062291205104, 'dropout_rate_Layer_4': 0.09819457738100042, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0009719631114621933, 'l1_Layer_2': 0.0006268403166410228, 'l1_Layer_3': 0.00019281979776042044, 'l1_Layer_4': 0.0041496184479700975, 'n_units_Layer_1': 90, 'n_units_Layer_2': 200, 'n_units_Layer_3': 180, 'n_units_Layer_4': 230}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 5.36% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 17.53 | sMAPE for Test Set is: 111.51% | rMAE for Test Set is: 5.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:30:24,483]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:30:29,459]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:30:29,874]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:30:42,508]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:30:47,271]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:30:54,085]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:31:01,398]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:31:24,462]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:32:16,520]\u001b[0m Trial 560 finished with value: 1.9435338945140164 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005708481825082129, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08035187561802182, 'dropout_rate_Layer_2': 0.31649023686426575, 'dropout_rate_Layer_3': 0.26201787322427594, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06914394319147965, 'l1_Layer_2': 0.003762370348228395, 'l1_Layer_3': 0.0002885417681609021, 'n_units_Layer_1': 80, 'n_units_Layer_2': 230, 'n_units_Layer_3': 160}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.06% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.13 | sMAPE for Test Set is: 101.35% | rMAE for Test Set is: 4.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:32:40,939]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:33:36,985]\u001b[0m Trial 563 finished with value: 2.04334612784217 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010117124893202095, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.164643414447617, 'dropout_rate_Layer_2': 0.24168193700272372, 'dropout_rate_Layer_3': 0.3241062799132502, 'dropout_rate_Layer_4': 0.0849702643247411, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0007889444116632008, 'l1_Layer_2': 0.0009518473141235375, 'l1_Layer_3': 0.0002762871066926948, 'l1_Layer_4': 0.005656711770221083, 'n_units_Layer_1': 80, 'n_units_Layer_2': 210, 'n_units_Layer_3': 180, 'n_units_Layer_4': 220}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 5.27% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 17.66 | sMAPE for Test Set is: 111.82% | rMAE for Test Set is: 5.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:33:41,801]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:33:47,110]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:33:56,306]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:33:56,632]\u001b[0m Trial 565 finished with value: 2.2478176634538105 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016303556887953482, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11425503228630676, 'dropout_rate_Layer_2': 0.0615831935674796, 'dropout_rate_Layer_3': 0.17241624638234704, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.5225023374285105e-05, 'l1_Layer_2': 0.03577856398129042, 'l1_Layer_3': 0.015570423974432078, 'n_units_Layer_1': 300, 'n_units_Layer_2': 185, 'n_units_Layer_3': 280}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.25 | sMAPE for Validation Set is: 5.74% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 17.71 | sMAPE for Test Set is: 112.30% | rMAE for Test Set is: 5.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:34:04,075]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:36:29,759]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:36:32,478]\u001b[0m Trial 571 finished with value: 2.0298170134297515 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008753302157190635, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1954581650004926, 'dropout_rate_Layer_2': 0.26035116314522877, 'dropout_rate_Layer_3': 0.3276142241512684, 'dropout_rate_Layer_4': 0.08506739146978577, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0006219530270333757, 'l1_Layer_2': 0.0006629896963550307, 'l1_Layer_3': 0.00043408709193083517, 'l1_Layer_4': 0.005613242965728032, 'n_units_Layer_1': 75, 'n_units_Layer_2': 210, 'n_units_Layer_3': 190, 'n_units_Layer_4': 210}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 5.26% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 16.22 | sMAPE for Test Set is: 108.97% | rMAE for Test Set is: 5.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:37:18,454]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:37:43,135]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:37:51,059]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:39:27,359]\u001b[0m Trial 573 finished with value: 1.9835223378371483 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006736629679308278, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14222550044945817, 'dropout_rate_Layer_2': 0.25070045131916213, 'dropout_rate_Layer_3': 0.32666877357417395, 'dropout_rate_Layer_4': 0.10011921485074024, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.000606872448481144, 'l1_Layer_2': 0.0006535006062308615, 'l1_Layer_3': 0.0002629682010197198, 'l1_Layer_4': 0.00972610606920897, 'n_units_Layer_1': 80, 'n_units_Layer_2': 190, 'n_units_Layer_3': 180, 'n_units_Layer_4': 205}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.98 | sMAPE for Validation Set is: 5.14% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 17.54 | sMAPE for Test Set is: 111.56% | rMAE for Test Set is: 5.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:39:37,782]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:39:44,999]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:40:22,607]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:40:27,051]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:40:34,456]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:41:49,081]\u001b[0m Trial 582 finished with value: 1.964010083821899 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007030286585454729, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.045038077862449, 'dropout_rate_Layer_2': 0.31273450209802545, 'dropout_rate_Layer_3': 0.2732943240239161, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.039336334187527425, 'l1_Layer_2': 0.012750412228823813, 'l1_Layer_3': 0.0003477636417528763, 'n_units_Layer_1': 50, 'n_units_Layer_2': 230, 'n_units_Layer_3': 170}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 5.10% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.09 | sMAPE for Test Set is: 101.13% | rMAE for Test Set is: 4.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:41:54,350]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:42:04,181]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:42:17,144]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:42:26,806]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:43:03,920]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:43:11,453]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:43:17,174]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:43:27,200]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:43:32,015]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:43:34,491]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:43:35,104]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:43:45,322]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:43:47,747]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:43:51,993]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:43:55,480]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:44:02,726]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:44:10,031]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:44:20,233]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:44:27,385]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:44:29,621]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:44:52,566]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:44:59,592]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:45:00,137]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:45:07,345]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:45:17,313]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:45:24,554]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:45:34,690]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:45:34,880]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:45:44,485]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:45:50,076]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:45:59,547]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:46:01,479]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:46:11,507]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:46:36,319]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:46:54,459]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:47:01,417]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:47:06,511]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:48:01,250]\u001b[0m Trial 615 finished with value: 2.0972697790064183 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011963632355883411, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17074180949045947, 'dropout_rate_Layer_2': 0.25745833597559614, 'dropout_rate_Layer_3': 0.3477892809948645, 'dropout_rate_Layer_4': 0.053237888185659464, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0006706922162027938, 'l1_Layer_2': 0.0011448531514180597, 'l1_Layer_3': 0.0004148990179321034, 'l1_Layer_4': 0.006782929626397176, 'n_units_Layer_1': 100, 'n_units_Layer_2': 170, 'n_units_Layer_3': 215, 'n_units_Layer_4': 245}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.10 | sMAPE for Validation Set is: 5.43% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 17.81 | sMAPE for Test Set is: 112.20% | rMAE for Test Set is: 5.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:48:08,328]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:48:08,539]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:48:15,543]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:48:20,743]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:48:28,730]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:48:33,292]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:48:38,294]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:48:50,674]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:48:56,104]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:49:05,838]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:49:06,049]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:49:16,553]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:49:27,398]\u001b[0m Trial 631 finished with value: 3.9391799108853314 and parameters: {'n_hidden': 3, 'learning_rate': 0.0203206005117282, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20878009867123692, 'dropout_rate_Layer_2': 0.12228512201309905, 'dropout_rate_Layer_3': 0.21049167147275855, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 8.91879306302615e-05, 'l1_Layer_2': 0.007692722530693079, 'l1_Layer_3': 0.0011081415011953296, 'n_units_Layer_1': 175, 'n_units_Layer_2': 150, 'n_units_Layer_3': 110}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.94 | sMAPE for Validation Set is: 9.96% | rMAE for Validation Set is: 1.19\n",
      "MAE for Test Set is: 15.00 | sMAPE for Test Set is: 107.33% | rMAE for Test Set is: 4.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:49:31,830]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:49:41,752]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:50:31,333]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:50:41,583]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:50:56,077]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:51:03,607]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:51:22,411]\u001b[0m Trial 636 finished with value: 1.9705852974904097 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006797101412269506, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1089437941611156, 'dropout_rate_Layer_2': 0.3355114408368741, 'dropout_rate_Layer_3': 0.24902206902580853, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07272842572090357, 'l1_Layer_2': 0.007405516035454221, 'l1_Layer_3': 0.00034530889349754733, 'n_units_Layer_1': 90, 'n_units_Layer_2': 180, 'n_units_Layer_3': 185}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.12% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 14.41 | sMAPE for Test Set is: 104.69% | rMAE for Test Set is: 4.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:51:52,759]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:52:02,792]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:52:12,865]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:52:42,924]\u001b[0m Trial 641 finished with value: 1.9691842985685977 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013031455564239422, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09253587980691808, 'dropout_rate_Layer_2': 0.06522010442387763, 'dropout_rate_Layer_3': 0.3572966103282609, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.036017267270793414, 'l1_Layer_2': 0.06253229291110855, 'l1_Layer_3': 0.005264811031430292, 'n_units_Layer_1': 190, 'n_units_Layer_2': 95, 'n_units_Layer_3': 265}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.15% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.37 | sMAPE for Test Set is: 76.51% | rMAE for Test Set is: 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:52:48,084]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:54:02,896]\u001b[0m Trial 644 finished with value: 2.0440603344666894 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007656486022835404, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13746455817069073, 'dropout_rate_Layer_2': 0.2508518621502657, 'dropout_rate_Layer_3': 0.31761802568774594, 'dropout_rate_Layer_4': 0.09362950753341004, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00045441379674299675, 'l1_Layer_2': 0.0011099028616330176, 'l1_Layer_3': 0.00022078245480016488, 'l1_Layer_4': 0.004226053446598166, 'n_units_Layer_1': 100, 'n_units_Layer_2': 225, 'n_units_Layer_3': 205, 'n_units_Layer_4': 220}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 5.28% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 17.44 | sMAPE for Test Set is: 111.32% | rMAE for Test Set is: 5.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:54:12,529]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:54:21,966]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:54:25,215]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:54:32,733]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:54:40,214]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:54:47,883]\u001b[0m Trial 646 finished with value: 2.012791677142877 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008720702407892129, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13578809052264804, 'dropout_rate_Layer_2': 0.2501684833600648, 'dropout_rate_Layer_3': 0.3997913271223867, 'dropout_rate_Layer_4': 0.09466313727546607, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.001325542013782962, 'l1_Layer_2': 0.0011956102153035334, 'l1_Layer_3': 0.0005388704370779237, 'l1_Layer_4': 0.004069415296069134, 'n_units_Layer_1': 100, 'n_units_Layer_2': 225, 'n_units_Layer_3': 215, 'n_units_Layer_4': 220}. Best is trial 414 with value: 1.9110506651166208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 5.20% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 17.77 | sMAPE for Test Set is: 112.06% | rMAE for Test Set is: 5.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:54:52,972]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:54:58,716]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:55:11,084]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:55:18,426]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:55:22,626]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:55:25,694]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:55:30,401]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:55:33,144]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:55:43,274]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:55:55,349]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:56:05,177]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:56:10,923]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:56:21,032]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:56:28,098]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:56:51,103]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:57:03,028]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:57:43,282]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:58:30,431]\u001b[0m Trial 665 finished with value: 1.899417599947981 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007023080672043184, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08383622770966107, 'dropout_rate_Layer_2': 0.38336915688416057, 'dropout_rate_Layer_3': 0.2466316732007513, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.049538727793599475, 'l1_Layer_2': 0.001526688471723653, 'l1_Layer_3': 0.00033379188148086167, 'n_units_Layer_1': 90, 'n_units_Layer_2': 130, 'n_units_Layer_3': 170}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 4.97% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 15.68 | sMAPE for Test Set is: 107.66% | rMAE for Test Set is: 4.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:58:38,257]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:58:56,221]\u001b[0m Trial 670 finished with value: 2.0575999840677786 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012551093137915385, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16183124033703955, 'dropout_rate_Layer_2': 0.29173746714884496, 'dropout_rate_Layer_3': 0.3198227249170175, 'dropout_rate_Layer_4': 0.09458745697471552, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0007789397967607884, 'l1_Layer_2': 0.0010013838527258203, 'l1_Layer_3': 0.0002703414742692764, 'l1_Layer_4': 0.004394520890067078, 'n_units_Layer_1': 70, 'n_units_Layer_2': 210, 'n_units_Layer_3': 205, 'n_units_Layer_4': 210}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 5.36% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.85 | sMAPE for Test Set is: 101.18% | rMAE for Test Set is: 4.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:59:01,631]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:59:05,803]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:59:05,934]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:59:29,307]\u001b[0m Trial 675 finished with value: 2.4516366570666297 and parameters: {'n_hidden': 3, 'learning_rate': 0.038669139793625414, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11342629907706447, 'dropout_rate_Layer_2': 0.03513537955668027, 'dropout_rate_Layer_3': 0.07702970602675224, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0029919035720791507, 'l1_Layer_2': 0.04153005070453271, 'l1_Layer_3': 0.002546825340632419, 'n_units_Layer_1': 80, 'n_units_Layer_2': 220, 'n_units_Layer_3': 200}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.45 | sMAPE for Validation Set is: 6.33% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 17.35 | sMAPE for Test Set is: 112.95% | rMAE for Test Set is: 5.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:00:31,557]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:00:37,390]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:00:42,061]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:00:54,555]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:01:54,741]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:01:59,285]\u001b[0m Trial 676 finished with value: 2.0305434389043344 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007369579332304983, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1673352474850917, 'dropout_rate_Layer_2': 0.30049507406354165, 'dropout_rate_Layer_3': 0.37841716027297606, 'dropout_rate_Layer_4': 0.11090462176623392, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0007446296882535356, 'l1_Layer_2': 0.0017387535377938266, 'l1_Layer_3': 9.635511776537766e-05, 'l1_Layer_4': 0.0024170405403471104, 'n_units_Layer_1': 105, 'n_units_Layer_2': 205, 'n_units_Layer_3': 190, 'n_units_Layer_4': 215}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 5.28% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 17.47 | sMAPE for Test Set is: 111.39% | rMAE for Test Set is: 5.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:02:02,249]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:02:11,347]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:02:17,107]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:02:23,935]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:02:29,297]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:02:34,704]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:03:17,074]\u001b[0m Trial 684 finished with value: 1.9788211463949537 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012119265171796382, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10509401632113984, 'dropout_rate_Layer_2': 0.29954159552125115, 'dropout_rate_Layer_3': 0.2539054350392917, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.045354374527202035, 'l1_Layer_2': 0.00741652961991074, 'l1_Layer_3': 0.00037959436482164487, 'n_units_Layer_1': 110, 'n_units_Layer_2': 110, 'n_units_Layer_3': 195}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.98 | sMAPE for Validation Set is: 5.15% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 15.58 | sMAPE for Test Set is: 107.58% | rMAE for Test Set is: 4.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:03:19,481]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:03:26,872]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:03:29,338]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:03:41,960]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:03:46,826]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:03:54,896]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:03:59,343]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:04:02,118]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:04:06,838]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:05:03,467]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:05:16,114]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:05:35,471]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:05:45,032]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:06:07,403]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:06:20,314]\u001b[0m Trial 698 finished with value: 1.966436518353013 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011734985951261422, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09140500094670734, 'dropout_rate_Layer_2': 0.3490752751690373, 'dropout_rate_Layer_3': 0.24211121109442993, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03178626247874206, 'l1_Layer_2': 0.0011073381907150699, 'l1_Layer_3': 0.00046898389445391845, 'n_units_Layer_1': 110, 'n_units_Layer_2': 120, 'n_units_Layer_3': 195}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.14% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 14.01 | sMAPE for Test Set is: 103.51% | rMAE for Test Set is: 4.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:06:23,120]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:06:28,177]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:06:35,048]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:06:48,018]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:07:04,941]\u001b[0m Trial 709 finished with value: 4.511416361487334 and parameters: {'n_hidden': 3, 'learning_rate': 0.033370459428722604, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3688594218319076, 'dropout_rate_Layer_2': 0.3518163723871227, 'dropout_rate_Layer_3': 0.02899150312685458, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.8934363956433298e-05, 'l1_Layer_2': 0.013183710091948034, 'l1_Layer_3': 0.003597405591556522, 'n_units_Layer_1': 205, 'n_units_Layer_2': 165, 'n_units_Layer_3': 210}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 12.13% | rMAE for Validation Set is: 1.36\n",
      "MAE for Test Set is: 18.24 | sMAPE for Test Set is: 113.67% | rMAE for Test Set is: 5.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:07:23,268]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:07:28,007]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:07:30,942]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:07:35,461]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:07:42,825]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:08:06,064]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:08:26,584]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:08:35,897]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:08:36,011]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:09:00,081]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:09:00,124]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:09:12,766]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:09:19,639]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:09:27,287]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:09:36,585]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:12:51,507]\u001b[0m Trial 721 finished with value: 1.937256871734918 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005950268702888365, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02507326334776561, 'dropout_rate_Layer_2': 0.35495690179597017, 'dropout_rate_Layer_3': 0.21764771790823784, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0497531241830344, 'l1_Layer_2': 0.0009328319141084321, 'l1_Layer_3': 0.0002216425503695068, 'n_units_Layer_1': 90, 'n_units_Layer_2': 135, 'n_units_Layer_3': 215}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.08% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.46 | sMAPE for Test Set is: 102.20% | rMAE for Test Set is: 4.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:12:52,112]\u001b[0m Trial 725 finished with value: 1.9350932004687067 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007008346649438209, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017326372387799327, 'dropout_rate_Layer_2': 0.3510230373595852, 'dropout_rate_Layer_3': 0.21429987073076043, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0496082527548688, 'l1_Layer_2': 0.0009391207166239938, 'l1_Layer_3': 0.00023992172686749857, 'n_units_Layer_1': 120, 'n_units_Layer_2': 120, 'n_units_Layer_3': 220}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.06% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 12.51 | sMAPE for Test Set is: 99.71% | rMAE for Test Set is: 3.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:13:04,701]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:13:05,016]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:13:12,585]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:13:19,849]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:13:24,841]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:13:35,379]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:13:45,419]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:13:52,903]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:14:24,079]\u001b[0m Trial 728 finished with value: 1.917703782340002 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028846299854805506, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03483428767817899, 'dropout_rate_Layer_2': 0.09605204740216691, 'dropout_rate_Layer_3': 0.0383188801788919, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07238527902255534, 'l1_Layer_2': 0.0821819474641282, 'l1_Layer_3': 0.00015455121082284337, 'n_units_Layer_1': 275, 'n_units_Layer_2': 180, 'n_units_Layer_3': 155}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.11% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.47 | sMAPE for Test Set is: 41.96% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:14:29,100]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:14:41,610]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:15:38,252]\u001b[0m Trial 735 finished with value: 2.0364457395223265 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010658719034123975, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18238728392590603, 'dropout_rate_Layer_2': 0.010120016991284397, 'dropout_rate_Layer_3': 0.35551615202355075, 'dropout_rate_Layer_4': 0.028391433417635847, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0008390845731368508, 'l1_Layer_2': 0.0006924976022484625, 'l1_Layer_3': 0.000605286540972402, 'l1_Layer_4': 0.0029493975841189094, 'n_units_Layer_1': 70, 'n_units_Layer_2': 200, 'n_units_Layer_3': 175, 'n_units_Layer_4': 215}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 5.28% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 17.63 | sMAPE for Test Set is: 111.75% | rMAE for Test Set is: 5.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:15:40,723]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:15:50,324]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:15:55,042]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:16:00,894]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:16:35,417]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:17:15,279]\u001b[0m Trial 744 finished with value: 1.9671003572545687 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013243793301614595, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2466673465819483, 'dropout_rate_Layer_2': 0.3291186995398526, 'dropout_rate_Layer_3': 0.27877959107813577, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04374257575139865, 'l1_Layer_2': 0.0030590471074864703, 'l1_Layer_3': 0.005952842223618347, 'n_units_Layer_1': 260, 'n_units_Layer_2': 265, 'n_units_Layer_3': 255}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.17% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 18.10 | sMAPE for Test Set is: 112.87% | rMAE for Test Set is: 5.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:18:12,390]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:18:14,969]\u001b[0m Trial 740 finished with value: 1.9088272174909793 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006898787951941191, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01856760847862226, 'dropout_rate_Layer_2': 0.35707251771545956, 'dropout_rate_Layer_3': 0.2128381556954418, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.030797290670871197, 'l1_Layer_2': 0.0005079375415670444, 'l1_Layer_3': 0.00024833302435658776, 'n_units_Layer_1': 90, 'n_units_Layer_2': 140, 'n_units_Layer_3': 220}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 5.02% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.33 | sMAPE for Test Set is: 92.74% | rMAE for Test Set is: 3.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:18:36,350]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:18:51,439]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:18:56,881]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:19:03,946]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:21:31,287]\u001b[0m Trial 751 finished with value: 1.9132926402633643 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005648166251268703, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021572348500298585, 'dropout_rate_Layer_2': 0.3588646947183238, 'dropout_rate_Layer_3': 0.1643239494586609, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.018362810466796737, 'l1_Layer_2': 0.0008783148715901435, 'l1_Layer_3': 0.0002265613954918735, 'n_units_Layer_1': 80, 'n_units_Layer_2': 135, 'n_units_Layer_3': 220}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 5.00% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.56 | sMAPE for Test Set is: 93.82% | rMAE for Test Set is: 3.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:21:36,518]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:21:43,953]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:21:58,403]\u001b[0m Trial 747 finished with value: 1.9112484316586116 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007265496819653883, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016913836871031828, 'dropout_rate_Layer_2': 0.3564867061576221, 'dropout_rate_Layer_3': 0.16750964883399194, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01941332793930598, 'l1_Layer_2': 0.0005196587838205574, 'l1_Layer_3': 0.000241849038598831, 'n_units_Layer_1': 70, 'n_units_Layer_2': 130, 'n_units_Layer_3': 225}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 5.00% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 12.18 | sMAPE for Test Set is: 98.59% | rMAE for Test Set is: 3.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:22:03,701]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:22:11,715]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:22:16,408]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:22:21,094]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:22:23,080]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:22:28,252]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:22:31,104]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:22:37,791]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:22:48,531]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:22:55,353]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:23:11,796]\u001b[0m Trial 761 finished with value: 1.950528489437849 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020965989749521787, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24243448885406085, 'dropout_rate_Layer_2': 0.17712941469254598, 'dropout_rate_Layer_3': 0.29741726926204726, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05224579894366996, 'l1_Layer_2': 0.09240950624284, 'l1_Layer_3': 0.021772379995010922, 'n_units_Layer_1': 285, 'n_units_Layer_2': 105, 'n_units_Layer_3': 290}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.17% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.16 | sMAPE for Test Set is: 51.42% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:23:19,647]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:23:42,458]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:23:49,728]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:23:57,384]\u001b[0m Trial 765 finished with value: 1.992704659893526 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013712612874005163, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18173404981392163, 'dropout_rate_Layer_2': 0.24992990222502176, 'dropout_rate_Layer_3': 0.32715260978194627, 'dropout_rate_Layer_4': 0.10733437687306677, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0013254839813692453, 'l1_Layer_2': 0.0007802984468208163, 'l1_Layer_3': 0.0004710434222623088, 'l1_Layer_4': 0.006355244109651585, 'n_units_Layer_1': 185, 'n_units_Layer_2': 205, 'n_units_Layer_3': 180, 'n_units_Layer_4': 190}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.99 | sMAPE for Validation Set is: 5.16% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 17.67 | sMAPE for Test Set is: 111.82% | rMAE for Test Set is: 5.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:24:21,873]\u001b[0m Trial 769 finished with value: 2.98435274137465 and parameters: {'n_hidden': 4, 'learning_rate': 0.009401680565422673, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3785206101605335, 'dropout_rate_Layer_2': 0.13696295278315823, 'dropout_rate_Layer_3': 0.39193448947747733, 'dropout_rate_Layer_4': 0.3823333586735031, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00010020490674953339, 'l1_Layer_2': 1.403542294929348e-05, 'l1_Layer_3': 1.1333625704666288e-05, 'l1_Layer_4': 1.360351856634675e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 55, 'n_units_Layer_3': 300, 'n_units_Layer_4': 270}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.98 | sMAPE for Validation Set is: 7.93% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 18.39 | sMAPE for Test Set is: 114.28% | rMAE for Test Set is: 5.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:24:27,134]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:24:33,488]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:24:36,658]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:24:44,018]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:24:46,660]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:24:53,465]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:25:05,789]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:25:10,648]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:25:13,907]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:25:30,309]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:25:33,623]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:25:37,826]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:25:58,414]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:26:03,181]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:26:58,893]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:27:02,311]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:27:21,676]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:27:33,766]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:27:41,148]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:27:50,930]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:28:08,450]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:28:13,667]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:28:28,058]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:28:32,880]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:28:35,302]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:28:40,922]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:28:43,444]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:28:47,842]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:28:52,543]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:28:57,243]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:29:00,093]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:29:07,804]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:29:14,745]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:29:22,651]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:29:29,811]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:29:41,644]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:30:11,632]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:30:16,792]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:30:24,074]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:30:29,561]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:30:34,039]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:30:36,882]\u001b[0m Trial 804 finished with value: 1.926604634902997 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007203350902673831, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.028106970352833095, 'dropout_rate_Layer_2': 0.32597858846601596, 'dropout_rate_Layer_3': 0.16440125934889893, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009622156242264913, 'l1_Layer_2': 0.000279859589678431, 'l1_Layer_3': 2.8961091516204133e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 155, 'n_units_Layer_3': 220}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.05% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.47 | sMAPE for Test Set is: 86.12% | rMAE for Test Set is: 2.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:30:41,616]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:30:46,586]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:30:51,874]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:30:58,229]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:31:08,978]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:31:13,491]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:31:33,241]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:31:42,763]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:31:48,443]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:32:00,213]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:32:05,371]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:32:15,301]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:32:27,869]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:32:32,679]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:33:22,238]\u001b[0m Trial 816 finished with value: 1.920565639367983 and parameters: {'n_hidden': 3, 'learning_rate': 0.002717047104676178, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.035777461949277584, 'dropout_rate_Layer_2': 0.08730098424659224, 'dropout_rate_Layer_3': 0.38987610403977446, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.031946022660096884, 'l1_Layer_2': 0.09930127791238227, 'l1_Layer_3': 0.006954559944612091, 'n_units_Layer_1': 90, 'n_units_Layer_2': 145, 'n_units_Layer_3': 250}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.06% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.39 | sMAPE for Test Set is: 89.71% | rMAE for Test Set is: 2.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:33:30,046]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:33:43,048]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:34:11,665]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:34:49,838]\u001b[0m Trial 828 finished with value: 2.062375475920778 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006211139521435446, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05320166805092022, 'dropout_rate_Layer_2': 0.27651798435920527, 'dropout_rate_Layer_3': 0.39202918585098945, 'dropout_rate_Layer_4': 0.19135567544954835, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0003991775880187875, 'l1_Layer_2': 0.00011341660354437599, 'l1_Layer_3': 0.02254575218378943, 'l1_Layer_4': 0.0023286511302142814, 'n_units_Layer_1': 55, 'n_units_Layer_2': 125, 'n_units_Layer_3': 110, 'n_units_Layer_4': 55}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 5.42% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.86 | sMAPE for Test Set is: 91.28% | rMAE for Test Set is: 3.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:35:04,212]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:35:13,341]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:35:35,690]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:36:23,087]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:36:43,090]\u001b[0m Trial 835 finished with value: 1.9190977706234327 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028267435775288074, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.042481804451824305, 'dropout_rate_Layer_2': 0.07391834787093901, 'dropout_rate_Layer_3': 0.39530033395432773, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03634322210551397, 'l1_Layer_2': 0.09719261122819552, 'l1_Layer_3': 0.0059737123997504514, 'n_units_Layer_1': 100, 'n_units_Layer_2': 140, 'n_units_Layer_3': 250}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.03% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.04 | sMAPE for Test Set is: 88.43% | rMAE for Test Set is: 2.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:36:54,475]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:36:59,642]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:37:04,354]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:38:24,237]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:38:46,005]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:38:51,124]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:39:00,753]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:39:08,276]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:39:13,168]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:40:13,139]\u001b[0m Trial 841 finished with value: 1.909038850306577 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006036152411204302, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04407354984886422, 'dropout_rate_Layer_2': 0.3411168677822512, 'dropout_rate_Layer_3': 0.1414124250897013, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.015865110384059782, 'l1_Layer_2': 0.0006010175551043988, 'l1_Layer_3': 1.4538729490890414e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 150, 'n_units_Layer_3': 260}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 5.00% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.09 | sMAPE for Test Set is: 92.07% | rMAE for Test Set is: 3.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:40:16,118]\u001b[0m Trial 846 finished with value: 1.957784454880258 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008982896996147853, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016109626151592803, 'dropout_rate_Layer_2': 0.3403061294396004, 'dropout_rate_Layer_3': 0.1753752684335621, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.026493581357687916, 'l1_Layer_2': 0.0002972535390238884, 'l1_Layer_3': 0.00010100175647600433, 'n_units_Layer_1': 65, 'n_units_Layer_2': 100, 'n_units_Layer_3': 230}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 5.16% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.40 | sMAPE for Test Set is: 85.73% | rMAE for Test Set is: 2.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:40:25,490]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:40:37,835]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:40:47,755]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:41:01,873]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:41:58,079]\u001b[0m Trial 852 finished with value: 2.0930435515515633 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016271404004812836, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0006071650386672914, 'dropout_rate_Layer_2': 0.2572051749787689, 'dropout_rate_Layer_3': 0.38789433737387197, 'dropout_rate_Layer_4': 0.1420926763435608, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 6.91329821247984e-05, 'l1_Layer_2': 5.096805712339806e-05, 'l1_Layer_3': 0.018984632404950907, 'l1_Layer_4': 0.0007011733628284425, 'n_units_Layer_1': 70, 'n_units_Layer_2': 140, 'n_units_Layer_3': 90, 'n_units_Layer_4': 175}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 5.45% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 13.23 | sMAPE for Test Set is: 101.65% | rMAE for Test Set is: 4.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:42:03,308]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:42:35,559]\u001b[0m Trial 851 finished with value: 2.0535800629354726 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017433151551609928, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17516076326928914, 'dropout_rate_Layer_2': 0.2609820112041993, 'dropout_rate_Layer_3': 0.36851639370824085, 'dropout_rate_Layer_4': 0.07477597521431956, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0007896112205508191, 'l1_Layer_2': 0.003278186657691707, 'l1_Layer_3': 0.0002556904203944324, 'l1_Layer_4': 0.0019082715703649632, 'n_units_Layer_1': 80, 'n_units_Layer_2': 150, 'n_units_Layer_3': 195, 'n_units_Layer_4': 200}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 5.30% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.53 | sMAPE for Test Set is: 100.05% | rMAE for Test Set is: 3.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:42:41,282]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:42:55,210]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:43:02,994]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:43:10,031]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:43:15,155]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:43:37,749]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:43:44,898]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:43:49,759]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:44:09,929]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:44:16,823]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:44:19,360]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:44:24,181]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:44:27,322]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:44:44,399]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:44:56,637]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:45:09,338]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:45:14,129]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:45:24,308]\u001b[0m Trial 868 finished with value: 2.0817578708215354 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011706652508930223, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0007450479528984236, 'dropout_rate_Layer_2': 0.26088626305710766, 'dropout_rate_Layer_3': 0.3422475418008151, 'dropout_rate_Layer_4': 0.14274755317206472, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 9.192076883903344e-05, 'l1_Layer_2': 1.00485219407474e-05, 'l1_Layer_3': 0.01813142640203762, 'l1_Layer_4': 0.0006462740418027094, 'n_units_Layer_1': 65, 'n_units_Layer_2': 170, 'n_units_Layer_3': 95, 'n_units_Layer_4': 180}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 5.41% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 13.24 | sMAPE for Test Set is: 101.52% | rMAE for Test Set is: 4.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:45:34,441]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:45:41,814]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:46:18,138]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:46:25,327]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:46:30,786]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:46:40,409]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:46:50,520]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:46:54,878]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:47:15,201]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:47:20,013]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:47:25,282]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:47:35,469]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:47:40,521]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:48:02,503]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:48:07,415]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:48:17,759]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:48:29,474]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:49:32,009]\u001b[0m Trial 890 finished with value: 2.073324095470279 and parameters: {'n_hidden': 4, 'learning_rate': 0.000546088546216227, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05929586467371581, 'dropout_rate_Layer_2': 0.26388550353338064, 'dropout_rate_Layer_3': 0.32699412568904274, 'dropout_rate_Layer_4': 0.15478285126534622, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0004364913000325417, 'l1_Layer_2': 1.0854557034601503e-05, 'l1_Layer_3': 0.000327582494291811, 'l1_Layer_4': 0.000863530543219733, 'n_units_Layer_1': 50, 'n_units_Layer_2': 190, 'n_units_Layer_3': 100, 'n_units_Layer_4': 200}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 5.40% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 15.00 | sMAPE for Test Set is: 106.04% | rMAE for Test Set is: 4.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:49:57,173]\u001b[0m Trial 875 finished with value: 1.9490823559343704 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007447285445068234, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03244607997527356, 'dropout_rate_Layer_2': 0.3212253789738299, 'dropout_rate_Layer_3': 0.13239261299733845, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.029863605623179173, 'l1_Layer_2': 0.002334017043504855, 'l1_Layer_3': 1.3783093437062949e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 115, 'n_units_Layer_3': 245}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.08% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 14.01 | sMAPE for Test Set is: 103.69% | rMAE for Test Set is: 4.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:50:42,868]\u001b[0m Trial 891 finished with value: 1.9651701562187085 and parameters: {'n_hidden': 3, 'learning_rate': 0.000925861612168981, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21711172358628977, 'dropout_rate_Layer_2': 0.1066174471878488, 'dropout_rate_Layer_3': 0.10422206628024337, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0995529848948891, 'l1_Layer_2': 0.020132082668968987, 'l1_Layer_3': 0.04536202779135549, 'n_units_Layer_1': 265, 'n_units_Layer_2': 95, 'n_units_Layer_3': 290}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.23% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.56 | sMAPE for Test Set is: 42.66% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:50:48,055]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:51:18,118]\u001b[0m Trial 892 finished with value: 2.06758591083619 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016586621668940754, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17445800602155248, 'dropout_rate_Layer_2': 0.25568910261359035, 'dropout_rate_Layer_3': 0.3722876493917017, 'dropout_rate_Layer_4': 0.07591900061285521, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0007164700655331014, 'l1_Layer_2': 0.002646320305381117, 'l1_Layer_3': 0.0002727548045988562, 'l1_Layer_4': 0.0019454770316276518, 'n_units_Layer_1': 80, 'n_units_Layer_2': 165, 'n_units_Layer_3': 195, 'n_units_Layer_4': 200}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 5.37% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.85 | sMAPE for Test Set is: 95.01% | rMAE for Test Set is: 3.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:51:27,920]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:51:28,003]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:51:36,544]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:51:41,226]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:51:45,975]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:51:46,378]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:51:54,005]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:51:58,881]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:52:03,842]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:53:05,290]\u001b[0m Trial 902 finished with value: 1.953697425773024 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020446532375454625, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016239164912760708, 'dropout_rate_Layer_2': 0.07006861102147711, 'dropout_rate_Layer_3': 0.25623666502975473, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.07553016041305999, 'l1_Layer_2': 0.07298283314447349, 'l1_Layer_3': 0.0039608865095678404, 'n_units_Layer_1': 120, 'n_units_Layer_2': 255, 'n_units_Layer_3': 275}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.13% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.17 | sMAPE for Test Set is: 84.96% | rMAE for Test Set is: 2.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:53:10,447]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:53:17,301]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:53:37,391]\u001b[0m Trial 904 finished with value: 2.1058063931793694 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015536310587078168, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17179703382466904, 'dropout_rate_Layer_2': 0.2909614429707088, 'dropout_rate_Layer_3': 0.39168653210026483, 'dropout_rate_Layer_4': 0.06252296609387271, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0006018888295040205, 'l1_Layer_2': 0.002568977684386031, 'l1_Layer_3': 0.00023774553439115932, 'l1_Layer_4': 0.0019450754611980683, 'n_units_Layer_1': 95, 'n_units_Layer_2': 160, 'n_units_Layer_3': 205, 'n_units_Layer_4': 195}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.11 | sMAPE for Validation Set is: 5.45% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 14.53 | sMAPE for Test Set is: 105.23% | rMAE for Test Set is: 4.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:54:39,034]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:54:46,322]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:54:51,207]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:54:56,493]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:55:03,408]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:55:31,125]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:55:43,372]\u001b[0m Trial 908 finished with value: 1.9285412797892338 and parameters: {'n_hidden': 3, 'learning_rate': 0.002191595289410087, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01682725167605143, 'dropout_rate_Layer_2': 0.06190095358303775, 'dropout_rate_Layer_3': 0.2062551421318837, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.07075080599334448, 'l1_Layer_2': 0.06272673641241698, 'l1_Layer_3': 0.003466996259167146, 'n_units_Layer_1': 120, 'n_units_Layer_2': 260, 'n_units_Layer_3': 280}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.05% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.13 | sMAPE for Test Set is: 95.55% | rMAE for Test Set is: 3.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:55:47,959]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:55:48,532]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:56:44,977]\u001b[0m Trial 917 finished with value: 2.1814702230325627 and parameters: {'n_hidden': 4, 'learning_rate': 0.007003659901889548, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07566334797262136, 'dropout_rate_Layer_2': 0.397020760173771, 'dropout_rate_Layer_3': 0.22518079573278504, 'dropout_rate_Layer_4': 0.09815518863282885, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.018203769065469097, 'l1_Layer_2': 2.2206165406469287e-05, 'l1_Layer_3': 5.5137215305557824e-05, 'l1_Layer_4': 0.00017714475508973416, 'n_units_Layer_1': 60, 'n_units_Layer_2': 70, 'n_units_Layer_3': 110, 'n_units_Layer_4': 125}. Best is trial 665 with value: 1.899417599947981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.18 | sMAPE for Validation Set is: 5.66% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 16.33 | sMAPE for Test Set is: 108.88% | rMAE for Test Set is: 5.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:57:06,763]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:57:36,766]\u001b[0m Trial 916 finished with value: 1.8872675335118672 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020680080692176053, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01548177649143374, 'dropout_rate_Layer_2': 0.053244584128069775, 'dropout_rate_Layer_3': 0.20325894787278292, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.07657777776101429, 'l1_Layer_2': 0.05623453563563062, 'l1_Layer_3': 0.0024771825611433524, 'n_units_Layer_1': 125, 'n_units_Layer_2': 260, 'n_units_Layer_3': 270}. Best is trial 916 with value: 1.8872675335118672.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.89 | sMAPE for Validation Set is: 4.96% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.98 | sMAPE for Test Set is: 88.28% | rMAE for Test Set is: 2.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:57:58,826]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:58:05,802]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:58:10,933]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:58:32,178]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:58:35,362]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:59:36,326]\u001b[0m Trial 924 finished with value: 1.9269121360512422 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022824097181959884, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00848624762539069, 'dropout_rate_Layer_2': 0.06562368710224627, 'dropout_rate_Layer_3': 0.18790758228669774, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0776172173789708, 'l1_Layer_2': 0.0996873957519048, 'l1_Layer_3': 0.0022791148294465506, 'n_units_Layer_1': 130, 'n_units_Layer_2': 275, 'n_units_Layer_3': 290}. Best is trial 916 with value: 1.8872675335118672.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.06% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.05 | sMAPE for Test Set is: 84.53% | rMAE for Test Set is: 2.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:59:49,115]\u001b[0m Trial 925 finished with value: 1.883548258984777 and parameters: {'n_hidden': 3, 'learning_rate': 0.002036408833593562, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023070984761976544, 'dropout_rate_Layer_2': 0.0371416282398207, 'dropout_rate_Layer_3': 0.20342430941583042, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.07854184675727245, 'l1_Layer_2': 0.07422628561010071, 'l1_Layer_3': 0.002201403393613992, 'n_units_Layer_1': 130, 'n_units_Layer_2': 255, 'n_units_Layer_3': 280}. Best is trial 925 with value: 1.883548258984777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.88 | sMAPE for Validation Set is: 4.98% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.87 | sMAPE for Test Set is: 79.07% | rMAE for Test Set is: 2.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:00:45,324]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:00:50,419]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:00:55,602]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:00:58,391]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:01:05,109]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:01:10,249]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:02:01,273]\u001b[0m Trial 931 finished with value: 1.9062877076875342 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020331562054741225, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0005247356523551787, 'dropout_rate_Layer_2': 0.034561891839654635, 'dropout_rate_Layer_3': 0.2031789896936084, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.08341753321266358, 'l1_Layer_2': 0.08231662715586212, 'l1_Layer_3': 0.0023551716804213418, 'n_units_Layer_1': 130, 'n_units_Layer_2': 255, 'n_units_Layer_3': 290}. Best is trial 925 with value: 1.883548258984777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 5.02% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.70 | sMAPE for Test Set is: 78.25% | rMAE for Test Set is: 2.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:02:05,993]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:03:02,630]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:04:18,548]\u001b[0m Trial 936 finished with value: 1.9140156390191903 and parameters: {'n_hidden': 3, 'learning_rate': 0.002030685484161871, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.004796853876948141, 'dropout_rate_Layer_2': 0.02907063922388539, 'dropout_rate_Layer_3': 0.20745683575881363, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.09609417237518068, 'l1_Layer_2': 0.08422471276303749, 'l1_Layer_3': 0.0017155377399343085, 'n_units_Layer_1': 130, 'n_units_Layer_2': 270, 'n_units_Layer_3': 295}. Best is trial 925 with value: 1.883548258984777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 5.04% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.64 | sMAPE for Test Set is: 82.88% | rMAE for Test Set is: 2.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:04:20,550]\u001b[0m Trial 934 finished with value: 1.898907840806901 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019103729184949544, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.005756116679666513, 'dropout_rate_Layer_2': 0.022564760321843888, 'dropout_rate_Layer_3': 0.20523779475955475, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.09646044348479081, 'l1_Layer_2': 0.08570887662338204, 'l1_Layer_3': 0.001713480215853476, 'n_units_Layer_1': 130, 'n_units_Layer_2': 255, 'n_units_Layer_3': 295}. Best is trial 925 with value: 1.883548258984777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 5.00% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.82 | sMAPE for Test Set is: 87.70% | rMAE for Test Set is: 2.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:04:26,222]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:04:32,582]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:05:29,245]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:05:34,401]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:05:41,187]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:05:46,608]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:06:07,933]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:06:20,650]\u001b[0m Trial 940 finished with value: 1.9059508558003377 and parameters: {'n_hidden': 3, 'learning_rate': 0.001888133455187361, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.004100232860849443, 'dropout_rate_Layer_2': 0.037037819720031284, 'dropout_rate_Layer_3': 0.21095345799782542, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0990005084779832, 'l1_Layer_2': 0.08361500576504845, 'l1_Layer_3': 0.0017580394822641944, 'n_units_Layer_1': 130, 'n_units_Layer_2': 255, 'n_units_Layer_3': 300}. Best is trial 925 with value: 1.883548258984777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 5.02% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.40 | sMAPE for Test Set is: 86.03% | rMAE for Test Set is: 2.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:06:25,855]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:06:32,329]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:06:40,339]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:06:45,572]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:06:50,613]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:06:57,944]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:07:44,297]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:07:49,540]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:08:15,917]\u001b[0m Trial 945 finished with value: 1.9146377824715843 and parameters: {'n_hidden': 3, 'learning_rate': 0.002026031912184497, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011994233002201026, 'dropout_rate_Layer_2': 0.02864039760478871, 'dropout_rate_Layer_3': 0.2210091609106216, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.07559597178511288, 'l1_Layer_2': 0.07539448616157565, 'l1_Layer_3': 0.002565511940388689, 'n_units_Layer_1': 135, 'n_units_Layer_2': 240, 'n_units_Layer_3': 295}. Best is trial 925 with value: 1.883548258984777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 5.05% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.86 | sMAPE for Test Set is: 87.94% | rMAE for Test Set is: 2.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:08:21,012]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:08:26,184]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:08:50,455]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:08:55,945]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:09:05,730]\u001b[0m Trial 954 finished with value: 1.925316102713402 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019901223924955716, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0014185674134351571, 'dropout_rate_Layer_2': 0.03359596124648128, 'dropout_rate_Layer_3': 0.2083500436394565, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.07270581676271398, 'l1_Layer_2': 0.07331990989641833, 'l1_Layer_3': 0.0025531816758434067, 'n_units_Layer_1': 125, 'n_units_Layer_2': 260, 'n_units_Layer_3': 300}. Best is trial 925 with value: 1.883548258984777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.06% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.29 | sMAPE for Test Set is: 81.13% | rMAE for Test Set is: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:10:24,655]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:10:32,157]\u001b[0m Trial 959 finished with value: 1.883399801289791 and parameters: {'n_hidden': 3, 'learning_rate': 0.002028751353693312, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0031796696611133537, 'dropout_rate_Layer_2': 0.030199337726397303, 'dropout_rate_Layer_3': 0.19550032581714805, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.07562424011346866, 'l1_Layer_2': 0.07088585463445658, 'l1_Layer_3': 0.0025791079424994355, 'n_units_Layer_1': 145, 'n_units_Layer_2': 265, 'n_units_Layer_3': 300}. Best is trial 959 with value: 1.883399801289791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.88 | sMAPE for Validation Set is: 4.96% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.98 | sMAPE for Test Set is: 84.13% | rMAE for Test Set is: 2.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:10:46,831]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:10:51,576]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:11:14,176]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:11:19,156]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:12:25,372]\u001b[0m Trial 964 finished with value: 1.9010296877447235 and parameters: {'n_hidden': 3, 'learning_rate': 0.001988211710913479, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0024354187180199776, 'dropout_rate_Layer_2': 0.011200995071693325, 'dropout_rate_Layer_3': 0.19993443506131925, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.07924459030189399, 'l1_Layer_2': 0.08563597111791996, 'l1_Layer_3': 0.0025504034765312417, 'n_units_Layer_1': 135, 'n_units_Layer_2': 270, 'n_units_Layer_3': 300}. Best is trial 959 with value: 1.883399801289791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 5.04% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.38 | sMAPE for Test Set is: 76.65% | rMAE for Test Set is: 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:12:30,641]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:12:40,565]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:12:45,444]\u001b[0m Trial 966 finished with value: 1.8842895976746774 and parameters: {'n_hidden': 3, 'learning_rate': 0.002002386193581423, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0089844498964456, 'dropout_rate_Layer_2': 0.011106176470238736, 'dropout_rate_Layer_3': 0.2040658126599891, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.09993719587235748, 'l1_Layer_2': 0.08576548219605815, 'l1_Layer_3': 0.001977991175121776, 'n_units_Layer_1': 140, 'n_units_Layer_2': 260, 'n_units_Layer_3': 300}. Best is trial 959 with value: 1.883399801289791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.88 | sMAPE for Validation Set is: 4.98% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.66 | sMAPE for Test Set is: 78.07% | rMAE for Test Set is: 2.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:13:26,728]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:13:32,028]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:13:39,265]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:13:59,183]\u001b[0m Trial 970 finished with value: 1.934659771013526 and parameters: {'n_hidden': 3, 'learning_rate': 0.000771411484141217, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18804699252280288, 'dropout_rate_Layer_2': 0.19041775436894764, 'dropout_rate_Layer_3': 0.020722986490140607, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08976748768758051, 'l1_Layer_2': 0.005299848125258574, 'l1_Layer_3': 0.0015799336230707772, 'n_units_Layer_1': 235, 'n_units_Layer_2': 70, 'n_units_Layer_3': 245}. Best is trial 959 with value: 1.883399801289791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.14% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.40 | sMAPE for Test Set is: 42.39% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:14:58,493]\u001b[0m Trial 973 finished with value: 1.90014659724866 and parameters: {'n_hidden': 3, 'learning_rate': 0.001986017093744568, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01427934917125726, 'dropout_rate_Layer_2': 0.009798520453689237, 'dropout_rate_Layer_3': 0.20433388410891035, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.09846693354693714, 'l1_Layer_2': 0.08508484165471723, 'l1_Layer_3': 0.002703984626232275, 'n_units_Layer_1': 135, 'n_units_Layer_2': 255, 'n_units_Layer_3': 300}. Best is trial 959 with value: 1.883399801289791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 5.03% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.55 | sMAPE for Test Set is: 77.54% | rMAE for Test Set is: 2.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:15:20,410]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:15:23,185]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:15:30,258]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:15:35,410]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:15:39,688]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:15:42,511]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:15:45,091]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:16:41,890]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:16:51,207]\u001b[0m Trial 981 finished with value: 1.9215623581653647 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007500017768303702, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03804418841318984, 'dropout_rate_Layer_2': 0.3891484803691745, 'dropout_rate_Layer_3': 0.22132138757932848, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06186001553766445, 'l1_Layer_2': 0.00031105783861730646, 'l1_Layer_3': 4.1927807723827785e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 150, 'n_units_Layer_3': 215}. Best is trial 959 with value: 1.883399801289791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.02% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.34 | sMAPE for Test Set is: 92.95% | rMAE for Test Set is: 3.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:17:13,543]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:17:21,512]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:17:28,756]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:17:33,291]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:17:38,462]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:17:45,232]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:18:00,067]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:18:07,586]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:18:12,907]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:18:39,352]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:18:44,186]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:18:47,202]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:18:54,209]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:19:16,628]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:19:53,246]\u001b[0m Trial 995 finished with value: 2.0792271329037972 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007058669940564652, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06399345429947642, 'dropout_rate_Layer_2': 0.3413909398495678, 'dropout_rate_Layer_3': 0.2350280337429024, 'dropout_rate_Layer_4': 0.20931219751198177, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.001609702969494349, 'l1_Layer_2': 0.00047235609416525925, 'l1_Layer_3': 0.00012694453761764006, 'l1_Layer_4': 0.00012535143816423775, 'n_units_Layer_1': 50, 'n_units_Layer_2': 140, 'n_units_Layer_3': 120, 'n_units_Layer_4': 110}. Best is trial 959 with value: 1.883399801289791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 5.38% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 14.44 | sMAPE for Test Set is: 104.66% | rMAE for Test Set is: 4.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:20:13,113]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:20:17,432]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:20:27,369]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:20:39,279]\u001b[0m Trial 998 finished with value: 1.8986795927159619 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005757404907207194, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22767713834399061, 'dropout_rate_Layer_2': 0.18225630990192962, 'dropout_rate_Layer_3': 0.027741118528483624, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.055509983931677984, 'l1_Layer_2': 0.006346877702994456, 'l1_Layer_3': 0.0004425220275578138, 'n_units_Layer_1': 255, 'n_units_Layer_2': 100, 'n_units_Layer_3': 235}. Best is trial 959 with value: 1.883399801289791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 5.08% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.94 | sMAPE for Test Set is: 37.18% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:20:47,073]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:20:54,028]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:21:01,655]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:21:16,371]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:21:55,852]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:22:01,043]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:22:07,810]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:22:32,679]\u001b[0m Trial 1005 finished with value: 1.896613706752131 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021444575973631427, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015589743003172474, 'dropout_rate_Layer_2': 0.04843678209761567, 'dropout_rate_Layer_3': 0.2219890166782991, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.09958763188284135, 'l1_Layer_2': 0.08485710700232281, 'l1_Layer_3': 0.00194541472564719, 'n_units_Layer_1': 125, 'n_units_Layer_2': 260, 'n_units_Layer_3': 300}. Best is trial 959 with value: 1.883399801289791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 4.98% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.03 | sMAPE for Test Set is: 88.45% | rMAE for Test Set is: 2.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:22:39,772]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:22:42,656]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:22:47,184]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:22:47,751]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:23:09,973]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:23:21,395]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:23:31,860]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:24:01,030]\u001b[0m Trial 1018 finished with value: 1.9039205632085465 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013593215955285207, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2308110421253724, 'dropout_rate_Layer_2': 0.20527479266940518, 'dropout_rate_Layer_3': 0.06298769775475167, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.060450374616436514, 'l1_Layer_2': 0.0030803755096061648, 'l1_Layer_3': 0.0002592172582553821, 'n_units_Layer_1': 280, 'n_units_Layer_2': 115, 'n_units_Layer_3': 200}. Best is trial 959 with value: 1.883399801289791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 5.06% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.37 | sMAPE for Test Set is: 41.52% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:24:10,236]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:24:15,034]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:24:44,657]\u001b[0m Trial 1015 finished with value: 1.8906886582756395 and parameters: {'n_hidden': 3, 'learning_rate': 0.002082169700819708, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007881187596941622, 'dropout_rate_Layer_2': 0.03181792702628742, 'dropout_rate_Layer_3': 0.19451831940810588, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.07568992528476948, 'l1_Layer_2': 0.09937599044647139, 'l1_Layer_3': 0.0027018914705611153, 'n_units_Layer_1': 140, 'n_units_Layer_2': 255, 'n_units_Layer_3': 300}. Best is trial 959 with value: 1.883399801289791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.89 | sMAPE for Validation Set is: 4.96% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 10.02 | sMAPE for Test Set is: 92.15% | rMAE for Test Set is: 3.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:25:05,675]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:25:08,554]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:25:11,530]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:25:13,874]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:25:18,983]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:25:25,918]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:25:36,069]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:25:41,243]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:25:51,119]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:25:57,984]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:26:03,587]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:26:10,340]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:26:17,974]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:26:55,028]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:27:02,486]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:27:33,990]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:27:39,508]\u001b[0m Trial 1035 finished with value: 2.110408315525375 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017358444664753044, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17272347373838498, 'dropout_rate_Layer_2': 0.2605676615767128, 'dropout_rate_Layer_3': 0.3763311197678304, 'dropout_rate_Layer_4': 0.08017797548325195, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0006125122154816248, 'l1_Layer_2': 0.002053333314854986, 'l1_Layer_3': 0.0002679524182795627, 'l1_Layer_4': 0.0020099538652123042, 'n_units_Layer_1': 80, 'n_units_Layer_2': 165, 'n_units_Layer_3': 190, 'n_units_Layer_4': 195}. Best is trial 959 with value: 1.883399801289791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.11 | sMAPE for Validation Set is: 5.44% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.12 | sMAPE for Test Set is: 96.18% | rMAE for Test Set is: 3.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:28:20,815]\u001b[0m Trial 1039 finished with value: 1.9067966626254318 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013548267020105263, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22706961735243034, 'dropout_rate_Layer_2': 0.1582038458969708, 'dropout_rate_Layer_3': 0.06610987316270311, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.07489055851584173, 'l1_Layer_2': 0.003181571503806374, 'l1_Layer_3': 0.00021513922727719144, 'n_units_Layer_1': 280, 'n_units_Layer_2': 115, 'n_units_Layer_3': 195}. Best is trial 959 with value: 1.883399801289791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 5.12% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.39 | sMAPE for Test Set is: 25.05% | rMAE for Test Set is: 0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:29:07,474]\u001b[0m Trial 1038 finished with value: 2.1036887788062213 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016060554896060193, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17320278811635914, 'dropout_rate_Layer_2': 0.26687839079273806, 'dropout_rate_Layer_3': 0.3711049034750261, 'dropout_rate_Layer_4': 0.07723584880330772, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0007050254562983681, 'l1_Layer_2': 0.0020213576635460593, 'l1_Layer_3': 0.0002841613112464408, 'l1_Layer_4': 0.002038667797570478, 'n_units_Layer_1': 80, 'n_units_Layer_2': 165, 'n_units_Layer_3': 195, 'n_units_Layer_4': 195}. Best is trial 959 with value: 1.883399801289791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.10 | sMAPE for Validation Set is: 5.45% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 16.57 | sMAPE for Test Set is: 110.02% | rMAE for Test Set is: 5.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:30:14,690]\u001b[0m Trial 1040 finished with value: 1.8515949890555838 and parameters: {'n_hidden': 3, 'learning_rate': 0.002148979702850556, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0067755602054985625, 'dropout_rate_Layer_2': 0.028766663784190072, 'dropout_rate_Layer_3': 0.20068213796910653, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.06585521609841906, 'l1_Layer_2': 0.08187048649328361, 'l1_Layer_3': 0.003296542602526966, 'n_units_Layer_1': 145, 'n_units_Layer_2': 265, 'n_units_Layer_3': 295}. Best is trial 1040 with value: 1.8515949890555838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.85 | sMAPE for Validation Set is: 4.86% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 17.39 | sMAPE for Test Set is: 111.21% | rMAE for Test Set is: 5.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:30:22,119]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:30:36,383]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:30:43,918]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:31:46,462]\u001b[0m Trial 1041 finished with value: 2.1266409747604995 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014364267134504382, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13295099545231062, 'dropout_rate_Layer_2': 0.2570751916629938, 'dropout_rate_Layer_3': 0.3808135936418643, 'dropout_rate_Layer_4': 0.08809802432706101, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00047210790246867275, 'l1_Layer_2': 0.0015806022601231675, 'l1_Layer_3': 0.00034099400636914513, 'l1_Layer_4': 0.002526619197489756, 'n_units_Layer_1': 75, 'n_units_Layer_2': 175, 'n_units_Layer_3': 190, 'n_units_Layer_4': 190}. Best is trial 1040 with value: 1.8515949890555838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 5.56% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 14.16 | sMAPE for Test Set is: 104.45% | rMAE for Test Set is: 4.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:31:51,440]\u001b[0m Trial 1045 finished with value: 2.018027901223252 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014400285252325552, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15936150982944997, 'dropout_rate_Layer_2': 0.25257618676725113, 'dropout_rate_Layer_3': 0.36555723389974815, 'dropout_rate_Layer_4': 0.08714684402629655, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0004732449977233155, 'l1_Layer_2': 0.001817445303587773, 'l1_Layer_3': 0.00032887676798958786, 'l1_Layer_4': 0.0026307727375731323, 'n_units_Layer_1': 70, 'n_units_Layer_2': 175, 'n_units_Layer_3': 180, 'n_units_Layer_4': 190}. Best is trial 1040 with value: 1.8515949890555838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.02 | sMAPE for Validation Set is: 5.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 15.11 | sMAPE for Test Set is: 106.85% | rMAE for Test Set is: 4.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:31:57,886]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:32:03,006]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:32:08,392]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:32:13,587]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:32:22,794]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:32:30,388]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:32:35,596]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:32:50,099]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:32:57,996]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:33:04,965]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:33:10,586]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:33:24,399]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:33:32,362]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:33:38,114]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:33:45,489]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:33:52,618]\u001b[0m Trial 1047 finished with value: 2.045547546630021 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014033300168549152, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15514348405052863, 'dropout_rate_Layer_2': 0.2544986273218371, 'dropout_rate_Layer_3': 0.38008282570472285, 'dropout_rate_Layer_4': 0.08793022997228161, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00048162802362507407, 'l1_Layer_2': 0.001531489009296954, 'l1_Layer_3': 0.0003367663532291067, 'l1_Layer_4': 0.0026476902309383785, 'n_units_Layer_1': 65, 'n_units_Layer_2': 175, 'n_units_Layer_3': 190, 'n_units_Layer_4': 190}. Best is trial 1040 with value: 1.8515949890555838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 5.29% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.75 | sMAPE for Test Set is: 97.78% | rMAE for Test Set is: 3.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:34:07,459]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:34:12,697]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:35:11,304]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:35:16,644]\u001b[0m Trial 1062 finished with value: 1.8989792141523665 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022483249182803445, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015583332339174905, 'dropout_rate_Layer_2': 0.024723964468394796, 'dropout_rate_Layer_3': 0.2006714690590915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.05905625612178506, 'l1_Layer_2': 0.09875291225342968, 'l1_Layer_3': 0.002754247575008719, 'n_units_Layer_1': 125, 'n_units_Layer_2': 290, 'n_units_Layer_3': 300}. Best is trial 1040 with value: 1.8515949890555838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 5.00% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.08 | sMAPE for Test Set is: 80.20% | rMAE for Test Set is: 2.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:36:36,717]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:36:37,308]\u001b[0m Trial 1067 finished with value: 1.8952699687316654 and parameters: {'n_hidden': 3, 'learning_rate': 0.002282063719337387, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026022645118985232, 'dropout_rate_Layer_2': 0.011070076104931445, 'dropout_rate_Layer_3': 0.1844819609155511, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.06031945004888751, 'l1_Layer_2': 0.08552209026888294, 'l1_Layer_3': 0.0013473654352543804, 'n_units_Layer_1': 135, 'n_units_Layer_2': 295, 'n_units_Layer_3': 295}. Best is trial 1040 with value: 1.8515949890555838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 5.00% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.71 | sMAPE for Test Set is: 78.42% | rMAE for Test Set is: 2.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:36:49,380]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:36:59,878]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:37:04,860]\u001b[0m Trial 1069 finished with value: 2.1078200435105647 and parameters: {'n_hidden': 3, 'learning_rate': 0.001467700711121928, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21941468196446628, 'dropout_rate_Layer_2': 0.15908949181301713, 'dropout_rate_Layer_3': 0.06044843412862931, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.07046431005146547, 'l1_Layer_2': 5.445303086558562e-05, 'l1_Layer_3': 3.7385485356942505e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 55, 'n_units_Layer_3': 180}. Best is trial 1040 with value: 1.8515949890555838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.11 | sMAPE for Validation Set is: 5.63% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 2.64 | sMAPE for Test Set is: 44.59% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:37:09,397]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:37:21,251]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:37:33,493]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:37:41,132]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 5.33% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 17.67 | sMAPE for Test Set is: 112.01% | rMAE for Test Set is: 5.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:38:14,676]\u001b[0m Trial 1073 finished with value: 2.061156278961864 and parameters: {'n_hidden': 4, 'learning_rate': 0.001499308588219801, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16097918637631994, 'dropout_rate_Layer_2': 0.2569003034332886, 'dropout_rate_Layer_3': 0.3902285139891942, 'dropout_rate_Layer_4': 0.08133993658372302, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0004606041967260576, 'l1_Layer_2': 0.0011953711543791327, 'l1_Layer_3': 0.00044832354477309646, 'l1_Layer_4': 0.004382923613998397, 'n_units_Layer_1': 60, 'n_units_Layer_2': 170, 'n_units_Layer_3': 180, 'n_units_Layer_4': 190}. Best is trial 1040 with value: 1.8515949890555838.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:38:19,969]\u001b[0m Trial 1076 finished with value: 1.944291734326929 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012599301808166293, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23277525979873379, 'dropout_rate_Layer_2': 0.13499273814229595, 'dropout_rate_Layer_3': 0.03214183468406934, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.046595607734062364, 'l1_Layer_2': 0.003178406535864759, 'l1_Layer_3': 0.00015794351681948992, 'n_units_Layer_1': 260, 'n_units_Layer_2': 120, 'n_units_Layer_3': 205}. Best is trial 1040 with value: 1.8515949890555838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.18% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.99 | sMAPE for Test Set is: 38.48% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:39:04,299]\u001b[0m Trial 1078 finished with value: 1.908518284281761 and parameters: {'n_hidden': 3, 'learning_rate': 0.001157127972510433, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2799715964794738, 'dropout_rate_Layer_2': 0.13424333394295251, 'dropout_rate_Layer_3': 0.03957755321008075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0549804869175632, 'l1_Layer_2': 0.003571922569363316, 'l1_Layer_3': 8.567429750750197e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 120, 'n_units_Layer_3': 160}. Best is trial 1040 with value: 1.8515949890555838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 5.11% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.39 | sMAPE for Test Set is: 40.77% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:39:14,302]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:39:19,322]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:39:28,299]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:40:17,249]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:40:22,590]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:40:28,025]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:40:32,191]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:40:32,908]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:40:38,270]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:40:47,742]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:41:02,435]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:42:09,211]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:42:13,266]\u001b[0m Trial 1090 finished with value: 1.9156175489621017 and parameters: {'n_hidden': 3, 'learning_rate': 0.002095697415176802, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021043739338375653, 'dropout_rate_Layer_2': 0.031129574563234903, 'dropout_rate_Layer_3': 0.1886565309278895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.09918794246785294, 'l1_Layer_2': 0.06321970897059093, 'l1_Layer_3': 0.002276854100399805, 'n_units_Layer_1': 140, 'n_units_Layer_2': 290, 'n_units_Layer_3': 295}. Best is trial 1040 with value: 1.8515949890555838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.03% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.77 | sMAPE for Test Set is: 83.40% | rMAE for Test Set is: 2.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:42:19,031]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:43:34,410]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:43:39,907]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:43:43,757]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:45:05,454]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:45:59,705]\u001b[0m Trial 1095 finished with value: 1.9000685867739346 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022444235895951363, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021400769106771626, 'dropout_rate_Layer_2': 0.010954551417244218, 'dropout_rate_Layer_3': 0.19531614049099458, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.09904831725318518, 'l1_Layer_2': 0.07532424957108264, 'l1_Layer_3': 0.00219054501919501, 'n_units_Layer_1': 150, 'n_units_Layer_2': 290, 'n_units_Layer_3': 290}. Best is trial 1040 with value: 1.8515949890555838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 5.01% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.48 | sMAPE for Test Set is: 82.06% | rMAE for Test Set is: 2.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:46:09,781]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:46:19,914]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:46:27,231]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:46:55,949]\u001b[0m Trial 1097 finished with value: 1.910565819154239 and parameters: {'n_hidden': 3, 'learning_rate': 0.002341448636177041, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02105739338230813, 'dropout_rate_Layer_2': 0.00027923041751122014, 'dropout_rate_Layer_3': 0.19517420319499101, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.09961219334012851, 'l1_Layer_2': 0.06797255461268312, 'l1_Layer_3': 0.0013622244041911603, 'n_units_Layer_1': 135, 'n_units_Layer_2': 290, 'n_units_Layer_3': 295}. Best is trial 1040 with value: 1.8515949890555838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 5.08% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.88 | sMAPE for Test Set is: 79.26% | rMAE for Test Set is: 2.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:47:50,547]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:47:57,834]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:48:05,462]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:48:12,846]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:48:17,933]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:48:25,238]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:48:32,310]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:50:06,709]\u001b[0m Trial 1107 finished with value: 1.9088734474661633 and parameters: {'n_hidden': 3, 'learning_rate': 0.002071790307205399, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 6.121702779434898e-06, 'dropout_rate_Layer_2': 0.014847325857193349, 'dropout_rate_Layer_3': 0.20102533345302376, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.08386641689604321, 'l1_Layer_2': 0.05609191895025179, 'l1_Layer_3': 0.002013477733779264, 'n_units_Layer_1': 140, 'n_units_Layer_2': 285, 'n_units_Layer_3': 300}. Best is trial 1040 with value: 1.8515949890555838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 5.03% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.64 | sMAPE for Test Set is: 82.75% | rMAE for Test Set is: 2.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:50:18,214]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:50:23,593]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:50:30,516]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:50:45,398]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:50:53,077]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:50:58,854]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:51:04,043]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:51:13,280]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:51:18,638]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:51:35,604]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:52:28,143]\u001b[0m Trial 1113 finished with value: 2.014521277541333 and parameters: {'n_hidden': 4, 'learning_rate': 0.001204245937840696, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1596387849535858, 'dropout_rate_Layer_2': 0.2646699498651921, 'dropout_rate_Layer_3': 0.39961134178578717, 'dropout_rate_Layer_4': 0.09240882610558626, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00044837909063803137, 'l1_Layer_2': 0.0013131004761452487, 'l1_Layer_3': 0.00025426886202262146, 'l1_Layer_4': 0.0029340177471490337, 'n_units_Layer_1': 65, 'n_units_Layer_2': 175, 'n_units_Layer_3': 195, 'n_units_Layer_4': 205}. Best is trial 1040 with value: 1.8515949890555838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 5.21% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 17.21 | sMAPE for Test Set is: 111.38% | rMAE for Test Set is: 5.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:52:47,738]\u001b[0m Trial 1120 finished with value: 1.920248208489942 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021305199975603884, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015668631163064828, 'dropout_rate_Layer_2': 0.017880767799622804, 'dropout_rate_Layer_3': 0.2099650439712185, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.06916074010562337, 'l1_Layer_2': 0.067267686833451, 'l1_Layer_3': 0.00224427110879421, 'n_units_Layer_1': 140, 'n_units_Layer_2': 250, 'n_units_Layer_3': 295}. Best is trial 1040 with value: 1.8515949890555838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.06% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.07 | sMAPE for Test Set is: 75.00% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:52:58,905]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:53:04,794]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:53:48,176]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:54:19,967]\u001b[0m Trial 1124 finished with value: 1.9163902797112922 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023712757784327986, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01580308912878189, 'dropout_rate_Layer_2': 0.012598623313667406, 'dropout_rate_Layer_3': 0.21927065203496693, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.08368360375114535, 'l1_Layer_2': 0.06539408044338248, 'l1_Layer_3': 0.0017410284098129775, 'n_units_Layer_1': 150, 'n_units_Layer_2': 250, 'n_units_Layer_3': 290}. Best is trial 1040 with value: 1.8515949890555838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.04% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.20 | sMAPE for Test Set is: 85.31% | rMAE for Test Set is: 2.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:54:25,509]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:54:32,268]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:54:57,693]\u001b[0m Trial 1125 finished with value: 1.9267760936507965 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023947076590759555, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.031290081509582145, 'dropout_rate_Layer_2': 0.008915888404923203, 'dropout_rate_Layer_3': 0.22135718453397607, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0868505081146816, 'l1_Layer_2': 0.05436994870868332, 'l1_Layer_3': 0.0018178110908679559, 'n_units_Layer_1': 150, 'n_units_Layer_2': 250, 'n_units_Layer_3': 295}. Best is trial 1040 with value: 1.8515949890555838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.09% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.79 | sMAPE for Test Set is: 78.76% | rMAE for Test Set is: 2.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:55:12,590]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:55:18,088]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:55:23,000]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:55:30,494]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:55:35,716]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:55:50,267]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:55:52,851]\u001b[0m Trial 1128 finished with value: 1.9304842596391507 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023690805424604546, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024775436123557155, 'dropout_rate_Layer_2': 0.02344152073642485, 'dropout_rate_Layer_3': 0.20138209113861805, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.08321048911297486, 'l1_Layer_2': 0.06316617924091442, 'l1_Layer_3': 0.0017824059441942694, 'n_units_Layer_1': 155, 'n_units_Layer_2': 245, 'n_units_Layer_3': 290}. Best is trial 1040 with value: 1.8515949890555838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.08% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.26 | sMAPE for Test Set is: 81.02% | rMAE for Test Set is: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:55:59,507]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:57:10,920]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:57:18,466]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:57:21,397]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:57:33,499]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:57:38,905]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:57:43,803]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:57:51,061]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:57:51,313]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:58:00,175]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:58:02,794]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:58:17,644]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:58:22,865]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:58:23,527]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:58:31,950]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:58:33,681]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:58:41,512]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:58:51,783]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:59:38,813]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:00:03,556]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:00:14,271]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:00:14,457]\u001b[0m Trial 1154 finished with value: 2.057434812249196 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012637836872520635, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16409997273612537, 'dropout_rate_Layer_2': 0.25488456067926735, 'dropout_rate_Layer_3': 0.39896742670679375, 'dropout_rate_Layer_4': 0.08461872721107686, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00046109914246304583, 'l1_Layer_2': 0.0007724659037673231, 'l1_Layer_3': 0.0002589054621593637, 'l1_Layer_4': 0.003092855212438665, 'n_units_Layer_1': 80, 'n_units_Layer_2': 175, 'n_units_Layer_3': 185, 'n_units_Layer_4': 210}. Best is trial 1040 with value: 1.8515949890555838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 5.33% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 14.02 | sMAPE for Test Set is: 104.52% | rMAE for Test Set is: 4.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:00:21,763]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:00:29,138]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:00:37,033]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:00:43,781]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:00:49,455]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:00:49,770]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:01:00,806]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:01:06,103]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:01:30,655]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:01:35,727]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:02:22,038]\u001b[0m Trial 1163 finished with value: 2.03988377595969 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011917223724885676, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17885138092287137, 'dropout_rate_Layer_2': 0.23971621405065544, 'dropout_rate_Layer_3': 0.39757351158084503, 'dropout_rate_Layer_4': 0.08997739738449419, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0005021676555925549, 'l1_Layer_2': 0.0009610113893349114, 'l1_Layer_3': 0.00020908656608890525, 'l1_Layer_4': 0.0028755509747160363, 'n_units_Layer_1': 80, 'n_units_Layer_2': 155, 'n_units_Layer_3': 185, 'n_units_Layer_4': 215}. Best is trial 1040 with value: 1.8515949890555838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 5.26% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 14.16 | sMAPE for Test Set is: 104.63% | rMAE for Test Set is: 4.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:02:44,911]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:02:50,551]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:04:59,442]\u001b[0m Trial 1171 finished with value: 1.9753190694130556 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007700102680858885, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04310956764053761, 'dropout_rate_Layer_2': 0.3537897393135856, 'dropout_rate_Layer_3': 0.003126613494147029, 'dropout_rate_Layer_4': 0.19803077471897276, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0011936115155487999, 'l1_Layer_2': 0.0017268466783831311, 'l1_Layer_3': 0.00014675668913004662, 'l1_Layer_4': 0.00014548540113446039, 'n_units_Layer_1': 50, 'n_units_Layer_2': 90, 'n_units_Layer_3': 75, 'n_units_Layer_4': 95}. Best is trial 1040 with value: 1.8515949890555838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.98 | sMAPE for Validation Set is: 5.19% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 16.01 | sMAPE for Test Set is: 109.06% | rMAE for Test Set is: 5.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:05:06,522]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:06:33,551]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:06:53,085]\u001b[0m Trial 1168 finished with value: 1.8505534777472583 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009662487959705098, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15876397766389985, 'dropout_rate_Layer_2': 0.2490809427548238, 'dropout_rate_Layer_3': 0.3835731631559851, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006498305018197253, 'l1_Layer_2': 0.000580059298619622, 'l1_Layer_3': 0.0002077330624600725, 'n_units_Layer_1': 70, 'n_units_Layer_2': 150, 'n_units_Layer_3': 210}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.85 | sMAPE for Validation Set is: 4.85% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.12 | sMAPE for Test Set is: 104.55% | rMAE for Test Set is: 4.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:07:00,963]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:07:07,970]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:08:06,235]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:08:09,581]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:08:16,708]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:08:20,985]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:08:26,222]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:08:28,775]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:08:40,558]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:09:09,242]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:09:18,544]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:09:19,077]\u001b[0m Trial 1182 finished with value: 1.920816149201029 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023714976509419164, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28118088434062366, 'dropout_rate_Layer_2': 0.2028155418199339, 'dropout_rate_Layer_3': 0.050938112663413526, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.047548412813126405, 'l1_Layer_2': 0.001429440577713753, 'l1_Layer_3': 0.0006051289872975179, 'n_units_Layer_1': 165, 'n_units_Layer_2': 130, 'n_units_Layer_3': 105}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.18% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.36 | sMAPE for Test Set is: 23.25% | rMAE for Test Set is: 0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:09:39,347]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:09:43,931]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:09:46,629]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:09:51,315]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:09:59,131]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:10:21,252]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:10:29,160]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:10:33,901]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:10:40,384]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:10:50,254]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:10:55,735]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:11:10,224]\u001b[0m Trial 1192 finished with value: 2.1332339631512176 and parameters: {'n_hidden': 4, 'learning_rate': 0.001021939887098187, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.038819014465827945, 'dropout_rate_Layer_2': 0.2912523927232792, 'dropout_rate_Layer_3': 0.14880144508631035, 'dropout_rate_Layer_4': 0.1945092928785801, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.000700123257476354, 'l1_Layer_2': 0.0013935015254543665, 'l1_Layer_3': 0.0007315631174132739, 'l1_Layer_4': 6.256473163012166e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 95, 'n_units_Layer_3': 100, 'n_units_Layer_4': 160}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 5.62% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 12.89 | sMAPE for Test Set is: 100.27% | rMAE for Test Set is: 4.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:11:49,997]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:12:04,567]\u001b[0m Trial 1199 finished with value: 1.9088774388950853 and parameters: {'n_hidden': 3, 'learning_rate': 0.00217300649673082, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.031090079094076576, 'dropout_rate_Layer_2': 0.05074156278753476, 'dropout_rate_Layer_3': 0.18598340073962202, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0641390770240864, 'l1_Layer_2': 0.08389282713989461, 'l1_Layer_3': 0.00172160909722952, 'n_units_Layer_1': 125, 'n_units_Layer_2': 265, 'n_units_Layer_3': 290}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 5.02% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.11 | sMAPE for Test Set is: 75.17% | rMAE for Test Set is: 1.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:12:19,904]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:12:27,687]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:12:54,564]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:12:59,486]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:13:02,567]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:13:06,944]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:13:14,808]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:13:49,045]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:14:08,697]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:14:16,449]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:14:21,959]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:14:28,591]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:14:32,002]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:14:39,055]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:14:44,930]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:14:56,362]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:15:19,465]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:15:24,356]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:15:31,271]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:15:43,774]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:15:56,234]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:16:03,842]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:16:16,375]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:16:21,970]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:16:26,873]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:16:41,448]\u001b[0m Trial 1213 finished with value: 2.1253520626906357 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012538778823749776, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1801785674766012, 'dropout_rate_Layer_2': 0.2470413385685337, 'dropout_rate_Layer_3': 0.3801367613868545, 'dropout_rate_Layer_4': 0.10647708683180661, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0002666579741129113, 'l1_Layer_2': 0.0009766318388672245, 'l1_Layer_3': 0.0002076460989315403, 'l1_Layer_4': 0.0028899812680676738, 'n_units_Layer_1': 70, 'n_units_Layer_2': 145, 'n_units_Layer_3': 200, 'n_units_Layer_4': 225}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 5.55% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.35 | sMAPE for Test Set is: 96.57% | rMAE for Test Set is: 3.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:16:48,311]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:17:00,285]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:17:00,622]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:17:08,129]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:17:15,313]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:17:27,573]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:18:02,048]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:18:16,838]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:18:25,030]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:18:49,059]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:18:54,231]\u001b[0m Trial 1233 finished with value: 1.9235976769404708 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022847863165838273, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006845424158299427, 'dropout_rate_Layer_2': 0.018242585790370656, 'dropout_rate_Layer_3': 0.20199714321301, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0998651608114042, 'l1_Layer_2': 0.08389542069764583, 'l1_Layer_3': 0.0022692763894689625, 'n_units_Layer_1': 120, 'n_units_Layer_2': 255, 'n_units_Layer_3': 295}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.07% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.80 | sMAPE for Test Set is: 83.57% | rMAE for Test Set is: 2.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:18:55,006]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:19:01,092]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:19:08,343]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:19:17,805]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:19:31,146]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:19:37,834]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:20:08,251]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:20:30,254]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:20:37,057]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:20:42,477]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:20:57,070]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:22:14,715]\u001b[0m Trial 1249 finished with value: 1.8705437479605223 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025044676002306445, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026808541114372836, 'dropout_rate_Layer_2': 0.023825508622405414, 'dropout_rate_Layer_3': 0.18755324259277537, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.051182612101290395, 'l1_Layer_2': 0.05700569468242611, 'l1_Layer_3': 0.0014007459744616207, 'n_units_Layer_1': 145, 'n_units_Layer_2': 245, 'n_units_Layer_3': 300}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.87 | sMAPE for Validation Set is: 4.94% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.20 | sMAPE for Test Set is: 80.59% | rMAE for Test Set is: 2.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:22:18,945]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:22:30,587]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:22:47,720]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:22:53,330]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:22:59,966]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:23:11,024]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:23:54,523]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:24:01,270]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:24:06,826]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:24:49,088]\u001b[0m Trial 1256 finished with value: 1.9588295873627766 and parameters: {'n_hidden': 3, 'learning_rate': 0.000570817006978977, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007949908517600877, 'dropout_rate_Layer_2': 0.29369253004031526, 'dropout_rate_Layer_3': 0.06097531145008339, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.049785048168566076, 'l1_Layer_2': 0.0003853184498331173, 'l1_Layer_3': 1.2434877975137564e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 105, 'n_units_Layer_3': 245}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 5.13% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.23 | sMAPE for Test Set is: 85.11% | rMAE for Test Set is: 2.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:25:36,371]\u001b[0m Trial 1259 finished with value: 2.0365950324948274 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016883584262438202, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16067441254671486, 'dropout_rate_Layer_2': 0.2627416083811898, 'dropout_rate_Layer_3': 0.39088831808023905, 'dropout_rate_Layer_4': 0.062004877935217875, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0008901083311963694, 'l1_Layer_2': 0.0011240130033613553, 'l1_Layer_3': 0.00036805519185074406, 'l1_Layer_4': 0.00725016715799453, 'n_units_Layer_1': 75, 'n_units_Layer_2': 185, 'n_units_Layer_3': 165, 'n_units_Layer_4': 220}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 5.27% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 16.24 | sMAPE for Test Set is: 108.80% | rMAE for Test Set is: 5.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:25:42,084]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:26:06,422]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:26:18,192]\u001b[0m Trial 1260 finished with value: 1.9257149492606551 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021332379071472085, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019326239110603154, 'dropout_rate_Layer_2': 0.006845377508110935, 'dropout_rate_Layer_3': 0.2106782785269109, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.08586179730389831, 'l1_Layer_2': 0.0595798102099316, 'l1_Layer_3': 0.0016929631435093542, 'n_units_Layer_1': 135, 'n_units_Layer_2': 290, 'n_units_Layer_3': 300}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.06% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.60 | sMAPE for Test Set is: 82.69% | rMAE for Test Set is: 2.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:26:35,708]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:26:43,644]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:26:58,939]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:27:45,760]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:27:52,843]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:28:00,397]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:28:05,557]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:28:05,870]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:28:15,171]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:28:22,848]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:28:32,903]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:29:23,430]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:29:50,671]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:29:57,699]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:30:18,147]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:30:49,653]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:30:55,441]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:31:02,477]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:31:09,872]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:31:15,241]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:31:27,276]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:31:27,993]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:31:41,448]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:31:46,889]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:32:16,787]\u001b[0m Trial 1286 finished with value: 2.3474800858684097 and parameters: {'n_hidden': 4, 'learning_rate': 0.01358954317675428, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09060849750386718, 'dropout_rate_Layer_2': 0.3020571776402107, 'dropout_rate_Layer_3': 0.35437790738909625, 'dropout_rate_Layer_4': 0.16568488055736924, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.4157573033027806e-05, 'l1_Layer_2': 2.115099628151709e-05, 'l1_Layer_3': 2.0883664189128572e-05, 'l1_Layer_4': 0.000489416460172053, 'n_units_Layer_1': 160, 'n_units_Layer_2': 120, 'n_units_Layer_3': 50, 'n_units_Layer_4': 70}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.35 | sMAPE for Validation Set is: 6.02% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 16.43 | sMAPE for Test Set is: 109.26% | rMAE for Test Set is: 5.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:32:24,247]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:32:32,339]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:32:39,595]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:33:19,477]\u001b[0m Trial 1288 finished with value: 2.106884955587334 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016657218878614775, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17907330944444008, 'dropout_rate_Layer_2': 0.25675038594715954, 'dropout_rate_Layer_3': 0.313366977926631, 'dropout_rate_Layer_4': 0.08816686752047453, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0005334163538389098, 'l1_Layer_2': 0.0009556889541339494, 'l1_Layer_3': 0.00023489579624763236, 'l1_Layer_4': 0.004119333276742836, 'n_units_Layer_1': 50, 'n_units_Layer_2': 150, 'n_units_Layer_3': 195, 'n_units_Layer_4': 250}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.11 | sMAPE for Validation Set is: 5.46% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.08 | sMAPE for Test Set is: 92.56% | rMAE for Test Set is: 3.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:33:45,213]\u001b[0m Trial 1292 finished with value: 2.0728646325532285 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016364686610723929, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18218887805966458, 'dropout_rate_Layer_2': 0.25775261490886797, 'dropout_rate_Layer_3': 0.30981713337961037, 'dropout_rate_Layer_4': 0.08925295655702564, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0005150808552283103, 'l1_Layer_2': 0.0009484351505020155, 'l1_Layer_3': 0.00023444532473307255, 'l1_Layer_4': 0.0041238727411620196, 'n_units_Layer_1': 50, 'n_units_Layer_2': 150, 'n_units_Layer_3': 165, 'n_units_Layer_4': 200}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 5.36% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 17.95 | sMAPE for Test Set is: 112.46% | rMAE for Test Set is: 5.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:33:52,374]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:34:06,385]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:34:31,149]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:34:43,932]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:35:15,555]\u001b[0m Trial 1298 finished with value: 2.498160026042377 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023004372114990264, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03925663999256648, 'dropout_rate_Layer_2': 0.36576089162840164, 'dropout_rate_Layer_3': 0.16152589058057706, 'dropout_rate_Layer_4': 0.24167400909818, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00016755847231267763, 'l1_Layer_2': 3.995856242538847e-05, 'l1_Layer_3': 0.001132559896420918, 'l1_Layer_4': 4.3728379035198395e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 165, 'n_units_Layer_3': 155, 'n_units_Layer_4': 200}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.50 | sMAPE for Validation Set is: 6.58% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 14.54 | sMAPE for Test Set is: 106.01% | rMAE for Test Set is: 4.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:35:20,938]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:35:30,425]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:35:35,780]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:35:43,665]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:35:56,663]\u001b[0m Trial 1297 finished with value: 1.9222376682771654 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025664309079222393, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029258105259519877, 'dropout_rate_Layer_2': 0.020287284045790478, 'dropout_rate_Layer_3': 0.2175102830412209, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.08477841170456843, 'l1_Layer_2': 0.08461114294531699, 'l1_Layer_3': 0.0026772652178922362, 'n_units_Layer_1': 140, 'n_units_Layer_2': 265, 'n_units_Layer_3': 295}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.08% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.77 | sMAPE for Test Set is: 83.40% | rMAE for Test Set is: 2.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:36:03,868]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:36:13,123]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:36:21,486]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:36:27,999]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:38:22,322]\u001b[0m Trial 1308 finished with value: 1.9797057355049603 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006324443898642592, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.196581469464842, 'dropout_rate_Layer_2': 0.25037257871742324, 'dropout_rate_Layer_3': 0.05096622457785066, 'dropout_rate_Layer_4': 0.08357334303593514, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0013272420041397666, 'l1_Layer_2': 0.0005943069688834795, 'l1_Layer_3': 0.0004204864517806085, 'l1_Layer_4': 0.009453988872175762, 'n_units_Layer_1': 60, 'n_units_Layer_2': 210, 'n_units_Layer_3': 185, 'n_units_Layer_4': 225}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.98 | sMAPE for Validation Set is: 5.13% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 17.39 | sMAPE for Test Set is: 111.18% | rMAE for Test Set is: 5.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:38:29,716]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:38:37,279]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:38:47,252]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:39:17,399]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:39:27,408]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:39:44,713]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:39:57,359]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:40:12,010]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:40:29,446]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:40:31,893]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:40:53,013]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:41:05,359]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:41:17,859]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:41:23,576]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:41:28,460]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:41:35,461]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:41:40,590]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:41:45,834]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:42:05,416]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:42:11,214]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:42:44,216]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:42:51,736]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:43:01,701]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:43:16,857]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:43:23,665]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:45:09,559]\u001b[0m Trial 1334 finished with value: 1.9876443188239297 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012391308367770987, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15192733196636707, 'dropout_rate_Layer_2': 0.23929845021574278, 'dropout_rate_Layer_3': 0.06372822466686932, 'dropout_rate_Layer_4': 0.11200660760297372, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00197020908474823, 'l1_Layer_2': 0.0005053583363073884, 'l1_Layer_3': 0.00032184031400120627, 'l1_Layer_4': 0.0032142000510281365, 'n_units_Layer_1': 55, 'n_units_Layer_2': 220, 'n_units_Layer_3': 180, 'n_units_Layer_4': 225}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.99 | sMAPE for Validation Set is: 5.18% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 17.19 | sMAPE for Test Set is: 110.74% | rMAE for Test Set is: 5.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:46:12,337]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:46:18,133]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:46:25,660]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:46:32,259]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:46:40,687]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:46:57,723]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:47:58,017]\u001b[0m Trial 1341 finished with value: 1.9371295638856942 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013207152620679638, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15066971965164075, 'dropout_rate_Layer_2': 0.2374824298428849, 'dropout_rate_Layer_3': 0.09915477958393329, 'dropout_rate_Layer_4': 0.11404394720397298, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0017645435898467016, 'l1_Layer_2': 0.0005265364077053173, 'l1_Layer_3': 0.0002129127953697802, 'l1_Layer_4': 0.0031268095121285734, 'n_units_Layer_1': 55, 'n_units_Layer_2': 225, 'n_units_Layer_3': 180, 'n_units_Layer_4': 225}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.03% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 17.35 | sMAPE for Test Set is: 111.10% | rMAE for Test Set is: 5.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:48:35,409]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:49:24,723]\u001b[0m Trial 1328 finished with value: 2.078636178712827 and parameters: {'n_hidden': 4, 'learning_rate': 0.004219706016694889, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16379738526974363, 'dropout_rate_Layer_2': 0.2449396273526073, 'dropout_rate_Layer_3': 0.0006731386139918472, 'dropout_rate_Layer_4': 0.3033171772120623, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00879123929960051, 'l1_Layer_2': 0.001661205776360179, 'l1_Layer_3': 0.015773846762586783, 'l1_Layer_4': 0.0002425715978177838, 'n_units_Layer_1': 75, 'n_units_Layer_2': 75, 'n_units_Layer_3': 120, 'n_units_Layer_4': 140}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 5.48% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.14 | sMAPE for Test Set is: 89.22% | rMAE for Test Set is: 2.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:49:32,176]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:49:39,564]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:49:49,061]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:50:21,374]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:50:27,257]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:51:02,091]\u001b[0m Trial 1343 finished with value: 1.8750670224639068 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026541205112859106, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013303755527606837, 'dropout_rate_Layer_2': 0.01625488598340557, 'dropout_rate_Layer_3': 0.21404092308269035, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.05066233488558559, 'l1_Layer_2': 0.0491694195382632, 'l1_Layer_3': 0.0034159802963144234, 'n_units_Layer_1': 135, 'n_units_Layer_2': 295, 'n_units_Layer_3': 295}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.88 | sMAPE for Validation Set is: 4.96% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.03 | sMAPE for Test Set is: 84.50% | rMAE for Test Set is: 2.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:51:07,584]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:51:15,728]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:51:43,547]\u001b[0m Trial 1349 finished with value: 1.9159951270225999 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023829143967701175, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014654086339967601, 'dropout_rate_Layer_2': 0.04762768029025605, 'dropout_rate_Layer_3': 0.20276926406484072, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.08523964804993533, 'l1_Layer_2': 0.0671226224320101, 'l1_Layer_3': 0.0020934797361337396, 'n_units_Layer_1': 145, 'n_units_Layer_2': 250, 'n_units_Layer_3': 300}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.05% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.38 | sMAPE for Test Set is: 81.48% | rMAE for Test Set is: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:51:51,207]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:52:23,795]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:52:28,872]\u001b[0m Trial 1354 finished with value: 1.9459044774195782 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022633767409101623, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29275377615510556, 'dropout_rate_Layer_2': 0.1663923920699042, 'dropout_rate_Layer_3': 0.07022012533263655, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06223746327179728, 'l1_Layer_2': 0.0033394575084798035, 'l1_Layer_3': 0.00023881335820385627, 'n_units_Layer_1': 295, 'n_units_Layer_2': 120, 'n_units_Layer_3': 130}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.18% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.07 | sMAPE for Test Set is: 38.00% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:52:34,444]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:52:39,011]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:52:41,624]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:52:51,826]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:52:56,971]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:53:03,922]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:53:36,136]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:53:44,017]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:53:51,073]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:53:56,519]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:54:04,120]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:54:36,477]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:54:45,539]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:54:51,309]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:55:08,731]\u001b[0m Trial 1362 finished with value: 1.9082642519363031 and parameters: {'n_hidden': 3, 'learning_rate': 0.002608664451312986, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014198489953428983, 'dropout_rate_Layer_2': 0.045974445025778576, 'dropout_rate_Layer_3': 0.17660242767557194, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0484451526250343, 'l1_Layer_2': 0.06154161184988307, 'l1_Layer_3': 0.0029344288558362987, 'n_units_Layer_1': 125, 'n_units_Layer_2': 290, 'n_units_Layer_3': 300}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 5.02% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.45 | sMAPE for Test Set is: 89.81% | rMAE for Test Set is: 2.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:55:18,491]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:55:24,036]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:55:31,091]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:55:57,742]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:56:02,529]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:56:05,137]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:56:10,653]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:56:20,406]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:56:27,578]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:56:59,631]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:58:03,708]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:58:09,839]\u001b[0m Trial 1376 finished with value: 1.998810321037108 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007433528311082537, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13341742603708517, 'dropout_rate_Layer_2': 0.27223720316904076, 'dropout_rate_Layer_3': 0.056134425654865504, 'dropout_rate_Layer_4': 0.09086894058770467, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0014373631467722316, 'l1_Layer_2': 0.000500405222444932, 'l1_Layer_3': 0.00016481188392158965, 'l1_Layer_4': 0.0031753782226584507, 'n_units_Layer_1': 60, 'n_units_Layer_2': 220, 'n_units_Layer_3': 170, 'n_units_Layer_4': 285}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:58:09,897]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 5.19% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 17.03 | sMAPE for Test Set is: 110.36% | rMAE for Test Set is: 5.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:58:22,226]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:58:29,809]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:59:15,994]\u001b[0m Trial 1385 finished with value: 1.9208444526475237 and parameters: {'n_hidden': 3, 'learning_rate': 0.002503451592086273, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02083092888621768, 'dropout_rate_Layer_2': 0.038155089265531954, 'dropout_rate_Layer_3': 0.18488852664175118, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0698744632233051, 'l1_Layer_2': 0.04652767195468132, 'l1_Layer_3': 0.003121396822429203, 'n_units_Layer_1': 125, 'n_units_Layer_2': 300, 'n_units_Layer_3': 300}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.06% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.79 | sMAPE for Test Set is: 78.71% | rMAE for Test Set is: 2.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:59:27,161]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:59:33,414]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:00:08,572]\u001b[0m Trial 1386 finished with value: 1.913553392669564 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022824458154629863, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013012849699577111, 'dropout_rate_Layer_2': 0.025668124053935017, 'dropout_rate_Layer_3': 0.1813908510588636, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0717129680205683, 'l1_Layer_2': 0.08610440830301398, 'l1_Layer_3': 0.0031955556627573916, 'n_units_Layer_1': 135, 'n_units_Layer_2': 285, 'n_units_Layer_3': 290}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 5.06% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.24 | sMAPE for Test Set is: 85.30% | rMAE for Test Set is: 2.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:00:15,760]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:00:33,042]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:00:41,494]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:00:48,152]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:00:51,493]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:00:54,659]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:01:21,327]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:01:45,586]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:01:53,439]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:02:03,271]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:02:10,884]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:02:20,761]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:02:30,520]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:02:37,729]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:03:03,497]\u001b[0m Trial 1396 finished with value: 1.917779168327872 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008298808746065239, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014517026284949575, 'dropout_rate_Layer_2': 0.3381686099969352, 'dropout_rate_Layer_3': 0.17801360568381233, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0474293939949556, 'l1_Layer_2': 0.00018975137498300024, 'l1_Layer_3': 0.0002504482269595609, 'n_units_Layer_1': 55, 'n_units_Layer_2': 105, 'n_units_Layer_3': 250}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.02% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.58 | sMAPE for Test Set is: 93.70% | rMAE for Test Set is: 3.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:03:13,359]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:03:20,204]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:03:25,549]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:03:30,630]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:03:43,834]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:04:00,511]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:04:06,464]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:04:38,841]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:05:09,406]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:05:16,877]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:05:28,262]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:06:54,103]\u001b[0m Trial 1416 finished with value: 1.8895547924095026 and parameters: {'n_hidden': 3, 'learning_rate': 0.002688484470236473, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019606536514397113, 'dropout_rate_Layer_2': 0.016243726757882358, 'dropout_rate_Layer_3': 0.20920583251798724, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.08388927069742372, 'l1_Layer_2': 0.07552456707307521, 'l1_Layer_3': 0.0021233383661325247, 'n_units_Layer_1': 125, 'n_units_Layer_2': 275, 'n_units_Layer_3': 300}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.89 | sMAPE for Validation Set is: 4.98% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.95 | sMAPE for Test Set is: 84.07% | rMAE for Test Set is: 2.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:07:18,496]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:07:26,118]\u001b[0m Trial 1413 finished with value: 2.011993609344937 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011390962788540506, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2112928066051888, 'dropout_rate_Layer_2': 0.2651687762891637, 'dropout_rate_Layer_3': 0.07117296938634857, 'dropout_rate_Layer_4': 0.09497266802639191, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0009533223806102778, 'l1_Layer_2': 0.0005379800353698093, 'l1_Layer_3': 0.00040107422540674195, 'l1_Layer_4': 0.003812428253342718, 'n_units_Layer_1': 55, 'n_units_Layer_2': 230, 'n_units_Layer_3': 170, 'n_units_Layer_4': 300}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 5.21% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 17.41 | sMAPE for Test Set is: 111.23% | rMAE for Test Set is: 5.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:07:38,418]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:07:46,169]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:08:45,367]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:08:52,618]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:08:57,466]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:09:02,922]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:09:10,594]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:09:17,793]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:09:35,661]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:09:44,771]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:09:55,251]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:10:10,193]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:10:17,775]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:11:20,062]\u001b[0m Trial 1423 finished with value: 1.968053643796697 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008601287104035092, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21925115713705615, 'dropout_rate_Layer_2': 0.2831022081551739, 'dropout_rate_Layer_3': 0.050286861911619296, 'dropout_rate_Layer_4': 0.09364634208309106, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0011399437123595284, 'l1_Layer_2': 0.0004974340408232854, 'l1_Layer_3': 0.0003904328922292407, 'l1_Layer_4': 0.003817269454793111, 'n_units_Layer_1': 55, 'n_units_Layer_2': 220, 'n_units_Layer_3': 175, 'n_units_Layer_4': 220}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.10% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 17.13 | sMAPE for Test Set is: 110.60% | rMAE for Test Set is: 5.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:11:29,841]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:11:31,889]\u001b[0m Trial 1432 finished with value: 1.9799303451108312 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013533897489149556, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2118804041922313, 'dropout_rate_Layer_2': 0.3295140302613462, 'dropout_rate_Layer_3': 0.05268602268490224, 'dropout_rate_Layer_4': 0.11782072097201114, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00121316809162136, 'l1_Layer_2': 0.0003353204246602969, 'l1_Layer_3': 0.0001307408985235825, 'l1_Layer_4': 0.006609623794008075, 'n_units_Layer_1': 160, 'n_units_Layer_2': 245, 'n_units_Layer_3': 175, 'n_units_Layer_4': 280}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.98 | sMAPE for Validation Set is: 5.15% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 17.58 | sMAPE for Test Set is: 111.65% | rMAE for Test Set is: 5.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:11:41,543]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:12:17,617]\u001b[0m Trial 1436 finished with value: 1.9435371823683798 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022803473453982944, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25807656025845555, 'dropout_rate_Layer_2': 0.04529009245338925, 'dropout_rate_Layer_3': 0.03734937884038529, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.026995293891678752, 'l1_Layer_2': 0.007017856935742511, 'l1_Layer_3': 5.54419654643122e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 85, 'n_units_Layer_3': 110}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.21% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.39 | sMAPE for Test Set is: 26.17% | rMAE for Test Set is: 0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:12:25,100]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:12:34,460]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:12:44,818]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:12:52,920]\u001b[0m Trial 1434 finished with value: 1.9394017773988752 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008010689140264303, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03339469454066028, 'dropout_rate_Layer_2': 0.35379520662041714, 'dropout_rate_Layer_3': 0.18620337647621782, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07168909299532988, 'l1_Layer_2': 0.00042778617345344387, 'l1_Layer_3': 0.00026098820376904843, 'n_units_Layer_1': 50, 'n_units_Layer_2': 160, 'n_units_Layer_3': 250}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.05% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 11.92 | sMAPE for Test Set is: 97.82% | rMAE for Test Set is: 3.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:13:02,545]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:13:35,338]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:14:52,535]\u001b[0m Trial 1440 finished with value: 1.926501794491844 and parameters: {'n_hidden': 3, 'learning_rate': 0.002508619501251275, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.005762147349935694, 'dropout_rate_Layer_2': 0.011565109170277197, 'dropout_rate_Layer_3': 0.19260843182187465, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.08506020328662862, 'l1_Layer_2': 0.08470690282165669, 'l1_Layer_3': 0.002146781049398804, 'n_units_Layer_1': 115, 'n_units_Layer_2': 275, 'n_units_Layer_3': 290}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.10% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.27 | sMAPE for Test Set is: 81.12% | rMAE for Test Set is: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:15:01,759]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:15:09,543]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:15:09,695]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:15:18,485]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:15:18,617]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:15:27,618]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:15:34,760]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:15:39,809]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:15:42,536]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:15:47,055]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:15:52,409]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:15:56,888]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:16:05,263]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:16:10,786]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:16:17,675]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:16:25,222]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:16:35,109]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:16:43,084]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:16:59,954]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:17:05,689]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:17:12,304]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:17:17,837]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:17:20,158]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:17:25,133]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:17:30,253]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:17:33,277]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:17:39,940]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:17:40,151]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:17:52,715]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:17:59,752]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:18:07,857]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:18:18,618]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:18:34,856]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:19:19,988]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:19:27,496]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:19:34,870]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:19:42,898]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:19:55,059]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:20:08,049]\u001b[0m Trial 1474 finished with value: 2.032810307303843 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009205617098690528, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2314320591820499, 'dropout_rate_Layer_2': 0.23087055517478822, 'dropout_rate_Layer_3': 0.05853579735725976, 'dropout_rate_Layer_4': 0.08849439646917424, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0009155458093885062, 'l1_Layer_2': 0.0006263400682753011, 'l1_Layer_3': 0.0005703907714100372, 'l1_Layer_4': 0.014885682749242655, 'n_units_Layer_1': 70, 'n_units_Layer_2': 225, 'n_units_Layer_3': 170, 'n_units_Layer_4': 265}. Best is trial 1168 with value: 1.8505534777472583.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 5.26% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 17.46 | sMAPE for Test Set is: 111.36% | rMAE for Test Set is: 5.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:20:34,629]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:20:40,645]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:21:05,265]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:21:12,203]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:21:22,421]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:21:22,861]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:21:35,200]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:21:40,322]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:21:45,323]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:21:52,326]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:21:58,074]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:22:10,498]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:22:35,038]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:22:44,769]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:22:49,323]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:22:57,607]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:23:02,442]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:23:04,581]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-01-01, MAE is:2.28 & sMAPE is:7.09% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 7.09% & 0.44\n",
      "for 2020-01-02, MAE is:1.03 & sMAPE is:3.31% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :1.66 & 5.20% & 0.31\n",
      "for 2020-01-03, MAE is:1.16 & sMAPE is:3.89% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :1.49 & 4.76% & 0.25\n",
      "for 2020-01-04, MAE is:1.54 & sMAPE is:5.19% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :1.51 & 4.87% & 0.25\n",
      "for 2020-01-05, MAE is:1.30 & sMAPE is:4.33% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :1.46 & 4.76% & 0.30\n",
      "for 2020-01-06, MAE is:0.88 & sMAPE is:2.92% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :1.37 & 4.46% & 0.29\n",
      "for 2020-01-07, MAE is:1.02 & sMAPE is:3.45% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :1.32 & 4.31% & 0.29\n",
      "for 2020-01-08, MAE is:1.74 & sMAPE is:6.78% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :1.37 & 4.62% & 0.31\n",
      "for 2020-01-09, MAE is:2.57 & sMAPE is:8.84% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :1.50 & 5.09% & 0.36\n",
      "for 2020-01-10, MAE is:1.12 & sMAPE is:3.96% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :1.46 & 4.98% & 0.41\n",
      "for 2020-01-11, MAE is:1.50 & sMAPE is:5.79% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :1.47 & 5.05% & 0.41\n",
      "for 2020-01-12, MAE is:1.21 & sMAPE is:4.88% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :1.45 & 5.04% & 0.39\n",
      "for 2020-01-13, MAE is:1.14 & sMAPE is:4.26% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :1.42 & 4.98% & 0.39\n",
      "for 2020-01-14, MAE is:1.06 & sMAPE is:4.43% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :1.40 & 4.94% & 0.38\n",
      "for 2020-01-15, MAE is:1.04 & sMAPE is:4.19% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :1.37 & 4.89% & 0.38\n",
      "for 2020-01-16, MAE is:0.86 & sMAPE is:3.44% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :1.34 & 4.80% & 0.37\n",
      "for 2020-01-17, MAE is:1.00 & sMAPE is:4.00% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :1.32 & 4.75% & 0.37\n",
      "for 2020-01-18, MAE is:2.00 & sMAPE is:8.21% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :1.36 & 4.94% & 0.40\n",
      "for 2020-01-19, MAE is:2.12 & sMAPE is:8.89% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :1.40 & 5.15% & 0.44\n",
      "for 2020-01-20, MAE is:2.94 & sMAPE is:12.08% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :1.48 & 5.50% & 0.46\n",
      "for 2020-01-21, MAE is:2.96 & sMAPE is:13.25% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :1.55 & 5.87% & 0.48\n",
      "for 2020-01-22, MAE is:3.34 & sMAPE is:14.44% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :1.63 & 6.26% & 0.51\n",
      "for 2020-01-23, MAE is:4.42 & sMAPE is:19.36% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :1.75 & 6.83% & 0.54\n",
      "for 2020-01-24, MAE is:1.74 & sMAPE is:8.48% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :1.75 & 6.89% & 0.53\n",
      "for 2020-01-25, MAE is:3.45 & sMAPE is:15.48% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :1.82 & 7.24% & 0.56\n",
      "for 2020-01-26, MAE is:5.44 & sMAPE is:23.99% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :1.96 & 7.88% & 0.61\n",
      "for 2020-01-27, MAE is:4.03 & sMAPE is:17.68% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :2.03 & 8.25% & 0.66\n",
      "for 2020-01-28, MAE is:3.33 & sMAPE is:14.60% & rMAE is:4.81 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 8.47% & 0.81\n",
      "for 2020-01-29, MAE is:6.26 & sMAPE is:25.86% & rMAE is:7.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 9.07% & 1.03\n",
      "for 2020-01-30, MAE is:4.87 & sMAPE is:20.41% & rMAE is:5.07 ||| daily mean of MAE & sMAPE & rMAE till now are :2.31 & 9.45% & 1.17\n",
      "for 2020-01-31, MAE is:2.99 & sMAPE is:14.85% & rMAE is:2.60 ||| daily mean of MAE & sMAPE & rMAE till now are :2.33 & 9.62% & 1.21\n",
      "for 2020-02-01, MAE is:3.96 & sMAPE is:21.78% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :2.38 & 10.00% & 1.21\n",
      "for 2020-02-02, MAE is:4.01 & sMAPE is:21.19% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 10.34% & 1.21\n",
      "for 2020-02-03, MAE is:5.35 & sMAPE is:25.30% & rMAE is:2.60 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 10.78% & 1.25\n",
      "for 2020-02-04, MAE is:0.77 & sMAPE is:4.18% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.47 & 10.59% & 1.22\n",
      "for 2020-02-05, MAE is:2.43 & sMAPE is:13.31% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :2.47 & 10.67% & 1.21\n",
      "for 2020-02-06, MAE is:7.22 & sMAPE is:36.19% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.60 & 11.36% & 1.22\n",
      "for 2020-02-07, MAE is:3.15 & sMAPE is:17.79% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :2.61 & 11.53% & 1.22\n",
      "for 2020-02-08, MAE is:2.62 & sMAPE is:17.47% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :2.61 & 11.68% & 1.21\n",
      "for 2020-02-09, MAE is:7.55 & sMAPE is:50.01% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :2.74 & 12.64% & 1.22\n",
      "for 2020-02-10, MAE is:5.08 & sMAPE is:35.31% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :2.79 & 13.19% & 1.20\n",
      "for 2020-02-11, MAE is:4.84 & sMAPE is:32.04% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :2.84 & 13.64% & 1.19\n",
      "for 2020-02-12, MAE is:4.38 & sMAPE is:28.81% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :2.88 & 13.99% & 1.19\n",
      "for 2020-02-13, MAE is:3.26 & sMAPE is:21.48% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :2.89 & 14.16% & 1.19\n",
      "for 2020-02-14, MAE is:4.42 & sMAPE is:28.55% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :2.92 & 14.48% & 1.20\n",
      "for 2020-02-15, MAE is:8.96 & sMAPE is:55.71% & rMAE is:4.40 ||| daily mean of MAE & sMAPE & rMAE till now are :3.05 & 15.38% & 1.27\n",
      "for 2020-02-16, MAE is:8.66 & sMAPE is:65.03% & rMAE is:3.76 ||| daily mean of MAE & sMAPE & rMAE till now are :3.17 & 16.44% & 1.32\n",
      "for 2020-02-17, MAE is:8.31 & sMAPE is:56.43% & rMAE is:6.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.28 & 17.27% & 1.42\n",
      "for 2020-02-18, MAE is:5.37 & sMAPE is:40.14% & rMAE is:2.71 ||| daily mean of MAE & sMAPE & rMAE till now are :3.32 & 17.74% & 1.45\n",
      "for 2020-02-19, MAE is:4.95 & sMAPE is:36.53% & rMAE is:2.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 18.11% & 1.47\n",
      "for 2020-02-20, MAE is:5.83 & sMAPE is:45.67% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :3.40 & 18.65% & 1.47\n",
      "for 2020-02-21, MAE is:6.33 & sMAPE is:53.40% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.46 & 19.32% & 1.47\n",
      "for 2020-02-22, MAE is:8.81 & sMAPE is:71.71% & rMAE is:2.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.56 & 20.31% & 1.49\n",
      "for 2020-02-23, MAE is:6.11 & sMAPE is:55.72% & rMAE is:5.98 ||| daily mean of MAE & sMAPE & rMAE till now are :3.61 & 20.96% & 1.57\n",
      "for 2020-02-24, MAE is:5.37 & sMAPE is:44.71% & rMAE is:3.22 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 21.40% & 1.60\n",
      "for 2020-02-25, MAE is:4.83 & sMAPE is:39.96% & rMAE is:3.96 ||| daily mean of MAE & sMAPE & rMAE till now are :3.66 & 21.73% & 1.64\n",
      "for 2020-02-26, MAE is:3.35 & sMAPE is:28.01% & rMAE is:4.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 21.84% & 1.69\n",
      "for 2020-02-27, MAE is:3.28 & sMAPE is:26.50% & rMAE is:3.92 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 21.92% & 1.73\n",
      "for 2020-02-28, MAE is:4.09 & sMAPE is:31.82% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 22.09% & 1.73\n",
      "for 2020-02-29, MAE is:6.92 & sMAPE is:52.86% & rMAE is:3.89 ||| daily mean of MAE & sMAPE & rMAE till now are :3.71 & 22.60% & 1.77\n",
      "for 2020-03-01, MAE is:5.31 & sMAPE is:44.60% & rMAE is:4.30 ||| daily mean of MAE & sMAPE & rMAE till now are :3.74 & 22.96% & 1.81\n",
      "for 2020-03-02, MAE is:5.13 & sMAPE is:40.66% & rMAE is:7.54 ||| daily mean of MAE & sMAPE & rMAE till now are :3.76 & 23.25% & 1.90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-03-03, MAE is:3.42 & sMAPE is:29.57% & rMAE is:16.58 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 23.35% & 2.13\n",
      "for 2020-03-04, MAE is:6.46 & sMAPE is:48.71% & rMAE is:21.49 ||| daily mean of MAE & sMAPE & rMAE till now are :3.80 & 23.74% & 2.44\n",
      "for 2020-03-05, MAE is:5.64 & sMAPE is:43.09% & rMAE is:11.77 ||| daily mean of MAE & sMAPE & rMAE till now are :3.82 & 24.04% & 2.58\n",
      "for 2020-03-06, MAE is:5.69 & sMAPE is:40.96% & rMAE is:5.40 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 24.30% & 2.62\n",
      "for 2020-03-07, MAE is:5.84 & sMAPE is:43.82% & rMAE is:7.71 ||| daily mean of MAE & sMAPE & rMAE till now are :3.88 & 24.59% & 2.70\n",
      "for 2020-03-08, MAE is:5.13 & sMAPE is:42.78% & rMAE is:14.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 24.86% & 2.87\n",
      "for 2020-03-09, MAE is:5.36 & sMAPE is:42.34% & rMAE is:11.69 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 25.11% & 3.00\n",
      "for 2020-03-10, MAE is:5.68 & sMAPE is:45.50% & rMAE is:12.38 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 25.40% & 3.13\n",
      "for 2020-03-11, MAE is:2.59 & sMAPE is:25.18% & rMAE is:2.96 ||| daily mean of MAE & sMAPE & rMAE till now are :3.93 & 25.40% & 3.13\n",
      "for 2020-03-12, MAE is:4.61 & sMAPE is:42.49% & rMAE is:2.73 ||| daily mean of MAE & sMAPE & rMAE till now are :3.94 & 25.63% & 3.12\n",
      "for 2020-03-13, MAE is:7.51 & sMAPE is:62.45% & rMAE is:2.37 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 26.14% & 3.11\n",
      "for 2020-03-14, MAE is:5.49 & sMAPE is:49.16% & rMAE is:2.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 26.45% & 3.11\n",
      "for 2020-03-15, MAE is:5.10 & sMAPE is:53.88% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 26.82% & 3.09\n",
      "for 2020-03-16, MAE is:6.31 & sMAPE is:55.59% & rMAE is:3.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 27.19% & 3.10\n",
      "for 2020-03-17, MAE is:5.40 & sMAPE is:52.80% & rMAE is:2.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 27.53% & 3.09\n",
      "for 2020-03-18, MAE is:8.18 & sMAPE is:74.80% & rMAE is:3.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 28.13% & 3.10\n",
      "for 2020-03-19, MAE is:4.82 & sMAPE is:51.20% & rMAE is:3.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 28.42% & 3.10\n",
      "for 2020-03-20, MAE is:4.18 & sMAPE is:43.40% & rMAE is:5.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 28.61% & 3.13\n",
      "for 2020-03-21, MAE is:7.13 & sMAPE is:63.78% & rMAE is:8.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 29.05% & 3.20\n",
      "for 2020-03-22, MAE is:7.47 & sMAPE is:72.19% & rMAE is:13.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 29.57% & 3.33\n",
      "for 2020-03-23, MAE is:8.65 & sMAPE is:72.52% & rMAE is:12.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.26 & 30.09% & 3.44\n",
      "for 2020-03-24, MAE is:5.84 & sMAPE is:59.61% & rMAE is:9.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 30.44% & 3.51\n",
      "for 2020-03-25, MAE is:6.45 & sMAPE is:65.48% & rMAE is:23.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 30.85% & 3.75\n",
      "for 2020-03-26, MAE is:6.84 & sMAPE is:67.66% & rMAE is:20.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 31.28% & 3.95\n",
      "for 2020-03-27, MAE is:5.93 & sMAPE is:64.80% & rMAE is:4.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 31.67% & 3.95\n",
      "for 2020-03-28, MAE is:6.69 & sMAPE is:77.79% & rMAE is:2.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 32.19% & 3.94\n",
      "for 2020-03-29, MAE is:7.69 & sMAPE is:89.95% & rMAE is:4.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 32.84% & 3.94\n",
      "for 2020-03-30, MAE is:5.40 & sMAPE is:59.41% & rMAE is:4.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 33.13% & 3.95\n",
      "for 2020-03-31, MAE is:10.39 & sMAPE is:99.55% & rMAE is:6.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 33.86% & 3.97\n",
      "for 2020-04-01, MAE is:5.88 & sMAPE is:74.50% & rMAE is:3.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 34.31% & 3.97\n",
      "for 2020-04-02, MAE is:7.47 & sMAPE is:89.86% & rMAE is:3.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 34.90% & 3.96\n",
      "for 2020-04-03, MAE is:9.68 & sMAPE is:109.00% & rMAE is:4.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 35.69% & 3.97\n",
      "for 2020-04-04, MAE is:8.23 & sMAPE is:95.07% & rMAE is:10.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 36.32% & 4.03\n",
      "for 2020-04-05, MAE is:9.34 & sMAPE is:103.69% & rMAE is:11.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 37.02% & 4.11\n",
      "for 2020-04-06, MAE is:9.21 & sMAPE is:102.64% & rMAE is:4.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 37.70% & 4.12\n",
      "for 2020-04-07, MAE is:7.59 & sMAPE is:92.35% & rMAE is:9.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 38.25% & 4.17\n",
      "for 2020-04-08, MAE is:8.98 & sMAPE is:99.17% & rMAE is:21.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 38.87% & 4.35\n",
      "for 2020-04-09, MAE is:7.67 & sMAPE is:90.68% & rMAE is:59.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 39.39% & 4.90\n",
      "for 2020-04-10, MAE is:6.90 & sMAPE is:82.12% & rMAE is:7.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 39.81% & 4.93\n",
      "for 2020-04-11, MAE is:9.68 & sMAPE is:98.78% & rMAE is:22.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 40.39% & 5.10\n",
      "for 2020-04-12, MAE is:7.90 & sMAPE is:101.27% & rMAE is:15.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 40.98% & 5.19\n",
      "for 2020-04-13, MAE is:10.97 & sMAPE is:140.05% & rMAE is:5.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.98 & 41.93% & 5.20\n",
      "for 2020-04-14, MAE is:11.19 & sMAPE is:109.00% & rMAE is:44.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 42.57% & 5.57\n",
      "for 2020-04-15, MAE is:9.43 & sMAPE is:102.19% & rMAE is:41.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.09 & 43.13% & 5.91\n",
      "for 2020-04-16, MAE is:8.80 & sMAPE is:99.28% & rMAE is:21.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 43.66% & 6.06\n",
      "for 2020-04-17, MAE is:7.32 & sMAPE is:85.16% & rMAE is:79.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.14 & 44.04% & 6.73\n",
      "for 2020-04-18, MAE is:6.34 & sMAPE is:76.79% & rMAE is:47.11 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 44.34% & 7.10\n",
      "for 2020-04-19, MAE is:7.70 & sMAPE is:88.61% & rMAE is:8.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.17 & 44.74% & 7.11\n",
      "for 2020-04-20, MAE is:7.81 & sMAPE is:88.21% & rMAE is:3.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 45.14% & 7.08\n",
      "for 2020-04-21, MAE is:5.57 & sMAPE is:75.64% & rMAE is:13.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 45.41% & 7.13\n",
      "for 2020-04-22, MAE is:7.67 & sMAPE is:85.37% & rMAE is:11.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 45.76% & 7.17\n",
      "for 2020-04-23, MAE is:6.24 & sMAPE is:77.27% & rMAE is:13.04 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 46.04% & 7.22\n",
      "for 2020-04-24, MAE is:7.29 & sMAPE is:85.77% & rMAE is:82.96 ||| daily mean of MAE & sMAPE & rMAE till now are :5.25 & 46.38% & 7.88\n",
      "for 2020-04-25, MAE is:7.20 & sMAPE is:85.12% & rMAE is:34.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.27 & 46.72% & 8.11\n",
      "for 2020-04-26, MAE is:7.80 & sMAPE is:89.01% & rMAE is:52.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.29 & 47.08% & 8.49\n",
      "for 2020-04-27, MAE is:7.73 & sMAPE is:84.17% & rMAE is:13.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.31 & 47.39% & 8.54\n",
      "for 2020-04-28, MAE is:5.11 & sMAPE is:63.85% & rMAE is:5.95 ||| daily mean of MAE & sMAPE & rMAE till now are :5.31 & 47.53% & 8.51\n",
      "for 2020-04-29, MAE is:5.88 & sMAPE is:70.80% & rMAE is:10.05 ||| daily mean of MAE & sMAPE & rMAE till now are :5.31 & 47.73% & 8.53\n",
      "for 2020-04-30, MAE is:7.72 & sMAPE is:85.41% & rMAE is:30.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.33 & 48.04% & 8.71\n",
      "for 2020-05-01, MAE is:6.55 & sMAPE is:78.08% & rMAE is:19.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.34 & 48.28% & 8.80\n",
      "for 2020-05-02, MAE is:8.45 & sMAPE is:84.72% & rMAE is:9.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 48.58% & 8.81\n",
      "for 2020-05-03, MAE is:7.21 & sMAPE is:76.10% & rMAE is:7.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 48.80% & 8.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-05-04, MAE is:7.15 & sMAPE is:69.98% & rMAE is:5.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 48.97% & 8.77\n",
      "for 2020-05-05, MAE is:7.09 & sMAPE is:67.14% & rMAE is:4.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 49.12% & 8.73\n",
      "for 2020-05-06, MAE is:4.29 & sMAPE is:47.15% & rMAE is:2.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 49.10% & 8.68\n",
      "for 2020-05-07, MAE is:3.68 & sMAPE is:38.41% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 49.02% & 8.63\n",
      "for 2020-05-08, MAE is:4.72 & sMAPE is:46.11% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 48.99% & 8.57\n",
      "for 2020-05-09, MAE is:6.35 & sMAPE is:56.26% & rMAE is:2.66 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 49.05% & 8.53\n",
      "for 2020-05-10, MAE is:6.97 & sMAPE is:63.61% & rMAE is:4.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 49.16% & 8.50\n",
      "for 2020-05-11, MAE is:6.40 & sMAPE is:57.50% & rMAE is:4.01 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 49.22% & 8.46\n",
      "for 2020-05-12, MAE is:2.22 & sMAPE is:20.04% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 49.00% & 8.40\n",
      "for 2020-05-13, MAE is:1.32 & sMAPE is:8.92% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 48.71% & 8.34\n",
      "for 2020-05-14, MAE is:1.20 & sMAPE is:8.25% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.32 & 48.41% & 8.28\n",
      "for 2020-05-15, MAE is:2.26 & sMAPE is:16.72% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.30 & 48.17% & 8.22\n",
      "for 2020-05-16, MAE is:5.48 & sMAPE is:45.22% & rMAE is:4.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.30 & 48.15% & 8.19\n",
      "for 2020-05-17, MAE is:3.12 & sMAPE is:31.31% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.29 & 48.03% & 8.15\n",
      "for 2020-05-18, MAE is:0.53 & sMAPE is:3.99% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :5.25 & 47.71% & 8.09\n",
      "for 2020-05-19, MAE is:2.42 & sMAPE is:17.60% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 47.50% & 8.04\n",
      "for 2020-05-20, MAE is:3.92 & sMAPE is:32.23% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 47.39% & 7.99\n",
      "for 2020-05-21, MAE is:5.57 & sMAPE is:48.84% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 47.40% & 7.94\n",
      "for 2020-05-22, MAE is:5.00 & sMAPE is:50.97% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 47.42% & 7.89\n",
      "for 2020-05-23, MAE is:10.01 & sMAPE is:112.43% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :5.26 & 47.88% & 7.85\n",
      "for 2020-05-24, MAE is:10.84 & sMAPE is:144.67% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.30 & 48.54% & 7.80\n",
      "for 2020-05-25, MAE is:7.14 & sMAPE is:84.29% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :5.31 & 48.79% & 7.76\n",
      "for 2020-05-26, MAE is:10.71 & sMAPE is:155.18% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.35 & 49.51% & 7.71\n",
      "for 2020-05-27, MAE is:7.03 & sMAPE is:132.75% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 50.07% & 7.66\n",
      "for 2020-05-28, MAE is:9.82 & sMAPE is:140.65% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 50.68% & 7.62\n",
      "for 2020-05-29, MAE is:6.82 & sMAPE is:116.91% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 51.12% & 7.58\n",
      "for 2020-05-30, MAE is:8.68 & sMAPE is:131.69% & rMAE is:4.85 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 51.66% & 7.56\n",
      "for 2020-05-31, MAE is:11.98 & sMAPE is:156.17% & rMAE is:10.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.46 & 52.34% & 7.58\n",
      "for 2020-06-01, MAE is:7.27 & sMAPE is:131.39% & rMAE is:2.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.47 & 52.86% & 7.55\n",
      "for 2020-06-02, MAE is:10.85 & sMAPE is:155.89% & rMAE is:310.08 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 53.53% & 9.52\n",
      "for 2020-06-03, MAE is:9.65 & sMAPE is:154.29% & rMAE is:27.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 54.18% & 9.63\n",
      "for 2020-06-04, MAE is:7.61 & sMAPE is:140.49% & rMAE is:16.02 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 54.73% & 9.67\n",
      "for 2020-06-05, MAE is:10.00 & sMAPE is:152.78% & rMAE is:11.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 55.36% & 9.68\n",
      "for 2020-06-06, MAE is:7.75 & sMAPE is:147.58% & rMAE is:8.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 55.94% & 9.67\n",
      "for 2020-06-07, MAE is:7.88 & sMAPE is:139.71% & rMAE is:13.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.60 & 56.47% & 9.70\n",
      "for 2020-06-08, MAE is:9.59 & sMAPE is:145.92% & rMAE is:30.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 57.03% & 9.83\n",
      "for 2020-06-09, MAE is:8.66 & sMAPE is:143.29% & rMAE is:38.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.65 & 57.56% & 10.01\n",
      "for 2020-06-10, MAE is:9.81 & sMAPE is:145.58% & rMAE is:24.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.67 & 58.11% & 10.09\n",
      "for 2020-06-11, MAE is:9.26 & sMAPE is:144.53% & rMAE is:52.04 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 58.64% & 10.35\n",
      "for 2020-06-12, MAE is:9.62 & sMAPE is:156.03% & rMAE is:49.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 59.23% & 10.59\n",
      "for 2020-06-13, MAE is:11.04 & sMAPE is:161.82% & rMAE is:38.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.75 & 59.85% & 10.76\n",
      "for 2020-06-14, MAE is:9.82 & sMAPE is:160.35% & rMAE is:20.71 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 60.46% & 10.82\n",
      "for 2020-06-15, MAE is:8.20 & sMAPE is:147.02% & rMAE is:26.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 60.98% & 10.92\n",
      "for 2020-06-16, MAE is:7.80 & sMAPE is:145.04% & rMAE is:32.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 61.48% & 11.04\n",
      "for 2020-06-17, MAE is:9.76 & sMAPE is:149.03% & rMAE is:54.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 61.99% & 11.30\n",
      "for 2020-06-18, MAE is:10.24 & sMAPE is:154.28% & rMAE is:37.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 62.54% & 11.46\n",
      "for 2020-06-19, MAE is:9.90 & sMAPE is:154.51% & rMAE is:61.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 63.08% & 11.75\n",
      "for 2020-06-20, MAE is:11.05 & sMAPE is:159.73% & rMAE is:111.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 63.64% & 12.33\n",
      "for 2020-06-21, MAE is:11.94 & sMAPE is:163.88% & rMAE is:85.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 64.22% & 12.75\n",
      "for 2020-06-22, MAE is:8.52 & sMAPE is:150.28% & rMAE is:122.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 64.71% & 13.38\n",
      "for 2020-06-23, MAE is:9.26 & sMAPE is:152.57% & rMAE is:226.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 65.21% & 14.60\n",
      "for 2020-06-24, MAE is:10.49 & sMAPE is:155.93% & rMAE is:53.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 65.73% & 14.82\n",
      "for 2020-06-25, MAE is:12.01 & sMAPE is:161.42% & rMAE is:150.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 66.27% & 15.59\n",
      "for 2020-06-26, MAE is:12.25 & sMAPE is:161.61% & rMAE is:326.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 66.81% & 17.34\n",
      "for 2020-06-27, MAE is:11.89 & sMAPE is:172.85% & rMAE is:26.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 67.40% & 17.39\n",
      "for 2020-06-28, MAE is:11.41 & sMAPE is:173.06% & rMAE is:27.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 67.98% & 17.44\n",
      "for 2020-06-29, MAE is:13.54 & sMAPE is:172.48% & rMAE is:41.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 68.56% & 17.57\n",
      "for 2020-06-30, MAE is:11.01 & sMAPE is:166.07% & rMAE is:35.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 69.10% & 17.67\n",
      "for 2020-07-01, MAE is:9.47 & sMAPE is:161.79% & rMAE is:27.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 69.60% & 17.73\n",
      "for 2020-07-02, MAE is:10.69 & sMAPE is:158.94% & rMAE is:118.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 70.09% & 18.27\n",
      "for 2020-07-03, MAE is:9.68 & sMAPE is:159.09% & rMAE is:46.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 70.57% & 18.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-07-04, MAE is:12.46 & sMAPE is:165.49% & rMAE is:35.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 71.08% & 18.51\n",
      "for 2020-07-05, MAE is:11.52 & sMAPE is:170.95% & rMAE is:54.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 71.62% & 18.70\n",
      "for 2020-07-06, MAE is:10.93 & sMAPE is:172.70% & rMAE is:33.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 72.15% & 18.78\n",
      "for 2020-07-07, MAE is:11.96 & sMAPE is:171.10% & rMAE is:42.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 72.68% & 18.91\n",
      "for 2020-07-08, MAE is:8.11 & sMAPE is:150.28% & rMAE is:36.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 73.08% & 19.00\n",
      "for 2020-07-09, MAE is:10.52 & sMAPE is:153.80% & rMAE is:53.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 73.51% & 19.18\n",
      "for 2020-07-10, MAE is:12.22 & sMAPE is:159.05% & rMAE is:36.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 73.95% & 19.27\n",
      "for 2020-07-11, MAE is:11.38 & sMAPE is:156.95% & rMAE is:44.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 74.38% & 19.40\n",
      "for 2020-07-12, MAE is:10.65 & sMAPE is:154.29% & rMAE is:18.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 74.79% & 19.40\n",
      "for 2020-07-13, MAE is:11.13 & sMAPE is:155.70% & rMAE is:16.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 75.21% & 19.38\n",
      "for 2020-07-14, MAE is:10.78 & sMAPE is:155.01% & rMAE is:21.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 75.62% & 19.39\n",
      "for 2020-07-15, MAE is:9.82 & sMAPE is:151.59% & rMAE is:43.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 76.00% & 19.52\n",
      "for 2020-07-16, MAE is:10.10 & sMAPE is:152.86% & rMAE is:378.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 76.39% & 21.33\n",
      "for 2020-07-17, MAE is:10.51 & sMAPE is:154.70% & rMAE is:274.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 76.78% & 22.60\n",
      "for 2020-07-18, MAE is:10.68 & sMAPE is:156.85% & rMAE is:120.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 77.18% & 23.09\n",
      "for 2020-07-19, MAE is:10.12 & sMAPE is:153.76% & rMAE is:211.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 77.57% & 24.03\n",
      "for 2020-07-20, MAE is:10.16 & sMAPE is:154.11% & rMAE is:141.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 77.94% & 24.61\n",
      "for 2020-07-21, MAE is:9.65 & sMAPE is:152.14% & rMAE is:206.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 78.31% & 25.51\n",
      "for 2020-07-22, MAE is:8.70 & sMAPE is:147.98% & rMAE is:231.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 78.65% & 26.52\n",
      "for 2020-07-23, MAE is:11.62 & sMAPE is:157.20% & rMAE is:376.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 79.03% & 28.23\n",
      "for 2020-07-24, MAE is:12.09 & sMAPE is:159.39% & rMAE is:744.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 79.42% & 31.70\n",
      "for 2020-07-25, MAE is:10.66 & sMAPE is:155.06% & rMAE is:158.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 79.79% & 32.32\n",
      "for 2020-07-26, MAE is:10.56 & sMAPE is:156.68% & rMAE is:161.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 80.16% & 32.94\n",
      "for 2020-07-27, MAE is:8.02 & sMAPE is:145.12% & rMAE is:916.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 80.47% & 37.17\n",
      "for 2020-07-28, MAE is:8.96 & sMAPE is:151.82% & rMAE is:96.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 80.81% & 37.45\n",
      "for 2020-07-29, MAE is:9.84 & sMAPE is:161.24% & rMAE is:28.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 81.19% & 37.41\n",
      "for 2020-07-30, MAE is:11.04 & sMAPE is:163.26% & rMAE is:34.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 81.58% & 37.39\n",
      "for 2020-07-31, MAE is:11.87 & sMAPE is:163.52% & rMAE is:56.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 81.96% & 37.49\n",
      "for 2020-08-01, MAE is:10.26 & sMAPE is:166.72% & rMAE is:20.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 82.36% & 37.40\n",
      "for 2020-08-02, MAE is:11.94 & sMAPE is:170.35% & rMAE is:28.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 82.77% & 37.36\n",
      "for 2020-08-03, MAE is:6.93 & sMAPE is:145.14% & rMAE is:34.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 83.06% & 37.35\n",
      "for 2020-08-04, MAE is:11.04 & sMAPE is:162.41% & rMAE is:76.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 83.42% & 37.53\n",
      "for 2020-08-05, MAE is:10.08 & sMAPE is:163.67% & rMAE is:51.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 83.79% & 37.60\n",
      "for 2020-08-06, MAE is:10.66 & sMAPE is:162.03% & rMAE is:88.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 84.15% & 37.83\n",
      "for 2020-08-07, MAE is:9.25 & sMAPE is:156.69% & rMAE is:126.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 84.48% & 38.23\n",
      "for 2020-08-08, MAE is:9.78 & sMAPE is:159.52% & rMAE is:39.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 84.82% & 38.23\n",
      "for 2020-08-09, MAE is:9.42 & sMAPE is:151.65% & rMAE is:20.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 85.12% & 38.16\n",
      "for 2020-08-10, MAE is:9.67 & sMAPE is:146.68% & rMAE is:21.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 85.40% & 38.08\n",
      "for 2020-08-11, MAE is:11.53 & sMAPE is:147.86% & rMAE is:15.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 85.67% & 37.98\n",
      "for 2020-08-12, MAE is:8.41 & sMAPE is:136.64% & rMAE is:10.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 85.90% & 37.85\n",
      "for 2020-08-13, MAE is:11.38 & sMAPE is:143.00% & rMAE is:11.04 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 86.15% & 37.73\n",
      "for 2020-08-14, MAE is:9.00 & sMAPE is:124.70% & rMAE is:6.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 86.32% & 37.60\n",
      "for 2020-08-15, MAE is:6.59 & sMAPE is:105.71% & rMAE is:3.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 86.41% & 37.45\n",
      "for 2020-08-16, MAE is:8.39 & sMAPE is:108.76% & rMAE is:4.15 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 86.51% & 37.30\n",
      "for 2020-08-17, MAE is:7.14 & sMAPE is:92.12% & rMAE is:2.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 86.53% & 37.15\n",
      "for 2020-08-18, MAE is:6.72 & sMAPE is:85.20% & rMAE is:2.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 86.52% & 37.00\n",
      "for 2020-08-19, MAE is:6.78 & sMAPE is:89.42% & rMAE is:2.98 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 86.54% & 36.86\n",
      "for 2020-08-20, MAE is:8.10 & sMAPE is:105.63% & rMAE is:6.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 86.62% & 36.72\n",
      "for 2020-08-21, MAE is:7.70 & sMAPE is:100.25% & rMAE is:6.99 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 86.68% & 36.60\n",
      "for 2020-08-22, MAE is:7.87 & sMAPE is:108.35% & rMAE is:19.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 86.77% & 36.52\n",
      "for 2020-08-23, MAE is:11.10 & sMAPE is:126.69% & rMAE is:29.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 86.94% & 36.49\n",
      "for 2020-08-24, MAE is:9.07 & sMAPE is:111.11% & rMAE is:14.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 87.04% & 36.40\n",
      "for 2020-08-25, MAE is:6.53 & sMAPE is:85.28% & rMAE is:8.73 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 87.03% & 36.29\n",
      "for 2020-08-26, MAE is:5.75 & sMAPE is:73.16% & rMAE is:4.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 86.97% & 36.15\n",
      "for 2020-08-27, MAE is:5.69 & sMAPE is:62.37% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 86.87% & 36.01\n",
      "for 2020-08-28, MAE is:4.36 & sMAPE is:41.69% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 86.68% & 35.87\n",
      "for 2020-08-29, MAE is:0.51 & sMAPE is:5.04% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 86.35% & 35.72\n",
      "for 2020-08-30, MAE is:0.33 & sMAPE is:2.65% & rMAE is:0.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 86.00% & 35.57\n",
      "for 2020-08-31, MAE is:2.52 & sMAPE is:18.32% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 85.73% & 35.43\n",
      "for 2020-09-01, MAE is:4.07 & sMAPE is:25.88% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 85.48% & 35.28\n",
      "for 2020-09-02, MAE is:1.33 & sMAPE is:7.66% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 85.17% & 35.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-09-03, MAE is:1.06 & sMAPE is:6.57% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 84.85% & 35.00\n",
      "for 2020-09-04, MAE is:0.75 & sMAPE is:4.51% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 84.52% & 34.86\n",
      "for 2020-09-05, MAE is:0.74 & sMAPE is:5.46% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 84.21% & 34.72\n",
      "for 2020-09-06, MAE is:0.50 & sMAPE is:3.87% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 83.88% & 34.58\n",
      "for 2020-09-07, MAE is:0.63 & sMAPE is:5.03% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 83.57% & 34.45\n",
      "for 2020-09-08, MAE is:0.41 & sMAPE is:3.64% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 83.25% & 34.31\n",
      "for 2020-09-09, MAE is:0.63 & sMAPE is:5.20% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 82.94% & 34.18\n",
      "for 2020-09-10, MAE is:0.61 & sMAPE is:5.43% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 82.64% & 34.04\n",
      "for 2020-09-11, MAE is:2.55 & sMAPE is:24.09% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 82.41% & 33.91\n",
      "for 2020-09-12, MAE is:1.08 & sMAPE is:9.72% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 82.13% & 33.78\n",
      "for 2020-09-13, MAE is:1.78 & sMAPE is:19.10% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 81.88% & 33.65\n",
      "for 2020-09-14, MAE is:2.10 & sMAPE is:18.62% & rMAE is:3.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 81.63% & 33.54\n",
      "for 2020-09-15, MAE is:0.75 & sMAPE is:6.52% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 81.34% & 33.41\n",
      "for 2020-09-16, MAE is:0.33 & sMAPE is:3.05% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 81.04% & 33.28\n",
      "for 2020-09-17, MAE is:0.53 & sMAPE is:5.20% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 80.75% & 33.16\n",
      "for 2020-09-18, MAE is:1.92 & sMAPE is:20.18% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 80.52% & 33.03\n",
      "for 2020-09-19, MAE is:3.76 & sMAPE is:43.46% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 80.38% & 32.91\n",
      "for 2020-09-20, MAE is:2.67 & sMAPE is:35.56% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 80.21% & 32.79\n",
      "for 2020-09-21, MAE is:1.69 & sMAPE is:21.77% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 79.99% & 32.67\n",
      "for 2020-09-22, MAE is:2.39 & sMAPE is:31.32% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 79.81% & 32.55\n",
      "for 2020-09-23, MAE is:1.83 & sMAPE is:24.36% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 79.60% & 32.43\n",
      "for 2020-09-24, MAE is:2.27 & sMAPE is:32.44% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 79.42% & 32.31\n",
      "for 2020-09-25, MAE is:4.07 & sMAPE is:59.03% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 79.35% & 32.19\n",
      "for 2020-09-26, MAE is:3.99 & sMAPE is:80.70% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 79.35% & 32.07\n",
      "for 2020-09-27, MAE is:6.00 & sMAPE is:118.90% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 79.50% & 31.96\n",
      "for 2020-09-28, MAE is:4.73 & sMAPE is:110.03% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 79.61% & 31.85\n",
      "for 2020-09-29, MAE is:3.42 & sMAPE is:93.36% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 79.66% & 31.73\n",
      "for 2020-09-30, MAE is:4.50 & sMAPE is:108.09% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 79.77% & 31.62\n",
      "for 2020-10-01, MAE is:3.29 & sMAPE is:81.58% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 79.77% & 31.51\n",
      "for 2020-10-02, MAE is:1.28 & sMAPE is:32.25% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 79.60% & 31.40\n",
      "for 2020-10-03, MAE is:3.28 & sMAPE is:71.28% & rMAE is:5.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 79.57% & 31.31\n",
      "for 2020-10-04, MAE is:1.67 & sMAPE is:40.30% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 79.43% & 31.20\n",
      "for 2020-10-05, MAE is:1.26 & sMAPE is:20.04% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 79.22% & 31.09\n",
      "for 2020-10-06, MAE is:0.79 & sMAPE is:12.24% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 78.98% & 30.98\n",
      "for 2020-10-07, MAE is:0.30 & sMAPE is:4.40% & rMAE is:0.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 78.71% & 30.87\n",
      "for 2020-10-08, MAE is:1.46 & sMAPE is:20.19% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 78.50% & 30.76\n",
      "for 2020-10-09, MAE is:3.52 & sMAPE is:34.72% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 78.35% & 30.65\n",
      "for 2020-10-10, MAE is:3.65 & sMAPE is:34.56% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 78.19% & 30.54\n",
      "for 2020-10-11, MAE is:6.74 & sMAPE is:51.22% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 78.10% & 30.44\n",
      "for 2020-10-12, MAE is:6.00 & sMAPE is:40.48% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 77.97% & 30.33\n",
      "for 2020-10-13, MAE is:4.88 & sMAPE is:30.16% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 77.80% & 30.23\n",
      "for 2020-10-14, MAE is:2.42 & sMAPE is:13.14% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 77.58% & 30.12\n",
      "for 2020-10-15, MAE is:7.36 & sMAPE is:46.38% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 77.47% & 30.02\n",
      "for 2020-10-16, MAE is:9.27 & sMAPE is:38.57% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 77.34% & 29.92\n",
      "for 2020-10-17, MAE is:3.65 & sMAPE is:20.71% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 77.14% & 29.82\n",
      "for 2020-10-18, MAE is:2.35 & sMAPE is:13.29% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 76.92% & 29.72\n",
      "for 2020-10-19, MAE is:7.32 & sMAPE is:22.88% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 76.74% & 29.62\n",
      "for 2020-10-20, MAE is:2.77 & sMAPE is:15.32% & rMAE is:3.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 76.53% & 29.53\n",
      "for 2020-10-21, MAE is:2.68 & sMAPE is:16.18% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 76.32% & 29.44\n",
      "for 2020-10-22, MAE is:4.64 & sMAPE is:29.26% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 76.17% & 29.34\n",
      "for 2020-10-23, MAE is:8.14 & sMAPE is:38.05% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 76.04% & 29.25\n",
      "for 2020-10-24, MAE is:3.14 & sMAPE is:23.99% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 75.86% & 29.15\n",
      "for 2020-10-25, MAE is:2.51 & sMAPE is:24.51% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 75.69% & 29.05\n",
      "for 2020-10-26, MAE is:1.72 & sMAPE is:12.69% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 75.48% & 28.96\n",
      "for 2020-10-27, MAE is:2.75 & sMAPE is:22.00% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 75.30% & 28.86\n",
      "for 2020-10-28, MAE is:2.56 & sMAPE is:31.13% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 75.16% & 28.77\n",
      "for 2020-10-29, MAE is:2.59 & sMAPE is:25.80% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 74.99% & 28.68\n",
      "for 2020-10-30, MAE is:2.39 & sMAPE is:24.98% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 74.83% & 28.58\n",
      "for 2020-10-31, MAE is:2.78 & sMAPE is:35.27% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 74.70% & 28.49\n",
      "for 2020-11-01, MAE is:1.56 & sMAPE is:29.95% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 74.55% & 28.40\n",
      "for 2020-11-02, MAE is:2.72 & sMAPE is:72.67% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 74.55% & 28.31\n",
      "for 2020-11-03, MAE is:2.66 & sMAPE is:60.74% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 74.50% & 28.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-11-04, MAE is:1.74 & sMAPE is:41.93% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 74.40% & 28.13\n",
      "for 2020-11-05, MAE is:2.67 & sMAPE is:74.43% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 74.40% & 28.04\n",
      "for 2020-11-06, MAE is:2.66 & sMAPE is:60.15% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 74.35% & 27.95\n",
      "for 2020-11-07, MAE is:0.83 & sMAPE is:22.89% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 74.19% & 27.86\n",
      "for 2020-11-08, MAE is:1.38 & sMAPE is:27.99% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 74.04% & 27.77\n",
      "for 2020-11-09, MAE is:2.61 & sMAPE is:46.82% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 73.95% & 27.69\n",
      "for 2020-11-10, MAE is:3.73 & sMAPE is:56.23% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 73.90% & 27.60\n",
      "for 2020-11-11, MAE is:1.33 & sMAPE is:18.70% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 73.72% & 27.52\n",
      "for 2020-11-12, MAE is:0.72 & sMAPE is:10.81% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 73.52% & 27.43\n",
      "for 2020-11-13, MAE is:2.75 & sMAPE is:52.65% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 73.46% & 27.35\n",
      "for 2020-11-14, MAE is:1.85 & sMAPE is:50.04% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 73.38% & 27.27\n",
      "for 2020-11-15, MAE is:2.64 & sMAPE is:88.05% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 73.43% & 27.19\n",
      "for 2020-11-16, MAE is:3.10 & sMAPE is:107.15% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 73.53% & 27.10\n",
      "for 2020-11-17, MAE is:2.93 & sMAPE is:104.22% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 73.63% & 27.02\n",
      "for 2020-11-18, MAE is:2.17 & sMAPE is:106.27% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 73.73% & 26.94\n",
      "for 2020-11-19, MAE is:1.92 & sMAPE is:104.52% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 73.83% & 26.86\n",
      "for 2020-11-20, MAE is:2.44 & sMAPE is:88.15% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 73.87% & 26.78\n",
      "for 2020-11-21, MAE is:2.44 & sMAPE is:108.94% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 73.98% & 26.70\n",
      "for 2020-11-22, MAE is:2.99 & sMAPE is:113.72% & rMAE is:5.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 74.10% & 26.63\n",
      "for 2020-11-23, MAE is:2.25 & sMAPE is:78.17% & rMAE is:3.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 74.11% & 26.56\n",
      "for 2020-11-24, MAE is:0.81 & sMAPE is:32.41% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 73.98% & 26.48\n",
      "for 2020-11-25, MAE is:1.21 & sMAPE is:45.00% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 73.90% & 26.41\n",
      "for 2020-11-26, MAE is:0.81 & sMAPE is:21.21% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 73.74% & 26.33\n",
      "for 2020-11-27, MAE is:2.11 & sMAPE is:28.81% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 73.60% & 26.25\n",
      "for 2020-11-28, MAE is:6.60 & sMAPE is:86.56% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 73.64% & 26.17\n",
      "for 2020-11-29, MAE is:4.86 & sMAPE is:45.08% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 73.56% & 26.10\n",
      "for 2020-11-30, MAE is:3.62 & sMAPE is:30.68% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 73.43% & 26.02\n",
      "for 2020-12-01, MAE is:4.84 & sMAPE is:38.40% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 73.32% & 25.94\n",
      "for 2020-12-02, MAE is:3.60 & sMAPE is:24.94% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 73.18% & 25.87\n",
      "for 2020-12-03, MAE is:5.99 & sMAPE is:39.15% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 73.08% & 25.79\n",
      "for 2020-12-04, MAE is:3.63 & sMAPE is:21.82% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 72.93% & 25.72\n",
      "for 2020-12-05, MAE is:5.22 & sMAPE is:30.53% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 72.80% & 25.64\n",
      "for 2020-12-06, MAE is:2.77 & sMAPE is:15.67% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.77 & 72.64% & 25.57\n",
      "for 2020-12-07, MAE is:1.97 & sMAPE is:12.39% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 72.46% & 25.49\n",
      "for 2020-12-08, MAE is:4.13 & sMAPE is:21.59% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 72.31% & 25.42\n",
      "for 2020-12-09, MAE is:12.81 & sMAPE is:32.47% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 72.20% & 25.35\n",
      "for 2020-12-10, MAE is:18.55 & sMAPE is:39.49% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 72.10% & 25.28\n",
      "for 2020-12-11, MAE is:2.74 & sMAPE is:13.03% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 71.93% & 25.21\n",
      "for 2020-12-12, MAE is:6.64 & sMAPE is:35.02% & rMAE is:2.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 71.82% & 25.14\n",
      "for 2020-12-13, MAE is:0.98 & sMAPE is:4.42% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 71.63% & 25.07\n",
      "for 2020-12-14, MAE is:0.68 & sMAPE is:3.09% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 71.43% & 25.00\n",
      "for 2020-12-15, MAE is:2.53 & sMAPE is:11.63% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.77 & 71.26% & 24.93\n",
      "for 2020-12-16, MAE is:1.79 & sMAPE is:7.58% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 71.08% & 24.86\n",
      "for 2020-12-17, MAE is:1.53 & sMAPE is:7.18% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :5.75 & 70.90% & 24.79\n",
      "for 2020-12-18, MAE is:1.69 & sMAPE is:8.37% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 70.72% & 24.72\n",
      "for 2020-12-19, MAE is:1.44 & sMAPE is:8.18% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 70.55% & 24.65\n",
      "for 2020-12-20, MAE is:2.15 & sMAPE is:14.24% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.71 & 70.39% & 24.59\n",
      "for 2020-12-21, MAE is:4.11 & sMAPE is:24.29% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :5.71 & 70.26% & 24.52\n",
      "for 2020-12-22, MAE is:4.25 & sMAPE is:31.19% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.71 & 70.15% & 24.45\n",
      "for 2020-12-23, MAE is:3.37 & sMAPE is:18.91% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 70.01% & 24.39\n",
      "for 2020-12-24, MAE is:2.61 & sMAPE is:17.12% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 69.86% & 24.32\n",
      "for 2020-12-25, MAE is:5.85 & sMAPE is:34.34% & rMAE is:2.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 69.76% & 24.26\n",
      "for 2020-12-26, MAE is:3.06 & sMAPE is:18.12% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 69.62% & 24.19\n",
      "for 2020-12-27, MAE is:5.20 & sMAPE is:54.91% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 69.58% & 24.13\n",
      "for 2020-12-28, MAE is:9.81 & sMAPE is:67.88% & rMAE is:5.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 69.57% & 24.08\n",
      "for 2020-12-29, MAE is:3.67 & sMAPE is:18.17% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 69.43% & 24.01\n",
      "for 2020-12-30, MAE is:5.14 & sMAPE is:24.34% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 69.31% & 23.95\n",
      "for 2020-12-31, MAE is:4.06 & sMAPE is:17.25% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 69.16% & 23.88\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3 (PC Version - Run on Laptop)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:15:25,382]\u001b[0m A new study created in RDB with name: NO_2_2021\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:15:49,105]\u001b[0m Trial 1 finished with value: 22.2322648122428 and parameters: {'n_hidden': 3, 'learning_rate': 0.007143244063960041, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16407427303917516, 'dropout_rate_Layer_2': 0.24247613691748615, 'dropout_rate_Layer_3': 0.03660672291753664, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.035153392740081356, 'l1_Layer_2': 0.01060920118415531, 'l1_Layer_3': 7.706574597302349e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 50, 'n_units_Layer_3': 145}. Best is trial 1 with value: 22.2322648122428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.23 | sMAPE for Validation Set is: 121.10% | rMAE for Validation Set is: 6.97\n",
      "MAE for Test Set is: 32.75 | sMAPE for Test Set is: 42.48% | rMAE for Test Set is: 1.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:15:55,078]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:16:09,303]\u001b[0m Trial 3 finished with value: 6.3626031765322395 and parameters: {'n_hidden': 4, 'learning_rate': 0.021385665526786543, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29826986480182144, 'dropout_rate_Layer_2': 0.28990132626268733, 'dropout_rate_Layer_3': 0.19325882652175363, 'dropout_rate_Layer_4': 0.18710305580832065, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0023220148648100693, 'l1_Layer_2': 0.015507652746016698, 'l1_Layer_3': 0.005617222201228093, 'l1_Layer_4': 0.0017227349630492474, 'n_units_Layer_1': 265, 'n_units_Layer_2': 140, 'n_units_Layer_3': 75, 'n_units_Layer_4': 95}. Best is trial 3 with value: 6.3626031765322395.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 76.34% | rMAE for Validation Set is: 1.99\n",
      "MAE for Test Set is: 66.15 | sMAPE for Test Set is: 144.91% | rMAE for Test Set is: 3.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:16:16,401]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:16:22,341]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.86 | sMAPE for Validation Set is: 89.32% | rMAE for Validation Set is: 3.09\n",
      "MAE for Test Set is: 56.55 | sMAPE for Test Set is: 101.63% | rMAE for Test Set is: 3.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:16:32,578]\u001b[0m Trial 0 finished with value: 9.855941530411842 and parameters: {'n_hidden': 4, 'learning_rate': 0.09355022305547263, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10872019107602392, 'dropout_rate_Layer_2': 0.008772763065625045, 'dropout_rate_Layer_3': 0.1385550380210432, 'dropout_rate_Layer_4': 0.18015439032584932, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0005519605447495112, 'l1_Layer_2': 0.03443996780565145, 'l1_Layer_3': 0.00940676198509759, 'l1_Layer_4': 7.626579903406148e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 80, 'n_units_Layer_3': 60, 'n_units_Layer_4': 185}. Best is trial 3 with value: 6.3626031765322395.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:16:39,915]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:16:42,377]\u001b[0m Trial 6 finished with value: 12.31851025783252 and parameters: {'n_hidden': 3, 'learning_rate': 0.018837442340091357, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36565023986698947, 'dropout_rate_Layer_2': 0.38370837676735475, 'dropout_rate_Layer_3': 0.32948816150148263, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0032973506234107272, 'l1_Layer_2': 0.0018364243694337585, 'l1_Layer_3': 0.0033757262343182305, 'n_units_Layer_1': 190, 'n_units_Layer_2': 50, 'n_units_Layer_3': 300}. Best is trial 3 with value: 6.3626031765322395.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.32 | sMAPE for Validation Set is: 98.63% | rMAE for Validation Set is: 3.86\n",
      "MAE for Test Set is: 55.75 | sMAPE for Test Set is: 102.56% | rMAE for Test Set is: 3.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:16:47,386]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:16:59,004]\u001b[0m Trial 8 finished with value: 5.7445919464954 and parameters: {'n_hidden': 3, 'learning_rate': 0.006127976427777622, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04522376207962826, 'dropout_rate_Layer_2': 0.20957926685345935, 'dropout_rate_Layer_3': 0.23368596785695375, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008653031584653149, 'l1_Layer_2': 5.759418945445633e-05, 'l1_Layer_3': 0.003066324116282794, 'n_units_Layer_1': 130, 'n_units_Layer_2': 270, 'n_units_Layer_3': 290}. Best is trial 8 with value: 5.7445919464954.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 75.84% | rMAE for Validation Set is: 1.80\n",
      "MAE for Test Set is: 64.17 | sMAPE for Test Set is: 138.09% | rMAE for Test Set is: 3.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:17:02,169]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:17:14,286]\u001b[0m Trial 10 finished with value: 13.99727407350071 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014576220090790166, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2965712615581592, 'dropout_rate_Layer_2': 0.29168073735437916, 'dropout_rate_Layer_3': 0.3648344037886361, 'dropout_rate_Layer_4': 0.04588953429808758, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.018345868917339518, 'l1_Layer_2': 0.015196429759720895, 'l1_Layer_3': 0.0035134449602335182, 'l1_Layer_4': 4.668026385659743e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 75, 'n_units_Layer_3': 190, 'n_units_Layer_4': 260}. Best is trial 8 with value: 5.7445919464954.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.00 | sMAPE for Validation Set is: 103.54% | rMAE for Validation Set is: 4.39\n",
      "MAE for Test Set is: 29.53 | sMAPE for Test Set is: 37.28% | rMAE for Test Set is: 1.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:17:19,123]\u001b[0m Trial 12 finished with value: 4.541297658046944 and parameters: {'n_hidden': 3, 'learning_rate': 0.014000088996703127, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009593947443193153, 'dropout_rate_Layer_2': 0.18648470364060696, 'dropout_rate_Layer_3': 0.3443096788938267, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004690454983705773, 'l1_Layer_2': 2.995661965574992e-05, 'l1_Layer_3': 1.1025970672467138e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 290, 'n_units_Layer_3': 145}. Best is trial 12 with value: 4.541297658046944.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 62.28% | rMAE for Validation Set is: 1.42\n",
      "MAE for Test Set is: 25.60 | sMAPE for Test Set is: 24.91% | rMAE for Test Set is: 1.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:17:24,149]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:17:28,752]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:17:29,040]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:17:35,838]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:18:06,005]\u001b[0m Trial 16 finished with value: 5.858179143278711 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010420667088599986, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008632788323083805, 'dropout_rate_Layer_2': 0.14516091380781376, 'dropout_rate_Layer_3': 0.3923450019078786, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006465537183841659, 'l1_Layer_2': 0.0014210838842003439, 'l1_Layer_3': 0.004276244641874434, 'n_units_Layer_1': 70, 'n_units_Layer_2': 230, 'n_units_Layer_3': 295}. Best is trial 12 with value: 4.541297658046944.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 75.52% | rMAE for Validation Set is: 1.84\n",
      "MAE for Test Set is: 67.37 | sMAPE for Test Set is: 152.00% | rMAE for Test Set is: 3.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:18:56,322]\u001b[0m Trial 19 finished with value: 3.5365566208966928 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030774211080710954, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3121089966609898, 'dropout_rate_Layer_2': 0.27885394802071073, 'dropout_rate_Layer_3': 0.19609554114590813, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001519852331032137, 'l1_Layer_2': 0.050596262428561, 'l1_Layer_3': 0.0002004795432163607, 'n_units_Layer_1': 300, 'n_units_Layer_2': 265, 'n_units_Layer_3': 125}. Best is trial 19 with value: 3.5365566208966928.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.54 | sMAPE for Validation Set is: 55.30% | rMAE for Validation Set is: 1.11\n",
      "MAE for Test Set is: 20.14 | sMAPE for Test Set is: 29.50% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:19:03,587]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:19:16,280]\u001b[0m Trial 18 finished with value: 2.0529870942865904 and parameters: {'n_hidden': 4, 'learning_rate': 0.03704021839878728, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26925365231957693, 'dropout_rate_Layer_2': 0.2342752439951824, 'dropout_rate_Layer_3': 0.18816495330694544, 'dropout_rate_Layer_4': 0.17110820836108775, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004528328837174341, 'l1_Layer_2': 0.0007038833524104149, 'l1_Layer_3': 0.003705917507258821, 'l1_Layer_4': 1.3930373005673546e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 170, 'n_units_Layer_3': 180, 'n_units_Layer_4': 160}. Best is trial 18 with value: 2.0529870942865904.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 46.23% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.68 | sMAPE for Test Set is: 15.22% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:19:25,899]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:19:30,685]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:19:35,629]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:19:40,346]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:19:41,384]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:19:50,025]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:19:52,404]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:19:55,149]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:19:57,460]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:20:02,816]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:20:08,009]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:20:14,779]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:20:15,263]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:20:24,704]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:20:24,771]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:20:32,092]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:20:32,162]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:20:40,978]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:20:55,860]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:21:05,317]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:21:07,805]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:21:20,272]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:21:25,251]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:21:30,272]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:21:40,476]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:22:31,685]\u001b[0m Trial 42 finished with value: 1.7790118818722505 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005000754729050293, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0911503991984243, 'dropout_rate_Layer_2': 0.3841883074193679, 'dropout_rate_Layer_3': 0.33893518704339937, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018023509757886557, 'l1_Layer_2': 6.846486990080799e-05, 'l1_Layer_3': 7.753980721603978e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 170, 'n_units_Layer_3': 210}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.78 | sMAPE for Validation Set is: 36.68% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 10.21 | sMAPE for Test Set is: 12.93% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:22:39,724]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:22:44,632]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:22:49,721]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:23:01,765]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:23:09,189]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:23:16,265]\u001b[0m Trial 47 finished with value: 6.264956924700582 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009043966349489466, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06972295353784576, 'dropout_rate_Layer_2': 0.2887670936634571, 'dropout_rate_Layer_3': 0.20282940806059196, 'dropout_rate_Layer_4': 0.26715871923225876, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0944409182008764, 'l1_Layer_2': 0.011658830636379241, 'l1_Layer_3': 0.0020423295290674047, 'l1_Layer_4': 0.0010132377906148294, 'n_units_Layer_1': 190, 'n_units_Layer_2': 250, 'n_units_Layer_3': 205, 'n_units_Layer_4': 155}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.26 | sMAPE for Validation Set is: 74.23% | rMAE for Validation Set is: 1.96\n",
      "MAE for Test Set is: 19.56 | sMAPE for Test Set is: 22.27% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:23:21,712]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:23:29,069]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:23:38,211]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:23:41,290]\u001b[0m Trial 53 finished with value: 12.607057745126852 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010976440080079255, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09189619441378105, 'dropout_rate_Layer_2': 0.007970359322585408, 'dropout_rate_Layer_3': 0.276641180231672, 'dropout_rate_Layer_4': 0.23805064920606003, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.053409113764375495, 'l1_Layer_2': 9.054443140606093e-05, 'l1_Layer_3': 0.0008197605116262346, 'l1_Layer_4': 3.596627880300222e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 245, 'n_units_Layer_3': 255, 'n_units_Layer_4': 160}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.61 | sMAPE for Validation Set is: 100.26% | rMAE for Validation Set is: 3.95\n",
      "MAE for Test Set is: 28.45 | sMAPE for Test Set is: 35.91% | rMAE for Test Set is: 1.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:23:48,360]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:23:53,520]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:23:53,845]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:24:08,511]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:24:08,564]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:24:16,647]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:24:32,324]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:24:37,478]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:24:42,057]\u001b[0m Trial 62 finished with value: 12.652003766514133 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012258379647012085, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08118808088535762, 'dropout_rate_Layer_2': 0.1772734356041534, 'dropout_rate_Layer_3': 0.11200754678512084, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008293913963801699, 'l1_Layer_2': 1.2293134557298413e-05, 'l1_Layer_3': 0.009189236994648286, 'n_units_Layer_1': 225, 'n_units_Layer_2': 295, 'n_units_Layer_3': 180}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.65 | sMAPE for Validation Set is: 99.15% | rMAE for Validation Set is: 3.97\n",
      "MAE for Test Set is: 31.69 | sMAPE for Test Set is: 40.62% | rMAE for Test Set is: 1.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:24:51,521]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:24:51,956]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:25:02,491]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:25:14,434]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:25:21,510]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:25:24,778]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:25:31,612]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:25:34,574]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:25:41,707]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:25:46,415]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:25:49,794]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:25:54,378]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:25:57,082]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:26:06,165]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:26:06,515]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:26:11,646]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:26:13,928]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:26:54,024]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:27:03,680]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:27:16,092]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:27:23,945]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:27:31,184]\u001b[0m Trial 84 finished with value: 11.026350243031814 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005893722793272965, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006323360674382578, 'dropout_rate_Layer_2': 0.0989401230950985, 'dropout_rate_Layer_3': 0.2413608110879783, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003056941651428142, 'l1_Layer_2': 1.1344382122568153e-05, 'l1_Layer_3': 0.00014396883143757362, 'n_units_Layer_1': 180, 'n_units_Layer_2': 230, 'n_units_Layer_3': 165}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.03 | sMAPE for Validation Set is: 94.66% | rMAE for Validation Set is: 3.46\n",
      "MAE for Test Set is: 17.79 | sMAPE for Test Set is: 17.72% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:27:40,432]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:27:40,734]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:27:48,464]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:27:57,771]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:28:05,296]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:28:12,790]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:28:15,338]\u001b[0m Trial 93 finished with value: 6.503656151186235 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012913985999585113, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1474332792526131, 'dropout_rate_Layer_2': 0.24134635107351443, 'dropout_rate_Layer_3': 0.12672093315539015, 'dropout_rate_Layer_4': 0.08524112242705516, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.08442757165680498, 'l1_Layer_2': 0.0009291998068171666, 'l1_Layer_3': 0.000184393733477164, 'l1_Layer_4': 1.0943340929876351e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 215, 'n_units_Layer_3': 285, 'n_units_Layer_4': 55}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.50 | sMAPE for Validation Set is: 77.31% | rMAE for Validation Set is: 2.04\n",
      "MAE for Test Set is: 65.91 | sMAPE for Test Set is: 144.00% | rMAE for Test Set is: 3.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:28:20,085]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:28:36,839]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:28:50,070]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:28:55,104]\u001b[0m Trial 97 finished with value: 6.543673153527931 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017194629626157867, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39189072404647207, 'dropout_rate_Layer_2': 0.1297940032894343, 'dropout_rate_Layer_3': 0.27636772198537607, 'dropout_rate_Layer_4': 0.15670292932455285, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.03245342784736076, 'l1_Layer_2': 5.770226814244491e-05, 'l1_Layer_3': 0.016482357535503825, 'l1_Layer_4': 0.0032129095048869954, 'n_units_Layer_1': 130, 'n_units_Layer_2': 160, 'n_units_Layer_3': 105, 'n_units_Layer_4': 110}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.54 | sMAPE for Validation Set is: 87.72% | rMAE for Validation Set is: 2.05\n",
      "MAE for Test Set is: 72.27 | sMAPE for Test Set is: 177.28% | rMAE for Test Set is: 4.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:29:07,351]\u001b[0m Trial 99 finished with value: 6.849121285804247 and parameters: {'n_hidden': 4, 'learning_rate': 0.00512500274872173, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35643030938144993, 'dropout_rate_Layer_2': 0.2881261685569285, 'dropout_rate_Layer_3': 0.18171410673157135, 'dropout_rate_Layer_4': 0.0887576860446076, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.02319502347504021, 'l1_Layer_2': 0.00165162862176749, 'l1_Layer_3': 0.0035879076440473727, 'l1_Layer_4': 0.0805915696919306, 'n_units_Layer_1': 290, 'n_units_Layer_2': 210, 'n_units_Layer_3': 130, 'n_units_Layer_4': 280}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.85 | sMAPE for Validation Set is: 78.69% | rMAE for Validation Set is: 2.15\n",
      "MAE for Test Set is: 64.27 | sMAPE for Test Set is: 136.33% | rMAE for Test Set is: 3.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:29:09,775]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:29:16,976]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:29:26,653]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:29:26,757]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:29:38,389]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:29:38,653]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:29:46,791]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:30:26,597]\u001b[0m Trial 107 finished with value: 2.2794262986395677 and parameters: {'n_hidden': 3, 'learning_rate': 0.003791790423685821, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28478120018548664, 'dropout_rate_Layer_2': 0.2708501456466806, 'dropout_rate_Layer_3': 0.17015615096935913, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014579996124191228, 'l1_Layer_2': 0.06150088741702963, 'l1_Layer_3': 0.00022730391333052228, 'n_units_Layer_1': 250, 'n_units_Layer_2': 210, 'n_units_Layer_3': 115}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.28 | sMAPE for Validation Set is: 41.96% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.74 | sMAPE for Test Set is: 15.51% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:30:31,620]\u001b[0m Trial 108 finished with value: 4.328997444796584 and parameters: {'n_hidden': 3, 'learning_rate': 0.059641330747638464, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33951468946057367, 'dropout_rate_Layer_2': 0.3666465750386961, 'dropout_rate_Layer_3': 0.2978769511877818, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.9917465198582466e-05, 'l1_Layer_2': 0.09341281753788992, 'l1_Layer_3': 2.8051251863094253e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 90, 'n_units_Layer_3': 220}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 63.22% | rMAE for Validation Set is: 1.36\n",
      "MAE for Test Set is: 11.90 | sMAPE for Test Set is: 15.11% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:30:38,599]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:30:41,740]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:30:46,502]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:30:56,286]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:31:11,628]\u001b[0m Trial 112 finished with value: 3.757292594648448 and parameters: {'n_hidden': 3, 'learning_rate': 0.012213261816325174, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22282814727963887, 'dropout_rate_Layer_2': 0.2742280959277144, 'dropout_rate_Layer_3': 0.1561117121590982, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.279760750320251e-05, 'l1_Layer_2': 0.07505961413158929, 'l1_Layer_3': 0.0005235569138443271, 'n_units_Layer_1': 225, 'n_units_Layer_2': 175, 'n_units_Layer_3': 145}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 55.90% | rMAE for Validation Set is: 1.18\n",
      "MAE for Test Set is: 13.78 | sMAPE for Test Set is: 20.32% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:31:23,911]\u001b[0m Trial 115 finished with value: 6.562960335537585 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006085224837484485, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.038751037591875905, 'dropout_rate_Layer_2': 0.3111524257260007, 'dropout_rate_Layer_3': 0.0822978787801997, 'dropout_rate_Layer_4': 0.37978379050013683, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003686021482542314, 'l1_Layer_2': 1.0676914411012888e-05, 'l1_Layer_3': 0.0023520315122428415, 'l1_Layer_4': 0.0001079880143572971, 'n_units_Layer_1': 265, 'n_units_Layer_2': 60, 'n_units_Layer_3': 120, 'n_units_Layer_4': 245}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.56 | sMAPE for Validation Set is: 88.72% | rMAE for Validation Set is: 2.06\n",
      "MAE for Test Set is: 72.23 | sMAPE for Test Set is: 177.04% | rMAE for Test Set is: 4.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:31:29,014]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:31:36,333]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:31:45,886]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:31:51,320]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.29 | sMAPE for Validation Set is: 43.14% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 10.83 | sMAPE for Test Set is: 13.99% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:31:55,732]\u001b[0m Trial 114 finished with value: 2.2856432487074705 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005340629213931245, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35194102298749436, 'dropout_rate_Layer_2': 0.26516547964484727, 'dropout_rate_Layer_3': 0.1582005527936214, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.731125252428823e-05, 'l1_Layer_2': 0.07722345781340603, 'l1_Layer_3': 0.000701012407470972, 'n_units_Layer_1': 225, 'n_units_Layer_2': 185, 'n_units_Layer_3': 150}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:31:58,252]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:32:00,779]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:32:03,911]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:32:16,103]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:32:20,465]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:32:28,254]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:32:28,638]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:32:37,253]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:32:40,027]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:32:44,634]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:32:49,111]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:32:49,592]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:33:00,855]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:33:01,309]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:33:09,403]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:33:11,903]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:33:16,665]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:33:19,217]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:33:24,302]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:33:33,792]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:33:34,278]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:33:42,803]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:33:49,840]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:33:52,826]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:34:41,729]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:34:46,979]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:34:51,911]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:34:56,890]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:35:04,133]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:35:08,900]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:35:11,883]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:35:21,515]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:35:34,660]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:35:44,061]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:35:49,072]\u001b[0m Trial 153 finished with value: 5.916790251043403 and parameters: {'n_hidden': 4, 'learning_rate': 0.004191424693806185, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06530815434395298, 'dropout_rate_Layer_2': 0.04171008420610806, 'dropout_rate_Layer_3': 0.33821904012793247, 'dropout_rate_Layer_4': 0.05378813015666825, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0012828402741308833, 'l1_Layer_2': 2.3407333115774143e-05, 'l1_Layer_3': 0.0007913033862323378, 'l1_Layer_4': 2.8295172407348363e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 65, 'n_units_Layer_3': 55, 'n_units_Layer_4': 75}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.92 | sMAPE for Validation Set is: 75.07% | rMAE for Validation Set is: 1.86\n",
      "MAE for Test Set is: 69.87 | sMAPE for Test Set is: 163.04% | rMAE for Test Set is: 4.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:35:56,230]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:36:02,101]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:36:13,645]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:36:28,434]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:36:38,209]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:36:58,068]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:37:07,422]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:37:17,492]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:37:22,737]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:37:26,853]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:37:31,820]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:37:37,510]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:37:39,607]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:37:52,545]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:37:57,482]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:38:04,239]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:38:04,546]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:38:23,296]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:38:30,748]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:38:31,008]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:38:41,161]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:38:43,734]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:38:52,948]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:39:05,637]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:39:13,607]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:39:20,861]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:39:28,759]\u001b[0m Trial 177 finished with value: 1.8366133281275865 and parameters: {'n_hidden': 3, 'learning_rate': 0.08832129389243733, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3851546059024291, 'dropout_rate_Layer_2': 0.3951057483276861, 'dropout_rate_Layer_3': 0.1754716880443406, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2987196766174297e-05, 'l1_Layer_2': 0.0004311866629287225, 'l1_Layer_3': 1.4641691214436504e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 140, 'n_units_Layer_3': 300}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.84 | sMAPE for Validation Set is: 35.39% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 15.52 | sMAPE for Test Set is: 16.88% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:39:31,009]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:39:38,490]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:39:45,427]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:39:53,268]\u001b[0m Trial 183 finished with value: 8.32918295567193 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005526012350540246, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04021913897387239, 'dropout_rate_Layer_2': 0.1857260057873254, 'dropout_rate_Layer_3': 0.3401512321597149, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008454830766009964, 'l1_Layer_2': 0.00031729108010409695, 'l1_Layer_3': 0.0001477451569657579, 'n_units_Layer_1': 155, 'n_units_Layer_2': 110, 'n_units_Layer_3': 215}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.33 | sMAPE for Validation Set is: 85.49% | rMAE for Validation Set is: 2.61\n",
      "MAE for Test Set is: 22.61 | sMAPE for Test Set is: 26.46% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:40:00,098]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:40:02,804]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:40:10,317]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:40:17,232]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:40:20,462]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:40:52,740]\u001b[0m Trial 191 finished with value: 8.370315272070904 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005944280165863616, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04308632808096168, 'dropout_rate_Layer_2': 0.1616259043553051, 'dropout_rate_Layer_3': 0.3529044971044646, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006616749213000676, 'l1_Layer_2': 0.00037225200058568113, 'l1_Layer_3': 0.00018519600542301996, 'n_units_Layer_1': 150, 'n_units_Layer_2': 110, 'n_units_Layer_3': 175}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.37 | sMAPE for Validation Set is: 85.40% | rMAE for Validation Set is: 2.62\n",
      "MAE for Test Set is: 22.64 | sMAPE for Test Set is: 26.24% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:41:07,892]\u001b[0m Trial 193 finished with value: 8.084455831199193 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014594470341610874, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0432302034363518, 'dropout_rate_Layer_2': 0.18638885347474146, 'dropout_rate_Layer_3': 0.3513898877416131, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010357459095926513, 'l1_Layer_2': 0.0003465979323056956, 'l1_Layer_3': 0.0004116073364512981, 'n_units_Layer_1': 155, 'n_units_Layer_2': 110, 'n_units_Layer_3': 220}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.08 | sMAPE for Validation Set is: 84.07% | rMAE for Validation Set is: 2.53\n",
      "MAE for Test Set is: 22.74 | sMAPE for Test Set is: 26.85% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:41:14,829]\u001b[0m Trial 192 finished with value: 2.0328758222844274 and parameters: {'n_hidden': 3, 'learning_rate': 0.07907515976295655, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3961421484334119, 'dropout_rate_Layer_2': 0.36717307899995055, 'dropout_rate_Layer_3': 0.23781201475714878, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.013388742640531e-05, 'l1_Layer_2': 0.00047123455285264816, 'l1_Layer_3': 1.0929540748834795e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 125, 'n_units_Layer_3': 285}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 43.26% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 16.66 | sMAPE for Test Set is: 17.86% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:41:24,494]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:41:27,909]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:41:35,250]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:41:42,882]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:42:02,347]\u001b[0m Trial 199 finished with value: 9.77660079585034 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012641518572201124, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10850210918948971, 'dropout_rate_Layer_2': 0.19532713453747463, 'dropout_rate_Layer_3': 0.30433291865329476, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011129994420455097, 'l1_Layer_2': 0.0013758252025142662, 'l1_Layer_3': 0.00045640507862530755, 'n_units_Layer_1': 155, 'n_units_Layer_2': 105, 'n_units_Layer_3': 215}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.78 | sMAPE for Validation Set is: 90.87% | rMAE for Validation Set is: 3.07\n",
      "MAE for Test Set is: 22.56 | sMAPE for Test Set is: 26.01% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:42:16,671]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:42:31,524]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:42:39,476]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:42:47,159]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:42:54,058]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:43:16,592]\u001b[0m Trial 198 finished with value: 2.8336158978309527 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010347766986950131, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2580713648641077, 'dropout_rate_Layer_2': 0.264393965356214, 'dropout_rate_Layer_3': 0.17416137619589425, 'dropout_rate_Layer_4': 0.16937068034713118, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0009031295475475908, 'l1_Layer_2': 0.029694001200103813, 'l1_Layer_3': 0.00016106085561081872, 'l1_Layer_4': 0.0005719792093201183, 'n_units_Layer_1': 90, 'n_units_Layer_2': 165, 'n_units_Layer_3': 215, 'n_units_Layer_4': 170}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.83 | sMAPE for Validation Set is: 58.16% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 10.77 | sMAPE for Test Set is: 13.85% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:43:26,977]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:43:34,080]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:43:51,104]\u001b[0m Trial 205 finished with value: 2.070566869178854 and parameters: {'n_hidden': 3, 'learning_rate': 0.02527197191931671, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3993938924009117, 'dropout_rate_Layer_2': 0.39290248531488353, 'dropout_rate_Layer_3': 0.20007604258590628, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.592333945214174e-05, 'l1_Layer_2': 0.0003068905730603679, 'l1_Layer_3': 1.0383633839128043e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 145, 'n_units_Layer_3': 290}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 55.07% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.85 | sMAPE for Test Set is: 14.48% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:44:31,085]\u001b[0m Trial 208 finished with value: 2.175439530364761 and parameters: {'n_hidden': 3, 'learning_rate': 0.02374395537130182, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39618145386386733, 'dropout_rate_Layer_2': 0.3905108031597711, 'dropout_rate_Layer_3': 0.19736868035784652, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.654902396449573e-05, 'l1_Layer_2': 0.00021123939902955547, 'l1_Layer_3': 0.0943385456574516, 'n_units_Layer_1': 175, 'n_units_Layer_2': 135, 'n_units_Layer_3': 280}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.18 | sMAPE for Validation Set is: 39.29% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.50 | sMAPE for Test Set is: 13.57% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:44:53,543]\u001b[0m Trial 210 finished with value: 6.030756278872601 and parameters: {'n_hidden': 4, 'learning_rate': 0.0045972516738126724, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06665404723537527, 'dropout_rate_Layer_2': 0.04081540066970237, 'dropout_rate_Layer_3': 0.3986154650959306, 'dropout_rate_Layer_4': 0.007052708806718488, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00026002640779242933, 'l1_Layer_2': 3.5335332014422086e-05, 'l1_Layer_3': 0.005211669407376929, 'l1_Layer_4': 0.0012276448442837228, 'n_units_Layer_1': 90, 'n_units_Layer_2': 95, 'n_units_Layer_3': 100, 'n_units_Layer_4': 70}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.03 | sMAPE for Validation Set is: 78.67% | rMAE for Validation Set is: 1.89\n",
      "MAE for Test Set is: 68.16 | sMAPE for Test Set is: 156.15% | rMAE for Test Set is: 4.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:45:00,602]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:45:33,145]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:45:33,702]\u001b[0m Trial 209 finished with value: 2.355449528351578 and parameters: {'n_hidden': 3, 'learning_rate': 0.04108401060660874, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24656089322217706, 'dropout_rate_Layer_2': 0.10630355505545298, 'dropout_rate_Layer_3': 0.19069972160387036, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1940192815717764e-05, 'l1_Layer_2': 0.00014467311496788463, 'l1_Layer_3': 4.523381500342122e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 115, 'n_units_Layer_3': 300}. Best is trial 42 with value: 1.7790118818722505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.36 | sMAPE for Validation Set is: 51.44% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 12.37 | sMAPE for Test Set is: 16.36% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:46:01,735]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:46:18,829]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:46:29,310]\u001b[0m Trial 215 finished with value: 1.7495135501386834 and parameters: {'n_hidden': 3, 'learning_rate': 0.015023539471872469, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33274951869921615, 'dropout_rate_Layer_2': 0.24738103161084082, 'dropout_rate_Layer_3': 0.2468610570775734, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017586614724480885, 'l1_Layer_2': 0.0014583240251143767, 'l1_Layer_3': 1.0310236468680459e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 170, 'n_units_Layer_3': 255}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.75 | sMAPE for Validation Set is: 36.10% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 11.40 | sMAPE for Test Set is: 13.76% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:46:41,695]\u001b[0m Trial 216 finished with value: 5.409233472436916 and parameters: {'n_hidden': 4, 'learning_rate': 0.004553547983224503, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06631301428833714, 'dropout_rate_Layer_2': 0.000279959427834953, 'dropout_rate_Layer_3': 0.3954481929875668, 'dropout_rate_Layer_4': 0.0033717576903100114, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00021081975912114415, 'l1_Layer_2': 3.664695180649588e-05, 'l1_Layer_3': 0.007636502438085724, 'l1_Layer_4': 0.001208463183375754, 'n_units_Layer_1': 90, 'n_units_Layer_2': 65, 'n_units_Layer_3': 105, 'n_units_Layer_4': 70}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.41 | sMAPE for Validation Set is: 69.94% | rMAE for Validation Set is: 1.70\n",
      "MAE for Test Set is: 58.67 | sMAPE for Test Set is: 115.95% | rMAE for Test Set is: 3.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:46:54,072]\u001b[0m Trial 217 finished with value: 5.62249912856349 and parameters: {'n_hidden': 4, 'learning_rate': 0.004513770739647249, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06696523942550817, 'dropout_rate_Layer_2': 0.04179528979056009, 'dropout_rate_Layer_3': 0.39582810289961146, 'dropout_rate_Layer_4': 0.004978580424443758, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00013220659222793586, 'l1_Layer_2': 3.31086735763274e-05, 'l1_Layer_3': 0.007534771171178825, 'l1_Layer_4': 0.0007143284615519599, 'n_units_Layer_1': 75, 'n_units_Layer_2': 100, 'n_units_Layer_3': 105, 'n_units_Layer_4': 70}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 72.07% | rMAE for Validation Set is: 1.76\n",
      "MAE for Test Set is: 59.77 | sMAPE for Test Set is: 119.64% | rMAE for Test Set is: 3.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:47:14,035]\u001b[0m Trial 219 finished with value: 6.334454316624691 and parameters: {'n_hidden': 4, 'learning_rate': 0.006964892698597331, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06725231590877781, 'dropout_rate_Layer_2': 0.05716772183372692, 'dropout_rate_Layer_3': 0.3967493883159137, 'dropout_rate_Layer_4': 0.011822970508006219, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00010583624141247841, 'l1_Layer_2': 3.279003445531362e-05, 'l1_Layer_3': 0.005414859791921144, 'l1_Layer_4': 0.0013148984900206064, 'n_units_Layer_1': 80, 'n_units_Layer_2': 90, 'n_units_Layer_3': 110, 'n_units_Layer_4': 80}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.33 | sMAPE for Validation Set is: 83.85% | rMAE for Validation Set is: 1.99\n",
      "MAE for Test Set is: 68.36 | sMAPE for Test Set is: 157.33% | rMAE for Test Set is: 4.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:47:18,747]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:47:41,532]\u001b[0m Trial 221 finished with value: 5.931988173511809 and parameters: {'n_hidden': 4, 'learning_rate': 0.0046702798040504185, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.049182796389027804, 'dropout_rate_Layer_2': 0.25988337569137654, 'dropout_rate_Layer_3': 0.3918042908939219, 'dropout_rate_Layer_4': 0.007354725419826631, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011624905835288352, 'l1_Layer_2': 3.621081391532145e-05, 'l1_Layer_3': 0.00731064737449816, 'l1_Layer_4': 0.0007989097908550193, 'n_units_Layer_1': 70, 'n_units_Layer_2': 95, 'n_units_Layer_3': 105, 'n_units_Layer_4': 80}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.93 | sMAPE for Validation Set is: 76.90% | rMAE for Validation Set is: 1.86\n",
      "MAE for Test Set is: 66.68 | sMAPE for Test Set is: 148.94% | rMAE for Test Set is: 3.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:47:46,351]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:47:53,277]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:47:58,880]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:48:05,667]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:48:10,514]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:48:13,385]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:48:18,410]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:48:37,495]\u001b[0m Trial 227 finished with value: 5.059060249656245 and parameters: {'n_hidden': 4, 'learning_rate': 0.0031755350352936683, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07129902052437496, 'dropout_rate_Layer_2': 0.2664785940920249, 'dropout_rate_Layer_3': 0.37675238509297376, 'dropout_rate_Layer_4': 0.0235519305996948, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001864093853854334, 'l1_Layer_2': 3.0245974242985093e-05, 'l1_Layer_3': 0.004550195453003068, 'l1_Layer_4': 0.0008355949535370711, 'n_units_Layer_1': 90, 'n_units_Layer_2': 95, 'n_units_Layer_3': 115, 'n_units_Layer_4': 175}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 66.66% | rMAE for Validation Set is: 1.59\n",
      "MAE for Test Set is: 58.98 | sMAPE for Test Set is: 117.48% | rMAE for Test Set is: 3.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:48:50,387]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:49:02,819]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:49:17,820]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:49:40,069]\u001b[0m Trial 233 finished with value: 5.284743931705241 and parameters: {'n_hidden': 4, 'learning_rate': 0.0033233137488866697, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05537480206474729, 'dropout_rate_Layer_2': 0.2743278943462247, 'dropout_rate_Layer_3': 0.3721044490147086, 'dropout_rate_Layer_4': 0.005846271579858384, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001213461014993024, 'l1_Layer_2': 3.079820059962085e-05, 'l1_Layer_3': 0.005793344840567703, 'l1_Layer_4': 0.0005957097550180838, 'n_units_Layer_1': 65, 'n_units_Layer_2': 115, 'n_units_Layer_3': 125, 'n_units_Layer_4': 175}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 68.69% | rMAE for Validation Set is: 1.66\n",
      "MAE for Test Set is: 55.07 | sMAPE for Test Set is: 104.37% | rMAE for Test Set is: 3.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:49:47,690]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:49:52,739]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:50:12,194]\u001b[0m Trial 236 finished with value: 2.1709414938154494 and parameters: {'n_hidden': 3, 'learning_rate': 0.01153449165804952, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.229951607468887, 'dropout_rate_Layer_2': 0.2537883887263046, 'dropout_rate_Layer_3': 0.13572254334634462, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019681411108936814, 'l1_Layer_2': 0.0029037812697909394, 'l1_Layer_3': 7.737094016853178e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 165, 'n_units_Layer_3': 235}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.17 | sMAPE for Validation Set is: 54.92% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 15.58 | sMAPE for Test Set is: 16.97% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:50:19,538]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:50:34,812]\u001b[0m Trial 238 finished with value: 6.147282999408333 and parameters: {'n_hidden': 3, 'learning_rate': 0.014885418731358086, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.322278534073677, 'dropout_rate_Layer_2': 0.10871967535167366, 'dropout_rate_Layer_3': 0.3230294662166021, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.004070441730955127, 'l1_Layer_2': 4.6986596191184393e-05, 'l1_Layer_3': 8.457809339968159e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 245, 'n_units_Layer_3': 260}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 80.63% | rMAE for Validation Set is: 1.93\n",
      "MAE for Test Set is: 71.32 | sMAPE for Test Set is: 172.18% | rMAE for Test Set is: 4.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:50:41,618]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:50:47,078]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:50:51,517]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:50:59,240]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:51:07,062]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:51:14,351]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:51:21,485]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:51:28,927]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:51:36,832]\u001b[0m Trial 229 finished with value: 1.8697962420694563 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021687819357658904, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26134398036073514, 'dropout_rate_Layer_2': 0.33900081473217886, 'dropout_rate_Layer_3': 0.14373941665111448, 'dropout_rate_Layer_4': 0.2875907104298817, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004194878107833874, 'l1_Layer_2': 0.0001891321170587281, 'l1_Layer_3': 3.990403433041124e-05, 'l1_Layer_4': 0.0002919932502125678, 'n_units_Layer_1': 55, 'n_units_Layer_2': 195, 'n_units_Layer_3': 200, 'n_units_Layer_4': 200}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.87 | sMAPE for Validation Set is: 48.79% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 10.79 | sMAPE for Test Set is: 13.92% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:51:45,940]\u001b[0m Trial 247 finished with value: 5.974230429904817 and parameters: {'n_hidden': 3, 'learning_rate': 0.003628810964710689, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27400450627574013, 'dropout_rate_Layer_2': 0.2374064709262454, 'dropout_rate_Layer_3': 0.24062196564732607, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00015891887996202482, 'l1_Layer_2': 0.00426831955337663, 'l1_Layer_3': 1.628454744626669e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 175, 'n_units_Layer_3': 210}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.97 | sMAPE for Validation Set is: 76.93% | rMAE for Validation Set is: 1.87\n",
      "MAE for Test Set is: 69.11 | sMAPE for Test Set is: 160.79% | rMAE for Test Set is: 4.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:51:58,086]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:52:05,652]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.79 | sMAPE for Validation Set is: 83.13% | rMAE for Validation Set is: 2.44\n",
      "MAE for Test Set is: 27.23 | sMAPE for Test Set is: 33.61% | rMAE for Test Set is: 1.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:52:18,284]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:52:18,308]\u001b[0m Trial 250 finished with value: 7.793726333137343 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014126097179359414, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08179838362663927, 'dropout_rate_Layer_2': 0.19368913109496547, 'dropout_rate_Layer_3': 0.3072624605069886, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010656184068242275, 'l1_Layer_2': 0.008637806701931547, 'l1_Layer_3': 1.0588832360073164e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 135, 'n_units_Layer_3': 225}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:52:24,632]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:52:29,742]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:52:34,352]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:52:37,837]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:52:49,063]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:52:52,493]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:52:59,616]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:53:07,100]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:53:11,879]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:53:16,762]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:53:22,081]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:53:34,117]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:53:38,688]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:53:41,653]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:53:48,560]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:53:48,880]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:53:56,795]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:53:57,078]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:54:04,608]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:54:09,812]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:54:14,300]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:54:16,933]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:54:21,155]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:54:28,950]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:54:36,383]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:54:41,751]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:54:45,050]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:54:48,768]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:54:54,175]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:54:58,972]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:55:11,408]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:55:18,186]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:55:25,780]\u001b[0m Trial 281 finished with value: 2.130924705061629 and parameters: {'n_hidden': 3, 'learning_rate': 0.07421203977276214, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3836765414694056, 'dropout_rate_Layer_2': 0.34550210944710225, 'dropout_rate_Layer_3': 0.23854255743143016, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1335013156417701e-05, 'l1_Layer_2': 0.0005841822605627737, 'l1_Layer_3': 1.6261245476232425e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 160, 'n_units_Layer_3': 270}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 36.68% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 18.63 | sMAPE for Test Set is: 20.30% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:55:30,641]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:55:33,100]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:55:37,906]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:55:42,390]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:55:47,720]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:55:52,357]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:55:52,925]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:56:04,277]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:56:06,861]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:56:12,311]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:56:17,312]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:56:24,371]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:56:39,408]\u001b[0m Trial 297 finished with value: 2.0926845956496205 and parameters: {'n_hidden': 3, 'learning_rate': 0.045822228028882174, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.317225258545081, 'dropout_rate_Layer_2': 0.33834306499634376, 'dropout_rate_Layer_3': 0.23048809319804725, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.387303287569375e-05, 'l1_Layer_2': 0.0004457799447549722, 'l1_Layer_3': 1.1112785136964742e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 115, 'n_units_Layer_3': 300}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 48.56% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.72 | sMAPE for Test Set is: 14.15% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:56:47,012]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:56:52,000]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:56:59,133]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:56:59,166]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:57:08,592]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:57:13,747]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:57:21,111]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:57:25,768]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:57:31,179]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:57:45,180]\u001b[0m Trial 306 finished with value: 7.4105778583067945 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008413470255215718, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04150207002363601, 'dropout_rate_Layer_2': 0.17700704951402768, 'dropout_rate_Layer_3': 0.34217540839816907, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003243119557552513, 'l1_Layer_2': 0.0006781372454562056, 'l1_Layer_3': 5.519492885819029e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 120, 'n_units_Layer_3': 225}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.41 | sMAPE for Validation Set is: 81.50% | rMAE for Validation Set is: 2.32\n",
      "MAE for Test Set is: 21.44 | sMAPE for Test Set is: 24.63% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:57:50,840]\u001b[0m Trial 308 finished with value: 6.913308000006716 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008664234891568657, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0333656934048699, 'dropout_rate_Layer_2': 0.23278839094833215, 'dropout_rate_Layer_3': 0.34298742534120263, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0026281745479273633, 'l1_Layer_2': 0.0006719708722301206, 'l1_Layer_3': 5.620887655918603e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 120, 'n_units_Layer_3': 230}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.91 | sMAPE for Validation Set is: 79.02% | rMAE for Validation Set is: 2.17\n",
      "MAE for Test Set is: 21.63 | sMAPE for Test Set is: 25.08% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:57:53,365]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:57:58,396]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:58:04,960]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:58:09,888]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:58:17,346]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:58:24,535]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:58:30,140]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:58:30,732]\u001b[0m Trial 313 finished with value: 6.78754761250017 and parameters: {'n_hidden': 3, 'learning_rate': 0.000855473813700998, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07567465799863479, 'dropout_rate_Layer_2': 0.22740764488159013, 'dropout_rate_Layer_3': 0.2914522958185571, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0023164084685837545, 'l1_Layer_2': 0.0009315587733520485, 'l1_Layer_3': 1.5232538717343849e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 130, 'n_units_Layer_3': 260}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.79 | sMAPE for Validation Set is: 78.49% | rMAE for Validation Set is: 2.13\n",
      "MAE for Test Set is: 20.81 | sMAPE for Test Set is: 23.73% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 18:58:43,388]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:58:50,468]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:58:50,800]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:59:00,429]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:59:00,455]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:59:10,393]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:59:15,276]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:59:22,240]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:59:22,563]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:59:30,500]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:59:37,488]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:59:42,883]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:59:49,469]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 18:59:55,311]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:00:02,984]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:00:08,096]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:00:12,807]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:00:20,198]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:00:20,302]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:00:27,887]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:00:32,403]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:00:37,267]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:00:40,203]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:00:47,474]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:00:54,970]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:01:01,969]\u001b[0m Trial 340 finished with value: 5.512302031476075 and parameters: {'n_hidden': 3, 'learning_rate': 0.03333787372424829, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39847777481106006, 'dropout_rate_Layer_2': 0.22032705597369687, 'dropout_rate_Layer_3': 0.3197795055249908, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0026982182366402036, 'l1_Layer_2': 0.006077299087030765, 'l1_Layer_3': 0.00011483929664180902, 'n_units_Layer_1': 200, 'n_units_Layer_2': 185, 'n_units_Layer_3': 270}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 70.07% | rMAE for Validation Set is: 1.73\n",
      "MAE for Test Set is: 24.58 | sMAPE for Test Set is: 30.26% | rMAE for Test Set is: 1.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:01:04,521]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:01:14,636]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:01:20,056]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:01:24,939]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:01:26,993]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:01:34,061]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:01:34,472]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:01:43,641]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:01:49,232]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:01:56,057]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:02:01,424]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:02:06,313]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:02:11,113]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:02:11,484]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:02:18,949]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:02:21,508]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:02:26,326]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:02:34,138]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:02:38,810]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:02:41,640]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:02:48,830]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:02:53,665]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:02:56,434]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:03:01,520]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:03:06,057]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:03:08,608]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:03:13,429]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:03:23,379]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:03:28,984]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:03:33,201]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:03:38,333]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:03:43,265]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:03:48,196]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:03:53,496]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:03:58,051]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:04:01,473]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:04:08,659]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:04:08,876]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:04:18,728]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:04:22,994]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:04:30,460]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:04:35,740]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:04:48,669]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:04:50,843]\u001b[0m Trial 383 finished with value: 7.506280028051876 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011989943855177465, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05998236506838617, 'dropout_rate_Layer_2': 0.17234704709857956, 'dropout_rate_Layer_3': 0.35689972779291623, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015744267904167452, 'l1_Layer_2': 0.004383364901945199, 'l1_Layer_3': 2.3633828282022978e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 90, 'n_units_Layer_3': 200}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.51 | sMAPE for Validation Set is: 81.47% | rMAE for Validation Set is: 2.35\n",
      "MAE for Test Set is: 23.27 | sMAPE for Test Set is: 27.35% | rMAE for Test Set is: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:04:58,436]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:05:07,708]\u001b[0m Trial 387 finished with value: 6.977649360504434 and parameters: {'n_hidden': 3, 'learning_rate': 0.020200217105951147, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29126942655165616, 'dropout_rate_Layer_2': 0.39598878458588216, 'dropout_rate_Layer_3': 0.2638420879822033, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 7.698017158827725e-05, 'l1_Layer_2': 7.519242888190203e-05, 'l1_Layer_3': 2.3842449949077335e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 130, 'n_units_Layer_3': 70}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.98 | sMAPE for Validation Set is: 96.84% | rMAE for Validation Set is: 2.19\n",
      "MAE for Test Set is: 73.90 | sMAPE for Test Set is: 186.82% | rMAE for Test Set is: 4.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:05:15,183]\u001b[0m Trial 389 finished with value: 6.165685422232335 and parameters: {'n_hidden': 3, 'learning_rate': 0.0176433021019848, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2918122552717203, 'dropout_rate_Layer_2': 0.3983524197189941, 'dropout_rate_Layer_3': 0.2592506148974068, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 5.462568868095914e-05, 'l1_Layer_2': 0.0015664072026608717, 'l1_Layer_3': 2.3724527067184814e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 125, 'n_units_Layer_3': 80}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 74.64% | rMAE for Validation Set is: 1.93\n",
      "MAE for Test Set is: 63.57 | sMAPE for Test Set is: 133.69% | rMAE for Test Set is: 3.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:05:18,103]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:05:25,412]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:05:33,135]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:05:40,468]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:05:45,055]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:05:49,756]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:05:54,136]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:05:59,783]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:06:07,120]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:06:14,555]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:06:21,622]\u001b[0m Trial 398 finished with value: 3.4884746240113995 and parameters: {'n_hidden': 3, 'learning_rate': 0.0213894549155902, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29489637610112607, 'dropout_rate_Layer_2': 0.268688379139204, 'dropout_rate_Layer_3': 0.1885006484941253, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00039364268637805117, 'l1_Layer_2': 0.01412237695236736, 'l1_Layer_3': 0.006369446192519005, 'n_units_Layer_1': 250, 'n_units_Layer_2': 175, 'n_units_Layer_3': 275}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.49 | sMAPE for Validation Set is: 54.96% | rMAE for Validation Set is: 1.09\n",
      "MAE for Test Set is: 24.03 | sMAPE for Test Set is: 36.28% | rMAE for Test Set is: 1.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:06:26,773]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:06:33,992]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:06:43,514]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:06:58,481]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:07:06,622]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:07:15,446]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:07:25,863]\u001b[0m Trial 408 finished with value: 3.7183637210973015 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007539817551938193, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0567824944260998, 'dropout_rate_Layer_2': 0.16789521209531455, 'dropout_rate_Layer_3': 0.3515842399080922, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018278720433454424, 'l1_Layer_2': 0.004429527244078142, 'l1_Layer_3': 2.6894062408960392e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 70, 'n_units_Layer_3': 200}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 55.13% | rMAE for Validation Set is: 1.17\n",
      "MAE for Test Set is: 32.17 | sMAPE for Test Set is: 43.78% | rMAE for Test Set is: 1.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:07:30,771]\u001b[0m Trial 401 finished with value: 1.870012642368743 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012726567171714857, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3808185025309121, 'dropout_rate_Layer_2': 0.3744876355732047, 'dropout_rate_Layer_3': 0.1144604753774932, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.258268044247838e-05, 'l1_Layer_2': 0.08506144336885363, 'l1_Layer_3': 0.0014720150792533815, 'n_units_Layer_1': 250, 'n_units_Layer_2': 175, 'n_units_Layer_3': 165}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.87 | sMAPE for Validation Set is: 36.66% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 10.54 | sMAPE for Test Set is: 13.39% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:07:35,655]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:07:43,007]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:08:09,674]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:08:19,458]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:08:29,202]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:08:34,721]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:08:39,285]\u001b[0m Trial 412 finished with value: 2.0132781880701036 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012655115305184384, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.292782367531955, 'dropout_rate_Layer_2': 0.27045110453325444, 'dropout_rate_Layer_3': 0.11196548701538558, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.408800994127976e-05, 'l1_Layer_2': 0.08626142155632914, 'l1_Layer_3': 0.00628699054177863, 'n_units_Layer_1': 250, 'n_units_Layer_2': 175, 'n_units_Layer_3': 165}. Best is trial 215 with value: 1.7495135501386834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 38.02% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.43 | sMAPE for Test Set is: 13.92% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:09:13,816]\u001b[0m Trial 416 finished with value: 1.6097560303672775 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012509603852372843, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2686746230730968, 'dropout_rate_Layer_2': 0.37559584694169634, 'dropout_rate_Layer_3': 0.05483974865301258, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.31930769569624e-05, 'l1_Layer_2': 0.0127881202652104, 'l1_Layer_3': 0.007142425162826937, 'n_units_Layer_1': 270, 'n_units_Layer_2': 175, 'n_units_Layer_3': 170}. Best is trial 416 with value: 1.6097560303672775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.61 | sMAPE for Validation Set is: 27.67% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 11.70 | sMAPE for Test Set is: 15.53% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:09:18,346]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:09:26,038]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:09:30,766]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:09:35,455]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:09:40,766]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.50 | sMAPE for Validation Set is: 81.70% | rMAE for Validation Set is: 2.35\n",
      "MAE for Test Set is: 22.32 | sMAPE for Test Set is: 25.89% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:09:57,396]\u001b[0m Trial 421 finished with value: 7.502861930914466 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008048713490646007, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02708304111681075, 'dropout_rate_Layer_2': 0.24221729202916603, 'dropout_rate_Layer_3': 0.33618538538393045, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0036980872864529842, 'l1_Layer_2': 0.002042657314087544, 'l1_Layer_3': 0.00010360161930160825, 'n_units_Layer_1': 165, 'n_units_Layer_2': 70, 'n_units_Layer_3': 180}. Best is trial 416 with value: 1.6097560303672775.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:09:57,877]\u001b[0m Trial 423 finished with value: 5.830614528713563 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008115621786148612, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028917257362218056, 'dropout_rate_Layer_2': 0.15628806846818133, 'dropout_rate_Layer_3': 0.33697109808880726, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003724806135999416, 'l1_Layer_2': 0.002231208557778112, 'l1_Layer_3': 4.01380908432276e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 70, 'n_units_Layer_3': 180}. Best is trial 416 with value: 1.6097560303672775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.83 | sMAPE for Validation Set is: 73.30% | rMAE for Validation Set is: 1.83\n",
      "MAE for Test Set is: 21.30 | sMAPE for Test Set is: 24.46% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:10:04,727]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:10:04,849]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:10:42,302]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:10:42,595]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:10:48,009]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:10:52,850]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:10:54,583]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:11:07,523]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:11:13,345]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:11:20,287]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:11:27,530]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:11:35,256]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:11:40,339]\u001b[0m Trial 432 finished with value: 1.708046168337404 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017378745835699592, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2969306858366978, 'dropout_rate_Layer_2': 0.3487043806091614, 'dropout_rate_Layer_3': 0.060193259506357455, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.895317855171351e-05, 'l1_Layer_2': 0.017742310968673174, 'l1_Layer_3': 0.007149566182518766, 'n_units_Layer_1': 245, 'n_units_Layer_2': 180, 'n_units_Layer_3': 170}. Best is trial 416 with value: 1.6097560303672775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.71 | sMAPE for Validation Set is: 32.00% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 13.21 | sMAPE for Test Set is: 17.77% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:11:47,024]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:11:56,480]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:12:24,422]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:12:33,621]\u001b[0m Trial 438 finished with value: 1.7649178727716899 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016564996971877308, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28921916749639454, 'dropout_rate_Layer_2': 0.37306727853115135, 'dropout_rate_Layer_3': 0.053611473206301656, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.17355452722263e-05, 'l1_Layer_2': 0.014542308264516392, 'l1_Layer_3': 0.004170835007138928, 'n_units_Layer_1': 245, 'n_units_Layer_2': 190, 'n_units_Layer_3': 170}. Best is trial 416 with value: 1.6097560303672775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.76 | sMAPE for Validation Set is: 33.42% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 11.50 | sMAPE for Test Set is: 15.23% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:12:39,421]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:12:46,569]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:13:03,339]\u001b[0m Trial 441 finished with value: 1.7266727052934765 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017922849362776141, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29419334781312223, 'dropout_rate_Layer_2': 0.3779203734360408, 'dropout_rate_Layer_3': 0.045569801783647, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.6133446359139896e-05, 'l1_Layer_2': 0.013577789209963192, 'l1_Layer_3': 0.007182505451951307, 'n_units_Layer_1': 245, 'n_units_Layer_2': 200, 'n_units_Layer_3': 175}. Best is trial 416 with value: 1.6097560303672775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.73 | sMAPE for Validation Set is: 28.74% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 10.83 | sMAPE for Test Set is: 14.02% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:13:13,278]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:13:21,005]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:13:24,011]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:13:30,764]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:13:33,888]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:13:38,806]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:13:45,958]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:13:53,100]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:14:05,917]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:14:15,022]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:14:22,680]\u001b[0m Trial 451 finished with value: 1.7402903168120645 and parameters: {'n_hidden': 3, 'learning_rate': 0.001830141972864568, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2826660280158779, 'dropout_rate_Layer_2': 0.37346825656527055, 'dropout_rate_Layer_3': 0.06943320976703676, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.5623297375748876e-05, 'l1_Layer_2': 0.009810492686552806, 'l1_Layer_3': 0.012182444702860363, 'n_units_Layer_1': 265, 'n_units_Layer_2': 205, 'n_units_Layer_3': 175}. Best is trial 416 with value: 1.6097560303672775.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:14:22,781]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.74 | sMAPE for Validation Set is: 30.32% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 11.37 | sMAPE for Test Set is: 15.00% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:14:36,129]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:14:44,116]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:14:51,423]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:14:58,563]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:15:05,821]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:15:08,370]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:15:13,995]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:15:18,845]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:15:28,364]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:15:31,242]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:15:38,354]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:15:46,155]\u001b[0m Trial 466 finished with value: 4.710729438935371 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010500932427202193, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05819031918077898, 'dropout_rate_Layer_2': 0.12064236202999847, 'dropout_rate_Layer_3': 0.24839687566538549, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002196132137727423, 'l1_Layer_2': 0.0033033401218813506, 'l1_Layer_3': 1.5977194056284625e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 70, 'n_units_Layer_3': 165}. Best is trial 416 with value: 1.6097560303672775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.71 | sMAPE for Validation Set is: 64.46% | rMAE for Validation Set is: 1.48\n",
      "MAE for Test Set is: 31.59 | sMAPE for Test Set is: 41.98% | rMAE for Test Set is: 1.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:15:55,660]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:16:00,959]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:16:13,017]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:16:20,965]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:16:25,780]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:16:40,178]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:16:48,202]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:16:48,481]\u001b[0m Trial 471 finished with value: 2.0044318462165283 and parameters: {'n_hidden': 3, 'learning_rate': 0.03712413169112214, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3961269921968171, 'dropout_rate_Layer_2': 0.3695082929188319, 'dropout_rate_Layer_3': 0.17980298461920974, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3042994854007687e-05, 'l1_Layer_2': 0.0002725330542140981, 'l1_Layer_3': 1.562542185270362e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 150, 'n_units_Layer_3': 280}. Best is trial 416 with value: 1.6097560303672775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 37.49% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.78 | sMAPE for Test Set is: 13.66% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:17:03,968]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:17:04,055]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:17:14,035]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:17:14,163]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:17:24,570]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:17:31,400]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:17:44,301]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:17:50,836]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:18:08,973]\u001b[0m Trial 485 finished with value: 9.352009483513006 and parameters: {'n_hidden': 3, 'learning_rate': 0.07030596878335114, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3600495098228153, 'dropout_rate_Layer_2': 0.2768129427147544, 'dropout_rate_Layer_3': 0.1711264660332609, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.081678502553886e-05, 'l1_Layer_2': 3.3944955103514614e-05, 'l1_Layer_3': 0.0001506344776363068, 'n_units_Layer_1': 185, 'n_units_Layer_2': 170, 'n_units_Layer_3': 280}. Best is trial 416 with value: 1.6097560303672775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.35 | sMAPE for Validation Set is: 133.78% | rMAE for Validation Set is: 2.93\n",
      "MAE for Test Set is: 23.73 | sMAPE for Test Set is: 31.12% | rMAE for Test Set is: 1.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:18:21,284]\u001b[0m Trial 484 finished with value: 1.5779252789893852 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015510057216827288, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2990199661683126, 'dropout_rate_Layer_2': 0.38652841457237125, 'dropout_rate_Layer_3': 0.05851237461396566, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.8460971331327416e-05, 'l1_Layer_2': 0.007068386376195907, 'l1_Layer_3': 0.013461357774806816, 'n_units_Layer_1': 235, 'n_units_Layer_2': 185, 'n_units_Layer_3': 160}. Best is trial 484 with value: 1.5779252789893852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.58 | sMAPE for Validation Set is: 24.46% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 11.15 | sMAPE for Test Set is: 14.49% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:18:23,951]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:18:31,808]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:18:38,476]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:18:43,871]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:18:45,445]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:18:53,198]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:19:00,408]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:19:03,867]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:19:08,221]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:19:13,141]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:19:22,694]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:19:35,925]\u001b[0m Trial 498 finished with value: 12.174933968520648 and parameters: {'n_hidden': 3, 'learning_rate': 0.03958347951615057, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.378307685828148, 'dropout_rate_Layer_2': 0.3598474182777159, 'dropout_rate_Layer_3': 0.30957668698014473, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026099802397314923, 'l1_Layer_2': 0.0007390235691134298, 'l1_Layer_3': 4.355866509203798e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 100, 'n_units_Layer_3': 265}. Best is trial 484 with value: 1.5779252789893852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.17 | sMAPE for Validation Set is: 116.98% | rMAE for Validation Set is: 3.82\n",
      "MAE for Test Set is: 99.62 | sMAPE for Test Set is: 62.79% | rMAE for Test Set is: 5.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:20:00,618]\u001b[0m Trial 499 finished with value: 5.889038113226133 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010923814108987418, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12498978460920117, 'dropout_rate_Layer_2': 0.11481630796497408, 'dropout_rate_Layer_3': 0.26475565789372785, 'dropout_rate_Layer_4': 0.2926875900329901, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0168592137574547, 'l1_Layer_2': 0.003182537762603115, 'l1_Layer_3': 0.029063507066137324, 'l1_Layer_4': 0.0032403190408542082, 'n_units_Layer_1': 125, 'n_units_Layer_2': 95, 'n_units_Layer_3': 95, 'n_units_Layer_4': 70}. Best is trial 484 with value: 1.5779252789893852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.89 | sMAPE for Validation Set is: 74.24% | rMAE for Validation Set is: 1.85\n",
      "MAE for Test Set is: 67.48 | sMAPE for Test Set is: 151.49% | rMAE for Test Set is: 4.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:20:09,701]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:20:12,826]\u001b[0m Trial 496 finished with value: 1.8387793721273855 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011729130695970844, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31143767797727334, 'dropout_rate_Layer_2': 0.37477081515295263, 'dropout_rate_Layer_3': 0.06425421124621587, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.223685776910567e-05, 'l1_Layer_2': 0.004545356323392565, 'l1_Layer_3': 0.009096766949892199, 'n_units_Layer_1': 255, 'n_units_Layer_2': 190, 'n_units_Layer_3': 185}. Best is trial 484 with value: 1.5779252789893852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.84 | sMAPE for Validation Set is: 35.21% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.88 | sMAPE for Test Set is: 14.13% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:20:17,822]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:20:22,796]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:20:29,404]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:20:35,372]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:20:49,949]\u001b[0m Trial 506 finished with value: 6.0801173438490155 and parameters: {'n_hidden': 3, 'learning_rate': 0.036295628941088884, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10183736874879679, 'dropout_rate_Layer_2': 0.0472909891680324, 'dropout_rate_Layer_3': 0.11617228782127667, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010939938102143752, 'l1_Layer_2': 0.00012168272460703368, 'l1_Layer_3': 0.0003051378793101119, 'n_units_Layer_1': 155, 'n_units_Layer_2': 190, 'n_units_Layer_3': 235}. Best is trial 484 with value: 1.5779252789893852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.08 | sMAPE for Validation Set is: 73.35% | rMAE for Validation Set is: 1.91\n",
      "MAE for Test Set is: 24.42 | sMAPE for Test Set is: 29.22% | rMAE for Test Set is: 1.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:20:59,435]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:21:04,742]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:21:09,793]\u001b[0m Trial 504 finished with value: 1.5555013884610895 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014322154324049442, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2960103221102188, 'dropout_rate_Layer_2': 0.3783660450121436, 'dropout_rate_Layer_3': 0.025424742966231574, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.7360981911544974e-05, 'l1_Layer_2': 0.004424356982248243, 'l1_Layer_3': 0.012347888555642617, 'n_units_Layer_1': 265, 'n_units_Layer_2': 180, 'n_units_Layer_3': 175}. Best is trial 504 with value: 1.5555013884610895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.56 | sMAPE for Validation Set is: 25.43% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.38 | sMAPE for Test Set is: 17.96% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:21:22,221]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:21:31,655]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:21:44,443]\u001b[0m Trial 510 finished with value: 5.86972490665751 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011841321754547161, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11956408101074817, 'dropout_rate_Layer_2': 0.11370250467605034, 'dropout_rate_Layer_3': 0.2605243400349108, 'dropout_rate_Layer_4': 0.28400772576715455, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.030227953030676775, 'l1_Layer_2': 0.001105740626639911, 'l1_Layer_3': 0.006733233786083922, 'l1_Layer_4': 0.003979276513777696, 'n_units_Layer_1': 125, 'n_units_Layer_2': 75, 'n_units_Layer_3': 100, 'n_units_Layer_4': 55}. Best is trial 504 with value: 1.5555013884610895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 74.72% | rMAE for Validation Set is: 1.84\n",
      "MAE for Test Set is: 67.04 | sMAPE for Test Set is: 149.88% | rMAE for Test Set is: 3.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:21:49,283]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:21:58,466]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:22:16,336]\u001b[0m Trial 515 finished with value: 5.7967838352293235 and parameters: {'n_hidden': 3, 'learning_rate': 0.006123332694511818, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19695202727856048, 'dropout_rate_Layer_2': 0.21411196335296712, 'dropout_rate_Layer_3': 0.28528568257452075, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010417507064046571, 'l1_Layer_2': 0.0003952404913745096, 'l1_Layer_3': 9.391860731918541e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 220, 'n_units_Layer_3': 245}. Best is trial 504 with value: 1.5555013884610895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 75.18% | rMAE for Validation Set is: 1.82\n",
      "MAE for Test Set is: 71.09 | sMAPE for Test Set is: 170.46% | rMAE for Test Set is: 4.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:22:26,660]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:22:35,993]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:22:40,598]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:22:50,983]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:22:57,963]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:23:05,342]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:23:10,396]\u001b[0m Trial 518 finished with value: 6.009340460001591 and parameters: {'n_hidden': 4, 'learning_rate': 0.053939490327103885, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.350980462055062, 'dropout_rate_Layer_2': 0.155863679215533, 'dropout_rate_Layer_3': 0.20919833747931457, 'dropout_rate_Layer_4': 0.22116766958213674, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0006543980432557812, 'l1_Layer_2': 0.002824853013264121, 'l1_Layer_3': 0.0011212118188502836, 'l1_Layer_4': 0.009525682319650147, 'n_units_Layer_1': 125, 'n_units_Layer_2': 180, 'n_units_Layer_3': 290, 'n_units_Layer_4': 165}. Best is trial 504 with value: 1.5555013884610895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.01 | sMAPE for Validation Set is: 77.93% | rMAE for Validation Set is: 1.88\n",
      "MAE for Test Set is: 70.56 | sMAPE for Test Set is: 167.50% | rMAE for Test Set is: 4.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:23:20,832]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:23:30,569]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:23:55,619]\u001b[0m Trial 522 finished with value: 2.4880050436473047 and parameters: {'n_hidden': 3, 'learning_rate': 0.030645576400732972, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37058313971628676, 'dropout_rate_Layer_2': 0.3745491596626808, 'dropout_rate_Layer_3': 0.13804075548160286, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005409666958323046, 'l1_Layer_2': 0.00343851478129939, 'l1_Layer_3': 0.005489456714792851, 'n_units_Layer_1': 125, 'n_units_Layer_2': 205, 'n_units_Layer_3': 255}. Best is trial 504 with value: 1.5555013884610895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.49 | sMAPE for Validation Set is: 44.32% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 10.32 | sMAPE for Test Set is: 13.07% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:24:30,225]\u001b[0m Trial 525 finished with value: 1.965779101710521 and parameters: {'n_hidden': 3, 'learning_rate': 0.02675087445060316, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3995492981061062, 'dropout_rate_Layer_2': 0.3749755864647651, 'dropout_rate_Layer_3': 0.19012945727634842, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.6722966198255995e-05, 'l1_Layer_2': 0.00027249773174593616, 'l1_Layer_3': 1.0197195635796063e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 145, 'n_units_Layer_3': 255}. Best is trial 504 with value: 1.5555013884610895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 35.65% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.75 | sMAPE for Test Set is: 13.94% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:24:35,455]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:24:57,105]\u001b[0m Trial 526 finished with value: 2.02933243556275 and parameters: {'n_hidden': 3, 'learning_rate': 0.008079227964658183, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39953322096910404, 'dropout_rate_Layer_2': 0.3479769125155919, 'dropout_rate_Layer_3': 0.0970686334332172, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.0686461753446014e-05, 'l1_Layer_2': 0.0002664971698106788, 'l1_Layer_3': 1.4360753294804225e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 145, 'n_units_Layer_3': 300}. Best is trial 504 with value: 1.5555013884610895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 41.41% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.35 | sMAPE for Test Set is: 13.10% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:25:02,462]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:25:02,832]\u001b[0m Trial 528 finished with value: 6.001426935682943 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011031539529589162, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13087531426988364, 'dropout_rate_Layer_2': 0.11180592318791206, 'dropout_rate_Layer_3': 0.18958949374177478, 'dropout_rate_Layer_4': 0.2914826217198596, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.05435522217202182, 'l1_Layer_2': 0.003098837615390171, 'l1_Layer_3': 0.0702165263789667, 'l1_Layer_4': 0.003621866205596944, 'n_units_Layer_1': 120, 'n_units_Layer_2': 75, 'n_units_Layer_3': 60, 'n_units_Layer_4': 50}. Best is trial 504 with value: 1.5555013884610895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.00 | sMAPE for Validation Set is: 75.29% | rMAE for Validation Set is: 1.88\n",
      "MAE for Test Set is: 67.74 | sMAPE for Test Set is: 152.79% | rMAE for Test Set is: 4.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:25:16,615]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:25:17,161]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:25:32,950]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:25:39,642]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:25:47,240]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:26:00,169]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:26:04,526]\u001b[0m Trial 532 finished with value: 1.3737040134578142 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015857913862370925, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3313557729825929, 'dropout_rate_Layer_2': 0.36647735256592573, 'dropout_rate_Layer_3': 0.02261536476928413, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7338419510568555e-05, 'l1_Layer_2': 0.004526692741867399, 'l1_Layer_3': 0.006181584382388104, 'n_units_Layer_1': 275, 'n_units_Layer_2': 175, 'n_units_Layer_3': 155}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.37 | sMAPE for Validation Set is: 20.93% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 11.13 | sMAPE for Test Set is: 14.49% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:26:09,646]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:26:16,465]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:26:21,661]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:26:26,687]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:26:43,717]\u001b[0m Trial 542 finished with value: 5.279333555406182 and parameters: {'n_hidden': 4, 'learning_rate': 0.014897343168878368, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08342107822472045, 'dropout_rate_Layer_2': 0.1553081845515071, 'dropout_rate_Layer_3': 0.39950663541653, 'dropout_rate_Layer_4': 0.010594576894434991, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.910514550867536e-05, 'l1_Layer_2': 2.6536742588908257e-05, 'l1_Layer_3': 0.0019094569658492046, 'l1_Layer_4': 0.005690156113340169, 'n_units_Layer_1': 175, 'n_units_Layer_2': 55, 'n_units_Layer_3': 110, 'n_units_Layer_4': 95}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 69.47% | rMAE for Validation Set is: 1.66\n",
      "MAE for Test Set is: 45.25 | sMAPE for Test Set is: 74.53% | rMAE for Test Set is: 2.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:26:51,253]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:26:56,832]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:27:01,853]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:27:02,277]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:27:09,318]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:27:24,621]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:27:51,355]\u001b[0m Trial 549 finished with value: 5.913657777798652 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010488190845302971, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16787725170877885, 'dropout_rate_Layer_2': 0.10954121326425412, 'dropout_rate_Layer_3': 0.2572516534614642, 'dropout_rate_Layer_4': 0.2525449506479309, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.02000566861996086, 'l1_Layer_2': 0.0012535612965323148, 'l1_Layer_3': 0.010084106860353896, 'l1_Layer_4': 0.009032765681714482, 'n_units_Layer_1': 135, 'n_units_Layer_2': 80, 'n_units_Layer_3': 80, 'n_units_Layer_4': 75}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.91 | sMAPE for Validation Set is: 75.29% | rMAE for Validation Set is: 1.85\n",
      "MAE for Test Set is: 68.45 | sMAPE for Test Set is: 156.54% | rMAE for Test Set is: 4.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:27:57,062]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:28:14,328]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:28:24,278]\u001b[0m Trial 547 finished with value: 2.1211824093345366 and parameters: {'n_hidden': 3, 'learning_rate': 0.0078075055491837455, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.381033151573984, 'dropout_rate_Layer_2': 0.32531397330236944, 'dropout_rate_Layer_3': 0.08827209710995286, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.807403519866425e-05, 'l1_Layer_2': 0.00019626451088389747, 'l1_Layer_3': 1.7091728265709703e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 160, 'n_units_Layer_3': 220}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 38.24% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.95 | sMAPE for Test Set is: 15.48% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:28:29,743]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:28:34,806]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:28:42,078]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:28:46,623]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:28:46,837]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:28:54,646]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:28:54,739]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:29:01,852]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:29:04,248]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:29:08,810]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:29:13,902]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:29:21,516]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:29:26,597]\u001b[0m Trial 562 finished with value: 10.066342990865502 and parameters: {'n_hidden': 3, 'learning_rate': 0.014493962228555526, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38636869360252957, 'dropout_rate_Layer_2': 0.34998947011443515, 'dropout_rate_Layer_3': 0.10041548963822104, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 9.453474348539724e-05, 'l1_Layer_2': 0.00010056610725939353, 'l1_Layer_3': 3.322299599492703e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 145, 'n_units_Layer_3': 200}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.07 | sMAPE for Validation Set is: 91.15% | rMAE for Validation Set is: 3.16\n",
      "MAE for Test Set is: 55.04 | sMAPE for Test Set is: 100.87% | rMAE for Test Set is: 3.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:29:28,403]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:29:34,053]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:29:36,733]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:29:45,230]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:30:17,733]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:30:24,742]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:30:31,767]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:30:32,317]\u001b[0m Trial 568 finished with value: 1.9613371146655012 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015490545849844296, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27522608681713634, 'dropout_rate_Layer_2': 0.33674858595587154, 'dropout_rate_Layer_3': 0.09773598982695514, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.682954094770326e-05, 'l1_Layer_2': 0.0157384864537427, 'l1_Layer_3': 0.0052810084136549855, 'n_units_Layer_1': 235, 'n_units_Layer_2': 190, 'n_units_Layer_3': 160}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 38.09% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.71 | sMAPE for Test Set is: 13.23% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:30:44,081]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:30:51,879]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:30:58,690]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:31:08,293]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:31:15,757]\u001b[0m Trial 574 finished with value: 6.212031957760051 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006929760885830691, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11671079196084568, 'dropout_rate_Layer_2': 0.08532778487315273, 'dropout_rate_Layer_3': 0.32031661801509964, 'dropout_rate_Layer_4': 0.3349734744954267, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.030059497035574173, 'l1_Layer_2': 0.019793153640870326, 'l1_Layer_3': 0.02626104909397659, 'l1_Layer_4': 0.08831097316316742, 'n_units_Layer_1': 300, 'n_units_Layer_2': 60, 'n_units_Layer_3': 105, 'n_units_Layer_4': 125}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 75.93% | rMAE for Validation Set is: 1.95\n",
      "MAE for Test Set is: 66.59 | sMAPE for Test Set is: 147.15% | rMAE for Test Set is: 3.94\n",
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 74.42% | rMAE for Validation Set is: 1.81\n",
      "MAE for Test Set is: 66.71 | sMAPE for Test Set is: 148.95% | rMAE for Test Set is: 3.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:31:30,152]\u001b[0m Trial 578 finished with value: 5.784104858142086 and parameters: {'n_hidden': 4, 'learning_rate': 0.00483920446190391, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11868364209439408, 'dropout_rate_Layer_2': 0.2922638256525695, 'dropout_rate_Layer_3': 0.36118806897327516, 'dropout_rate_Layer_4': 0.0059010253958053, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00012568079584486663, 'l1_Layer_2': 2.681215418227756e-05, 'l1_Layer_3': 0.0013716747524191559, 'l1_Layer_4': 0.001485919614663723, 'n_units_Layer_1': 145, 'n_units_Layer_2': 60, 'n_units_Layer_3': 115, 'n_units_Layer_4': 125}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:31:31,055]\u001b[0m Trial 579 finished with value: 5.607149070396176 and parameters: {'n_hidden': 3, 'learning_rate': 0.004783527237631287, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3986269239584012, 'dropout_rate_Layer_2': 0.2933076362768809, 'dropout_rate_Layer_3': 0.05344387434673652, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.519772902960731e-05, 'l1_Layer_2': 0.00028775803817659377, 'l1_Layer_3': 1.4929542373424463e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 140, 'n_units_Layer_3': 230}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 70.43% | rMAE for Validation Set is: 1.76\n",
      "MAE for Test Set is: 46.26 | sMAPE for Test Set is: 75.41% | rMAE for Test Set is: 2.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:31:38,048]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:31:42,872]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:31:46,287]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:31:53,365]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:31:59,061]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:32:03,944]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:32:08,543]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:32:08,944]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:32:16,129]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:32:18,910]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:32:23,366]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:32:26,312]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:32:30,666]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:32:31,144]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:32:38,921]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:32:43,733]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:32:56,155]\u001b[0m Trial 595 finished with value: 4.643639610390366 and parameters: {'n_hidden': 3, 'learning_rate': 0.02189450036670658, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13200074150955948, 'dropout_rate_Layer_2': 0.38133402238207925, 'dropout_rate_Layer_3': 0.01662978870750728, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020337478927312728, 'l1_Layer_2': 0.0006188049944094518, 'l1_Layer_3': 2.7024918883194903e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 160, 'n_units_Layer_3': 300}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 63.20% | rMAE for Validation Set is: 1.46\n",
      "MAE for Test Set is: 23.33 | sMAPE for Test Set is: 28.33% | rMAE for Test Set is: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:33:00,767]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:33:05,590]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:33:08,183]\u001b[0m Trial 597 finished with value: 5.745964517385294 and parameters: {'n_hidden': 3, 'learning_rate': 0.022402562759678495, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12941335338769996, 'dropout_rate_Layer_2': 0.3816181151360498, 'dropout_rate_Layer_3': 0.17611475846444324, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002665862653969006, 'l1_Layer_2': 0.0012032397728802366, 'l1_Layer_3': 2.8590753772141793e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 160, 'n_units_Layer_3': 300}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.75 | sMAPE for Validation Set is: 70.28% | rMAE for Validation Set is: 1.80\n",
      "MAE for Test Set is: 24.23 | sMAPE for Test Set is: 30.15% | rMAE for Test Set is: 1.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:33:21,768]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:33:32,205]\u001b[0m Trial 600 finished with value: 4.283614148301389 and parameters: {'n_hidden': 4, 'learning_rate': 0.004956047989049471, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13316904255703158, 'dropout_rate_Layer_2': 0.23107444609531289, 'dropout_rate_Layer_3': 0.3493742970847703, 'dropout_rate_Layer_4': 0.03068743836506376, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00017287219727674512, 'l1_Layer_2': 2.715428782425975e-05, 'l1_Layer_3': 0.0011237646893636954, 'l1_Layer_4': 0.0005880759429421255, 'n_units_Layer_1': 195, 'n_units_Layer_2': 110, 'n_units_Layer_3': 115, 'n_units_Layer_4': 85}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 58.77% | rMAE for Validation Set is: 1.34\n",
      "MAE for Test Set is: 51.96 | sMAPE for Test Set is: 93.73% | rMAE for Test Set is: 3.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:33:39,256]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:33:43,924]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:33:51,277]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:33:58,778]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 74.57% | rMAE for Validation Set is: 1.84\n",
      "MAE for Test Set is: 60.58 | sMAPE for Test Set is: 122.34% | rMAE for Test Set is: 3.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:34:08,459]\u001b[0m Trial 604 finished with value: 5.864861051219418 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022693665762474097, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03774460112289607, 'dropout_rate_Layer_2': 0.2577217381303821, 'dropout_rate_Layer_3': 0.18420157574694637, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 6.059334679406895e-05, 'l1_Layer_2': 0.0001821601448118135, 'l1_Layer_3': 5.72345316351216e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 125, 'n_units_Layer_3': 190}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:34:16,422]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:34:30,886]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:34:31,065]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:34:45,764]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:34:51,256]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:34:59,133]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:35:13,062]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:35:19,113]\u001b[0m Trial 610 finished with value: 4.6801804697181515 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005022583152171823, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.062490555772619014, 'dropout_rate_Layer_2': 0.13128704705490446, 'dropout_rate_Layer_3': 0.23742301550756478, 'dropout_rate_Layer_4': 0.32486775404210805, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.014360212561763449, 'l1_Layer_2': 0.003916416859077918, 'l1_Layer_3': 0.02044629587569529, 'l1_Layer_4': 0.0019090419597271083, 'n_units_Layer_1': 275, 'n_units_Layer_2': 95, 'n_units_Layer_3': 175, 'n_units_Layer_4': 110}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 61.65% | rMAE for Validation Set is: 1.47\n",
      "MAE for Test Set is: 63.64 | sMAPE for Test Set is: 132.85% | rMAE for Test Set is: 3.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:35:26,066]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:35:38,144]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:35:50,884]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:36:01,368]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:36:07,972]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:36:15,698]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:36:15,778]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:36:27,425]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:36:42,404]\u001b[0m Trial 622 finished with value: 5.0187312094558685 and parameters: {'n_hidden': 4, 'learning_rate': 0.0040305640121748336, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1327286369382112, 'dropout_rate_Layer_2': 0.222907510905464, 'dropout_rate_Layer_3': 0.3167046682260681, 'dropout_rate_Layer_4': 0.01822428891357741, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00017230216029025925, 'l1_Layer_2': 1.970079221844685e-05, 'l1_Layer_3': 0.006624620289634022, 'l1_Layer_4': 0.0007311188909876024, 'n_units_Layer_1': 190, 'n_units_Layer_2': 120, 'n_units_Layer_3': 115, 'n_units_Layer_4': 105}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.02 | sMAPE for Validation Set is: 66.54% | rMAE for Validation Set is: 1.57\n",
      "MAE for Test Set is: 40.59 | sMAPE for Test Set is: 64.90% | rMAE for Test Set is: 2.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:36:42,911]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:36:55,715]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:37:04,935]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:37:10,071]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:37:10,978]\u001b[0m Trial 626 finished with value: 5.695844674161329 and parameters: {'n_hidden': 4, 'learning_rate': 0.004416525820310936, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13644753564870163, 'dropout_rate_Layer_2': 0.22135684041868325, 'dropout_rate_Layer_3': 0.31500900487673034, 'dropout_rate_Layer_4': 0.08573203317158345, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00018692888432438466, 'l1_Layer_2': 1.994747859103674e-05, 'l1_Layer_3': 0.006373481808521809, 'l1_Layer_4': 0.0007913809422503466, 'n_units_Layer_1': 195, 'n_units_Layer_2': 115, 'n_units_Layer_3': 115, 'n_units_Layer_4': 105}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.70 | sMAPE for Validation Set is: 71.79% | rMAE for Validation Set is: 1.79\n",
      "MAE for Test Set is: 59.13 | sMAPE for Test Set is: 117.37% | rMAE for Test Set is: 3.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:37:19,537]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:37:26,916]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:37:41,185]\u001b[0m Trial 629 finished with value: 1.4661230866137818 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026479696661025616, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12581014866069687, 'dropout_rate_Layer_2': 0.16588732963830588, 'dropout_rate_Layer_3': 0.04486125365786067, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002500968990257803, 'l1_Layer_2': 0.00852776220090077, 'l1_Layer_3': 0.003183033259161604, 'n_units_Layer_1': 220, 'n_units_Layer_2': 210, 'n_units_Layer_3': 180}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 24.14% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.31 | sMAPE for Test Set is: 14.72% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:37:48,734]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:37:54,030]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:38:01,483]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:38:18,504]\u001b[0m Trial 632 finished with value: 4.4038519758801 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006916229909224493, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04866654347964892, 'dropout_rate_Layer_2': 0.16461473590096046, 'dropout_rate_Layer_3': 0.24123760688763157, 'dropout_rate_Layer_4': 0.2660941261779508, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.013420855827370848, 'l1_Layer_2': 0.0020325761122809093, 'l1_Layer_3': 0.028795031645252104, 'l1_Layer_4': 0.009385249513814205, 'n_units_Layer_1': 260, 'n_units_Layer_2': 75, 'n_units_Layer_3': 190, 'n_units_Layer_4': 65}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 79.76% | rMAE for Validation Set is: 1.38\n",
      "MAE for Test Set is: 48.73 | sMAPE for Test Set is: 87.55% | rMAE for Test Set is: 2.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:38:45,910]\u001b[0m Trial 636 finished with value: 4.5033174607570015 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006060464076897848, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04774645071497541, 'dropout_rate_Layer_2': 0.13489252778883515, 'dropout_rate_Layer_3': 0.24021325875593147, 'dropout_rate_Layer_4': 0.25828817422658656, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.008399778957551776, 'l1_Layer_2': 0.0016484679588519013, 'l1_Layer_3': 0.03737715382844994, 'l1_Layer_4': 0.008020470965472138, 'n_units_Layer_1': 265, 'n_units_Layer_2': 70, 'n_units_Layer_3': 155, 'n_units_Layer_4': 65}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 72.10% | rMAE for Validation Set is: 1.41\n",
      "MAE for Test Set is: 68.56 | sMAPE for Test Set is: 138.06% | rMAE for Test Set is: 4.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:38:48,795]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:38:52,993]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:38:53,484]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:39:01,341]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:39:08,023]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:39:20,460]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:39:40,664]\u001b[0m Trial 641 finished with value: 3.501898096287372 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006223539341454726, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.047409620170538846, 'dropout_rate_Layer_2': 0.16425392931338761, 'dropout_rate_Layer_3': 0.23934398492835393, 'dropout_rate_Layer_4': 0.24546188429120014, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00798435435447432, 'l1_Layer_2': 0.0016243325701275038, 'l1_Layer_3': 0.01815609429477633, 'l1_Layer_4': 0.008679467206519098, 'n_units_Layer_1': 265, 'n_units_Layer_2': 65, 'n_units_Layer_3': 195, 'n_units_Layer_4': 150}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.50 | sMAPE for Validation Set is: 57.81% | rMAE for Validation Set is: 1.10\n",
      "MAE for Test Set is: 41.08 | sMAPE for Test Set is: 62.73% | rMAE for Test Set is: 2.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:40:07,325]\u001b[0m Trial 644 finished with value: 3.0675544775492516 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006011747806731251, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.049621472387935864, 'dropout_rate_Layer_2': 0.16682318857734357, 'dropout_rate_Layer_3': 0.1950790506219938, 'dropout_rate_Layer_4': 0.22495919568689074, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.007928775333086037, 'l1_Layer_2': 0.0019078316435530824, 'l1_Layer_3': 0.017873759556489184, 'l1_Layer_4': 0.0093068365644875, 'n_units_Layer_1': 265, 'n_units_Layer_2': 60, 'n_units_Layer_3': 185, 'n_units_Layer_4': 150}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.07 | sMAPE for Validation Set is: 54.62% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 15.13 | sMAPE for Test Set is: 17.67% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:40:28,006]\u001b[0m Trial 645 finished with value: 2.096215636566378 and parameters: {'n_hidden': 3, 'learning_rate': 0.0870927652050844, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3883995337513721, 'dropout_rate_Layer_2': 0.3754848950805064, 'dropout_rate_Layer_3': 0.1497452715338752, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.7074695394736865e-05, 'l1_Layer_2': 0.0004840428396398962, 'l1_Layer_3': 1.0088326722043821e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 135, 'n_units_Layer_3': 255}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.10 | sMAPE for Validation Set is: 42.21% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 13.45 | sMAPE for Test Set is: 15.63% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:40:35,285]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:40:37,768]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:40:42,028]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:40:47,392]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:40:49,965]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:40:54,312]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:40:54,691]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:41:01,107]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:41:06,177]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:41:12,700]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:41:15,841]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:41:20,655]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:41:22,902]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:41:29,755]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:41:31,478]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:41:35,820]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:41:38,034]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:41:41,035]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:41:45,819]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:41:51,271]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:41:55,372]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:42:00,583]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:42:39,992]\u001b[0m Trial 669 finished with value: 3.0698049872239204 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005992709177570976, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.045442892518441844, 'dropout_rate_Layer_2': 0.17433290940651489, 'dropout_rate_Layer_3': 0.1856973854720606, 'dropout_rate_Layer_4': 0.22974809270629581, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.007693845834356934, 'l1_Layer_2': 0.0018535379422712412, 'l1_Layer_3': 0.016387945659280416, 'l1_Layer_4': 0.010849041650500655, 'n_units_Layer_1': 265, 'n_units_Layer_2': 55, 'n_units_Layer_3': 190, 'n_units_Layer_4': 160}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.07 | sMAPE for Validation Set is: 58.87% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 42.33 | sMAPE for Test Set is: 64.15% | rMAE for Test Set is: 2.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:42:49,658]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:42:54,965]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:43:04,388]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:43:09,708]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:43:17,259]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.77 | sMAPE for Validation Set is: 42.31% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 16.10 | sMAPE for Test Set is: 19.13% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:43:20,146]\u001b[0m Trial 668 finished with value: 1.7695672265696185 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006423986993498493, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04470873238399174, 'dropout_rate_Layer_2': 0.17905219508606623, 'dropout_rate_Layer_3': 0.14990559763447536, 'dropout_rate_Layer_4': 0.24325188856628222, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00899104763185431, 'l1_Layer_2': 0.0008974646354684774, 'l1_Layer_3': 0.016857896792343705, 'l1_Layer_4': 0.013555533672475507, 'n_units_Layer_1': 260, 'n_units_Layer_2': 55, 'n_units_Layer_3': 190, 'n_units_Layer_4': 155}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:43:29,791]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:43:36,698]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:43:49,155]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:43:52,292]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:43:57,086]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:44:01,738]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:44:11,596]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:44:18,673]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:44:26,651]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:44:44,152]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:44:49,512]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:45:11,640]\u001b[0m Trial 685 finished with value: 2.7947774337702533 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006184862367858795, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3655461581051845, 'dropout_rate_Layer_2': 0.17859621186929522, 'dropout_rate_Layer_3': 0.13450322518414076, 'dropout_rate_Layer_4': 0.21594926401045483, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.010240545627766929, 'l1_Layer_2': 0.000886948001392367, 'l1_Layer_3': 0.03674602475087434, 'l1_Layer_4': 0.010167304158541758, 'n_units_Layer_1': 250, 'n_units_Layer_2': 60, 'n_units_Layer_3': 190, 'n_units_Layer_4': 150}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.79 | sMAPE for Validation Set is: 48.77% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 36.52 | sMAPE for Test Set is: 50.95% | rMAE for Test Set is: 2.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:45:14,400]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:45:19,555]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:45:26,553]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:45:26,924]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:45:36,994]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:45:39,665]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:45:49,285]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:45:52,038]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:45:59,046]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:45:59,660]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:46:28,289]\u001b[0m Trial 697 finished with value: 1.7494632606071348 and parameters: {'n_hidden': 3, 'learning_rate': 0.004081679945631787, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38771626026514017, 'dropout_rate_Layer_2': 0.08822335100334294, 'dropout_rate_Layer_3': 0.16065644018393976, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.039307907995594e-05, 'l1_Layer_2': 0.05154151505705635, 'l1_Layer_3': 0.011379338693030495, 'n_units_Layer_1': 270, 'n_units_Layer_2': 185, 'n_units_Layer_3': 150}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.75 | sMAPE for Validation Set is: 30.76% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 11.02 | sMAPE for Test Set is: 14.28% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:46:35,427]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:46:35,641]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:46:46,450]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:46:46,541]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:46:56,428]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:46:56,535]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:47:06,867]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:47:07,150]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:47:14,135]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:47:14,288]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:47:23,173]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:47:28,991]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:47:33,603]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:47:40,951]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:47:58,265]\u001b[0m Trial 711 finished with value: 2.2028350973527737 and parameters: {'n_hidden': 3, 'learning_rate': 0.0049477169395208956, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3838453059979984, 'dropout_rate_Layer_2': 0.1095529676488993, 'dropout_rate_Layer_3': 0.16762309024597744, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2498423700397646e-05, 'l1_Layer_2': 0.04334260985388988, 'l1_Layer_3': 0.012275619978102989, 'n_units_Layer_1': 270, 'n_units_Layer_2': 160, 'n_units_Layer_3': 170}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.20 | sMAPE for Validation Set is: 38.45% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.64 | sMAPE for Test Set is: 15.44% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:48:20,275]\u001b[0m Trial 714 finished with value: 5.069385489458936 and parameters: {'n_hidden': 4, 'learning_rate': 0.005245805589621474, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12034591040205256, 'dropout_rate_Layer_2': 0.24271764629470868, 'dropout_rate_Layer_3': 0.3824867550125578, 'dropout_rate_Layer_4': 0.10568085732123754, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00017982798886068563, 'l1_Layer_2': 1.786269021218692e-05, 'l1_Layer_3': 0.007567045926268313, 'l1_Layer_4': 0.0004591828790639176, 'n_units_Layer_1': 190, 'n_units_Layer_2': 110, 'n_units_Layer_3': 100, 'n_units_Layer_4': 110}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.07 | sMAPE for Validation Set is: 66.77% | rMAE for Validation Set is: 1.59\n",
      "MAE for Test Set is: 46.92 | sMAPE for Test Set is: 81.96% | rMAE for Test Set is: 2.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:48:29,530]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:48:34,760]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:48:56,894]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:49:05,397]\u001b[0m Trial 713 finished with value: 1.9429747502064414 and parameters: {'n_hidden': 3, 'learning_rate': 0.0450028409352528, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37250687377046654, 'dropout_rate_Layer_2': 0.35425975483331684, 'dropout_rate_Layer_3': 0.27879612056608255, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7572082604763003e-05, 'l1_Layer_2': 0.0007627637557113455, 'l1_Layer_3': 1.501637188020008e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 150, 'n_units_Layer_3': 240}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 47.62% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 13.87 | sMAPE for Test Set is: 17.95% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:49:12,252]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:49:24,618]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:49:31,944]\u001b[0m Trial 718 finished with value: 2.0718131800105195 and parameters: {'n_hidden': 3, 'learning_rate': 0.005734706038823346, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3750543277036212, 'dropout_rate_Layer_2': 0.056583806107023, 'dropout_rate_Layer_3': 0.16196808052804684, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.331594457737668e-05, 'l1_Layer_2': 0.05100780646756337, 'l1_Layer_3': 0.01570468719081117, 'n_units_Layer_1': 275, 'n_units_Layer_2': 160, 'n_units_Layer_3': 140}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 36.71% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.36 | sMAPE for Test Set is: 14.57% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:49:37,169]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:49:37,407]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:49:48,947]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:49:49,270]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:49:57,904]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:50:01,187]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:50:16,610]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:50:21,621]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:50:26,360]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:50:36,617]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:50:41,994]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:50:46,643]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:50:53,416]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:50:58,904]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:51:04,150]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:51:09,502]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:51:15,989]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:51:27,239]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:51:32,270]\u001b[0m Trial 734 finished with value: 2.8062024569899506 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005647288060573947, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.036178747892834005, 'dropout_rate_Layer_2': 0.1609326614624635, 'dropout_rate_Layer_3': 0.17550112828090944, 'dropout_rate_Layer_4': 0.17043292390761178, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0044642652210647735, 'l1_Layer_2': 0.0002527473568916589, 'l1_Layer_3': 0.0006293134029583752, 'l1_Layer_4': 0.01827747726356147, 'n_units_Layer_1': 235, 'n_units_Layer_2': 65, 'n_units_Layer_3': 180, 'n_units_Layer_4': 225}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.81 | sMAPE for Validation Set is: 47.44% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 42.83 | sMAPE for Test Set is: 66.97% | rMAE for Test Set is: 2.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:51:41,804]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:51:57,332]\u001b[0m Trial 742 finished with value: 5.476168954003543 and parameters: {'n_hidden': 3, 'learning_rate': 0.04344955361304441, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3081528532812159, 'dropout_rate_Layer_2': 0.3144660294586684, 'dropout_rate_Layer_3': 0.28494026806642314, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.334222246099638e-05, 'l1_Layer_2': 9.448095004155437e-05, 'l1_Layer_3': 1.4995797457569688e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 300, 'n_units_Layer_3': 245}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:51:57,400]\u001b[0m Trial 740 finished with value: 5.282698163260103 and parameters: {'n_hidden': 4, 'learning_rate': 0.004081491973341725, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10094171538569102, 'dropout_rate_Layer_2': 0.24279241950801003, 'dropout_rate_Layer_3': 0.21135540350623003, 'dropout_rate_Layer_4': 0.0733400005640005, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00016666531489188704, 'l1_Layer_2': 0.0016100929435390664, 'l1_Layer_3': 0.005374800232042873, 'l1_Layer_4': 0.00045331871898401146, 'n_units_Layer_1': 75, 'n_units_Layer_2': 280, 'n_units_Layer_3': 135, 'n_units_Layer_4': 85}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 90.06% | rMAE for Validation Set is: 1.72\n",
      "MAE for Test Set is: 22.56 | sMAPE for Test Set is: 28.98% | rMAE for Test Set is: 1.34\n",
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 68.82% | rMAE for Validation Set is: 1.66\n",
      "MAE for Test Set is: 55.54 | sMAPE for Test Set is: 104.29% | rMAE for Test Set is: 3.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:52:06,719]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:52:11,012]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:52:11,384]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:52:20,394]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:52:28,142]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:52:47,355]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:52:55,197]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:53:05,097]\u001b[0m Trial 748 finished with value: 4.091645929778934 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005007747667462595, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02989655908779868, 'dropout_rate_Layer_2': 0.16630238078219473, 'dropout_rate_Layer_3': 0.13614280613717228, 'dropout_rate_Layer_4': 0.15878866673959297, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0047886756952270435, 'l1_Layer_2': 0.00018154401831026664, 'l1_Layer_3': 0.00026705482053523684, 'l1_Layer_4': 0.021227750686094823, 'n_units_Layer_1': 230, 'n_units_Layer_2': 105, 'n_units_Layer_3': 200, 'n_units_Layer_4': 225}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 60.17% | rMAE for Validation Set is: 1.28\n",
      "MAE for Test Set is: 43.08 | sMAPE for Test Set is: 66.89% | rMAE for Test Set is: 2.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:53:28,333]\u001b[0m Trial 752 finished with value: 2.4492867896248596 and parameters: {'n_hidden': 3, 'learning_rate': 0.013351573231264733, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.370944355476436, 'dropout_rate_Layer_2': 0.350929253574386, 'dropout_rate_Layer_3': 0.12168158270084556, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012945909033828032, 'l1_Layer_2': 0.0007470694493842893, 'l1_Layer_3': 2.1772066581479466e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 150, 'n_units_Layer_3': 230}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.45 | sMAPE for Validation Set is: 51.18% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 11.96 | sMAPE for Test Set is: 15.29% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:53:39,550]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:53:45,113]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:53:52,570]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:53:59,389]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:54:05,126]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:54:12,622]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:54:13,088]\u001b[0m Trial 751 finished with value: 1.7788239634140783 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005075909584877443, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2009139343735036, 'dropout_rate_Layer_2': 0.21419923545272235, 'dropout_rate_Layer_3': 0.13420099941297975, 'dropout_rate_Layer_4': 0.16438750467682156, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.012844740755280413, 'l1_Layer_2': 6.462491099570823e-05, 'l1_Layer_3': 0.0005270154384689536, 'l1_Layer_4': 0.05233881198165084, 'n_units_Layer_1': 225, 'n_units_Layer_2': 105, 'n_units_Layer_3': 175, 'n_units_Layer_4': 245}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.78 | sMAPE for Validation Set is: 40.09% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 20.68 | sMAPE for Test Set is: 24.41% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:54:20,354]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:54:20,808]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:54:28,633]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:54:33,162]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:54:42,750]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:54:54,922]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:54:59,954]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:55:02,877]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:55:17,103]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:55:22,780]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:55:32,678]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:55:40,204]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:55:50,601]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:55:55,384]\u001b[0m Trial 767 finished with value: 3.4128341617574267 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005040538875547858, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23114420426894824, 'dropout_rate_Layer_2': 0.20164876801431708, 'dropout_rate_Layer_3': 0.16032621922711163, 'dropout_rate_Layer_4': 0.15975239593033985, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.010010027304240781, 'l1_Layer_2': 0.00011963801758234608, 'l1_Layer_3': 0.0007795837904631711, 'l1_Layer_4': 0.029228554020474654, 'n_units_Layer_1': 235, 'n_units_Layer_2': 80, 'n_units_Layer_3': 180, 'n_units_Layer_4': 250}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.41 | sMAPE for Validation Set is: 66.25% | rMAE for Validation Set is: 1.07\n",
      "MAE for Test Set is: 15.77 | sMAPE for Test Set is: 18.48% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:55:55,902]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:56:03,182]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:56:10,916]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:56:15,838]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:56:20,520]\u001b[0m Trial 775 finished with value: 6.368039952254229 and parameters: {'n_hidden': 4, 'learning_rate': 0.001086410565599402, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11685362986981696, 'dropout_rate_Layer_2': 0.21310029538202596, 'dropout_rate_Layer_3': 0.31084462003188246, 'dropout_rate_Layer_4': 0.12883504929046724, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00014709111781432418, 'l1_Layer_2': 3.453722764247967e-05, 'l1_Layer_3': 0.004345746024565502, 'l1_Layer_4': 0.00011819227701685598, 'n_units_Layer_1': 180, 'n_units_Layer_2': 290, 'n_units_Layer_3': 100, 'n_units_Layer_4': 95}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 76.64% | rMAE for Validation Set is: 2.00\n",
      "MAE for Test Set is: 66.10 | sMAPE for Test Set is: 144.85% | rMAE for Test Set is: 3.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:56:37,538]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:56:43,438]\u001b[0m Trial 779 finished with value: 1.864675322422963 and parameters: {'n_hidden': 3, 'learning_rate': 0.005432602221535079, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2897445201277921, 'dropout_rate_Layer_2': 0.09483171210610418, 'dropout_rate_Layer_3': 0.1551475023838955, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.124695196350668e-05, 'l1_Layer_2': 0.08514488744051961, 'l1_Layer_3': 0.005920000289048148, 'n_units_Layer_1': 65, 'n_units_Layer_2': 160, 'n_units_Layer_3': 145}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.86 | sMAPE for Validation Set is: 31.23% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.99 | sMAPE for Test Set is: 13.84% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:56:52,836]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:57:00,041]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:57:15,677]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:57:32,942]\u001b[0m Trial 784 finished with value: 6.245963276667847 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013332851119782377, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11227933049691272, 'dropout_rate_Layer_2': 0.20873585815204224, 'dropout_rate_Layer_3': 0.38706331539310845, 'dropout_rate_Layer_4': 0.10734722866444044, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00011380770112444212, 'l1_Layer_2': 0.0015662611707422777, 'l1_Layer_3': 0.0030399346248011585, 'l1_Layer_4': 0.0001657072193488423, 'n_units_Layer_1': 175, 'n_units_Layer_2': 90, 'n_units_Layer_3': 95, 'n_units_Layer_4': 80}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.25 | sMAPE for Validation Set is: 76.12% | rMAE for Validation Set is: 1.96\n",
      "MAE for Test Set is: 66.52 | sMAPE for Test Set is: 146.89% | rMAE for Test Set is: 3.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:57:38,153]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:58:07,619]\u001b[0m Trial 786 finished with value: 7.623166199602679 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009522449076562156, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10865456340478317, 'dropout_rate_Layer_2': 0.20332134666928314, 'dropout_rate_Layer_3': 0.3773892443584665, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011025379617902874, 'l1_Layer_2': 0.0011995038043454876, 'l1_Layer_3': 0.003050150050014164, 'n_units_Layer_1': 180, 'n_units_Layer_2': 295, 'n_units_Layer_3': 90}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.62 | sMAPE for Validation Set is: 82.14% | rMAE for Validation Set is: 2.39\n",
      "MAE for Test Set is: 26.58 | sMAPE for Test Set is: 32.17% | rMAE for Test Set is: 1.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:58:15,426]\u001b[0m Trial 783 finished with value: 2.9119546328782486 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006046809306920437, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18857358802111246, 'dropout_rate_Layer_2': 0.18922985789181893, 'dropout_rate_Layer_3': 0.15591766171188273, 'dropout_rate_Layer_4': 0.12417944418558768, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.007014162500217797, 'l1_Layer_2': 1.6615900990251275e-05, 'l1_Layer_3': 0.0026814620131990568, 'l1_Layer_4': 0.03146633249058728, 'n_units_Layer_1': 255, 'n_units_Layer_2': 55, 'n_units_Layer_3': 185, 'n_units_Layer_4': 260}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.91 | sMAPE for Validation Set is: 47.10% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 13.61 | sMAPE for Test Set is: 16.10% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:58:27,346]\u001b[0m Trial 787 finished with value: 6.278534937569025 and parameters: {'n_hidden': 4, 'learning_rate': 0.001157491217977822, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1021753718141751, 'dropout_rate_Layer_2': 0.19796774045019339, 'dropout_rate_Layer_3': 0.37721223497065504, 'dropout_rate_Layer_4': 0.1480636312999594, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 8.279558717913974e-05, 'l1_Layer_2': 0.001139795852597206, 'l1_Layer_3': 0.0026737321480095133, 'l1_Layer_4': 0.00017381602178886867, 'n_units_Layer_1': 170, 'n_units_Layer_2': 300, 'n_units_Layer_3': 85, 'n_units_Layer_4': 80}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.28 | sMAPE for Validation Set is: 76.25% | rMAE for Validation Set is: 1.97\n",
      "MAE for Test Set is: 66.38 | sMAPE for Test Set is: 146.20% | rMAE for Test Set is: 3.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:58:42,854]\u001b[0m Trial 789 finished with value: 6.026887467959024 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011888712542086704, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10959382662662977, 'dropout_rate_Layer_2': 0.199825396792438, 'dropout_rate_Layer_3': 0.3789778077583736, 'dropout_rate_Layer_4': 0.15039554629425134, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 6.0474300708106294e-05, 'l1_Layer_2': 0.0010490270300351238, 'l1_Layer_3': 0.002589453893241505, 'l1_Layer_4': 0.00020409135757165024, 'n_units_Layer_1': 175, 'n_units_Layer_2': 300, 'n_units_Layer_3': 90, 'n_units_Layer_4': 80}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.03 | sMAPE for Validation Set is: 75.40% | rMAE for Validation Set is: 1.89\n",
      "MAE for Test Set is: 67.74 | sMAPE for Test Set is: 152.81% | rMAE for Test Set is: 4.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:58:49,543]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:59:00,149]\u001b[0m Trial 790 finished with value: 6.326328661488293 and parameters: {'n_hidden': 4, 'learning_rate': 0.001109608080312975, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10576326682796976, 'dropout_rate_Layer_2': 0.19483324019193707, 'dropout_rate_Layer_3': 0.37700951313507125, 'dropout_rate_Layer_4': 0.15561187811584204, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 6.263344284896958e-05, 'l1_Layer_2': 0.0009963940703971686, 'l1_Layer_3': 0.002634885590674517, 'l1_Layer_4': 0.00014288824539214593, 'n_units_Layer_1': 175, 'n_units_Layer_2': 295, 'n_units_Layer_3': 95, 'n_units_Layer_4': 85}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.33 | sMAPE for Validation Set is: 76.44% | rMAE for Validation Set is: 1.98\n",
      "MAE for Test Set is: 66.18 | sMAPE for Test Set is: 145.25% | rMAE for Test Set is: 3.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:59:20,101]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:59:31,781]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.02 | sMAPE for Validation Set is: 75.40% | rMAE for Validation Set is: 1.89\n",
      "MAE for Test Set is: 67.80 | sMAPE for Test Set is: 153.11% | rMAE for Test Set is: 4.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:59:39,166]\u001b[0m Trial 793 finished with value: 6.020872752290139 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011272410707879508, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10853827012070379, 'dropout_rate_Layer_2': 0.18973738666706522, 'dropout_rate_Layer_3': 0.37751722470217985, 'dropout_rate_Layer_4': 0.14979853070408503, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 5.474772503705126e-05, 'l1_Layer_2': 0.0010961766410301284, 'l1_Layer_3': 0.0023304309107267654, 'l1_Layer_4': 0.00018154723732084982, 'n_units_Layer_1': 170, 'n_units_Layer_2': 300, 'n_units_Layer_3': 90, 'n_units_Layer_4': 90}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:59:49,488]\u001b[0m Trial 794 finished with value: 6.082151683713953 and parameters: {'n_hidden': 4, 'learning_rate': 0.001140811033904909, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1105796483442453, 'dropout_rate_Layer_2': 0.18338063297603813, 'dropout_rate_Layer_3': 0.37814102800484023, 'dropout_rate_Layer_4': 0.14735451482200732, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 5.9806016907105534e-05, 'l1_Layer_2': 0.0014525349881613196, 'l1_Layer_3': 0.0024844473188674453, 'l1_Layer_4': 0.00014951162354061114, 'n_units_Layer_1': 175, 'n_units_Layer_2': 300, 'n_units_Layer_3': 85, 'n_units_Layer_4': 90}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.08 | sMAPE for Validation Set is: 75.54% | rMAE for Validation Set is: 1.91\n",
      "MAE for Test Set is: 67.38 | sMAPE for Test Set is: 151.01% | rMAE for Test Set is: 3.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:59:54,460]\u001b[0m Trial 795 finished with value: 6.065665304448278 and parameters: {'n_hidden': 4, 'learning_rate': 0.001148921699590411, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1112947956647894, 'dropout_rate_Layer_2': 0.19059436484970074, 'dropout_rate_Layer_3': 0.3762797716415302, 'dropout_rate_Layer_4': 0.14627260109215923, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 5.7272703463680485e-05, 'l1_Layer_2': 0.0011047817966517719, 'l1_Layer_3': 0.002233097166043585, 'l1_Layer_4': 0.0002101987967163433, 'n_units_Layer_1': 165, 'n_units_Layer_2': 300, 'n_units_Layer_3': 85, 'n_units_Layer_4': 90}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.07 | sMAPE for Validation Set is: 75.49% | rMAE for Validation Set is: 1.90\n",
      "MAE for Test Set is: 67.47 | sMAPE for Test Set is: 151.46% | rMAE for Test Set is: 4.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:00:04,433]\u001b[0m Trial 796 finished with value: 6.270086807440914 and parameters: {'n_hidden': 4, 'learning_rate': 0.001122552673291813, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10280960380013061, 'dropout_rate_Layer_2': 0.192854753551193, 'dropout_rate_Layer_3': 0.3779031526294149, 'dropout_rate_Layer_4': 0.14683160610717141, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 5.244784472337061e-05, 'l1_Layer_2': 0.0009775851408892306, 'l1_Layer_3': 0.0021365168696575432, 'l1_Layer_4': 0.00015746277722427735, 'n_units_Layer_1': 170, 'n_units_Layer_2': 300, 'n_units_Layer_3': 85, 'n_units_Layer_4': 85}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.27 | sMAPE for Validation Set is: 76.23% | rMAE for Validation Set is: 1.97\n",
      "MAE for Test Set is: 66.46 | sMAPE for Test Set is: 146.59% | rMAE for Test Set is: 3.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:00:11,613]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:00:12,016]\u001b[0m Trial 797 finished with value: 6.058359569301181 and parameters: {'n_hidden': 4, 'learning_rate': 0.001200626551733517, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10886468102535912, 'dropout_rate_Layer_2': 0.18479625593587662, 'dropout_rate_Layer_3': 0.3756345256847472, 'dropout_rate_Layer_4': 0.15085343051783937, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 5.8539223053611114e-05, 'l1_Layer_2': 0.0010594784748101309, 'l1_Layer_3': 0.00212193863849144, 'l1_Layer_4': 0.0001819533615507344, 'n_units_Layer_1': 170, 'n_units_Layer_2': 300, 'n_units_Layer_3': 80, 'n_units_Layer_4': 85}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.06 | sMAPE for Validation Set is: 75.50% | rMAE for Validation Set is: 1.90\n",
      "MAE for Test Set is: 67.58 | sMAPE for Test Set is: 152.00% | rMAE for Test Set is: 4.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:00:27,862]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:00:32,320]\u001b[0m Trial 799 finished with value: 6.124691285929861 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011550467055712191, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10045839084821631, 'dropout_rate_Layer_2': 0.18499942653607723, 'dropout_rate_Layer_3': 0.37022214461884845, 'dropout_rate_Layer_4': 0.146276882537424, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.218889824361212e-05, 'l1_Layer_2': 0.0016378066822250676, 'l1_Layer_3': 0.0019720649040173063, 'l1_Layer_4': 0.00019315121040806634, 'n_units_Layer_1': 170, 'n_units_Layer_2': 300, 'n_units_Layer_3': 80, 'n_units_Layer_4': 90}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 75.66% | rMAE for Validation Set is: 1.92\n",
      "MAE for Test Set is: 67.10 | sMAPE for Test Set is: 149.65% | rMAE for Test Set is: 3.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:00:47,142]\u001b[0m Trial 802 finished with value: 6.052379660900811 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014260362998842172, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11057466599567299, 'dropout_rate_Layer_2': 0.18643791402024254, 'dropout_rate_Layer_3': 0.36942495065985126, 'dropout_rate_Layer_4': 0.13611648125255194, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.519556612749254e-05, 'l1_Layer_2': 0.001504253454074612, 'l1_Layer_3': 0.0021583042043100387, 'l1_Layer_4': 0.0001926935035290561, 'n_units_Layer_1': 165, 'n_units_Layer_2': 300, 'n_units_Layer_3': 85, 'n_units_Layer_4': 90}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.05 | sMAPE for Validation Set is: 75.44% | rMAE for Validation Set is: 1.90\n",
      "MAE for Test Set is: 67.54 | sMAPE for Test Set is: 151.83% | rMAE for Test Set is: 4.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:00:50,232]\u001b[0m Trial 801 finished with value: 1.9296704719403104 and parameters: {'n_hidden': 3, 'learning_rate': 0.005009226168647474, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2919785867477803, 'dropout_rate_Layer_2': 0.088868268405357, 'dropout_rate_Layer_3': 0.11517654127456503, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.714494236810521e-05, 'l1_Layer_2': 0.08602276510023239, 'l1_Layer_3': 0.011874747217295806, 'n_units_Layer_1': 70, 'n_units_Layer_2': 155, 'n_units_Layer_3': 145}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 35.65% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.81 | sMAPE for Test Set is: 13.94% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:01:02,609]\u001b[0m Trial 803 finished with value: 6.386936817731477 and parameters: {'n_hidden': 4, 'learning_rate': 0.001320099627351302, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11281484060956028, 'dropout_rate_Layer_2': 0.18124494690036724, 'dropout_rate_Layer_3': 0.3680009118221849, 'dropout_rate_Layer_4': 0.13966324720051226, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.9150852042534714e-05, 'l1_Layer_2': 0.001638055573886271, 'l1_Layer_3': 0.0020179836745228157, 'l1_Layer_4': 0.0002485871531690763, 'n_units_Layer_1': 165, 'n_units_Layer_2': 300, 'n_units_Layer_3': 80, 'n_units_Layer_4': 90}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.39 | sMAPE for Validation Set is: 76.73% | rMAE for Validation Set is: 2.00\n",
      "MAE for Test Set is: 66.00 | sMAPE for Test Set is: 144.39% | rMAE for Test Set is: 3.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:01:06,776]\u001b[0m Trial 804 finished with value: 6.356914930954617 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012603360257562363, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10773660557682256, 'dropout_rate_Layer_2': 0.18084820907579569, 'dropout_rate_Layer_3': 0.3696925649664426, 'dropout_rate_Layer_4': 0.1368259269483334, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.01039261579272e-05, 'l1_Layer_2': 0.0015326496721940923, 'l1_Layer_3': 0.0019293327739070406, 'l1_Layer_4': 0.00019671626013805136, 'n_units_Layer_1': 165, 'n_units_Layer_2': 300, 'n_units_Layer_3': 85, 'n_units_Layer_4': 90}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 76.58% | rMAE for Validation Set is: 1.99\n",
      "MAE for Test Set is: 66.07 | sMAPE for Test Set is: 144.73% | rMAE for Test Set is: 3.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:01:14,412]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:01:22,313]\u001b[0m Trial 805 finished with value: 6.364572517794376 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012672987832621063, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10908656547169357, 'dropout_rate_Layer_2': 0.18482469386119646, 'dropout_rate_Layer_3': 0.36884762381319636, 'dropout_rate_Layer_4': 0.14225267590207458, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.727312929348936e-05, 'l1_Layer_2': 0.0016667004038525344, 'l1_Layer_3': 0.0018093070138796806, 'l1_Layer_4': 0.00016729382192253052, 'n_units_Layer_1': 165, 'n_units_Layer_2': 300, 'n_units_Layer_3': 80, 'n_units_Layer_4': 90}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 76.62% | rMAE for Validation Set is: 2.00\n",
      "MAE for Test Set is: 66.05 | sMAPE for Test Set is: 144.64% | rMAE for Test Set is: 3.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:01:34,289]\u001b[0m Trial 807 finished with value: 6.198022919861166 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012322215516857036, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11313412682100858, 'dropout_rate_Layer_2': 0.1858856774837627, 'dropout_rate_Layer_3': 0.3709514503361049, 'dropout_rate_Layer_4': 0.1525412738247223, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.7079156415274024e-05, 'l1_Layer_2': 0.0013058172285204423, 'l1_Layer_3': 0.0021912633084864796, 'l1_Layer_4': 0.00019069754691897423, 'n_units_Layer_1': 160, 'n_units_Layer_2': 295, 'n_units_Layer_3': 80, 'n_units_Layer_4': 90}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 75.92% | rMAE for Validation Set is: 1.94\n",
      "MAE for Test Set is: 66.74 | sMAPE for Test Set is: 147.90% | rMAE for Test Set is: 3.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:01:41,650]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:01:47,029]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:01:51,879]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:01:56,827]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:02:03,420]\u001b[0m Trial 810 finished with value: 6.1272696896648675 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011859657173266928, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11535994925468186, 'dropout_rate_Layer_2': 0.19494411267400624, 'dropout_rate_Layer_3': 0.37213631107810397, 'dropout_rate_Layer_4': 0.15240996038566962, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 5.7060244906860755e-05, 'l1_Layer_2': 0.0013000567838292866, 'l1_Layer_3': 0.00219609317083009, 'l1_Layer_4': 0.00019708525788503264, 'n_units_Layer_1': 160, 'n_units_Layer_2': 295, 'n_units_Layer_3': 80, 'n_units_Layer_4': 90}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 75.67% | rMAE for Validation Set is: 1.92\n",
      "MAE for Test Set is: 67.10 | sMAPE for Test Set is: 149.64% | rMAE for Test Set is: 3.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:02:05,900]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:02:20,934]\u001b[0m Trial 814 finished with value: 6.130208902075651 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010036768103033019, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09966317675973138, 'dropout_rate_Layer_2': 0.1858885957621995, 'dropout_rate_Layer_3': 0.37406569133344314, 'dropout_rate_Layer_4': 0.16768668821177618, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.958614223543018e-05, 'l1_Layer_2': 0.0008539513773224603, 'l1_Layer_3': 0.0022382976156253118, 'l1_Layer_4': 0.0002470020524592176, 'n_units_Layer_1': 160, 'n_units_Layer_2': 295, 'n_units_Layer_3': 75, 'n_units_Layer_4': 90}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 75.68% | rMAE for Validation Set is: 1.92\n",
      "MAE for Test Set is: 67.08 | sMAPE for Test Set is: 149.53% | rMAE for Test Set is: 3.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:02:21,476]\u001b[0m Trial 815 finished with value: 6.346777992252963 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012311310969463903, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09897164654503462, 'dropout_rate_Layer_2': 0.1759578404703881, 'dropout_rate_Layer_3': 0.3649398099063552, 'dropout_rate_Layer_4': 0.14829209903663018, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.0868093867491684e-05, 'l1_Layer_2': 0.0011651820975435642, 'l1_Layer_3': 0.0016962407691892922, 'l1_Layer_4': 0.0002427787361395336, 'n_units_Layer_1': 160, 'n_units_Layer_2': 290, 'n_units_Layer_3': 75, 'n_units_Layer_4': 95}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.35 | sMAPE for Validation Set is: 76.54% | rMAE for Validation Set is: 1.99\n",
      "MAE for Test Set is: 66.11 | sMAPE for Test Set is: 144.91% | rMAE for Test Set is: 3.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:02:29,191]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:02:32,618]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:02:39,187]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:02:42,653]\u001b[0m Trial 816 finished with value: 6.128574839229372 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010199982073987282, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09710379630057142, 'dropout_rate_Layer_2': 0.19186323770350783, 'dropout_rate_Layer_3': 0.38054810450968224, 'dropout_rate_Layer_4': 0.16672349833368202, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 6.284291973274192e-05, 'l1_Layer_2': 0.001017983086353773, 'l1_Layer_3': 0.0019132839837381604, 'l1_Layer_4': 0.00022695601608358328, 'n_units_Layer_1': 165, 'n_units_Layer_2': 300, 'n_units_Layer_3': 75, 'n_units_Layer_4': 85}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 75.66% | rMAE for Validation Set is: 1.92\n",
      "MAE for Test Set is: 67.09 | sMAPE for Test Set is: 149.60% | rMAE for Test Set is: 3.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:02:49,389]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:02:54,643]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:03:11,602]\u001b[0m Trial 823 finished with value: 6.124968060388981 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010842971622317798, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09907570687314861, 'dropout_rate_Layer_2': 0.1733447582281895, 'dropout_rate_Layer_3': 0.3651219068742046, 'dropout_rate_Layer_4': 0.14445667343378135, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.6718480532105706e-05, 'l1_Layer_2': 0.0007477190066544047, 'l1_Layer_3': 0.0017948655893757148, 'l1_Layer_4': 0.0001957891040895241, 'n_units_Layer_1': 170, 'n_units_Layer_2': 300, 'n_units_Layer_3': 85, 'n_units_Layer_4': 85}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 75.67% | rMAE for Validation Set is: 1.92\n",
      "MAE for Test Set is: 67.15 | sMAPE for Test Set is: 149.88% | rMAE for Test Set is: 3.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:03:26,199]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:03:29,189]\u001b[0m Trial 824 finished with value: 6.079063180701646 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011107093129231356, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12151796521977468, 'dropout_rate_Layer_2': 0.1706784244248926, 'dropout_rate_Layer_3': 0.3630298657730212, 'dropout_rate_Layer_4': 0.13831813291205708, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.595576490680175e-05, 'l1_Layer_2': 0.002047642726278052, 'l1_Layer_3': 0.0016649633090143694, 'l1_Layer_4': 0.00014212624403364587, 'n_units_Layer_1': 175, 'n_units_Layer_2': 295, 'n_units_Layer_3': 85, 'n_units_Layer_4': 95}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.08 | sMAPE for Validation Set is: 75.55% | rMAE for Validation Set is: 1.91\n",
      "MAE for Test Set is: 67.42 | sMAPE for Test Set is: 151.21% | rMAE for Test Set is: 3.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:03:34,226]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:03:44,297]\u001b[0m Trial 825 finished with value: 6.054944891805658 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011161715993531357, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11774315245763424, 'dropout_rate_Layer_2': 0.17249053221728275, 'dropout_rate_Layer_3': 0.365683461292604, 'dropout_rate_Layer_4': 0.15461025401882042, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.5076258424719944e-05, 'l1_Layer_2': 0.0006990944113522749, 'l1_Layer_3': 0.0015617475980093099, 'l1_Layer_4': 0.00019322663095793389, 'n_units_Layer_1': 175, 'n_units_Layer_2': 295, 'n_units_Layer_3': 85, 'n_units_Layer_4': 95}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.05 | sMAPE for Validation Set is: 75.48% | rMAE for Validation Set is: 1.90\n",
      "MAE for Test Set is: 67.58 | sMAPE for Test Set is: 151.98% | rMAE for Test Set is: 4.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:03:53,272]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:04:00,925]\u001b[0m Trial 827 finished with value: 2.0068875960846575 and parameters: {'n_hidden': 3, 'learning_rate': 0.030114608494067316, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3269801764509622, 'dropout_rate_Layer_2': 0.2940680446101184, 'dropout_rate_Layer_3': 0.2723119849650081, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7623800162831488e-05, 'l1_Layer_2': 0.0018178513781567536, 'l1_Layer_3': 6.0063507664114926e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 200, 'n_units_Layer_3': 260}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 41.11% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 13.94 | sMAPE for Test Set is: 15.91% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:04:08,974]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:04:17,052]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:04:21,697]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:04:27,230]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:04:35,013]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:04:39,191]\u001b[0m Trial 832 finished with value: 6.227343289247794 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012147171915959406, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10680053432307851, 'dropout_rate_Layer_2': 0.16545082010647919, 'dropout_rate_Layer_3': 0.3720289193513105, 'dropout_rate_Layer_4': 0.15698125202433424, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.7356847648651464e-05, 'l1_Layer_2': 0.0014008671114353033, 'l1_Layer_3': 0.001365366776183919, 'l1_Layer_4': 9.387020796300625e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 285, 'n_units_Layer_3': 80, 'n_units_Layer_4': 95}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.23 | sMAPE for Validation Set is: 76.04% | rMAE for Validation Set is: 1.95\n",
      "MAE for Test Set is: 66.60 | sMAPE for Test Set is: 147.25% | rMAE for Test Set is: 3.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:04:41,904]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.74 | sMAPE for Validation Set is: 57.09% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 14.87 | sMAPE for Test Set is: 18.99% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:05:03,996]\u001b[0m Trial 836 finished with value: 2.7411590176375245 and parameters: {'n_hidden': 3, 'learning_rate': 0.027440183442196852, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32072908623636903, 'dropout_rate_Layer_2': 0.294530947106867, 'dropout_rate_Layer_3': 0.2950083484652972, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.717027824346688e-05, 'l1_Layer_2': 0.0019563264441000744, 'l1_Layer_3': 6.822701716219463e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 205, 'n_units_Layer_3': 245}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:05:06,805]\u001b[0m Trial 837 finished with value: 2.4388175768897065 and parameters: {'n_hidden': 3, 'learning_rate': 0.02724360912789792, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33005323447466806, 'dropout_rate_Layer_2': 0.2941006373715352, 'dropout_rate_Layer_3': 0.26890015154119495, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0453882805186136e-05, 'l1_Layer_2': 0.0019300060736795084, 'l1_Layer_3': 6.299949759919768e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 225, 'n_units_Layer_3': 240}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.44 | sMAPE for Validation Set is: 51.98% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 12.09 | sMAPE for Test Set is: 15.32% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:05:09,486]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:05:26,639]\u001b[0m Trial 840 finished with value: 6.458390514179857 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011541516182019555, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12563879421634674, 'dropout_rate_Layer_2': 0.182975917358281, 'dropout_rate_Layer_3': 0.3886938001357151, 'dropout_rate_Layer_4': 0.14339180869656146, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.587231495745703e-05, 'l1_Layer_2': 0.0019666445385138113, 'l1_Layer_3': 0.002637611542554875, 'l1_Layer_4': 0.00015078286946146167, 'n_units_Layer_1': 170, 'n_units_Layer_2': 300, 'n_units_Layer_3': 90, 'n_units_Layer_4': 85}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.46 | sMAPE for Validation Set is: 77.02% | rMAE for Validation Set is: 2.03\n",
      "MAE for Test Set is: 65.74 | sMAPE for Test Set is: 143.17% | rMAE for Test Set is: 3.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:05:32,354]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:05:41,759]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:05:46,536]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:05:52,454]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:06:06,629]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:06:07,068]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:06:29,392]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:06:34,847]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:06:39,964]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:06:44,813]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:06:58,877]\u001b[0m Trial 850 finished with value: 6.231429044549511 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013039336880515588, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10776779212245818, 'dropout_rate_Layer_2': 0.19828665801373643, 'dropout_rate_Layer_3': 0.36655653624423906, 'dropout_rate_Layer_4': 0.1466343237820533, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 7.055199561615543e-05, 'l1_Layer_2': 0.0009157666959322975, 'l1_Layer_3': 0.0020944332621079267, 'l1_Layer_4': 0.0001587998292219281, 'n_units_Layer_1': 170, 'n_units_Layer_2': 300, 'n_units_Layer_3': 90, 'n_units_Layer_4': 90}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.23 | sMAPE for Validation Set is: 76.06% | rMAE for Validation Set is: 1.95\n",
      "MAE for Test Set is: 66.59 | sMAPE for Test Set is: 147.18% | rMAE for Test Set is: 3.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:07:02,183]\u001b[0m Trial 851 finished with value: 6.230523491184691 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012880422295278766, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10405757866869221, 'dropout_rate_Layer_2': 0.18543228878073434, 'dropout_rate_Layer_3': 0.3835998355913491, 'dropout_rate_Layer_4': 0.15047837890155405, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 5.6097492286775575e-05, 'l1_Layer_2': 0.001202424677649734, 'l1_Layer_3': 0.0020645945522412006, 'l1_Layer_4': 0.00015952062052842985, 'n_units_Layer_1': 170, 'n_units_Layer_2': 300, 'n_units_Layer_3': 90, 'n_units_Layer_4': 90}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.23 | sMAPE for Validation Set is: 76.06% | rMAE for Validation Set is: 1.95\n",
      "MAE for Test Set is: 66.59 | sMAPE for Test Set is: 147.18% | rMAE for Test Set is: 3.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:07:21,676]\u001b[0m Trial 852 finished with value: 2.0856836243647603 and parameters: {'n_hidden': 3, 'learning_rate': 0.004818716609227953, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28177238969773166, 'dropout_rate_Layer_2': 0.1349529132870801, 'dropout_rate_Layer_3': 0.14782127406434092, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.664880001344662e-05, 'l1_Layer_2': 0.043645955130233616, 'l1_Layer_3': 0.010299011390786057, 'n_units_Layer_1': 265, 'n_units_Layer_2': 160, 'n_units_Layer_3': 185}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 35.27% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.07 | sMAPE for Test Set is: 14.03% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:07:26,286]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:07:36,070]\u001b[0m Trial 853 finished with value: 1.7214545493083853 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021089918857836107, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28245456350333203, 'dropout_rate_Layer_2': 0.14228395491859455, 'dropout_rate_Layer_3': 0.14925015035577122, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005555206306406137, 'l1_Layer_2': 0.044103946489064495, 'l1_Layer_3': 0.010573274336406787, 'n_units_Layer_1': 265, 'n_units_Layer_2': 160, 'n_units_Layer_3': 160}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.72 | sMAPE for Validation Set is: 32.22% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 12.74 | sMAPE for Test Set is: 17.21% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:07:43,214]\u001b[0m Trial 855 finished with value: 6.102953091433675 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009371418459057919, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12617242287376487, 'dropout_rate_Layer_2': 0.2010310603920534, 'dropout_rate_Layer_3': 0.3538123195820844, 'dropout_rate_Layer_4': 0.13699745688660253, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.138672151880273e-05, 'l1_Layer_2': 0.0016079403677132045, 'l1_Layer_3': 0.0008996758817238643, 'l1_Layer_4': 0.00010627215327706452, 'n_units_Layer_1': 175, 'n_units_Layer_2': 300, 'n_units_Layer_3': 95, 'n_units_Layer_4': 100}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 75.62% | rMAE for Validation Set is: 1.91\n",
      "MAE for Test Set is: 67.28 | sMAPE for Test Set is: 150.55% | rMAE for Test Set is: 3.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:07:53,607]\u001b[0m Trial 856 finished with value: 6.166404722536065 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009611338180944999, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11098503625768136, 'dropout_rate_Layer_2': 0.20208044999697242, 'dropout_rate_Layer_3': 0.35479546391650996, 'dropout_rate_Layer_4': 0.1584304111237328, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.471273352169622e-05, 'l1_Layer_2': 0.0011024786157459825, 'l1_Layer_3': 0.001566838231139917, 'l1_Layer_4': 0.0002286634439129602, 'n_units_Layer_1': 170, 'n_units_Layer_2': 300, 'n_units_Layer_3': 95, 'n_units_Layer_4': 100}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 75.80% | rMAE for Validation Set is: 1.93\n",
      "MAE for Test Set is: 66.86 | sMAPE for Test Set is: 148.48% | rMAE for Test Set is: 3.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:07:53,988]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:00,049]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:02,301]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:07,123]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:12,190]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:24,513]\u001b[0m Trial 862 finished with value: 6.184033731269747 and parameters: {'n_hidden': 4, 'learning_rate': 0.001061785110035119, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12070864280413625, 'dropout_rate_Layer_2': 0.16989283446157405, 'dropout_rate_Layer_3': 0.392066005363717, 'dropout_rate_Layer_4': 0.13524100798628944, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 7.207577446102036e-05, 'l1_Layer_2': 0.0025249063141481684, 'l1_Layer_3': 0.0009608020652647912, 'l1_Layer_4': 0.00010828174299760755, 'n_units_Layer_1': 165, 'n_units_Layer_2': 295, 'n_units_Layer_3': 85, 'n_units_Layer_4': 105}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 75.88% | rMAE for Validation Set is: 1.94\n",
      "MAE for Test Set is: 66.81 | sMAPE for Test Set is: 148.24% | rMAE for Test Set is: 3.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:08:27,647]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:31,829]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:32,285]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:37,610]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:42,133]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:45,294]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:52,305]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:56,932]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:59,768]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:09:06,630]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:09:09,117]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:09:24,427]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:09:24,600]\u001b[0m Trial 874 finished with value: 6.46047289031019 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010670932499159624, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04724962789424565, 'dropout_rate_Layer_2': 0.2105804676749822, 'dropout_rate_Layer_3': 0.3640603236223457, 'dropout_rate_Layer_4': 0.1511072501640904, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 5.838319566503756e-05, 'l1_Layer_2': 0.0006769182607043506, 'l1_Layer_3': 0.003252335533235003, 'l1_Layer_4': 0.00028076843116398384, 'n_units_Layer_1': 175, 'n_units_Layer_2': 300, 'n_units_Layer_3': 100, 'n_units_Layer_4': 95}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.46 | sMAPE for Validation Set is: 77.04% | rMAE for Validation Set is: 2.03\n",
      "MAE for Test Set is: 65.74 | sMAPE for Test Set is: 143.19% | rMAE for Test Set is: 3.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:09:36,177]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:09:40,836]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:09:52,814]\u001b[0m Trial 877 finished with value: 2.0443756699041846 and parameters: {'n_hidden': 3, 'learning_rate': 0.03652496720493541, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.354038934675349, 'dropout_rate_Layer_2': 0.254448534947082, 'dropout_rate_Layer_3': 0.24766972974902315, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.1089278956524045e-05, 'l1_Layer_2': 0.0003151653845598447, 'l1_Layer_3': 1.3997135187217838e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 195, 'n_units_Layer_3': 265}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 50.09% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 16.50 | sMAPE for Test Set is: 18.04% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:10:02,991]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:10:11,088]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:10:20,596]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:10:21,215]\u001b[0m Trial 880 finished with value: 2.2931333200405235 and parameters: {'n_hidden': 3, 'learning_rate': 0.04654426383130628, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38592815937251446, 'dropout_rate_Layer_2': 0.22600579937875068, 'dropout_rate_Layer_3': 0.19839644401222778, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.813220742251735e-05, 'l1_Layer_2': 0.0013709738139801681, 'l1_Layer_3': 3.0069734342187796e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 170, 'n_units_Layer_3': 260}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.29 | sMAPE for Validation Set is: 54.56% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 10.41 | sMAPE for Test Set is: 13.28% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:10:30,188]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:10:45,062]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:10:50,236]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:11:02,734]\u001b[0m Trial 886 finished with value: 6.164823111657644 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009438742129642332, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12147094273676763, 'dropout_rate_Layer_2': 0.16702547232218412, 'dropout_rate_Layer_3': 0.3862065013930054, 'dropout_rate_Layer_4': 0.14768854613225288, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 6.206436854259162e-05, 'l1_Layer_2': 0.001070676541042151, 'l1_Layer_3': 0.0026827342855311317, 'l1_Layer_4': 0.00010361467718580561, 'n_units_Layer_1': 175, 'n_units_Layer_2': 280, 'n_units_Layer_3': 100, 'n_units_Layer_4': 100}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 75.79% | rMAE for Validation Set is: 1.93\n",
      "MAE for Test Set is: 66.88 | sMAPE for Test Set is: 148.60% | rMAE for Test Set is: 3.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:11:07,580]\u001b[0m Trial 887 finished with value: 6.231372924408873 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009556904319664991, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11977633174570092, 'dropout_rate_Layer_2': 0.17372292746756632, 'dropout_rate_Layer_3': 0.38608568088054174, 'dropout_rate_Layer_4': 0.16356076743606354, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 6.236095048589221e-05, 'l1_Layer_2': 0.0007839108386201595, 'l1_Layer_3': 0.003278300887315785, 'l1_Layer_4': 0.0001796798691966809, 'n_units_Layer_1': 175, 'n_units_Layer_2': 280, 'n_units_Layer_3': 75, 'n_units_Layer_4': 100}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.23 | sMAPE for Validation Set is: 76.05% | rMAE for Validation Set is: 1.95\n",
      "MAE for Test Set is: 66.56 | sMAPE for Test Set is: 147.04% | rMAE for Test Set is: 3.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:11:12,783]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:11:17,896]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:11:22,936]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:11:27,670]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:11:36,641]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:11:40,215]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:11:45,064]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:11:49,600]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:11:59,818]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:12:07,696]\u001b[0m Trial 891 finished with value: 3.3674118210637496 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006648424286131172, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.039831432566679634, 'dropout_rate_Layer_2': 0.18212169840932027, 'dropout_rate_Layer_3': 0.19170555414498455, 'dropout_rate_Layer_4': 0.27158100779531874, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.009656296514394869, 'l1_Layer_2': 9.826962503353309e-05, 'l1_Layer_3': 0.0006819974468831832, 'l1_Layer_4': 0.036916467117982375, 'n_units_Layer_1': 275, 'n_units_Layer_2': 105, 'n_units_Layer_3': 200, 'n_units_Layer_4': 160}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.37 | sMAPE for Validation Set is: 59.22% | rMAE for Validation Set is: 1.06\n",
      "MAE for Test Set is: 53.20 | sMAPE for Test Set is: 94.48% | rMAE for Test Set is: 3.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:12:12,314]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:12:17,437]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:12:24,278]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:12:31,589]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:12:34,580]\u001b[0m Trial 900 finished with value: 6.243451472314398 and parameters: {'n_hidden': 3, 'learning_rate': 0.018854716514999963, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34783344641788116, 'dropout_rate_Layer_2': 0.26450016944807714, 'dropout_rate_Layer_3': 0.22657060746605426, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0017567378915851017, 'l1_Layer_2': 0.007005806996668057, 'l1_Layer_3': 4.2028231038538166e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 275, 'n_units_Layer_3': 175}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 82.35% | rMAE for Validation Set is: 1.96\n",
      "MAE for Test Set is: 71.17 | sMAPE for Test Set is: 170.95% | rMAE for Test Set is: 4.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:12:44,657]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:12:52,182]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:12:56,695]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:13:03,693]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:13:11,308]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:13:11,711]\u001b[0m Trial 903 finished with value: 5.737313000248224 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007957398375186288, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16734982100733017, 'dropout_rate_Layer_2': 0.23387799055015385, 'dropout_rate_Layer_3': 0.1595733708936124, 'dropout_rate_Layer_4': 0.3038011853792521, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.1236745393987213e-05, 'l1_Layer_2': 0.0001166872523537647, 'l1_Layer_3': 0.0006860399877278807, 'l1_Layer_4': 0.007595972743138807, 'n_units_Layer_1': 280, 'n_units_Layer_2': 70, 'n_units_Layer_3': 220, 'n_units_Layer_4': 185}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 72.65% | rMAE for Validation Set is: 1.80\n",
      "MAE for Test Set is: 63.87 | sMAPE for Test Set is: 135.24% | rMAE for Test Set is: 3.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:13:18,361]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:13:25,566]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:13:34,598]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:13:35,013]\u001b[0m Trial 910 finished with value: 6.14231049199401 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013020018909670442, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1117317334607618, 'dropout_rate_Layer_2': 0.16890704362890405, 'dropout_rate_Layer_3': 0.3934241755149612, 'dropout_rate_Layer_4': 0.12091517148477421, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 5.8365137729400334e-05, 'l1_Layer_2': 0.0012179001370314225, 'l1_Layer_3': 0.002089119297600336, 'l1_Layer_4': 0.0003950615765345182, 'n_units_Layer_1': 160, 'n_units_Layer_2': 290, 'n_units_Layer_3': 95, 'n_units_Layer_4': 85}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 75.73% | rMAE for Validation Set is: 1.93\n",
      "MAE for Test Set is: 67.05 | sMAPE for Test Set is: 149.41% | rMAE for Test Set is: 3.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:13:45,868]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:13:50,888]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:14:06,021]\u001b[0m Trial 913 finished with value: 1.9981370016525712 and parameters: {'n_hidden': 3, 'learning_rate': 0.004014757258172512, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37750110537539067, 'dropout_rate_Layer_2': 0.09218805677317952, 'dropout_rate_Layer_3': 0.17571350866600022, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6188582189089694e-05, 'l1_Layer_2': 0.03526381608071207, 'l1_Layer_3': 0.021820392817096024, 'n_units_Layer_1': 270, 'n_units_Layer_2': 165, 'n_units_Layer_3': 160}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 38.34% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.12 | sMAPE for Test Set is: 14.55% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:14:10,804]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:14:23,238]\u001b[0m Trial 916 finished with value: 5.005214160676204 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009526535954663384, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0783374446453555, 'dropout_rate_Layer_2': 0.22016986176386633, 'dropout_rate_Layer_3': 0.18871833722461528, 'dropout_rate_Layer_4': 0.27545283637196366, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.010400927943752681, 'l1_Layer_2': 6.057638002404279e-05, 'l1_Layer_3': 0.000907034993878486, 'l1_Layer_4': 2.2820956032284302e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 55, 'n_units_Layer_3': 170, 'n_units_Layer_4': 150}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.01 | sMAPE for Validation Set is: 67.38% | rMAE for Validation Set is: 1.57\n",
      "MAE for Test Set is: 48.13 | sMAPE for Test Set is: 84.21% | rMAE for Test Set is: 2.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:14:29,751]\u001b[0m Trial 918 finished with value: 6.2230018163856355 and parameters: {'n_hidden': 4, 'learning_rate': 0.00104796699947059, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1075376025079183, 'dropout_rate_Layer_2': 0.16094089906222514, 'dropout_rate_Layer_3': 0.35580961349578877, 'dropout_rate_Layer_4': 0.14256939800626398, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.0848120887904322e-05, 'l1_Layer_2': 0.002037331313934064, 'l1_Layer_3': 0.0007957729922573522, 'l1_Layer_4': 9.476895933588812e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 295, 'n_units_Layer_3': 100, 'n_units_Layer_4': 90}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 76.03% | rMAE for Validation Set is: 1.95\n",
      "MAE for Test Set is: 66.64 | sMAPE for Test Set is: 147.42% | rMAE for Test Set is: 3.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:14:34,744]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:14:42,349]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:14:52,133]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:14:52,823]\u001b[0m Trial 921 finished with value: 6.35694647883749 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009681540253824868, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12048414981514244, 'dropout_rate_Layer_2': 0.20808397273224366, 'dropout_rate_Layer_3': 0.373059522139253, 'dropout_rate_Layer_4': 0.16890034618633357, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.3760364255297326e-05, 'l1_Layer_2': 0.001763904205474291, 'l1_Layer_3': 0.0036150473891020858, 'l1_Layer_4': 0.0001347388373161595, 'n_units_Layer_1': 185, 'n_units_Layer_2': 290, 'n_units_Layer_3': 105, 'n_units_Layer_4': 100}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 76.56% | rMAE for Validation Set is: 1.99\n",
      "MAE for Test Set is: 66.04 | sMAPE for Test Set is: 144.61% | rMAE for Test Set is: 3.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:14:59,253]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:15:01,746]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:15:06,543]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:15:11,451]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:15:11,562]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:15:20,870]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:15:23,621]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:15:28,784]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:15:31,431]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:15:36,170]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:15:40,369]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:15:40,930]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:15:46,242]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:15:51,539]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:16:00,674]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:16:08,094]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:16:27,810]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:16:32,961]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:16:42,232]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:16:49,540]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:16:57,368]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:16:57,496]\u001b[0m Trial 941 finished with value: 6.429567291739924 and parameters: {'n_hidden': 3, 'learning_rate': 0.006765323555678276, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3654983640301831, 'dropout_rate_Layer_2': 0.2790785663348877, 'dropout_rate_Layer_3': 0.27755169733485263, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.028881573216488193, 'l1_Layer_2': 0.004887758023484206, 'l1_Layer_3': 2.190053271142698e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 140, 'n_units_Layer_3': 275}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.43 | sMAPE for Validation Set is: 85.44% | rMAE for Validation Set is: 2.02\n",
      "MAE for Test Set is: 71.64 | sMAPE for Test Set is: 173.85% | rMAE for Test Set is: 4.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:17:06,563]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:17:06,733]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:17:14,197]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:17:17,966]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:17:24,222]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:17:29,540]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:17:34,655]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:17:39,588]\u001b[0m Trial 947 finished with value: 2.212788816900749 and parameters: {'n_hidden': 3, 'learning_rate': 0.030828557229225652, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3999684329287542, 'dropout_rate_Layer_2': 0.20502286467661227, 'dropout_rate_Layer_3': 0.1670431134858989, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.660694743032238e-05, 'l1_Layer_2': 0.0007040359821199718, 'l1_Layer_3': 1.3711777714717619e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 155, 'n_units_Layer_3': 255}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.21 | sMAPE for Validation Set is: 43.23% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 18.21 | sMAPE for Test Set is: 20.30% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:17:40,378]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:17:48,232]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:17:53,495]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:17:58,090]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:18:05,941]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:18:13,330]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:18:15,842]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:18:22,382]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:18:27,280]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:18:32,201]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:18:35,154]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:18:39,674]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:18:40,159]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:18:46,321]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:18:49,206]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:18:55,960]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:19:01,066]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:19:01,445]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:19:10,171]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:19:12,535]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:19:16,665]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:19:19,617]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:19:26,486]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:19:27,011]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:19:35,350]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:19:43,146]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:19:51,069]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:20:02,582]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:20:08,069]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:20:12,760]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:20:17,960]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:20:18,107]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:20:28,111]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:20:35,433]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:20:40,260]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:20:47,586]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:20:47,776]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:20:55,188]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:20:59,325]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:21:06,922]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:21:14,334]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:21:20,823]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:21:30,921]\u001b[0m Trial 992 finished with value: 6.477854207699898 and parameters: {'n_hidden': 3, 'learning_rate': 0.007948078679910145, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3829143277699412, 'dropout_rate_Layer_2': 0.35680066267944266, 'dropout_rate_Layer_3': 0.30655890110855577, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.6851446775947974e-05, 'l1_Layer_2': 6.296261325897191e-05, 'l1_Layer_3': 0.00022958956629261516, 'n_units_Layer_1': 205, 'n_units_Layer_2': 185, 'n_units_Layer_3': 285}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.48 | sMAPE for Validation Set is: 76.26% | rMAE for Validation Set is: 2.03\n",
      "MAE for Test Set is: 62.24 | sMAPE for Test Set is: 128.31% | rMAE for Test Set is: 3.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:21:31,323]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:21:42,060]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:21:42,558]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:21:52,102]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:21:56,780]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:22:07,283]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:22:11,669]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:22:16,500]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:22:16,958]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:22:25,058]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:22:30,316]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:22:38,089]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:22:50,059]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:22:55,681]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:23:03,056]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:23:15,427]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:23:17,815]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:23:22,495]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:23:30,328]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:23:42,226]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:23:47,370]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:24:24,144]\u001b[0m Trial 1015 finished with value: 2.4390947302182515 and parameters: {'n_hidden': 3, 'learning_rate': 0.08131957231361023, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3892313559989079, 'dropout_rate_Layer_2': 0.38580350743352887, 'dropout_rate_Layer_3': 0.2318540303403627, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1883078149174716e-05, 'l1_Layer_2': 0.00040956760769227617, 'l1_Layer_3': 1.3153433641378645e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 125, 'n_units_Layer_3': 280}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.44 | sMAPE for Validation Set is: 44.36% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 10.92 | sMAPE for Test Set is: 13.62% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:24:29,861]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:24:41,971]\u001b[0m Trial 1018 finished with value: 2.1649935247218486 and parameters: {'n_hidden': 3, 'learning_rate': 0.07741476203419348, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3890817427670863, 'dropout_rate_Layer_2': 0.3902479456563379, 'dropout_rate_Layer_3': 0.2401008188648622, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.941815065916961e-05, 'l1_Layer_2': 0.00039863146499696556, 'l1_Layer_3': 1.173684175805239e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 125, 'n_units_Layer_3': 280}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.16 | sMAPE for Validation Set is: 45.19% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 15.99 | sMAPE for Test Set is: 17.63% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:24:46,862]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:24:52,057]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:24:52,187]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:24:58,956]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:25:03,795]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:25:08,357]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:25:17,937]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:25:23,300]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:25:30,591]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:25:33,718]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:25:43,061]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:25:48,651]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:25:52,916]\u001b[0m Trial 1030 finished with value: 3.151125715604716 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008405518232012558, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11674126517275855, 'dropout_rate_Layer_2': 0.25207641906770367, 'dropout_rate_Layer_3': 0.39389094009047115, 'dropout_rate_Layer_4': 0.007215105652368272, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.139006626160101e-05, 'l1_Layer_2': 1.985939846869758e-05, 'l1_Layer_3': 0.0016269088485053292, 'l1_Layer_4': 5.238905533864032e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 280, 'n_units_Layer_3': 85, 'n_units_Layer_4': 95}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.15 | sMAPE for Validation Set is: 51.23% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 31.73 | sMAPE for Test Set is: 42.09% | rMAE for Test Set is: 1.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:25:58,089]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:26:03,144]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:26:07,767]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:26:12,432]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:26:17,798]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:26:22,835]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:26:27,158]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:26:32,262]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:26:37,572]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:26:42,320]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:26:49,600]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:26:54,961]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:27:02,288]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:27:07,947]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:27:17,684]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:27:22,614]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:27:32,489]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:27:39,112]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:27:44,512]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:27:48,232]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:27:52,550]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:27:55,912]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:28:00,267]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:28:05,502]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:28:10,895]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:28:23,019]\u001b[0m Trial 1056 finished with value: 3.4842448657701275 and parameters: {'n_hidden': 4, 'learning_rate': 0.001420468077592427, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03589320771048842, 'dropout_rate_Layer_2': 0.2532407167725928, 'dropout_rate_Layer_3': 0.3852898595332005, 'dropout_rate_Layer_4': 0.016583837960849043, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.085793029196623e-05, 'l1_Layer_2': 3.154709688390188e-05, 'l1_Layer_3': 0.0012665224834169462, 'l1_Layer_4': 0.00029402727161880084, 'n_units_Layer_1': 65, 'n_units_Layer_2': 250, 'n_units_Layer_3': 285, 'n_units_Layer_4': 90}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.48 | sMAPE for Validation Set is: 53.36% | rMAE for Validation Set is: 1.09\n",
      "MAE for Test Set is: 29.56 | sMAPE for Test Set is: 37.22% | rMAE for Test Set is: 1.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:28:33,375]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:28:33,727]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:28:47,751]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:28:53,503]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:29:00,705]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:29:08,031]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:29:13,660]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:29:18,661]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:29:23,103]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:29:28,185]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:29:28,583]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:29:35,774]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:29:41,258]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:29:41,693]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:29:50,609]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:29:54,836]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:30:12,424]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:30:14,465]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:30:20,327]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:30:22,530]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:30:32,452]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:30:49,521]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:31:04,208]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:31:11,562]\u001b[0m Trial 1082 finished with value: 7.998731385694131 and parameters: {'n_hidden': 4, 'learning_rate': 0.04810443981931892, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38046391719295763, 'dropout_rate_Layer_2': 0.30162003135880977, 'dropout_rate_Layer_3': 0.22356840325753205, 'dropout_rate_Layer_4': 0.3756646519738088, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.928810376748755e-05, 'l1_Layer_2': 0.0008311594539724129, 'l1_Layer_3': 1.7483098864265212e-05, 'l1_Layer_4': 0.00034216448270023194, 'n_units_Layer_1': 195, 'n_units_Layer_2': 190, 'n_units_Layer_3': 100, 'n_units_Layer_4': 55}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.00 | sMAPE for Validation Set is: 83.78% | rMAE for Validation Set is: 2.51\n",
      "MAE for Test Set is: 61.20 | sMAPE for Test Set is: 124.05% | rMAE for Test Set is: 3.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:31:12,183]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:31:19,801]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:31:25,293]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:31:30,315]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:31:33,078]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:31:47,557]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:31:48,047]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:31:56,111]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:32:03,850]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:32:11,279]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:32:18,523]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:32:24,300]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:32:30,068]\u001b[0m Trial 1090 finished with value: 2.282726224507019 and parameters: {'n_hidden': 3, 'learning_rate': 0.03566544769188551, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35069734729840996, 'dropout_rate_Layer_2': 0.28161166519550307, 'dropout_rate_Layer_3': 0.243858013099563, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.100149522879691e-05, 'l1_Layer_2': 0.000317870662662412, 'l1_Layer_3': 1.3236171322470547e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 195, 'n_units_Layer_3': 265}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.28 | sMAPE for Validation Set is: 47.07% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 10.54 | sMAPE for Test Set is: 13.38% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:32:48,613]\u001b[0m Trial 1096 finished with value: 2.2696331987994185 and parameters: {'n_hidden': 3, 'learning_rate': 0.0360946757765497, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3464005564535267, 'dropout_rate_Layer_2': 0.24553669719605392, 'dropout_rate_Layer_3': 0.24044522295214799, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.267432099706489e-05, 'l1_Layer_2': 0.00030471086720517787, 'l1_Layer_3': 1.3457813467584363e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 200, 'n_units_Layer_3': 265}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.27 | sMAPE for Validation Set is: 59.56% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 12.70 | sMAPE for Test Set is: 15.01% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:33:04,175]\u001b[0m Trial 1097 finished with value: 2.856991257703515 and parameters: {'n_hidden': 3, 'learning_rate': 0.004709477670636038, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34251931269139957, 'dropout_rate_Layer_2': 0.2612001736290831, 'dropout_rate_Layer_3': 0.24862650160786437, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001605947161064242, 'l1_Layer_2': 0.0005996763717464696, 'l1_Layer_3': 1.4169044768993794e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 200, 'n_units_Layer_3': 260}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.86 | sMAPE for Validation Set is: 57.96% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 11.99 | sMAPE for Test Set is: 15.42% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:33:09,059]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:33:11,932]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:33:21,157]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:33:51,156]\u001b[0m Trial 1101 finished with value: 3.1205019387317794 and parameters: {'n_hidden': 3, 'learning_rate': 0.06714026350731779, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.360940183564213, 'dropout_rate_Layer_2': 0.22727690233311285, 'dropout_rate_Layer_3': 0.18135295939142065, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.733202921080809e-05, 'l1_Layer_2': 0.0004347007346626257, 'l1_Layer_3': 0.002138144091246242, 'n_units_Layer_1': 225, 'n_units_Layer_2': 215, 'n_units_Layer_3': 250}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.12 | sMAPE for Validation Set is: 50.84% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 12.03 | sMAPE for Test Set is: 15.93% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:33:56,370]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:34:06,568]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:34:06,704]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:34:15,981]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:34:25,893]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:34:26,265]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:34:35,205]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:34:39,654]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:34:42,388]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:34:47,224]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:34:54,146]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:35:03,629]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:35:06,904]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:35:09,806]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:35:14,789]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:35:22,137]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:35:28,862]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:35:34,440]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:35:41,262]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:35:46,400]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:35:49,113]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:35:54,556]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:35:59,444]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:35:59,726]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:36:12,227]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:36:12,279]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:36:21,786]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:36:28,759]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:36:33,839]\u001b[0m Trial 1128 finished with value: 6.540753533799226 and parameters: {'n_hidden': 3, 'learning_rate': 0.031178137678523864, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39181006461976614, 'dropout_rate_Layer_2': 0.26987220734693723, 'dropout_rate_Layer_3': 0.23130894080446607, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.4956393945791874e-05, 'l1_Layer_2': 0.002353387693792882, 'l1_Layer_3': 4.016864520034637e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 180, 'n_units_Layer_3': 240}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.54 | sMAPE for Validation Set is: 78.25% | rMAE for Validation Set is: 2.05\n",
      "MAE for Test Set is: 59.25 | sMAPE for Test Set is: 118.30% | rMAE for Test Set is: 3.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:36:34,401]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:36:42,822]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:36:50,517]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:36:53,069]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:36:59,977]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:37:04,703]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:37:12,204]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:37:19,071]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:37:24,877]\u001b[0m Trial 1135 finished with value: 9.337009779787108 and parameters: {'n_hidden': 3, 'learning_rate': 0.039756208330323374, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3759027325436236, 'dropout_rate_Layer_2': 0.321613498923004, 'dropout_rate_Layer_3': 0.15902948718352664, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.653034817052687e-05, 'l1_Layer_2': 0.00024381786477511798, 'l1_Layer_3': 1.1782547379279153e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 145, 'n_units_Layer_3': 270}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.34 | sMAPE for Validation Set is: 85.94% | rMAE for Validation Set is: 2.93\n",
      "MAE for Test Set is: 25.34 | sMAPE for Test Set is: 30.70% | rMAE for Test Set is: 1.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:37:29,536]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:37:42,511]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:37:54,465]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:37:59,806]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:38:05,059]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:38:07,955]\u001b[0m Trial 1141 finished with value: 2.036728951270479 and parameters: {'n_hidden': 3, 'learning_rate': 0.019918020949326754, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3555775160969769, 'dropout_rate_Layer_2': 0.2498705108677604, 'dropout_rate_Layer_3': 0.19263968545717033, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2867862269216515e-05, 'l1_Layer_2': 0.00048501061233552063, 'l1_Layer_3': 1.673410953400079e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 130, 'n_units_Layer_3': 280}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 41.77% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.00 | sMAPE for Test Set is: 13.54% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:38:12,560]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:38:17,152]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:38:34,529]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:38:40,646]\u001b[0m Trial 1149 finished with value: 2.1901111120078283 and parameters: {'n_hidden': 3, 'learning_rate': 0.021224755712259544, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3123854777363115, 'dropout_rate_Layer_2': 0.3708725713997796, 'dropout_rate_Layer_3': 0.19485687656454154, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3696693488722245e-05, 'l1_Layer_2': 0.001056772181212535, 'l1_Layer_3': 1.9174741452271223e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 130, 'n_units_Layer_3': 280}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.19 | sMAPE for Validation Set is: 44.81% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.88 | sMAPE for Test Set is: 14.40% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:38:47,133]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:38:52,697]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:38:57,665]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:39:02,739]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:39:11,880]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:39:14,444]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:39:21,359]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:39:25,187]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:39:27,525]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:39:34,447]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:39:37,614]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:39:42,139]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:39:58,880]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:40:02,268]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:40:07,030]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:40:12,027]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:40:16,108]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:40:19,553]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:40:31,243]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:40:36,758]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:40:41,485]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:40:46,571]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:40:54,032]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:41:03,013]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:41:18,326]\u001b[0m Trial 1171 finished with value: 1.9420559147465195 and parameters: {'n_hidden': 3, 'learning_rate': 0.0060017150845964005, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3904891377087497, 'dropout_rate_Layer_2': 0.33412229537844074, 'dropout_rate_Layer_3': 0.26469007311108644, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5899519170178143e-05, 'l1_Layer_2': 0.0014077625589444796, 'l1_Layer_3': 2.3970207750431166e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 140, 'n_units_Layer_3': 270}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 38.81% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.49 | sMAPE for Test Set is: 14.00% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:41:18,856]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:41:27,700]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:41:30,430]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:41:35,182]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:41:40,286]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:41:45,234]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:41:48,613]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:41:51,569]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:41:56,357]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:42:01,370]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:42:08,217]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:42:08,833]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:42:21,418]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:42:26,808]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:42:33,932]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:42:34,596]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:42:43,246]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:42:43,424]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:42:53,453]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:42:53,560]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:43:03,330]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:43:08,463]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:43:08,983]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:43:15,539]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:43:22,149]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:43:23,052]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:43:30,348]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:43:34,638]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:43:44,381]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:43:49,991]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:43:50,038]\u001b[0m Trial 1202 finished with value: 5.563230257457122 and parameters: {'n_hidden': 4, 'learning_rate': 0.004747104514397792, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14002215432725146, 'dropout_rate_Layer_2': 0.21767650540872993, 'dropout_rate_Layer_3': 0.3506531386171069, 'dropout_rate_Layer_4': 0.019259537378066047, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.086033778969973e-05, 'l1_Layer_2': 0.0007228591145636729, 'l1_Layer_3': 0.007063935060351878, 'l1_Layer_4': 0.0002323752611927823, 'n_units_Layer_1': 195, 'n_units_Layer_2': 175, 'n_units_Layer_3': 285, 'n_units_Layer_4': 135}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 71.81% | rMAE for Validation Set is: 1.74\n",
      "MAE for Test Set is: 59.96 | sMAPE for Test Set is: 120.41% | rMAE for Test Set is: 3.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:43:59,066]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:44:03,608]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:44:10,922]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:44:18,396]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:44:25,397]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:44:28,377]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:44:37,340]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:44:40,791]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:44:55,035]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:45:00,294]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:45:05,401]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:45:12,292]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:45:27,546]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:45:29,933]\u001b[0m Trial 1214 finished with value: 3.204170394318183 and parameters: {'n_hidden': 3, 'learning_rate': 0.002968600534356222, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37591122192110227, 'dropout_rate_Layer_2': 0.335566172507425, 'dropout_rate_Layer_3': 0.3049850441912781, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5815098536042624e-05, 'l1_Layer_2': 0.0014716949542559951, 'l1_Layer_3': 3.673741177660444e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 150, 'n_units_Layer_3': 285}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.20 | sMAPE for Validation Set is: 57.42% | rMAE for Validation Set is: 1.00\n",
      "MAE for Test Set is: 11.31 | sMAPE for Test Set is: 14.39% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:45:42,580]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:45:48,151]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:45:53,262]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:45:55,377]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:46:04,126]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:46:04,234]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:46:12,718]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:46:22,079]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:46:27,863]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:46:31,144]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:46:36,364]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:46:43,577]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:46:50,991]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:46:56,032]\u001b[0m Trial 1232 finished with value: 7.454305436405714 and parameters: {'n_hidden': 3, 'learning_rate': 0.006008827150884147, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39380495374453967, 'dropout_rate_Layer_2': 0.3771855048718901, 'dropout_rate_Layer_3': 0.0023110775595859, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2447539075014844e-05, 'l1_Layer_2': 0.0007950579511866011, 'l1_Layer_3': 2.4034655899820958e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 160, 'n_units_Layer_3': 295}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.45 | sMAPE for Validation Set is: 112.41% | rMAE for Validation Set is: 2.34\n",
      "MAE for Test Set is: 74.17 | sMAPE for Test Set is: 188.93% | rMAE for Test Set is: 4.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:47:10,615]\u001b[0m Trial 1234 finished with value: 4.478103150970535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0053815900964590485, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39073954943467204, 'dropout_rate_Layer_2': 0.3431712736935279, 'dropout_rate_Layer_3': 0.32206381857622013, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1961835163801542e-05, 'l1_Layer_2': 0.003857262471705184, 'l1_Layer_3': 2.3381556219047832e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 105, 'n_units_Layer_3': 295}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 63.40% | rMAE for Validation Set is: 1.40\n",
      "MAE for Test Set is: 50.52 | sMAPE for Test Set is: 88.78% | rMAE for Test Set is: 2.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:47:25,217]\u001b[0m Trial 1235 finished with value: 1.54690683195933 and parameters: {'n_hidden': 3, 'learning_rate': 0.004699872615531579, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03951714359178574, 'dropout_rate_Layer_2': 0.35682155742434735, 'dropout_rate_Layer_3': 0.03921124270416039, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.648793699043267e-05, 'l1_Layer_2': 0.013990373453735262, 'l1_Layer_3': 0.00942284670118485, 'n_units_Layer_1': 265, 'n_units_Layer_2': 205, 'n_units_Layer_3': 165}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.55 | sMAPE for Validation Set is: 23.81% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 10.79 | sMAPE for Test Set is: 13.83% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:47:32,501]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:47:33,478]\u001b[0m Trial 1236 finished with value: 2.254457103877208 and parameters: {'n_hidden': 3, 'learning_rate': 0.004423732937412609, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33701162845374616, 'dropout_rate_Layer_2': 0.04699273953593833, 'dropout_rate_Layer_3': 0.26431773097809064, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.1641032067015014e-05, 'l1_Layer_2': 0.0012409767428012528, 'l1_Layer_3': 5.287878783343667e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 145, 'n_units_Layer_3': 280}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.25 | sMAPE for Validation Set is: 52.95% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.95 | sMAPE for Test Set is: 14.60% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:47:42,355]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:47:42,461]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:47:50,236]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:47:54,809]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:47:59,955]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:48:01,995]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:48:10,103]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:48:19,327]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:48:27,169]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:48:42,231]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:48:44,762]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:48:52,603]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:48:57,513]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:49:02,420]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:49:14,030]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:49:22,049]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:49:34,962]\u001b[0m Trial 1255 finished with value: 7.215473087660296 and parameters: {'n_hidden': 3, 'learning_rate': 0.0203443921084388, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37046496634055237, 'dropout_rate_Layer_2': 0.3889833265091524, 'dropout_rate_Layer_3': 0.2749861384995381, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 2.876728507702702e-05, 'l1_Layer_2': 0.0004872552906511543, 'l1_Layer_3': 1.1914150941329771e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 170, 'n_units_Layer_3': 270}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.22 | sMAPE for Validation Set is: 92.33% | rMAE for Validation Set is: 2.26\n",
      "MAE for Test Set is: 66.81 | sMAPE for Test Set is: 148.83% | rMAE for Test Set is: 3.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:49:40,125]\u001b[0m Trial 1252 finished with value: 2.3926240084604635 and parameters: {'n_hidden': 3, 'learning_rate': 0.008811442454980131, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36901628010294724, 'dropout_rate_Layer_2': 0.32981499627807914, 'dropout_rate_Layer_3': 0.27474025790604545, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.6894425254478123e-05, 'l1_Layer_2': 0.00032990607012593927, 'l1_Layer_3': 1.2375728546591536e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 155, 'n_units_Layer_3': 270}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.39 | sMAPE for Validation Set is: 54.29% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 11.97 | sMAPE for Test Set is: 15.27% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:49:47,127]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:49:52,364]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:50:00,333]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:50:04,654]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:50:26,828]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:50:27,340]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:50:37,671]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:50:45,958]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:50:53,309]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:51:03,260]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:51:15,169]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:51:27,896]\u001b[0m Trial 1263 finished with value: 1.6888482969636816 and parameters: {'n_hidden': 3, 'learning_rate': 0.010132661990329736, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38256582357372393, 'dropout_rate_Layer_2': 0.35126743859663695, 'dropout_rate_Layer_3': 0.23257369350445167, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9166405536894138e-05, 'l1_Layer_2': 0.0002633718671875747, 'l1_Layer_3': 1.9337751470428518e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 135, 'n_units_Layer_3': 245}. Best is trial 532 with value: 1.3737040134578142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.69 | sMAPE for Validation Set is: 43.46% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 12.20 | sMAPE for Test Set is: 14.38% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:51:32,848]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:51:37,892]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:51:42,867]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:51:47,865]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:51:52,569]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:51:53,040]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:52:01,519]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:52:01,677]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:52:12,167]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:52:18,801]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:52:26,563]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:52:33,869]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:52:41,182]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:52:48,571]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:52:56,882]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:53:20,790]\u001b[0m Trial 1276 finished with value: 1.3257092247600344 and parameters: {'n_hidden': 3, 'learning_rate': 0.001435090145170151, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14734262842891993, 'dropout_rate_Layer_2': 0.0913782804819239, 'dropout_rate_Layer_3': 0.04760271226098849, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005845025450149828, 'l1_Layer_2': 0.003036619761309867, 'l1_Layer_3': 0.011182792892444853, 'n_units_Layer_1': 275, 'n_units_Layer_2': 200, 'n_units_Layer_3': 185}. Best is trial 1276 with value: 1.3257092247600344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.33 | sMAPE for Validation Set is: 21.64% | rMAE for Validation Set is: 0.42\n",
      "MAE for Test Set is: 11.22 | sMAPE for Test Set is: 14.81% | rMAE for Test Set is: 0.66\n",
      "MAE for Validation Set is: 5.95 | sMAPE for Validation Set is: 75.55% | rMAE for Validation Set is: 1.86\n",
      "MAE for Test Set is: 68.47 | sMAPE for Test Set is: 156.72% | rMAE for Test Set is: 4.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:53:20,987]\u001b[0m Trial 1284 finished with value: 5.9469919427634395 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007332186592972324, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01195555642150561, 'dropout_rate_Layer_2': 0.19445278441567335, 'dropout_rate_Layer_3': 0.21999627345012307, 'dropout_rate_Layer_4': 0.22306635959454665, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.02357290424802547, 'l1_Layer_2': 3.050289506536035e-05, 'l1_Layer_3': 0.0012580885973625948, 'l1_Layer_4': 0.03542735681413868, 'n_units_Layer_1': 245, 'n_units_Layer_2': 100, 'n_units_Layer_3': 155, 'n_units_Layer_4': 155}. Best is trial 1276 with value: 1.3257092247600344.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:53:33,536]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:53:40,373]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:53:45,399]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:53:52,938]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:54:01,055]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:54:06,305]\u001b[0m Trial 1287 finished with value: 2.332936397503401 and parameters: {'n_hidden': 3, 'learning_rate': 0.01007519942593596, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3809200353274016, 'dropout_rate_Layer_2': 0.3497387560105434, 'dropout_rate_Layer_3': 0.23435386134920813, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0034194385282828e-05, 'l1_Layer_2': 0.00025948545280737585, 'l1_Layer_3': 3.141784785165239e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 140, 'n_units_Layer_3': 235}. Best is trial 1276 with value: 1.3257092247600344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.33 | sMAPE for Validation Set is: 54.54% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 12.75 | sMAPE for Test Set is: 14.96% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:54:10,460]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:54:13,856]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:54:18,545]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:54:28,783]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:54:37,991]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:54:45,393]\u001b[0m Trial 1294 finished with value: 1.9648472867879807 and parameters: {'n_hidden': 3, 'learning_rate': 0.007886431238134936, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3852828667318079, 'dropout_rate_Layer_2': 0.3658207973430887, 'dropout_rate_Layer_3': 0.2130274466281804, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7977727752640083e-05, 'l1_Layer_2': 0.0006558818263210019, 'l1_Layer_3': 1.582951667906441e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 135, 'n_units_Layer_3': 245}. Best is trial 1276 with value: 1.3257092247600344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 45.73% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.06 | sMAPE for Test Set is: 14.45% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:54:48,477]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:54:55,984]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:55:00,360]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:55:01,024]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:55:11,921]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:55:12,576]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:55:22,642]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:55:29,562]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:55:34,931]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:55:40,127]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:55:45,076]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:55:57,114]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:56:04,324]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:56:10,016]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:56:15,015]\u001b[0m Trial 1304 finished with value: 1.9053156108441682 and parameters: {'n_hidden': 3, 'learning_rate': 0.007488618478548387, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39977634401082546, 'dropout_rate_Layer_2': 0.3652864843818101, 'dropout_rate_Layer_3': 0.21457768933948348, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003729337817525063, 'l1_Layer_2': 0.0008692434045754107, 'l1_Layer_3': 1.9320860943835695e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 150, 'n_units_Layer_3': 255}. Best is trial 1276 with value: 1.3257092247600344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 47.28% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 10.66 | sMAPE for Test Set is: 13.78% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:56:21,881]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:56:34,823]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:56:42,230]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:56:47,400]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:56:54,652]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:57:00,108]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:57:06,921]\u001b[0m Trial 1312 finished with value: 1.967845004623481 and parameters: {'n_hidden': 3, 'learning_rate': 0.007416891419859061, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3937921669990812, 'dropout_rate_Layer_2': 0.3679889424165851, 'dropout_rate_Layer_3': 0.2154101252798306, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8055700778212097e-05, 'l1_Layer_2': 0.0006426433215284037, 'l1_Layer_3': 1.94829850282051e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 150, 'n_units_Layer_3': 245}. Best is trial 1276 with value: 1.3257092247600344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 36.92% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.16 | sMAPE for Test Set is: 12.66% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:57:07,575]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:57:14,935]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:57:19,859]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:57:24,347]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:57:29,158]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:57:41,357]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:57:46,512]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:57:46,694]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:57:54,238]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:58:00,872]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:58:04,630]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:58:11,411]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:58:16,761]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:58:21,571]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:58:26,594]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:58:27,040]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:58:48,109]\u001b[0m Trial 1336 finished with value: 6.242016634862513 and parameters: {'n_hidden': 3, 'learning_rate': 0.009262532522300214, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39318933704603354, 'dropout_rate_Layer_2': 0.3678734458929337, 'dropout_rate_Layer_3': 0.21553836136468804, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004250598831342354, 'l1_Layer_2': 0.001712395700086644, 'l1_Layer_3': 8.564771364996669e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 150, 'n_units_Layer_3': 230}. Best is trial 1276 with value: 1.3257092247600344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 80.76% | rMAE for Validation Set is: 1.96\n",
      "MAE for Test Set is: 70.17 | sMAPE for Test Set is: 165.55% | rMAE for Test Set is: 4.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:58:55,180]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:59:00,589]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:59:05,319]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:59:09,932]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:59:15,185]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:59:18,083]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:59:27,360]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:59:30,678]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:59:35,192]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:59:40,196]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:59:40,511]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:59:48,727]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:59:51,905]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:59:56,524]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:00:04,367]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:00:09,598]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:00:15,917]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:00:21,588]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:00:28,010]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:00:40,542]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:00:51,041]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:00:58,262]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:01:03,689]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:01:11,991]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:01:21,862]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:01:29,263]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:01:36,729]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:01:54,180]\u001b[0m Trial 1350 finished with value: 1.6479085625875518 and parameters: {'n_hidden': 3, 'learning_rate': 0.003879414740204084, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38496215858192234, 'dropout_rate_Layer_2': 0.33864874566887876, 'dropout_rate_Layer_3': 0.18337325928067075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021545094246672994, 'l1_Layer_2': 0.0025517149600885, 'l1_Layer_3': 3.3541041453131776e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 175, 'n_units_Layer_3': 245}. Best is trial 1276 with value: 1.3257092247600344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.65 | sMAPE for Validation Set is: 38.41% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 9.70 | sMAPE for Test Set is: 12.25% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:02:01,341]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:02:08,438]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:02:14,096]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:02:18,811]\u001b[0m Trial 1364 finished with value: 3.4400320951040135 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009365223203393068, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0820934598633129, 'dropout_rate_Layer_2': 0.22096045742250764, 'dropout_rate_Layer_3': 0.18978373562947387, 'dropout_rate_Layer_4': 0.2757230249241379, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.01039080187571663, 'l1_Layer_2': 6.467619469873936e-05, 'l1_Layer_3': 0.0008044420873625358, 'l1_Layer_4': 0.004114018379004829, 'n_units_Layer_1': 275, 'n_units_Layer_2': 55, 'n_units_Layer_3': 160, 'n_units_Layer_4': 140}. Best is trial 1276 with value: 1.3257092247600344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.44 | sMAPE for Validation Set is: 56.91% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 47.93 | sMAPE for Test Set is: 81.34% | rMAE for Test Set is: 2.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:02:26,305]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:02:31,133]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:02:35,916]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:02:36,103]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:02:45,272]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:02:50,271]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:02:57,095]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:03:04,577]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:03:09,568]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:03:16,918]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:03:17,073]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:03:27,021]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:03:27,044]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:03:50,444]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:03:55,891]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:04:03,021]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:04:12,842]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:04:29,890]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:04:35,566]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:04:42,188]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:04:50,536]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:04:55,184]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:05:04,321]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:05:12,387]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:05:17,027]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:05:22,223]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:05:33,914]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:05:39,090]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:05:44,595]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:05:54,581]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:06:07,075]\u001b[0m Trial 1393 finished with value: 1.8666455861243971 and parameters: {'n_hidden': 3, 'learning_rate': 0.005787177776144171, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38514720688856957, 'dropout_rate_Layer_2': 0.3548986064956434, 'dropout_rate_Layer_3': 0.16662853820975868, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003233166899493672, 'l1_Layer_2': 0.0024623684369278853, 'l1_Layer_3': 3.0296933137241026e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 175, 'n_units_Layer_3': 240}. Best is trial 1276 with value: 1.3257092247600344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.87 | sMAPE for Validation Set is: 41.83% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 10.12 | sMAPE for Test Set is: 12.61% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:06:12,128]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:06:18,926]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:06:21,714]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:06:43,030]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:07:18,190]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:07:22,641]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:07:23,653]\u001b[0m Trial 1402 finished with value: 1.967919859341454 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035587258317382967, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39992850609689845, 'dropout_rate_Layer_2': 0.3558326681204758, 'dropout_rate_Layer_3': 0.1852023226530664, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00046831007270580367, 'l1_Layer_2': 0.002406083866717015, 'l1_Layer_3': 3.3170611540984725e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 175, 'n_units_Layer_3': 225}. Best is trial 1276 with value: 1.3257092247600344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 44.49% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.11 | sMAPE for Test Set is: 12.60% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:07:29,537]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:07:36,884]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:07:43,104]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:07:54,980]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:07:55,625]\u001b[0m Trial 1407 finished with value: 5.782641852701164 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010606435860692725, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07257493453261683, 'dropout_rate_Layer_2': 0.20365594685228613, 'dropout_rate_Layer_3': 0.18708930433409712, 'dropout_rate_Layer_4': 0.29879175406949876, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.011172078850644838, 'l1_Layer_2': 6.783459844669239e-05, 'l1_Layer_3': 0.0005545808567269918, 'l1_Layer_4': 2.8127918268132994e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 60, 'n_units_Layer_3': 150, 'n_units_Layer_4': 135}. Best is trial 1276 with value: 1.3257092247600344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 74.12% | rMAE for Validation Set is: 1.81\n",
      "MAE for Test Set is: 66.33 | sMAPE for Test Set is: 148.11% | rMAE for Test Set is: 3.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:08:07,138]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:08:13,823]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:08:20,615]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:08:27,837]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:08:34,883]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:08:40,307]\u001b[0m Trial 1411 finished with value: 1.4790368156202878 and parameters: {'n_hidden': 3, 'learning_rate': 0.004078182707881627, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08180906361678819, 'dropout_rate_Layer_2': 0.04239048965134916, 'dropout_rate_Layer_3': 0.0395982229280537, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006960897425840719, 'l1_Layer_2': 0.005408794792422367, 'l1_Layer_3': 0.01482046439813432, 'n_units_Layer_1': 55, 'n_units_Layer_2': 190, 'n_units_Layer_3': 180}. Best is trial 1276 with value: 1.3257092247600344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 23.20% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 10.52 | sMAPE for Test Set is: 13.58% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:08:45,269]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:08:52,187]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:09:14,442]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:09:19,926]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:09:29,789]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:09:36,501]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:09:37,025]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:09:46,184]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:10:11,921]\u001b[0m Trial 1424 finished with value: 1.799094464662679 and parameters: {'n_hidden': 3, 'learning_rate': 0.004042841931209109, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.056632371481792045, 'dropout_rate_Layer_2': 0.05252253192748406, 'dropout_rate_Layer_3': 0.3512184053666958, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006242832365503865, 'l1_Layer_2': 0.004492725606914479, 'l1_Layer_3': 0.020838187552036876, 'n_units_Layer_1': 50, 'n_units_Layer_2': 185, 'n_units_Layer_3': 175}. Best is trial 1276 with value: 1.3257092247600344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.80 | sMAPE for Validation Set is: 33.07% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 10.47 | sMAPE for Test Set is: 13.05% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:10:23,406]\u001b[0m Trial 1426 finished with value: 1.4590124133846334 and parameters: {'n_hidden': 3, 'learning_rate': 0.003715959074351789, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.056490185330345506, 'dropout_rate_Layer_2': 0.054667155240962474, 'dropout_rate_Layer_3': 0.026533993603032824, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006844818708866667, 'l1_Layer_2': 0.006964257338503395, 'l1_Layer_3': 0.019999853643799703, 'n_units_Layer_1': 50, 'n_units_Layer_2': 185, 'n_units_Layer_3': 175}. Best is trial 1276 with value: 1.3257092247600344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 25.94% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 10.53 | sMAPE for Test Set is: 13.60% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:10:28,868]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:11:03,688]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:11:09,591]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:11:14,401]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:11:21,975]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:11:30,942]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:11:48,504]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:11:53,781]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:12:03,609]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:12:03,944]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:12:14,304]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:12:19,036]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:12:24,030]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:12:24,261]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:12:33,864]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:12:34,024]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:12:43,147]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:12:52,923]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:12:58,646]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:13:03,755]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:13:08,605]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:13:13,329]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:13:20,796]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:13:28,258]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:13:33,479]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:13:38,832]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:13:45,737]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:13:46,415]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:13:55,162]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:14:00,463]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:14:08,593]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:14:15,581]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:14:23,284]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:14:28,125]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:14:33,584]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:14:46,167]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:14:53,048]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:15:08,674]\u001b[0m Trial 1457 finished with value: 1.7195394902587104 and parameters: {'n_hidden': 3, 'learning_rate': 0.002150964852036463, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3995669561921894, 'dropout_rate_Layer_2': 0.13419186623585858, 'dropout_rate_Layer_3': 0.18879305311829564, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026882989909538175, 'l1_Layer_2': 0.00233981235217816, 'l1_Layer_3': 2.8570498249804576e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 175, 'n_units_Layer_3': 240}. Best is trial 1276 with value: 1.3257092247600344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.72 | sMAPE for Validation Set is: 42.42% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 10.10 | sMAPE for Test Set is: 12.79% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:15:15,737]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:15:28,355]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:15:35,382]\u001b[0m Trial 1465 finished with value: 1.9164997714885204 and parameters: {'n_hidden': 3, 'learning_rate': 0.0039922927889521, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08073517923152973, 'dropout_rate_Layer_2': 0.30385803681930046, 'dropout_rate_Layer_3': 0.0007756438540124436, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005436053172372592, 'l1_Layer_2': 0.008128323181612145, 'l1_Layer_3': 0.022682655617078044, 'n_units_Layer_1': 65, 'n_units_Layer_2': 200, 'n_units_Layer_3': 180}. Best is trial 1276 with value: 1.3257092247600344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 36.63% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 10.53 | sMAPE for Test Set is: 13.59% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:16:25,535]\u001b[0m Trial 1468 finished with value: 2.3431717616458014 and parameters: {'n_hidden': 3, 'learning_rate': 0.00717800638576545, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37264138382563883, 'dropout_rate_Layer_2': 0.13745706194290078, 'dropout_rate_Layer_3': 0.22215339882746243, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021882587199464028, 'l1_Layer_2': 0.001272405278089463, 'l1_Layer_3': 2.6209222295743278e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 160, 'n_units_Layer_3': 240}. Best is trial 1276 with value: 1.3257092247600344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.34 | sMAPE for Validation Set is: 47.77% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 10.48 | sMAPE for Test Set is: 13.37% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:16:32,784]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:16:39,865]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:16:49,745]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:16:57,425]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:17:02,739]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:17:07,804]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:17:15,250]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:17:22,099]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:17:25,122]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:17:31,787]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:17:35,955]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:17:42,611]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:17:42,990]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:17:52,767]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:17:52,868]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:18:01,387]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:18:03,592]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:18:12,854]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:18:12,915]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:18:24,086]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:18:29,913]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:19:04,655]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:19:12,691]\u001b[0m Trial 1491 finished with value: 4.489369464097276 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005012851418361305, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09828422598832148, 'dropout_rate_Layer_2': 0.191478580439695, 'dropout_rate_Layer_3': 0.1271843014322327, 'dropout_rate_Layer_4': 0.17859064384447637, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0036431886043697998, 'l1_Layer_2': 0.0004682546562714187, 'l1_Layer_3': 1.4293480653852923e-05, 'l1_Layer_4': 0.011078812504081213, 'n_units_Layer_1': 265, 'n_units_Layer_2': 230, 'n_units_Layer_3': 190, 'n_units_Layer_4': 165}. Best is trial 1276 with value: 1.3257092247600344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 70.91% | rMAE for Validation Set is: 1.41\n",
      "MAE for Test Set is: 45.31 | sMAPE for Test Set is: 73.10% | rMAE for Test Set is: 2.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:19:22,143]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:19:34,569]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:19:41,750]\u001b[0m Trial 1492 finished with value: 2.004570387873034 and parameters: {'n_hidden': 3, 'learning_rate': 0.004235973665957885, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0637572090978128, 'dropout_rate_Layer_2': 0.3160433097846623, 'dropout_rate_Layer_3': 0.039482388224193754, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007648956643275017, 'l1_Layer_2': 0.011105549289080531, 'l1_Layer_3': 0.023992343894148796, 'n_units_Layer_1': 60, 'n_units_Layer_2': 190, 'n_units_Layer_3': 170}. Best is trial 1276 with value: 1.3257092247600344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 37.79% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.36 | sMAPE for Test Set is: 15.01% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:19:44,782]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:19:51,585]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:19:59,076]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:20:04,238]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:20:19,441]\u001b[0m Trial 1496 finished with value: 4.920326546339548 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005995459370017053, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09215862991521963, 'dropout_rate_Layer_2': 0.1909131473192574, 'dropout_rate_Layer_3': 0.13367942553230514, 'dropout_rate_Layer_4': 0.17270717581502168, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0022178396545791414, 'l1_Layer_2': 0.000316118228405493, 'l1_Layer_3': 3.070884034437951e-05, 'l1_Layer_4': 0.011478810466559583, 'n_units_Layer_1': 265, 'n_units_Layer_2': 55, 'n_units_Layer_3': 190, 'n_units_Layer_4': 160}. Best is trial 1276 with value: 1.3257092247600344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.92 | sMAPE for Validation Set is: 64.64% | rMAE for Validation Set is: 1.54\n",
      "MAE for Test Set is: 35.11 | sMAPE for Test Set is: 49.07% | rMAE for Test Set is: 2.08\n",
      "for 2021-01-01, MAE is:3.35 & sMAPE is:13.56% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 13.56% & 0.48\n",
      "for 2021-01-02, MAE is:1.71 & sMAPE is:6.53% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 10.05% & 0.34\n",
      "for 2021-01-03, MAE is:1.27 & sMAPE is:4.97% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :2.11 & 8.36% & 0.25\n",
      "for 2021-01-04, MAE is:16.16 & sMAPE is:41.05% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.62 & 16.53% & 0.36\n",
      "for 2021-01-05, MAE is:13.85 & sMAPE is:30.86% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 19.40% & 0.40\n",
      "for 2021-01-06, MAE is:7.64 & sMAPE is:18.66% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.33 & 19.27% & 0.41\n",
      "for 2021-01-07, MAE is:27.57 & sMAPE is:46.62% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :10.22 & 23.18% & 0.44\n",
      "for 2021-01-08, MAE is:24.79 & sMAPE is:33.28% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :12.04 & 24.44% & 0.45\n",
      "for 2021-01-09, MAE is:7.85 & sMAPE is:14.40% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :11.58 & 23.33% & 0.43\n",
      "for 2021-01-10, MAE is:8.30 & sMAPE is:18.90% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :11.25 & 22.88% & 0.44\n",
      "for 2021-01-11, MAE is:4.65 & sMAPE is:11.18% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :10.65 & 21.82% & 0.44\n",
      "for 2021-01-12, MAE is:10.84 & sMAPE is:25.26% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :10.67 & 22.11% & 0.57\n",
      "for 2021-01-13, MAE is:4.89 & sMAPE is:11.70% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :10.22 & 21.31% & 0.59\n",
      "for 2021-01-14, MAE is:30.38 & sMAPE is:49.30% & rMAE is:6.47 ||| daily mean of MAE & sMAPE & rMAE till now are :11.66 & 23.31% & 1.01\n",
      "for 2021-01-15, MAE is:16.30 & sMAPE is:23.08% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :11.97 & 23.29% & 1.07\n",
      "for 2021-01-16, MAE is:15.07 & sMAPE is:24.77% & rMAE is:3.43 ||| daily mean of MAE & sMAPE & rMAE till now are :12.17 & 23.38% & 1.21\n",
      "for 2021-01-17, MAE is:5.12 & sMAPE is:9.49% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :11.75 & 22.57% & 1.17\n",
      "for 2021-01-18, MAE is:7.90 & sMAPE is:14.26% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :11.54 & 22.10% & 1.14\n",
      "for 2021-01-19, MAE is:6.43 & sMAPE is:14.60% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :11.27 & 21.71% & 1.15\n",
      "for 2021-01-20, MAE is:8.61 & sMAPE is:22.85% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :11.14 & 21.77% & 1.15\n",
      "for 2021-01-21, MAE is:4.53 & sMAPE is:15.34% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :10.82 & 21.46% & 1.10\n",
      "for 2021-01-22, MAE is:5.28 & sMAPE is:18.50% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :10.57 & 21.33% & 1.06\n",
      "for 2021-01-23, MAE is:11.29 & sMAPE is:30.68% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :10.60 & 21.73% & 1.04\n",
      "for 2021-01-24, MAE is:9.73 & sMAPE is:21.06% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :10.56 & 21.70% & 1.09\n",
      "for 2021-01-25, MAE is:13.91 & sMAPE is:23.98% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :10.70 & 21.80% & 1.12\n",
      "for 2021-01-26, MAE is:10.63 & sMAPE is:18.14% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :10.70 & 21.65% & 1.10\n",
      "for 2021-01-27, MAE is:7.32 & sMAPE is:13.10% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :10.57 & 21.34% & 1.07\n",
      "for 2021-01-28, MAE is:6.26 & sMAPE is:11.32% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :10.42 & 20.98% & 1.04\n",
      "for 2021-01-29, MAE is:5.69 & sMAPE is:11.59% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :10.25 & 20.66% & 1.02\n",
      "for 2021-01-30, MAE is:5.52 & sMAPE is:11.30% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :10.10 & 20.34% & 1.00\n",
      "for 2021-01-31, MAE is:4.80 & sMAPE is:9.71% & rMAE is:2.89 ||| daily mean of MAE & sMAPE & rMAE till now are :9.93 & 20.00% & 1.06\n",
      "for 2021-02-01, MAE is:10.80 & sMAPE is:19.23% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :9.95 & 19.98% & 1.10\n",
      "for 2021-02-02, MAE is:7.23 & sMAPE is:13.28% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :9.87 & 19.77% & 1.10\n",
      "for 2021-02-03, MAE is:6.50 & sMAPE is:14.33% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :9.77 & 19.61% & 1.08\n",
      "for 2021-02-04, MAE is:10.96 & sMAPE is:21.75% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :9.80 & 19.68% & 1.10\n",
      "for 2021-02-05, MAE is:4.79 & sMAPE is:9.36% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :9.67 & 19.39% & 1.12\n",
      "for 2021-02-06, MAE is:8.06 & sMAPE is:18.46% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :9.62 & 19.36% & 1.11\n",
      "for 2021-02-07, MAE is:3.41 & sMAPE is:8.49% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :9.46 & 19.08% & 1.09\n",
      "for 2021-02-08, MAE is:9.31 & sMAPE is:19.02% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :9.45 & 19.08% & 1.10\n",
      "for 2021-02-09, MAE is:16.66 & sMAPE is:27.78% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :9.63 & 19.29% & 1.11\n",
      "for 2021-02-10, MAE is:17.59 & sMAPE is:24.76% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :9.83 & 19.43% & 1.10\n",
      "for 2021-02-11, MAE is:20.31 & sMAPE is:24.79% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :10.08 & 19.55% & 1.09\n",
      "for 2021-02-12, MAE is:9.36 & sMAPE is:15.05% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :10.06 & 19.45% & 1.09\n",
      "for 2021-02-13, MAE is:7.45 & sMAPE is:13.73% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :10.00 & 19.32% & 1.08\n",
      "for 2021-02-14, MAE is:4.85 & sMAPE is:10.13% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :9.89 & 19.12% & 1.07\n",
      "for 2021-02-15, MAE is:7.44 & sMAPE is:14.73% & rMAE is:3.35 ||| daily mean of MAE & sMAPE & rMAE till now are :9.83 & 19.02% & 1.12\n",
      "for 2021-02-16, MAE is:5.99 & sMAPE is:11.11% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :9.75 & 18.85% & 1.10\n",
      "for 2021-02-17, MAE is:6.39 & sMAPE is:12.60% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :9.68 & 18.72% & 1.09\n",
      "for 2021-02-18, MAE is:7.86 & sMAPE is:16.89% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :9.65 & 18.68% & 1.07\n",
      "for 2021-02-19, MAE is:7.26 & sMAPE is:15.58% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :9.60 & 18.62% & 1.06\n",
      "for 2021-02-20, MAE is:7.06 & sMAPE is:17.93% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :9.55 & 18.61% & 1.04\n",
      "for 2021-02-21, MAE is:3.91 & sMAPE is:11.00% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :9.44 & 18.46% & 1.03\n",
      "for 2021-02-22, MAE is:3.65 & sMAPE is:8.79% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :9.33 & 18.28% & 1.02\n",
      "for 2021-02-23, MAE is:2.04 & sMAPE is:5.22% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :9.20 & 18.04% & 1.00\n",
      "for 2021-02-24, MAE is:3.95 & sMAPE is:12.42% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :9.10 & 17.94% & 0.99\n",
      "for 2021-02-25, MAE is:2.98 & sMAPE is:9.58% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.99 & 17.79% & 0.98\n",
      "for 2021-02-26, MAE is:2.47 & sMAPE is:7.96% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :8.88 & 17.61% & 0.96\n",
      "for 2021-02-27, MAE is:7.04 & sMAPE is:22.03% & rMAE is:3.15 ||| daily mean of MAE & sMAPE & rMAE till now are :8.85 & 17.69% & 1.00\n",
      "for 2021-02-28, MAE is:3.71 & sMAPE is:11.31% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :8.76 & 17.58% & 1.00\n",
      "for 2021-03-01, MAE is:3.64 & sMAPE is:9.95% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :8.67 & 17.45% & 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-03-02, MAE is:7.92 & sMAPE is:19.40% & rMAE is:2.14 ||| daily mean of MAE & sMAPE & rMAE till now are :8.66 & 17.49% & 1.01\n",
      "for 2021-03-03, MAE is:5.48 & sMAPE is:12.77% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :8.61 & 17.41% & 1.00\n",
      "for 2021-03-04, MAE is:6.92 & sMAPE is:17.78% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :8.58 & 17.42% & 1.00\n",
      "for 2021-03-05, MAE is:9.36 & sMAPE is:19.48% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 17.45% & 0.99\n",
      "for 2021-03-06, MAE is:3.41 & sMAPE is:8.97% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :8.51 & 17.32% & 1.00\n",
      "for 2021-03-07, MAE is:3.82 & sMAPE is:10.41% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 17.21% & 1.00\n",
      "for 2021-03-08, MAE is:17.81 & sMAPE is:32.51% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :8.58 & 17.44% & 1.00\n",
      "for 2021-03-09, MAE is:11.58 & sMAPE is:20.42% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :8.63 & 17.49% & 1.00\n",
      "for 2021-03-10, MAE is:8.49 & sMAPE is:18.30% & rMAE is:3.77 ||| daily mean of MAE & sMAPE & rMAE till now are :8.63 & 17.50% & 1.04\n",
      "for 2021-03-11, MAE is:2.26 & sMAPE is:6.50% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :8.53 & 17.34% & 1.03\n",
      "for 2021-03-12, MAE is:1.88 & sMAPE is:5.12% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 17.17% & 1.02\n",
      "for 2021-03-13, MAE is:1.41 & sMAPE is:3.93% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :8.34 & 16.98% & 1.01\n",
      "for 2021-03-14, MAE is:2.75 & sMAPE is:7.29% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :8.27 & 16.85% & 1.02\n",
      "for 2021-03-15, MAE is:4.66 & sMAPE is:10.57% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :8.22 & 16.77% & 1.01\n",
      "for 2021-03-16, MAE is:7.12 & sMAPE is:14.80% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :8.20 & 16.74% & 1.01\n",
      "for 2021-03-17, MAE is:8.61 & sMAPE is:16.88% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :8.21 & 16.74% & 1.01\n",
      "for 2021-03-18, MAE is:3.52 & sMAPE is:7.17% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :8.15 & 16.62% & 1.00\n",
      "for 2021-03-19, MAE is:2.59 & sMAPE is:6.32% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :8.08 & 16.49% & 0.99\n",
      "for 2021-03-20, MAE is:2.55 & sMAPE is:6.81% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :8.01 & 16.36% & 0.99\n",
      "for 2021-03-21, MAE is:3.22 & sMAPE is:9.11% & rMAE is:2.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.95 & 16.27% & 1.01\n",
      "for 2021-03-22, MAE is:5.69 & sMAPE is:14.01% & rMAE is:2.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.92 & 16.24% & 1.03\n",
      "for 2021-03-23, MAE is:3.60 & sMAPE is:7.83% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.87 & 16.14% & 1.03\n",
      "for 2021-03-24, MAE is:0.89 & sMAPE is:2.32% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :7.78 & 15.98% & 1.01\n",
      "for 2021-03-25, MAE is:3.09 & sMAPE is:7.99% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 15.88% & 1.01\n",
      "for 2021-03-26, MAE is:1.92 & sMAPE is:5.07% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 15.75% & 1.00\n",
      "for 2021-03-27, MAE is:1.86 & sMAPE is:5.13% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 15.63% & 1.00\n",
      "for 2021-03-28, MAE is:1.76 & sMAPE is:4.72% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 15.50% & 1.00\n",
      "for 2021-03-29, MAE is:1.79 & sMAPE is:4.76% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.46 & 15.38% & 0.99\n",
      "for 2021-03-30, MAE is:3.26 & sMAPE is:8.76% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.41 & 15.31% & 0.99\n",
      "for 2021-03-31, MAE is:2.86 & sMAPE is:7.43% & rMAE is:2.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.36 & 15.22% & 1.01\n",
      "for 2021-04-01, MAE is:3.97 & sMAPE is:10.51% & rMAE is:5.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 15.17% & 1.05\n",
      "for 2021-04-02, MAE is:6.85 & sMAPE is:24.08% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 15.27% & 1.06\n",
      "for 2021-04-03, MAE is:5.66 & sMAPE is:16.44% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 15.28% & 1.07\n",
      "for 2021-04-04, MAE is:10.31 & sMAPE is:43.62% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :7.33 & 15.58% & 1.07\n",
      "for 2021-04-05, MAE is:11.19 & sMAPE is:62.11% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.37 & 16.07% & 1.06\n",
      "for 2021-04-06, MAE is:9.17 & sMAPE is:30.09% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 16.22% & 1.07\n",
      "for 2021-04-07, MAE is:4.96 & sMAPE is:13.47% & rMAE is:3.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.37 & 16.19% & 1.09\n",
      "for 2021-04-08, MAE is:3.97 & sMAPE is:10.41% & rMAE is:2.36 ||| daily mean of MAE & sMAPE & rMAE till now are :7.33 & 16.13% & 1.10\n",
      "for 2021-04-09, MAE is:2.38 & sMAPE is:6.74% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 16.03% & 1.10\n",
      "for 2021-04-10, MAE is:6.01 & sMAPE is:15.91% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 16.03% & 1.10\n",
      "for 2021-04-11, MAE is:5.12 & sMAPE is:13.24% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 16.00% & 1.09\n",
      "for 2021-04-12, MAE is:4.11 & sMAPE is:9.21% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 15.94% & 1.08\n",
      "for 2021-04-13, MAE is:3.09 & sMAPE is:7.12% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 15.85% & 1.07\n",
      "for 2021-04-14, MAE is:13.91 & sMAPE is:23.74% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 15.93% & 1.07\n",
      "for 2021-04-15, MAE is:13.37 & sMAPE is:22.11% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 15.99% & 1.07\n",
      "for 2021-04-16, MAE is:7.03 & sMAPE is:12.32% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 15.95% & 1.06\n",
      "for 2021-04-17, MAE is:3.03 & sMAPE is:6.50% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 15.86% & 1.06\n",
      "for 2021-04-18, MAE is:2.75 & sMAPE is:5.80% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 15.77% & 1.05\n",
      "for 2021-04-19, MAE is:2.16 & sMAPE is:4.54% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 15.67% & 1.05\n",
      "for 2021-04-20, MAE is:1.67 & sMAPE is:3.73% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 15.56% & 1.04\n",
      "for 2021-04-21, MAE is:4.20 & sMAPE is:9.81% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 15.51% & 1.03\n",
      "for 2021-04-22, MAE is:3.20 & sMAPE is:8.10% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 15.44% & 1.03\n",
      "for 2021-04-23, MAE is:5.46 & sMAPE is:12.71% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 15.42% & 1.02\n",
      "for 2021-04-24, MAE is:4.42 & sMAPE is:9.96% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 15.37% & 1.03\n",
      "for 2021-04-25, MAE is:4.60 & sMAPE is:10.52% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 15.33% & 1.03\n",
      "for 2021-04-26, MAE is:10.07 & sMAPE is:17.42% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 15.35% & 1.03\n",
      "for 2021-04-27, MAE is:6.89 & sMAPE is:12.25% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 15.32% & 1.03\n",
      "for 2021-04-28, MAE is:7.81 & sMAPE is:13.12% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 15.30% & 1.02\n",
      "for 2021-04-29, MAE is:6.39 & sMAPE is:11.30% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 15.27% & 1.02\n",
      "for 2021-04-30, MAE is:7.49 & sMAPE is:12.89% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 15.25% & 1.02\n",
      "for 2021-05-01, MAE is:3.53 & sMAPE is:7.15% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 15.18% & 1.01\n",
      "for 2021-05-02, MAE is:5.25 & sMAPE is:11.46% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 15.15% & 1.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-05-03, MAE is:11.45 & sMAPE is:19.10% & rMAE is:2.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 15.18% & 1.03\n",
      "for 2021-05-04, MAE is:13.70 & sMAPE is:26.43% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 15.27% & 1.04\n",
      "for 2021-05-05, MAE is:4.90 & sMAPE is:9.90% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 15.23% & 1.03\n",
      "for 2021-05-06, MAE is:13.42 & sMAPE is:22.60% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 15.29% & 1.03\n",
      "for 2021-05-07, MAE is:8.75 & sMAPE is:13.00% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 15.27% & 1.03\n",
      "for 2021-05-08, MAE is:7.16 & sMAPE is:13.45% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 15.26% & 1.04\n",
      "for 2021-05-09, MAE is:12.27 & sMAPE is:28.84% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 15.36% & 1.04\n",
      "for 2021-05-10, MAE is:3.31 & sMAPE is:6.79% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.13 & 15.29% & 1.03\n",
      "for 2021-05-11, MAE is:6.05 & sMAPE is:11.85% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.13 & 15.27% & 1.03\n",
      "for 2021-05-12, MAE is:2.17 & sMAPE is:4.17% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 15.18% & 1.02\n",
      "for 2021-05-13, MAE is:1.91 & sMAPE is:3.84% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 15.10% & 1.02\n",
      "for 2021-05-14, MAE is:3.74 & sMAPE is:7.60% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 15.04% & 1.01\n",
      "for 2021-05-15, MAE is:3.02 & sMAPE is:6.29% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 14.98% & 1.01\n",
      "for 2021-05-16, MAE is:14.30 & sMAPE is:39.11% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 15.16% & 1.01\n",
      "for 2021-05-17, MAE is:9.27 & sMAPE is:18.98% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 15.18% & 1.02\n",
      "for 2021-05-18, MAE is:6.80 & sMAPE is:12.99% & rMAE is:3.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 15.17% & 1.04\n",
      "for 2021-05-19, MAE is:1.64 & sMAPE is:3.03% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 15.08% & 1.04\n",
      "for 2021-05-20, MAE is:2.35 & sMAPE is:4.53% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 15.01% & 1.04\n",
      "for 2021-05-21, MAE is:16.99 & sMAPE is:49.68% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 15.25% & 1.04\n",
      "for 2021-05-22, MAE is:24.15 & sMAPE is:99.99% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 15.85% & 1.04\n",
      "for 2021-05-23, MAE is:18.19 & sMAPE is:65.79% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 16.20% & 1.04\n",
      "for 2021-05-24, MAE is:8.60 & sMAPE is:22.52% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 16.24% & 1.04\n",
      "for 2021-05-25, MAE is:3.64 & sMAPE is:7.38% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 16.18% & 1.04\n",
      "for 2021-05-26, MAE is:2.27 & sMAPE is:4.55% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.21 & 16.10% & 1.03\n",
      "for 2021-05-27, MAE is:2.17 & sMAPE is:4.28% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 16.02% & 1.03\n",
      "for 2021-05-28, MAE is:2.89 & sMAPE is:5.75% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 15.95% & 1.03\n",
      "for 2021-05-29, MAE is:9.29 & sMAPE is:21.48% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 15.99% & 1.02\n",
      "for 2021-05-30, MAE is:12.53 & sMAPE is:35.55% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 16.12% & 1.02\n",
      "for 2021-05-31, MAE is:7.93 & sMAPE is:15.95% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 16.12% & 1.02\n",
      "for 2021-06-01, MAE is:4.04 & sMAPE is:7.67% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 16.06% & 1.02\n",
      "for 2021-06-02, MAE is:2.68 & sMAPE is:5.07% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 15.99% & 1.01\n",
      "for 2021-06-03, MAE is:2.87 & sMAPE is:5.60% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 15.92% & 1.02\n",
      "for 2021-06-04, MAE is:3.49 & sMAPE is:6.38% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 15.86% & 1.01\n",
      "for 2021-06-05, MAE is:2.44 & sMAPE is:4.46% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 15.79% & 1.01\n",
      "for 2021-06-06, MAE is:3.28 & sMAPE is:6.16% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 15.73% & 1.00\n",
      "for 2021-06-07, MAE is:1.77 & sMAPE is:3.16% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 15.65% & 1.00\n",
      "for 2021-06-08, MAE is:2.51 & sMAPE is:4.50% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 15.58% & 1.00\n",
      "for 2021-06-09, MAE is:1.69 & sMAPE is:3.00% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 15.50% & 1.00\n",
      "for 2021-06-10, MAE is:1.41 & sMAPE is:2.53% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 15.42% & 0.99\n",
      "for 2021-06-11, MAE is:1.82 & sMAPE is:3.36% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 15.34% & 0.99\n",
      "for 2021-06-12, MAE is:17.31 & sMAPE is:49.52% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 15.55% & 0.99\n",
      "for 2021-06-13, MAE is:26.42 & sMAPE is:109.65% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 16.13% & 0.99\n",
      "for 2021-06-14, MAE is:7.40 & sMAPE is:15.36% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 16.12% & 0.99\n",
      "for 2021-06-15, MAE is:3.80 & sMAPE is:7.59% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 16.07% & 0.99\n",
      "for 2021-06-16, MAE is:3.61 & sMAPE is:7.06% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 16.02% & 0.99\n",
      "for 2021-06-17, MAE is:2.17 & sMAPE is:4.47% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 15.95% & 0.98\n",
      "for 2021-06-18, MAE is:2.61 & sMAPE is:5.31% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 15.88% & 0.98\n",
      "for 2021-06-19, MAE is:4.06 & sMAPE is:8.00% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 15.84% & 0.98\n",
      "for 2021-06-20, MAE is:5.60 & sMAPE is:12.50% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 15.82% & 0.97\n",
      "for 2021-06-21, MAE is:3.25 & sMAPE is:6.39% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 15.76% & 0.97\n",
      "for 2021-06-22, MAE is:2.49 & sMAPE is:4.70% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 15.70% & 0.97\n",
      "for 2021-06-23, MAE is:4.57 & sMAPE is:8.61% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 15.66% & 0.97\n",
      "for 2021-06-24, MAE is:8.87 & sMAPE is:15.76% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 15.66% & 0.97\n",
      "for 2021-06-25, MAE is:4.92 & sMAPE is:8.52% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 15.62% & 0.97\n",
      "for 2021-06-26, MAE is:6.68 & sMAPE is:11.37% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 15.60% & 0.97\n",
      "for 2021-06-27, MAE is:8.19 & sMAPE is:15.59% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 15.60% & 0.97\n",
      "for 2021-06-28, MAE is:8.08 & sMAPE is:14.04% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 15.59% & 0.97\n",
      "for 2021-06-29, MAE is:2.67 & sMAPE is:4.53% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 15.52% & 0.97\n",
      "for 2021-06-30, MAE is:2.09 & sMAPE is:3.51% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 15.46% & 0.96\n",
      "for 2021-07-01, MAE is:1.55 & sMAPE is:2.68% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 15.39% & 0.96\n",
      "for 2021-07-02, MAE is:1.94 & sMAPE is:3.41% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 15.32% & 0.96\n",
      "for 2021-07-03, MAE is:2.85 & sMAPE is:5.03% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 15.27% & 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-07-04, MAE is:3.17 & sMAPE is:5.56% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 15.21% & 0.96\n",
      "for 2021-07-05, MAE is:2.09 & sMAPE is:3.65% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 15.15% & 0.96\n",
      "for 2021-07-06, MAE is:2.33 & sMAPE is:4.04% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 15.09% & 0.96\n",
      "for 2021-07-07, MAE is:1.50 & sMAPE is:2.69% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 15.03% & 0.96\n",
      "for 2021-07-08, MAE is:3.23 & sMAPE is:5.72% & rMAE is:2.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 14.98% & 0.96\n",
      "for 2021-07-09, MAE is:1.54 & sMAPE is:2.73% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 14.91% & 0.97\n",
      "for 2021-07-10, MAE is:1.77 & sMAPE is:3.11% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 14.85% & 0.97\n",
      "for 2021-07-11, MAE is:3.60 & sMAPE is:6.43% & rMAE is:4.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 14.81% & 0.99\n",
      "for 2021-07-12, MAE is:1.97 & sMAPE is:3.38% & rMAE is:3.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 14.75% & 1.00\n",
      "for 2021-07-13, MAE is:2.80 & sMAPE is:4.92% & rMAE is:2.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 14.70% & 1.01\n",
      "for 2021-07-14, MAE is:3.12 & sMAPE is:5.37% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 14.65% & 1.01\n",
      "for 2021-07-15, MAE is:1.71 & sMAPE is:2.88% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 14.59% & 1.01\n",
      "for 2021-07-16, MAE is:1.60 & sMAPE is:2.69% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 14.53% & 1.01\n",
      "for 2021-07-17, MAE is:5.75 & sMAPE is:10.62% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 14.51% & 1.01\n",
      "for 2021-07-18, MAE is:16.35 & sMAPE is:45.43% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 14.67% & 1.01\n",
      "for 2021-07-19, MAE is:11.98 & sMAPE is:21.75% & rMAE is:4.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 14.70% & 1.03\n",
      "for 2021-07-20, MAE is:1.71 & sMAPE is:2.92% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 14.64% & 1.03\n",
      "for 2021-07-21, MAE is:1.60 & sMAPE is:2.74% & rMAE is:2.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 14.58% & 1.03\n",
      "for 2021-07-22, MAE is:1.67 & sMAPE is:2.81% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 14.52% & 1.03\n",
      "for 2021-07-23, MAE is:1.88 & sMAPE is:3.22% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 14.47% & 1.04\n",
      "for 2021-07-24, MAE is:2.01 & sMAPE is:3.48% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 14.42% & 1.03\n",
      "for 2021-07-25, MAE is:3.66 & sMAPE is:6.67% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 14.38% & 1.03\n",
      "for 2021-07-26, MAE is:2.94 & sMAPE is:5.16% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 14.33% & 1.03\n",
      "for 2021-07-27, MAE is:2.36 & sMAPE is:4.10% & rMAE is:2.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 14.28% & 1.04\n",
      "for 2021-07-28, MAE is:2.32 & sMAPE is:3.98% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 14.24% & 1.04\n",
      "for 2021-07-29, MAE is:8.24 & sMAPE is:15.86% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 14.24% & 1.04\n",
      "for 2021-07-30, MAE is:2.96 & sMAPE is:5.52% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 14.20% & 1.04\n",
      "for 2021-07-31, MAE is:10.77 & sMAPE is:22.83% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 14.24% & 1.04\n",
      "for 2021-08-01, MAE is:5.32 & sMAPE is:10.03% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 14.22% & 1.04\n",
      "for 2021-08-02, MAE is:2.66 & sMAPE is:4.76% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 14.18% & 1.04\n",
      "for 2021-08-03, MAE is:2.18 & sMAPE is:3.81% & rMAE is:4.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 14.13% & 1.06\n",
      "for 2021-08-04, MAE is:4.53 & sMAPE is:7.74% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 14.10% & 1.06\n",
      "for 2021-08-05, MAE is:2.86 & sMAPE is:4.80% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 14.06% & 1.06\n",
      "for 2021-08-06, MAE is:2.38 & sMAPE is:4.04% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 14.01% & 1.06\n",
      "for 2021-08-07, MAE is:3.37 & sMAPE is:5.73% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 13.97% & 1.05\n",
      "for 2021-08-08, MAE is:19.96 & sMAPE is:57.21% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 14.17% & 1.05\n",
      "for 2021-08-09, MAE is:10.79 & sMAPE is:18.72% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 14.19% & 1.05\n",
      "for 2021-08-10, MAE is:6.13 & sMAPE is:9.29% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 14.17% & 1.05\n",
      "for 2021-08-11, MAE is:5.72 & sMAPE is:8.34% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 14.14% & 1.05\n",
      "for 2021-08-12, MAE is:4.77 & sMAPE is:6.84% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 14.11% & 1.05\n",
      "for 2021-08-13, MAE is:2.62 & sMAPE is:3.68% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 14.06% & 1.04\n",
      "for 2021-08-14, MAE is:5.68 & sMAPE is:8.59% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 14.04% & 1.04\n",
      "for 2021-08-15, MAE is:8.60 & sMAPE is:12.95% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 14.03% & 1.04\n",
      "for 2021-08-16, MAE is:4.32 & sMAPE is:6.06% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 14.00% & 1.04\n",
      "for 2021-08-17, MAE is:6.43 & sMAPE is:10.83% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 13.99% & 1.04\n",
      "for 2021-08-18, MAE is:3.10 & sMAPE is:4.36% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 13.94% & 1.04\n",
      "for 2021-08-19, MAE is:4.37 & sMAPE is:5.94% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 13.91% & 1.04\n",
      "for 2021-08-20, MAE is:3.53 & sMAPE is:4.58% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 13.87% & 1.03\n",
      "for 2021-08-21, MAE is:2.89 & sMAPE is:3.80% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 13.83% & 1.03\n",
      "for 2021-08-22, MAE is:4.39 & sMAPE is:5.78% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 13.79% & 1.03\n",
      "for 2021-08-23, MAE is:1.45 & sMAPE is:1.90% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 13.74% & 1.02\n",
      "for 2021-08-24, MAE is:1.94 & sMAPE is:2.45% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 13.69% & 1.02\n",
      "for 2021-08-25, MAE is:3.98 & sMAPE is:5.19% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 13.66% & 1.02\n",
      "for 2021-08-26, MAE is:7.11 & sMAPE is:8.84% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 13.64% & 1.02\n",
      "for 2021-08-27, MAE is:8.61 & sMAPE is:10.39% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 13.62% & 1.02\n",
      "for 2021-08-28, MAE is:2.90 & sMAPE is:3.49% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 13.58% & 1.02\n",
      "for 2021-08-29, MAE is:4.89 & sMAPE is:5.89% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 13.55% & 1.02\n",
      "for 2021-08-30, MAE is:15.69 & sMAPE is:15.93% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 13.56% & 1.01\n",
      "for 2021-08-31, MAE is:12.07 & sMAPE is:11.08% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 13.55% & 1.01\n",
      "for 2021-09-01, MAE is:9.35 & sMAPE is:8.89% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 13.53% & 1.01\n",
      "for 2021-09-02, MAE is:5.90 & sMAPE is:5.78% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 13.50% & 1.01\n",
      "for 2021-09-03, MAE is:5.23 & sMAPE is:5.36% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 13.47% & 1.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-09-04, MAE is:5.90 & sMAPE is:6.14% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 13.44% & 1.00\n",
      "for 2021-09-05, MAE is:8.18 & sMAPE is:8.32% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 13.41% & 1.00\n",
      "for 2021-09-06, MAE is:13.11 & sMAPE is:11.26% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 13.41% & 1.00\n",
      "for 2021-09-07, MAE is:9.21 & sMAPE is:8.21% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 13.39% & 1.00\n",
      "for 2021-09-08, MAE is:5.41 & sMAPE is:5.00% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 13.35% & 1.00\n",
      "for 2021-09-09, MAE is:2.50 & sMAPE is:2.40% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 13.31% & 0.99\n",
      "for 2021-09-10, MAE is:4.64 & sMAPE is:4.38% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 13.27% & 0.99\n",
      "for 2021-09-11, MAE is:4.86 & sMAPE is:4.74% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 13.24% & 0.99\n",
      "for 2021-09-12, MAE is:6.86 & sMAPE is:7.00% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 13.22% & 0.99\n",
      "for 2021-09-13, MAE is:1.89 & sMAPE is:1.87% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 13.17% & 0.99\n",
      "for 2021-09-14, MAE is:9.36 & sMAPE is:8.09% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 13.15% & 0.99\n",
      "for 2021-09-15, MAE is:3.28 & sMAPE is:2.95% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 13.11% & 0.98\n",
      "for 2021-09-16, MAE is:10.78 & sMAPE is:9.16% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 13.10% & 0.98\n",
      "for 2021-09-17, MAE is:5.14 & sMAPE is:4.30% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 13.06% & 0.98\n",
      "for 2021-09-18, MAE is:9.01 & sMAPE is:7.66% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 13.04% & 0.98\n",
      "for 2021-09-19, MAE is:19.23 & sMAPE is:19.77% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 13.07% & 0.99\n",
      "for 2021-09-20, MAE is:11.66 & sMAPE is:10.46% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 13.06% & 0.99\n",
      "for 2021-09-21, MAE is:6.50 & sMAPE is:5.64% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 13.03% & 0.99\n",
      "for 2021-09-22, MAE is:5.73 & sMAPE is:5.12% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 13.00% & 0.99\n",
      "for 2021-09-23, MAE is:13.08 & sMAPE is:12.64% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 13.00% & 0.98\n",
      "for 2021-09-24, MAE is:7.55 & sMAPE is:7.55% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 12.98% & 0.98\n",
      "for 2021-09-25, MAE is:14.13 & sMAPE is:13.78% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 12.98% & 0.98\n",
      "for 2021-09-26, MAE is:5.89 & sMAPE is:5.48% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 12.95% & 0.98\n",
      "for 2021-09-27, MAE is:3.55 & sMAPE is:3.36% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 12.92% & 0.98\n",
      "for 2021-09-28, MAE is:4.03 & sMAPE is:3.76% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 12.88% & 0.98\n",
      "for 2021-09-29, MAE is:5.24 & sMAPE is:5.22% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 12.86% & 0.98\n",
      "for 2021-09-30, MAE is:9.90 & sMAPE is:11.05% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 12.85% & 0.98\n",
      "for 2021-10-01, MAE is:13.80 & sMAPE is:17.30% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 12.87% & 0.98\n",
      "for 2021-10-02, MAE is:13.17 & sMAPE is:17.94% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 12.88% & 0.98\n",
      "for 2021-10-03, MAE is:38.17 & sMAPE is:88.32% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 13.16% & 0.97\n",
      "for 2021-10-04, MAE is:30.49 & sMAPE is:35.25% & rMAE is:3.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 13.24% & 0.98\n",
      "for 2021-10-05, MAE is:10.88 & sMAPE is:10.98% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 13.23% & 0.99\n",
      "for 2021-10-06, MAE is:6.87 & sMAPE is:7.15% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 13.21% & 0.99\n",
      "for 2021-10-07, MAE is:14.34 & sMAPE is:12.41% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 13.20% & 0.98\n",
      "for 2021-10-08, MAE is:5.25 & sMAPE is:4.46% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 13.17% & 0.98\n",
      "for 2021-10-09, MAE is:10.55 & sMAPE is:8.94% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 13.16% & 0.98\n",
      "for 2021-10-10, MAE is:11.39 & sMAPE is:9.56% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 13.15% & 0.98\n",
      "for 2021-10-11, MAE is:10.48 & sMAPE is:9.20% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 13.13% & 0.98\n",
      "for 2021-10-12, MAE is:8.54 & sMAPE is:7.39% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 13.11% & 0.98\n",
      "for 2021-10-13, MAE is:17.59 & sMAPE is:13.90% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 13.11% & 0.97\n",
      "for 2021-10-14, MAE is:22.81 & sMAPE is:20.54% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 13.14% & 0.97\n",
      "for 2021-10-15, MAE is:10.79 & sMAPE is:12.16% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 13.14% & 0.97\n",
      "for 2021-10-16, MAE is:7.98 & sMAPE is:8.29% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 13.12% & 0.97\n",
      "for 2021-10-17, MAE is:9.66 & sMAPE is:9.06% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 13.11% & 0.97\n",
      "for 2021-10-18, MAE is:26.42 & sMAPE is:18.55% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 13.12% & 0.97\n",
      "for 2021-10-19, MAE is:41.51 & sMAPE is:28.68% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 13.18% & 0.97\n",
      "for 2021-10-20, MAE is:33.19 & sMAPE is:39.57% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 13.27% & 0.97\n",
      "for 2021-10-21, MAE is:12.46 & sMAPE is:18.39% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 13.28% & 0.97\n",
      "for 2021-10-22, MAE is:9.37 & sMAPE is:11.11% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 13.28% & 0.97\n",
      "for 2021-10-23, MAE is:23.89 & sMAPE is:22.18% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 13.31% & 0.97\n",
      "for 2021-10-24, MAE is:21.16 & sMAPE is:21.73% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 13.34% & 0.97\n",
      "for 2021-10-25, MAE is:9.31 & sMAPE is:9.15% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 13.32% & 0.97\n",
      "for 2021-10-26, MAE is:6.43 & sMAPE is:6.54% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 13.30% & 0.97\n",
      "for 2021-10-27, MAE is:12.79 & sMAPE is:14.91% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 13.30% & 0.97\n",
      "for 2021-10-28, MAE is:4.25 & sMAPE is:5.44% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 13.28% & 0.96\n",
      "for 2021-10-29, MAE is:4.75 & sMAPE is:5.92% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 13.25% & 0.96\n",
      "for 2021-10-30, MAE is:5.47 & sMAPE is:7.33% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 13.23% & 0.96\n",
      "for 2021-10-31, MAE is:9.03 & sMAPE is:13.77% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 13.24% & 0.96\n",
      "for 2021-11-01, MAE is:15.32 & sMAPE is:25.12% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 13.28% & 0.96\n",
      "for 2021-11-02, MAE is:19.40 & sMAPE is:23.93% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.36 & 13.31% & 0.96\n",
      "for 2021-11-03, MAE is:14.28 & sMAPE is:15.48% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :7.38 & 13.32% & 0.96\n",
      "for 2021-11-04, MAE is:14.45 & sMAPE is:14.07% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.41 & 13.32% & 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-11-05, MAE is:9.49 & sMAPE is:10.29% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :7.41 & 13.31% & 0.96\n",
      "for 2021-11-06, MAE is:5.75 & sMAPE is:7.13% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :7.41 & 13.29% & 0.96\n",
      "for 2021-11-07, MAE is:8.77 & sMAPE is:14.44% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.41 & 13.29% & 0.96\n",
      "for 2021-11-08, MAE is:47.08 & sMAPE is:39.23% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 13.38% & 0.96\n",
      "for 2021-11-09, MAE is:27.58 & sMAPE is:28.33% & rMAE is:2.97 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 13.42% & 0.96\n",
      "for 2021-11-10, MAE is:6.88 & sMAPE is:7.86% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 13.41% & 0.96\n",
      "for 2021-11-11, MAE is:2.22 & sMAPE is:2.51% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 13.37% & 0.96\n",
      "for 2021-11-12, MAE is:4.56 & sMAPE is:5.04% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 13.35% & 0.96\n",
      "for 2021-11-13, MAE is:5.80 & sMAPE is:6.37% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 13.32% & 0.96\n",
      "for 2021-11-14, MAE is:7.30 & sMAPE is:7.81% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 13.31% & 0.96\n",
      "for 2021-11-15, MAE is:2.97 & sMAPE is:3.04% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 13.27% & 0.95\n",
      "for 2021-11-16, MAE is:3.43 & sMAPE is:3.60% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 13.24% & 0.95\n",
      "for 2021-11-17, MAE is:4.23 & sMAPE is:4.63% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.53 & 13.22% & 0.95\n",
      "for 2021-11-18, MAE is:5.47 & sMAPE is:6.19% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.53 & 13.20% & 0.95\n",
      "for 2021-11-19, MAE is:3.92 & sMAPE is:4.73% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 13.17% & 0.95\n",
      "for 2021-11-20, MAE is:2.91 & sMAPE is:3.37% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 13.14% & 0.95\n",
      "for 2021-11-21, MAE is:6.66 & sMAPE is:7.14% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 13.12% & 0.95\n",
      "for 2021-11-22, MAE is:28.31 & sMAPE is:21.72% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 13.15% & 0.95\n",
      "for 2021-11-23, MAE is:12.55 & sMAPE is:11.37% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 13.14% & 0.95\n",
      "for 2021-11-24, MAE is:8.91 & sMAPE is:8.24% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 13.13% & 0.95\n",
      "for 2021-11-25, MAE is:11.12 & sMAPE is:10.27% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 13.12% & 0.95\n",
      "for 2021-11-26, MAE is:8.85 & sMAPE is:7.78% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 13.10% & 0.95\n",
      "for 2021-11-27, MAE is:35.01 & sMAPE is:24.12% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 13.14% & 0.94\n",
      "for 2021-11-28, MAE is:42.62 & sMAPE is:24.97% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.78 & 13.17% & 0.94\n",
      "for 2021-11-29, MAE is:91.03 & sMAPE is:38.12% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :8.03 & 13.25% & 0.94\n",
      "for 2021-11-30, MAE is:83.55 & sMAPE is:49.86% & rMAE is:3.06 ||| daily mean of MAE & sMAPE & rMAE till now are :8.26 & 13.36% & 0.95\n",
      "for 2021-12-01, MAE is:26.62 & sMAPE is:20.67% & rMAE is:3.34 ||| daily mean of MAE & sMAPE & rMAE till now are :8.31 & 13.38% & 0.96\n",
      "for 2021-12-02, MAE is:68.24 & sMAPE is:38.04% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :8.49 & 13.45% & 0.96\n",
      "for 2021-12-03, MAE is:34.55 & sMAPE is:22.18% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :8.57 & 13.48% & 0.96\n",
      "for 2021-12-04, MAE is:7.16 & sMAPE is:5.45% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :8.57 & 13.45% & 0.95\n",
      "for 2021-12-05, MAE is:13.60 & sMAPE is:10.53% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.58 & 13.44% & 0.95\n",
      "for 2021-12-06, MAE is:30.28 & sMAPE is:16.65% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :8.64 & 13.45% & 0.95\n",
      "for 2021-12-07, MAE is:39.42 & sMAPE is:22.56% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :8.73 & 13.48% & 0.95\n",
      "for 2021-12-08, MAE is:13.19 & sMAPE is:10.15% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :8.75 & 13.47% & 0.95\n",
      "for 2021-12-09, MAE is:4.45 & sMAPE is:3.49% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :8.73 & 13.44% & 0.95\n",
      "for 2021-12-10, MAE is:21.23 & sMAPE is:13.62% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :8.77 & 13.44% & 0.95\n",
      "for 2021-12-11, MAE is:23.89 & sMAPE is:13.55% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 13.44% & 0.95\n",
      "for 2021-12-12, MAE is:20.45 & sMAPE is:14.90% & rMAE is:2.83 ||| daily mean of MAE & sMAPE & rMAE till now are :8.85 & 13.45% & 0.95\n",
      "for 2021-12-13, MAE is:6.40 & sMAPE is:4.62% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :8.84 & 13.42% & 0.95\n",
      "for 2021-12-14, MAE is:75.16 & sMAPE is:35.29% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :9.03 & 13.48% & 0.95\n",
      "for 2021-12-15, MAE is:32.26 & sMAPE is:22.47% & rMAE is:3.83 ||| daily mean of MAE & sMAPE & rMAE till now are :9.10 & 13.51% & 0.96\n",
      "for 2021-12-16, MAE is:25.21 & sMAPE is:17.75% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :9.14 & 13.52% & 0.96\n",
      "for 2021-12-17, MAE is:31.43 & sMAPE is:18.73% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :9.21 & 13.54% & 0.96\n",
      "for 2021-12-18, MAE is:13.38 & sMAPE is:8.56% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :9.22 & 13.52% & 0.96\n",
      "for 2021-12-19, MAE is:14.36 & sMAPE is:9.64% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :9.23 & 13.51% & 0.96\n",
      "for 2021-12-20, MAE is:147.24 & sMAPE is:55.60% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :9.62 & 13.63% & 0.96\n",
      "for 2021-12-21, MAE is:135.49 & sMAPE is:36.86% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :9.98 & 13.70% & 0.96\n",
      "for 2021-12-22, MAE is:80.58 & sMAPE is:27.73% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :10.18 & 13.73% & 0.96\n",
      "for 2021-12-23, MAE is:33.05 & sMAPE is:13.65% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :10.24 & 13.73% & 0.96\n",
      "for 2021-12-24, MAE is:21.62 & sMAPE is:11.01% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :10.27 & 13.73% & 0.96\n",
      "for 2021-12-25, MAE is:17.17 & sMAPE is:8.93% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :10.29 & 13.71% & 0.96\n",
      "for 2021-12-26, MAE is:14.73 & sMAPE is:8.09% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :10.30 & 13.70% & 0.95\n",
      "for 2021-12-27, MAE is:19.54 & sMAPE is:10.84% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :10.33 & 13.69% & 0.95\n",
      "for 2021-12-28, MAE is:37.66 & sMAPE is:22.74% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :10.41 & 13.72% & 0.95\n",
      "for 2021-12-29, MAE is:22.09 & sMAPE is:13.05% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :10.44 & 13.71% & 0.95\n",
      "for 2021-12-30, MAE is:14.58 & sMAPE is:10.16% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :10.45 & 13.70% & 0.95\n",
      "for 2021-12-31, MAE is:8.87 & sMAPE is:6.62% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :10.45 & 13.68% & 0.94\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3 (PC Version - Run on Laptop)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:43:42,020]\u001b[0m A new study created in RDB with name: NO_2_2022\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:44:43,159]\u001b[0m Trial 0 finished with value: 31.844920563786612 and parameters: {'n_hidden': 4, 'learning_rate': 0.004674205923648338, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011689730584641157, 'dropout_rate_Layer_2': 0.03861872596092524, 'dropout_rate_Layer_3': 0.3035722060535271, 'dropout_rate_Layer_4': 0.20827980360280365, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.720215346069762e-05, 'l1_Layer_2': 0.0024969450574088368, 'l1_Layer_3': 0.006053512651891074, 'l1_Layer_4': 0.00010741715936203848, 'n_units_Layer_1': 285, 'n_units_Layer_2': 255, 'n_units_Layer_3': 280, 'n_units_Layer_4': 235}. Best is trial 0 with value: 31.844920563786612.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.84 | sMAPE for Validation Set is: 41.06% | rMAE for Validation Set is: 1.89\n",
      "MAE for Test Set is: 164.44 | sMAPE for Test Set is: 111.97% | rMAE for Test Set is: 2.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:44:53,456]\u001b[0m Trial 1 finished with value: 27.355221279826242 and parameters: {'n_hidden': 3, 'learning_rate': 0.013082851152659258, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09390063139455483, 'dropout_rate_Layer_2': 0.15543427608854868, 'dropout_rate_Layer_3': 0.2542010885983505, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.030780235094749364, 'l1_Layer_2': 1.3403332394695744e-05, 'l1_Layer_3': 0.010158879000812337, 'n_units_Layer_1': 150, 'n_units_Layer_2': 155, 'n_units_Layer_3': 240}. Best is trial 1 with value: 27.355221279826242.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.36 | sMAPE for Validation Set is: 32.99% | rMAE for Validation Set is: 1.62\n",
      "MAE for Test Set is: 158.76 | sMAPE for Test Set is: 104.71% | rMAE for Test Set is: 2.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:45:16,777]\u001b[0m Trial 3 finished with value: 31.1674128599895 and parameters: {'n_hidden': 3, 'learning_rate': 0.09423843318816652, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22249948852024756, 'dropout_rate_Layer_2': 0.2617292579592147, 'dropout_rate_Layer_3': 0.11119421604232499, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 8.748113491137025e-05, 'l1_Layer_2': 9.328509867132451e-05, 'l1_Layer_3': 0.00041372702197171114, 'n_units_Layer_1': 240, 'n_units_Layer_2': 140, 'n_units_Layer_3': 300}. Best is trial 1 with value: 27.355221279826242.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.17 | sMAPE for Validation Set is: 39.84% | rMAE for Validation Set is: 1.85\n",
      "MAE for Test Set is: 162.61 | sMAPE for Test Set is: 109.59% | rMAE for Test Set is: 2.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:45:28,608]\u001b[0m Trial 4 finished with value: 35.15521572771019 and parameters: {'n_hidden': 3, 'learning_rate': 0.05118436344856112, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16181558179896777, 'dropout_rate_Layer_2': 0.07649171741776693, 'dropout_rate_Layer_3': 0.15657901674427968, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.9014689266482023e-05, 'l1_Layer_2': 3.6902821523300254e-05, 'l1_Layer_3': 8.99651663964976e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 275, 'n_units_Layer_3': 130}. Best is trial 1 with value: 27.355221279826242.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.16 | sMAPE for Validation Set is: 47.93% | rMAE for Validation Set is: 2.08\n",
      "MAE for Test Set is: 169.72 | sMAPE for Test Set is: 118.59% | rMAE for Test Set is: 2.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:45:31,029]\u001b[0m Trial 2 finished with value: 31.02531302357075 and parameters: {'n_hidden': 3, 'learning_rate': 0.005995663073622448, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07764753864378351, 'dropout_rate_Layer_2': 0.04031808044463108, 'dropout_rate_Layer_3': 0.16577648078555593, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 5.5288888930368954e-05, 'l1_Layer_2': 0.0024959804109899223, 'l1_Layer_3': 0.0026484746306958693, 'n_units_Layer_1': 85, 'n_units_Layer_2': 180, 'n_units_Layer_3': 75}. Best is trial 1 with value: 27.355221279826242.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.03 | sMAPE for Validation Set is: 39.64% | rMAE for Validation Set is: 1.84\n",
      "MAE for Test Set is: 162.63 | sMAPE for Test Set is: 109.86% | rMAE for Test Set is: 2.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:45:35,903]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:45:40,630]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:45:41,026]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:45:46,203]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:45:48,760]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:45:53,309]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:45:57,882]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:46:03,571]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:46:08,073]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:46:13,357]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:46:18,436]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:46:23,710]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:46:33,786]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:46:43,245]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:46:50,548]\u001b[0m Trial 11 finished with value: 26.766485502893033 and parameters: {'n_hidden': 3, 'learning_rate': 0.002886585837500548, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01192602996714176, 'dropout_rate_Layer_2': 0.07475913279982281, 'dropout_rate_Layer_3': 0.09614173584861768, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.016993807116711e-05, 'l1_Layer_2': 0.00010963743185542242, 'l1_Layer_3': 0.008485436181082077, 'n_units_Layer_1': 145, 'n_units_Layer_2': 300, 'n_units_Layer_3': 225}. Best is trial 11 with value: 26.766485502893033.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.77 | sMAPE for Validation Set is: 32.39% | rMAE for Validation Set is: 1.59\n",
      "MAE for Test Set is: 155.36 | sMAPE for Test Set is: 100.85% | rMAE for Test Set is: 2.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:46:51,053]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:46:56,613]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:47:00,989]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:47:11,073]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:47:15,980]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:47:21,163]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:47:33,172]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:47:38,995]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:47:46,494]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:48:10,960]\u001b[0m Trial 30 finished with value: 26.851933846526975 and parameters: {'n_hidden': 3, 'learning_rate': 0.010650530482457139, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022829686764380866, 'dropout_rate_Layer_2': 0.15424330684481383, 'dropout_rate_Layer_3': 0.1441067043763662, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2153316758326586e-05, 'l1_Layer_2': 1.5422271716359657e-05, 'l1_Layer_3': 0.00047261306304722915, 'n_units_Layer_1': 125, 'n_units_Layer_2': 235, 'n_units_Layer_3': 190}. Best is trial 11 with value: 26.766485502893033.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:48:11,014]\u001b[0m Trial 27 finished with value: 11.058390561375539 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020382145293657856, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2699534304701696, 'dropout_rate_Layer_2': 0.03968267653199327, 'dropout_rate_Layer_3': 0.32824675573582346, 'dropout_rate_Layer_4': 0.0775352893184504, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.6402154422630455e-05, 'l1_Layer_2': 0.011762317208106342, 'l1_Layer_3': 3.711317598436747e-05, 'l1_Layer_4': 0.03035379038657657, 'n_units_Layer_1': 130, 'n_units_Layer_2': 175, 'n_units_Layer_3': 145, 'n_units_Layer_4': 165}. Best is trial 27 with value: 11.058390561375539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.85 | sMAPE for Validation Set is: 33.11% | rMAE for Validation Set is: 1.59\n",
      "MAE for Test Set is: 150.14 | sMAPE for Test Set is: 95.13% | rMAE for Test Set is: 2.49\n",
      "MAE for Validation Set is: 11.06 | sMAPE for Validation Set is: 13.77% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 37.58 | sMAPE for Test Set is: 21.47% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:48:18,117]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:48:18,289]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:48:26,702]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:48:26,878]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:48:34,556]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:48:37,215]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:48:42,619]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:49:02,724]\u001b[0m Trial 37 finished with value: 25.03017090098596 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010906750080178751, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3761567810117803, 'dropout_rate_Layer_2': 0.13407866522264628, 'dropout_rate_Layer_3': 0.0886894549282439, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007579399808189938, 'l1_Layer_2': 1.3730095811107255e-05, 'l1_Layer_3': 0.0014324337211469545, 'n_units_Layer_1': 130, 'n_units_Layer_2': 265, 'n_units_Layer_3': 75}. Best is trial 27 with value: 11.058390561375539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.03 | sMAPE for Validation Set is: 30.15% | rMAE for Validation Set is: 1.48\n",
      "MAE for Test Set is: 148.42 | sMAPE for Test Set is: 93.48% | rMAE for Test Set is: 2.46\n",
      "MAE for Validation Set is: 10.53 | sMAPE for Validation Set is: 13.29% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 34.29 | sMAPE for Test Set is: 20.21% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:49:05,895]\u001b[0m Trial 39 finished with value: 10.529827925666085 and parameters: {'n_hidden': 3, 'learning_rate': 0.010699990985653506, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08820009365305367, 'dropout_rate_Layer_2': 0.07942209225363298, 'dropout_rate_Layer_3': 0.1558367761580498, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001566156876726968, 'l1_Layer_2': 2.456981503694196e-05, 'l1_Layer_3': 9.631903884095001e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 285, 'n_units_Layer_3': 295}. Best is trial 39 with value: 10.529827925666085.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:49:17,500]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:49:22,479]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:49:34,164]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:49:56,279]\u001b[0m Trial 41 finished with value: 10.605268431162704 and parameters: {'n_hidden': 4, 'learning_rate': 0.004470458793415999, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010201344563968595, 'dropout_rate_Layer_2': 0.1700798790798933, 'dropout_rate_Layer_3': 0.06150831634762928, 'dropout_rate_Layer_4': 0.318087232828281, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0029920695351883238, 'l1_Layer_2': 0.010991666855511029, 'l1_Layer_3': 0.001017426542995612, 'l1_Layer_4': 8.896694115983196e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 85, 'n_units_Layer_3': 235, 'n_units_Layer_4': 180}. Best is trial 39 with value: 10.529827925666085.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.61 | sMAPE for Validation Set is: 13.56% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 37.31 | sMAPE for Test Set is: 21.29% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:50:21,059]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:50:33,302]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:50:33,336]\u001b[0m Trial 44 finished with value: 27.91345357909105 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022245061742844213, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1258950601713369, 'dropout_rate_Layer_2': 0.2994648655062135, 'dropout_rate_Layer_3': 0.12364998171913584, 'dropout_rate_Layer_4': 0.1517582333547503, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 5.800964380569662e-05, 'l1_Layer_2': 0.008746003922139053, 'l1_Layer_3': 0.09022068783630177, 'l1_Layer_4': 5.863787308442935e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 90, 'n_units_Layer_3': 265, 'n_units_Layer_4': 255}. Best is trial 39 with value: 10.529827925666085.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.91 | sMAPE for Validation Set is: 34.16% | rMAE for Validation Set is: 1.65\n",
      "MAE for Test Set is: 157.79 | sMAPE for Test Set is: 103.71% | rMAE for Test Set is: 2.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:50:42,806]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:50:47,295]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:51:02,616]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:51:09,330]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:51:12,916]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:51:22,803]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:51:27,579]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:51:44,498]\u001b[0m Trial 55 finished with value: 26.78149164320592 and parameters: {'n_hidden': 3, 'learning_rate': 0.012898778678093732, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3953823052663522, 'dropout_rate_Layer_2': 0.3930160883472904, 'dropout_rate_Layer_3': 0.36287500801277683, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013436056364499787, 'l1_Layer_2': 0.00024664132041694105, 'l1_Layer_3': 2.4835266739560356e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 275, 'n_units_Layer_3': 160}. Best is trial 39 with value: 10.529827925666085.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.78 | sMAPE for Validation Set is: 33.22% | rMAE for Validation Set is: 1.59\n",
      "MAE for Test Set is: 147.53 | sMAPE for Test Set is: 92.82% | rMAE for Test Set is: 2.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:51:49,816]\u001b[0m Trial 49 finished with value: 10.03573200001175 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023726039761684074, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03997320272120683, 'dropout_rate_Layer_2': 0.028990726719671372, 'dropout_rate_Layer_3': 0.10078125753053428, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.058286153481944e-05, 'l1_Layer_2': 1.1354138256152796e-05, 'l1_Layer_3': 0.005705374585488954, 'n_units_Layer_1': 270, 'n_units_Layer_2': 260, 'n_units_Layer_3': 265}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.04 | sMAPE for Validation Set is: 12.50% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 32.67 | sMAPE for Test Set is: 19.19% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:51:52,406]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:51:54,912]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:51:59,690]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:52:07,089]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:52:34,437]\u001b[0m Trial 60 finished with value: 33.51582439844391 and parameters: {'n_hidden': 3, 'learning_rate': 0.026365230349358847, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3146780110273229, 'dropout_rate_Layer_2': 0.1168713610309732, 'dropout_rate_Layer_3': 0.1372950991216401, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001651354826466936, 'l1_Layer_2': 0.00011826193516610544, 'l1_Layer_3': 0.00025573309452785073, 'n_units_Layer_1': 195, 'n_units_Layer_2': 150, 'n_units_Layer_3': 135}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.52 | sMAPE for Validation Set is: 43.99% | rMAE for Validation Set is: 1.99\n",
      "MAE for Test Set is: 168.03 | sMAPE for Test Set is: 116.53% | rMAE for Test Set is: 2.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:52:39,853]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:52:45,070]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:52:51,747]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:52:57,094]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:53:05,128]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:53:19,911]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:53:27,143]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:53:41,649]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:53:46,719]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:53:49,910]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:53:52,843]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:53:57,386]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:54:01,912]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:54:07,315]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:54:14,331]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:54:24,014]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:54:29,649]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:54:34,580]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:54:41,640]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:54:49,885]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:54:56,871]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:55:09,028]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:55:09,256]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:55:17,173]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:55:19,562]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:55:26,112]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:55:33,316]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:56:27,713]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:56:32,952]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:56:35,415]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:56:40,200]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:56:45,052]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:56:48,068]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:56:52,928]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:56:57,750]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:57:02,140]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:57:57,276]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:58:04,176]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:58:11,677]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:58:22,214]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:58:22,318]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:58:30,600]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:58:30,757]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:58:46,309]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:58:51,378]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:58:58,664]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:59:06,164]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:59:06,246]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:59:14,429]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:59:21,599]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:59:27,415]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:59:32,108]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:59:37,221]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:59:42,215]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:59:46,907]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:59:52,200]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:00:12,528]\u001b[0m Trial 115 finished with value: 33.67029427881792 and parameters: {'n_hidden': 4, 'learning_rate': 0.0036573300589611106, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3800173335476503, 'dropout_rate_Layer_2': 0.3416791460764771, 'dropout_rate_Layer_3': 0.08420761764839715, 'dropout_rate_Layer_4': 0.02067993592588198, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.034210084877637874, 'l1_Layer_2': 3.064708058075231e-05, 'l1_Layer_3': 0.00015684070590363383, 'l1_Layer_4': 0.002476684841929289, 'n_units_Layer_1': 180, 'n_units_Layer_2': 70, 'n_units_Layer_3': 80, 'n_units_Layer_4': 275}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.67 | sMAPE for Validation Set is: 44.13% | rMAE for Validation Set is: 1.99\n",
      "MAE for Test Set is: 168.95 | sMAPE for Test Set is: 117.81% | rMAE for Test Set is: 2.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:00:17,254]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:00:24,709]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:00:24,744]\u001b[0m Trial 118 finished with value: 27.442926019201508 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023112124419184645, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11957737642694993, 'dropout_rate_Layer_2': 0.16198355077128745, 'dropout_rate_Layer_3': 0.147523061230099, 'dropout_rate_Layer_4': 0.09522538899778624, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.253296528860449e-05, 'l1_Layer_2': 0.0005755904262088272, 'l1_Layer_3': 1.1815837550781764e-05, 'l1_Layer_4': 0.008139982738779604, 'n_units_Layer_1': 50, 'n_units_Layer_2': 150, 'n_units_Layer_3': 245, 'n_units_Layer_4': 65}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.44 | sMAPE for Validation Set is: 33.74% | rMAE for Validation Set is: 1.63\n",
      "MAE for Test Set is: 154.21 | sMAPE for Test Set is: 99.80% | rMAE for Test Set is: 2.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:00:33,280]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:00:37,894]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:00:53,190]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:00:58,095]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.91 | sMAPE for Validation Set is: 35.47% | rMAE for Validation Set is: 1.71\n",
      "MAE for Test Set is: 164.77 | sMAPE for Test Set is: 112.03% | rMAE for Test Set is: 2.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:01:20,103]\u001b[0m Trial 122 finished with value: 28.908450858712865 and parameters: {'n_hidden': 3, 'learning_rate': 0.005963493234964278, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21349104211368655, 'dropout_rate_Layer_2': 0.12070870004284254, 'dropout_rate_Layer_3': 0.016637033542868763, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.01946547144472241, 'l1_Layer_2': 0.02193176208716745, 'l1_Layer_3': 6.657552226374864e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 75, 'n_units_Layer_3': 55}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:01:32,692]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:01:44,943]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:01:48,712]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:01:53,325]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:02:00,030]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:02:27,530]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:02:32,454]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:02:39,314]\u001b[0m Trial 126 finished with value: 28.16958627835776 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005104370634174576, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06764346696241512, 'dropout_rate_Layer_2': 0.2790616816522326, 'dropout_rate_Layer_3': 0.1113230828912049, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005491491469345055, 'l1_Layer_2': 2.9682297773295365e-05, 'l1_Layer_3': 1.9608205268537695e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 90, 'n_units_Layer_3': 150}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.17 | sMAPE for Validation Set is: 34.72% | rMAE for Validation Set is: 1.67\n",
      "MAE for Test Set is: 156.89 | sMAPE for Test Set is: 102.35% | rMAE for Test Set is: 2.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:02:52,364]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:03:01,242]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:03:08,692]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:03:13,766]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:03:14,608]\u001b[0m Trial 134 finished with value: 10.707993984444405 and parameters: {'n_hidden': 3, 'learning_rate': 0.008926213905984168, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04827283275797438, 'dropout_rate_Layer_2': 0.2533467620336925, 'dropout_rate_Layer_3': 0.05559180882934395, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.71987256902476e-05, 'l1_Layer_2': 0.05429358089128665, 'l1_Layer_3': 0.00018447027373194363, 'n_units_Layer_1': 95, 'n_units_Layer_2': 100, 'n_units_Layer_3': 265}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.71 | sMAPE for Validation Set is: 13.57% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 36.74 | sMAPE for Test Set is: 20.97% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:03:23,185]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:03:45,515]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:03:57,819]\u001b[0m Trial 139 finished with value: 10.689304195071955 and parameters: {'n_hidden': 3, 'learning_rate': 0.00832601121322994, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05099669896882339, 'dropout_rate_Layer_2': 0.23939155590519065, 'dropout_rate_Layer_3': 0.06000087767986257, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7020590509657817e-05, 'l1_Layer_2': 0.043789271402105555, 'l1_Layer_3': 0.00017437224238506753, 'n_units_Layer_1': 95, 'n_units_Layer_2': 100, 'n_units_Layer_3': 260}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.69 | sMAPE for Validation Set is: 13.52% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 36.36 | sMAPE for Test Set is: 20.81% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:04:02,323]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:04:07,547]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:04:25,185]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:04:31,808]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:04:37,548]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:04:57,581]\u001b[0m Trial 148 finished with value: 38.49687787919071 and parameters: {'n_hidden': 4, 'learning_rate': 0.033292475058418994, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2549429736568723, 'dropout_rate_Layer_2': 0.08525685099404803, 'dropout_rate_Layer_3': 0.05434619337919991, 'dropout_rate_Layer_4': 0.32459670122694306, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00405250383522501, 'l1_Layer_2': 1.576452846850547e-05, 'l1_Layer_3': 0.00014246775014891138, 'l1_Layer_4': 1.1951915671396442e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 250, 'n_units_Layer_3': 60, 'n_units_Layer_4': 160}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.50 | sMAPE for Validation Set is: 54.27% | rMAE for Validation Set is: 2.28\n",
      "MAE for Test Set is: 175.32 | sMAPE for Test Set is: 126.60% | rMAE for Test Set is: 2.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:05:59,043]\u001b[0m Trial 142 finished with value: 28.989335425668145 and parameters: {'n_hidden': 4, 'learning_rate': 0.06604385744426947, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3673152013808465, 'dropout_rate_Layer_2': 0.28610323783920705, 'dropout_rate_Layer_3': 0.08557675050198599, 'dropout_rate_Layer_4': 0.00432258634912639, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.452660545412315e-05, 'l1_Layer_2': 0.02202955834917961, 'l1_Layer_3': 0.004978273611712819, 'l1_Layer_4': 0.02838362454952517, 'n_units_Layer_1': 205, 'n_units_Layer_2': 245, 'n_units_Layer_3': 290, 'n_units_Layer_4': 130}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.99 | sMAPE for Validation Set is: 35.76% | rMAE for Validation Set is: 1.72\n",
      "MAE for Test Set is: 159.78 | sMAPE for Test Set is: 106.26% | rMAE for Test Set is: 2.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:06:06,405]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:06:11,289]\u001b[0m Trial 149 finished with value: 31.468914114687475 and parameters: {'n_hidden': 3, 'learning_rate': 0.013636389309232997, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31606681142329224, 'dropout_rate_Layer_2': 0.014575099520777492, 'dropout_rate_Layer_3': 0.34512264752110866, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0029053472366680705, 'l1_Layer_2': 5.902879842279603e-05, 'l1_Layer_3': 0.016355218162227597, 'n_units_Layer_1': 235, 'n_units_Layer_2': 110, 'n_units_Layer_3': 80}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.47 | sMAPE for Validation Set is: 40.25% | rMAE for Validation Set is: 1.86\n",
      "MAE for Test Set is: 163.63 | sMAPE for Test Set is: 110.95% | rMAE for Test Set is: 2.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:06:16,319]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:06:19,033]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:06:25,913]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:06:25,954]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:06:32,685]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:06:33,083]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:06:38,654]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:06:39,179]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:06:44,285]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:06:49,576]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:07:13,985]\u001b[0m Trial 160 finished with value: 29.486765538913573 and parameters: {'n_hidden': 3, 'learning_rate': 0.00606875488101121, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08523097202290107, 'dropout_rate_Layer_2': 0.054726277083560884, 'dropout_rate_Layer_3': 0.15469491616521533, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 5.3183507574657755e-05, 'l1_Layer_2': 0.004864240377606734, 'l1_Layer_3': 0.00010902325958950202, 'n_units_Layer_1': 80, 'n_units_Layer_2': 165, 'n_units_Layer_3': 160}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.49 | sMAPE for Validation Set is: 36.83% | rMAE for Validation Set is: 1.75\n",
      "MAE for Test Set is: 160.99 | sMAPE for Test Set is: 107.80% | rMAE for Test Set is: 2.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:07:25,878]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:07:40,741]\u001b[0m Trial 162 finished with value: 10.721578959042356 and parameters: {'n_hidden': 3, 'learning_rate': 0.005738765484156141, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0661836518028257, 'dropout_rate_Layer_2': 0.16928911713053177, 'dropout_rate_Layer_3': 0.06830923645310802, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5256261557366575e-05, 'l1_Layer_2': 0.056896666550238846, 'l1_Layer_3': 2.7157302095107347e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 55, 'n_units_Layer_3': 235}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.72 | sMAPE for Validation Set is: 13.56% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 35.88 | sMAPE for Test Set is: 20.55% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:07:58,665]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:08:32,120]\u001b[0m Trial 165 finished with value: 10.545692086352984 and parameters: {'n_hidden': 3, 'learning_rate': 0.005218633373245422, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06784848017149131, 'dropout_rate_Layer_2': 0.24801997015477528, 'dropout_rate_Layer_3': 0.0602417974608314, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.389326129273156e-05, 'l1_Layer_2': 0.05959165686845154, 'l1_Layer_3': 2.500238713345211e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 55, 'n_units_Layer_3': 235}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.55 | sMAPE for Validation Set is: 13.42% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 34.48 | sMAPE for Test Set is: 19.87% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:08:37,280]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:08:44,423]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:08:52,093]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:08:52,600]\u001b[0m Trial 166 finished with value: 10.703137822657325 and parameters: {'n_hidden': 3, 'learning_rate': 0.007110163285738662, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0646344349223204, 'dropout_rate_Layer_2': 0.23816333053943606, 'dropout_rate_Layer_3': 0.022340685168964813, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0528619113002216e-05, 'l1_Layer_2': 0.05616645265863809, 'l1_Layer_3': 2.9453619334283823e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 65, 'n_units_Layer_3': 230}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.70 | sMAPE for Validation Set is: 13.51% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 35.16 | sMAPE for Test Set is: 20.21% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:09:00,623]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:09:05,039]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:09:10,023]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:09:15,432]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:09:19,486]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:09:24,443]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:09:29,384]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:09:34,439]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:09:36,915]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:09:39,466]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:09:46,427]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:09:51,753]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:09:59,208]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:10:03,993]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:10:14,070]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:10:23,761]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:10:36,538]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:10:46,361]\u001b[0m Trial 187 finished with value: 29.685792064293803 and parameters: {'n_hidden': 4, 'learning_rate': 0.03135008803790125, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15814538769011766, 'dropout_rate_Layer_2': 0.0795659999175613, 'dropout_rate_Layer_3': 0.34338634274120816, 'dropout_rate_Layer_4': 0.20054639404835625, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00013805066397530185, 'l1_Layer_2': 1.633412049725545e-05, 'l1_Layer_3': 4.2899259996287544e-05, 'l1_Layer_4': 0.034983912139859435, 'n_units_Layer_1': 120, 'n_units_Layer_2': 155, 'n_units_Layer_3': 280, 'n_units_Layer_4': 105}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.69 | sMAPE for Validation Set is: 38.14% | rMAE for Validation Set is: 1.76\n",
      "MAE for Test Set is: 158.00 | sMAPE for Test Set is: 104.10% | rMAE for Test Set is: 2.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:10:52,131]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:10:59,318]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:11:09,339]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:11:11,423]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:11:14,029]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:11:16,801]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:11:23,593]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:11:23,907]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:11:36,448]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:11:46,104]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:11:48,929]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:11:51,437]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:11:56,281]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:12:08,343]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.43 | sMAPE for Validation Set is: 35.07% | rMAE for Validation Set is: 1.68\n",
      "MAE for Test Set is: 157.54 | sMAPE for Test Set is: 103.67% | rMAE for Test Set is: 2.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:12:19,572]\u001b[0m Trial 200 finished with value: 28.430485370944997 and parameters: {'n_hidden': 3, 'learning_rate': 0.00860218353238266, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2696692040161843, 'dropout_rate_Layer_2': 0.000524159367814872, 'dropout_rate_Layer_3': 0.20946220403203397, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022605195993643222, 'l1_Layer_2': 0.004466155409303564, 'l1_Layer_3': 8.029297313556772e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 200, 'n_units_Layer_3': 105}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:12:24,053]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:12:24,135]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:12:32,776]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:12:32,858]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:12:42,383]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:12:47,146]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:12:54,436]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:12:59,522]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:13:04,829]\u001b[0m Trial 208 finished with value: 39.3543411569078 and parameters: {'n_hidden': 4, 'learning_rate': 0.092495914822122, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3973364859584572, 'dropout_rate_Layer_2': 0.2955283263780134, 'dropout_rate_Layer_3': 0.3997581624813742, 'dropout_rate_Layer_4': 0.38971293352835307, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.012000128613506895, 'l1_Layer_2': 2.9130296042039425e-05, 'l1_Layer_3': 2.6486982716761672e-05, 'l1_Layer_4': 1.8141853401313326e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 185, 'n_units_Layer_3': 260, 'n_units_Layer_4': 135}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 39.35 | sMAPE for Validation Set is: 59.89% | rMAE for Validation Set is: 2.33\n",
      "MAE for Test Set is: 172.62 | sMAPE for Test Set is: 123.96% | rMAE for Test Set is: 2.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:13:12,444]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:13:19,887]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:13:34,279]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:13:44,323]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:13:49,505]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:13:54,330]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:13:54,577]\u001b[0m Trial 212 finished with value: 10.650969504217862 and parameters: {'n_hidden': 3, 'learning_rate': 0.005600655191285829, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07092414763436472, 'dropout_rate_Layer_2': 0.1686824575466217, 'dropout_rate_Layer_3': 0.0722063311156692, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4998518101824603e-05, 'l1_Layer_2': 0.05995394018109608, 'l1_Layer_3': 2.583109231856684e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 50, 'n_units_Layer_3': 220}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.65 | sMAPE for Validation Set is: 13.49% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 35.87 | sMAPE for Test Set is: 20.58% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:14:01,002]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:14:05,671]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:14:10,670]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:14:14,879]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:14:17,615]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:14:22,092]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:14:27,337]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:14:34,591]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:14:42,211]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:14:42,680]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:14:51,106]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:14:56,067]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:15:01,457]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:15:31,863]\u001b[0m Trial 233 finished with value: 10.619606870139778 and parameters: {'n_hidden': 3, 'learning_rate': 0.007431056533454276, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10197407018471606, 'dropout_rate_Layer_2': 0.22974385318522111, 'dropout_rate_Layer_3': 0.05479083978770443, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.016044172273625687, 'l1_Layer_2': 0.03558008554714383, 'l1_Layer_3': 2.2504124443917702e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 60, 'n_units_Layer_3': 265}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.62 | sMAPE for Validation Set is: 13.16% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 35.60 | sMAPE for Test Set is: 20.11% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:15:38,796]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:15:44,023]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:15:44,154]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:15:53,880]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:16:24,156]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:16:28,943]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:16:38,841]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:16:41,735]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:16:46,542]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:16:49,233]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:16:58,516]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:17:05,619]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:17:08,995]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:17:13,812]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:17:28,014]\u001b[0m Trial 245 finished with value: 24.41805877705082 and parameters: {'n_hidden': 3, 'learning_rate': 0.08587998462572277, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008283732563534096, 'dropout_rate_Layer_2': 0.2145806099000357, 'dropout_rate_Layer_3': 0.14082259262224192, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003137019952730746, 'l1_Layer_2': 0.00048328178043588764, 'l1_Layer_3': 1.1655898783864165e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 220, 'n_units_Layer_3': 175}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.42 | sMAPE for Validation Set is: 29.39% | rMAE for Validation Set is: 1.45\n",
      "MAE for Test Set is: 146.12 | sMAPE for Test Set is: 90.61% | rMAE for Test Set is: 2.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:17:33,021]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:17:38,718]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:18:07,845]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:18:13,500]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:18:22,513]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:18:30,065]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:18:30,120]\u001b[0m Trial 248 finished with value: 26.648396987977197 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016594725698088036, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00240757287632426, 'dropout_rate_Layer_2': 0.21043462830727674, 'dropout_rate_Layer_3': 0.19818277304337245, 'dropout_rate_Layer_4': 0.1383295630962301, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0002694687821943094, 'l1_Layer_2': 0.0031296911927626817, 'l1_Layer_3': 0.09907827284171071, 'l1_Layer_4': 0.0003145842535927111, 'n_units_Layer_1': 155, 'n_units_Layer_2': 140, 'n_units_Layer_3': 200, 'n_units_Layer_4': 300}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.65 | sMAPE for Validation Set is: 32.29% | rMAE for Validation Set is: 1.58\n",
      "MAE for Test Set is: 154.11 | sMAPE for Test Set is: 99.45% | rMAE for Test Set is: 2.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:18:48,431]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:18:52,962]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:19:00,732]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:19:07,996]\u001b[0m Trial 256 finished with value: 28.28429641920761 and parameters: {'n_hidden': 3, 'learning_rate': 0.00685317066183379, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04928066518598848, 'dropout_rate_Layer_2': 0.038299537570223766, 'dropout_rate_Layer_3': 0.17827356665780456, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 4.595695818168685e-05, 'l1_Layer_2': 0.0051348756309042886, 'l1_Layer_3': 8.382803517787709e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 165, 'n_units_Layer_3': 170}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.28 | sMAPE for Validation Set is: 34.60% | rMAE for Validation Set is: 1.68\n",
      "MAE for Test Set is: 159.53 | sMAPE for Test Set is: 105.92% | rMAE for Test Set is: 2.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:19:08,157]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:19:18,513]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:19:25,983]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:19:26,122]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:19:31,851]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:19:34,311]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:19:43,610]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:19:44,178]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:19:52,033]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:20:04,576]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:20:17,249]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:20:21,914]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:20:26,577]\u001b[0m Trial 267 finished with value: 25.548414876731854 and parameters: {'n_hidden': 3, 'learning_rate': 0.09975969223323071, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007302329007977433, 'dropout_rate_Layer_2': 0.20153596542002206, 'dropout_rate_Layer_3': 0.15637252112755085, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000371517075992396, 'l1_Layer_2': 0.0009042312196008517, 'l1_Layer_3': 1.500523374581015e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 215, 'n_units_Layer_3': 170}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.55 | sMAPE for Validation Set is: 31.12% | rMAE for Validation Set is: 1.51\n",
      "MAE for Test Set is: 148.28 | sMAPE for Test Set is: 93.42% | rMAE for Test Set is: 2.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:20:31,265]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:20:34,647]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:20:39,223]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:20:47,071]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:20:54,314]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:21:01,720]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:21:06,552]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:21:13,774]\u001b[0m Trial 275 finished with value: 28.147380443631604 and parameters: {'n_hidden': 3, 'learning_rate': 0.09465353765322158, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01770118058038664, 'dropout_rate_Layer_2': 0.19498555466156164, 'dropout_rate_Layer_3': 0.1479486453424977, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005401545530956213, 'l1_Layer_2': 0.002696505227419261, 'l1_Layer_3': 1.093334646205282e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 205, 'n_units_Layer_3': 210}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.15 | sMAPE for Validation Set is: 34.89% | rMAE for Validation Set is: 1.67\n",
      "MAE for Test Set is: 158.98 | sMAPE for Test Set is: 104.84% | rMAE for Test Set is: 2.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:21:48,032]\u001b[0m Trial 280 finished with value: 11.584458236108281 and parameters: {'n_hidden': 3, 'learning_rate': 0.001246627389455854, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2071605618263564, 'dropout_rate_Layer_2': 0.1999916952206194, 'dropout_rate_Layer_3': 0.22782104543797432, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00045057239652498786, 'l1_Layer_2': 0.0014157720525387102, 'l1_Layer_3': 0.09320742162831078, 'n_units_Layer_1': 160, 'n_units_Layer_2': 155, 'n_units_Layer_3': 200}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.58 | sMAPE for Validation Set is: 14.63% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 39.56 | sMAPE for Test Set is: 22.12% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:22:05,433]\u001b[0m Trial 281 finished with value: 26.398050908234314 and parameters: {'n_hidden': 3, 'learning_rate': 0.061100082259648, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07623380400161847, 'dropout_rate_Layer_2': 0.23749615754786152, 'dropout_rate_Layer_3': 0.013972725920513546, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2980718489479581e-05, 'l1_Layer_2': 0.0014544904344295823, 'l1_Layer_3': 0.00027606166028167566, 'n_units_Layer_1': 295, 'n_units_Layer_2': 215, 'n_units_Layer_3': 145}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.40 | sMAPE for Validation Set is: 31.60% | rMAE for Validation Set is: 1.56\n",
      "MAE for Test Set is: 156.04 | sMAPE for Test Set is: 101.64% | rMAE for Test Set is: 2.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:22:10,498]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:22:30,228]\u001b[0m Trial 282 finished with value: 24.726130403380154 and parameters: {'n_hidden': 3, 'learning_rate': 0.05327302244717593, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0756207560987105, 'dropout_rate_Layer_2': 0.1334636352581512, 'dropout_rate_Layer_3': 0.007323632317810275, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2955872840996082e-05, 'l1_Layer_2': 0.0020455321785019694, 'l1_Layer_3': 0.00037812626137811913, 'n_units_Layer_1': 285, 'n_units_Layer_2': 200, 'n_units_Layer_3': 135}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.73 | sMAPE for Validation Set is: 29.53% | rMAE for Validation Set is: 1.46\n",
      "MAE for Test Set is: 148.74 | sMAPE for Test Set is: 93.58% | rMAE for Test Set is: 2.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:22:35,301]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:22:40,165]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:22:45,136]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:22:45,600]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:22:53,338]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:22:56,420]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:23:01,203]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:23:06,343]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:23:14,034]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:23:28,408]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:23:35,828]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:23:41,266]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:23:45,890]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:23:51,481]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:23:51,632]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:23:57,422]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:24:04,541]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:24:11,382]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:24:11,524]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:24:20,321]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:24:20,459]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:24:28,705]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:24:29,027]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:24:36,187]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:24:41,534]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:24:49,124]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.38 | sMAPE for Validation Set is: 13.11% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 33.63 | sMAPE for Test Set is: 19.50% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:24:55,961]\u001b[0m Trial 307 finished with value: 10.383355860505914 and parameters: {'n_hidden': 3, 'learning_rate': 0.01072578733115713, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05508659180338706, 'dropout_rate_Layer_2': 0.28255472120633984, 'dropout_rate_Layer_3': 0.058548489114862164, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.046584377858047185, 'l1_Layer_2': 0.030578313467183652, 'l1_Layer_3': 5.579277175990084e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 295, 'n_units_Layer_3': 205}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:24:59,512]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:25:03,628]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:25:06,068]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:25:08,975]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:25:11,644]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:25:13,785]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:25:18,317]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:25:21,668]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:25:25,981]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:25:26,529]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:25:34,352]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:25:51,386]\u001b[0m Trial 322 finished with value: 10.51949236544817 and parameters: {'n_hidden': 3, 'learning_rate': 0.007918817272271148, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.079663731492066, 'dropout_rate_Layer_2': 0.26377127329112027, 'dropout_rate_Layer_3': 0.06437032508800598, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.020783313711794572, 'l1_Layer_2': 0.05869079170922659, 'l1_Layer_3': 0.00012792641665617302, 'n_units_Layer_1': 95, 'n_units_Layer_2': 95, 'n_units_Layer_3': 220}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.52 | sMAPE for Validation Set is: 13.31% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 34.04 | sMAPE for Test Set is: 19.60% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:26:07,087]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:26:14,003]\u001b[0m Trial 324 finished with value: 10.221134145246538 and parameters: {'n_hidden': 3, 'learning_rate': 0.007972888220551103, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07150541211553373, 'dropout_rate_Layer_2': 0.3010512192573155, 'dropout_rate_Layer_3': 0.09535455659179112, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09827640904823495, 'l1_Layer_2': 0.03258012243628825, 'l1_Layer_3': 2.0990707079943933e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 180, 'n_units_Layer_3': 225}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.22 | sMAPE for Validation Set is: 12.84% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 33.84 | sMAPE for Test Set is: 19.43% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:26:21,026]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:26:26,902]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:26:31,089]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:26:36,082]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:26:36,770]\u001b[0m Trial 325 finished with value: 10.294987385233023 and parameters: {'n_hidden': 3, 'learning_rate': 0.007075562589182222, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00017505998336058912, 'dropout_rate_Layer_2': 0.08073423424661713, 'dropout_rate_Layer_3': 0.03982531431980247, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3193743027605591e-05, 'l1_Layer_2': 4.8071612126290656e-05, 'l1_Layer_3': 4.235650068724179e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 295, 'n_units_Layer_3': 300}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.29 | sMAPE for Validation Set is: 12.94% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 33.48 | sMAPE for Test Set is: 19.70% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:27:02,977]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:27:09,728]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:27:14,452]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:27:17,818]\u001b[0m Trial 331 finished with value: 23.03664575026244 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009914494528961825, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19034278155063641, 'dropout_rate_Layer_2': 0.19690760678929808, 'dropout_rate_Layer_3': 0.2573502545068819, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011416947472102617, 'l1_Layer_2': 0.00037995515990193074, 'l1_Layer_3': 0.012893442546295934, 'n_units_Layer_1': 170, 'n_units_Layer_2': 200, 'n_units_Layer_3': 115}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.04 | sMAPE for Validation Set is: 26.66% | rMAE for Validation Set is: 1.36\n",
      "MAE for Test Set is: 146.39 | sMAPE for Test Set is: 90.99% | rMAE for Test Set is: 2.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:27:25,199]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:27:30,087]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:27:34,400]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:27:39,549]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:27:44,249]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:27:44,413]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:27:53,362]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:27:58,230]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:28:03,084]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:28:07,706]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:28:32,283]\u001b[0m Trial 344 finished with value: 10.386154472201897 and parameters: {'n_hidden': 3, 'learning_rate': 0.005093003995882475, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011662328906082535, 'dropout_rate_Layer_2': 0.2796778679921035, 'dropout_rate_Layer_3': 0.11397735646539614, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009247175940802673, 'l1_Layer_2': 0.021273210211975833, 'l1_Layer_3': 2.1223270158313133e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 215, 'n_units_Layer_3': 225}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.39 | sMAPE for Validation Set is: 13.09% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 34.55 | sMAPE for Test Set is: 19.85% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:28:35,559]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:28:42,548]\u001b[0m Trial 345 finished with value: 10.137753929452524 and parameters: {'n_hidden': 3, 'learning_rate': 0.004885004609063073, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1646305741883197, 'dropout_rate_Layer_2': 0.2787702089760261, 'dropout_rate_Layer_3': 0.11504102575183944, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.024664816565541918, 'l1_Layer_2': 0.023377048458913884, 'l1_Layer_3': 1.9915732466338337e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 210, 'n_units_Layer_3': 225}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.14 | sMAPE for Validation Set is: 12.74% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 33.40 | sMAPE for Test Set is: 19.22% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:28:47,503]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:28:53,046]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:28:58,096]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.05 | sMAPE for Validation Set is: 43.38% | rMAE for Validation Set is: 1.96\n",
      "MAE for Test Set is: 166.81 | sMAPE for Test Set is: 115.09% | rMAE for Test Set is: 2.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:29:00,550]\u001b[0m Trial 347 finished with value: 33.05352505660812 and parameters: {'n_hidden': 3, 'learning_rate': 0.003709515039868384, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18484746566565644, 'dropout_rate_Layer_2': 0.20720111613892067, 'dropout_rate_Layer_3': 0.284868077630128, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022468747433778097, 'l1_Layer_2': 0.0003717393857629644, 'l1_Layer_3': 0.016059832143455743, 'n_units_Layer_1': 235, 'n_units_Layer_2': 195, 'n_units_Layer_3': 110}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:29:09,683]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:29:10,311]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:29:17,777]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:29:18,105]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:29:26,561]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:29:28,876]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:29:33,379]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:29:36,521]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:29:42,884]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:29:48,025]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:29:53,222]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:29:58,319]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:30:20,320]\u001b[0m Trial 358 finished with value: 10.185754239750086 and parameters: {'n_hidden': 3, 'learning_rate': 0.005121118913759844, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013988971144840313, 'dropout_rate_Layer_2': 0.27473529866946383, 'dropout_rate_Layer_3': 0.09300806050044114, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.023103274365943633, 'l1_Layer_2': 0.023025940558131286, 'l1_Layer_3': 1.979132985424234e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 190, 'n_units_Layer_3': 240}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.19 | sMAPE for Validation Set is: 12.83% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 33.31 | sMAPE for Test Set is: 19.22% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:30:25,384]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:30:30,640]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:31:12,191]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.08 | sMAPE for Validation Set is: 12.70% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 33.27 | sMAPE for Test Set is: 19.20% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:31:17,065]\u001b[0m Trial 364 finished with value: 10.075938277271208 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025968498221436683, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09914732911836795, 'dropout_rate_Layer_2': 0.08154900356211586, 'dropout_rate_Layer_3': 0.20988170835557834, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007326538239229968, 'l1_Layer_2': 2.5570409626226464e-05, 'l1_Layer_3': 3.742154026826605e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 285, 'n_units_Layer_3': 270}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:31:27,345]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:31:52,382]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:31:57,253]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:31:57,460]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:32:11,408]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:32:23,226]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:32:28,168]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:32:32,809]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:32:33,140]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:32:41,288]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:32:46,401]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:32:51,230]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:32:56,626]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:33:01,372]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:35:20,962]\u001b[0m Trial 383 finished with value: 10.05164963038496 and parameters: {'n_hidden': 3, 'learning_rate': 0.004764751661428725, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05909740000725519, 'dropout_rate_Layer_2': 0.2715586458748075, 'dropout_rate_Layer_3': 0.1122245644575444, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008033486145579469, 'l1_Layer_2': 0.0006681826978898429, 'l1_Layer_3': 0.0005251531237808923, 'n_units_Layer_1': 260, 'n_units_Layer_2': 180, 'n_units_Layer_3': 120}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.05 | sMAPE for Validation Set is: 12.72% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 34.06 | sMAPE for Test Set is: 19.59% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:35:25,360]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:35:35,218]\u001b[0m Trial 377 finished with value: 10.48970461973265 and parameters: {'n_hidden': 3, 'learning_rate': 0.005564992312005128, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04606520210948853, 'dropout_rate_Layer_2': 0.2547949969027135, 'dropout_rate_Layer_3': 0.0021775495354346107, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09426797417474654, 'l1_Layer_2': 0.0006328317525657951, 'l1_Layer_3': 7.134168898989815e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 185, 'n_units_Layer_3': 135}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.49 | sMAPE for Validation Set is: 13.34% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 34.02 | sMAPE for Test Set is: 19.58% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:35:42,473]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:35:52,208]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:35:56,966]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:36:07,145]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:36:09,848]\u001b[0m Trial 385 finished with value: 28.82935358864413 and parameters: {'n_hidden': 3, 'learning_rate': 0.005956748325598919, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06744354260766383, 'dropout_rate_Layer_2': 0.05490779948032598, 'dropout_rate_Layer_3': 0.14592786715032258, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 6.138200358970708e-05, 'l1_Layer_2': 0.005789157648356008, 'l1_Layer_3': 8.719285175203085e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 150, 'n_units_Layer_3': 170}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.83 | sMAPE for Validation Set is: 35.64% | rMAE for Validation Set is: 1.71\n",
      "MAE for Test Set is: 160.11 | sMAPE for Test Set is: 106.72% | rMAE for Test Set is: 2.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:36:12,295]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:36:15,070]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:36:19,321]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:36:22,817]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:36:27,081]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:36:27,916]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:36:33,226]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:36:37,577]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:36:42,630]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:36:49,897]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:37:07,482]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:37:20,210]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:37:25,523]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:37:28,826]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:37:33,547]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:37:41,268]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:37:48,224]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:37:52,845]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:38:00,397]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:38:08,167]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:38:15,382]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:38:20,340]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:38:23,601]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:39:58,599]\u001b[0m Trial 398 finished with value: 10.149083388548767 and parameters: {'n_hidden': 3, 'learning_rate': 0.00211869001031439, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03583915372877871, 'dropout_rate_Layer_2': 0.2810968290558577, 'dropout_rate_Layer_3': 0.11803007125491011, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013853110240689798, 'l1_Layer_2': 0.0005924486702589182, 'l1_Layer_3': 6.957064097816842e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 175, 'n_units_Layer_3': 120}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.15 | sMAPE for Validation Set is: 12.95% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 33.47 | sMAPE for Test Set is: 19.32% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:40:33,505]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:40:55,331]\u001b[0m Trial 414 finished with value: 10.052816679668604 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023306343977619734, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.042944743501413675, 'dropout_rate_Layer_2': 0.26389380878483737, 'dropout_rate_Layer_3': 0.11518697747946788, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011172397428077206, 'l1_Layer_2': 0.0005673602329514985, 'l1_Layer_3': 6.004574180250585e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 180, 'n_units_Layer_3': 125}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.05 | sMAPE for Validation Set is: 12.72% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 33.19 | sMAPE for Test Set is: 19.13% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:41:05,217]\u001b[0m Trial 416 finished with value: 10.279421876298207 and parameters: {'n_hidden': 3, 'learning_rate': 0.00651553209257126, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14791215096659885, 'dropout_rate_Layer_2': 0.08332595617085499, 'dropout_rate_Layer_3': 0.025564670141893897, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2650053170918503e-05, 'l1_Layer_2': 5.775029755487014e-05, 'l1_Layer_3': 6.984102241385817e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 275, 'n_units_Layer_3': 135}. Best is trial 49 with value: 10.03573200001175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.28 | sMAPE for Validation Set is: 12.89% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 33.61 | sMAPE for Test Set is: 19.60% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:41:10,121]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:41:17,328]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:41:22,138]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:41:22,266]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:41:30,310]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:41:30,559]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:45:40,776]\u001b[0m Trial 424 finished with value: 9.931326717353622 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019130169314689617, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12301679662340864, 'dropout_rate_Layer_2': 0.32039923431667533, 'dropout_rate_Layer_3': 0.1037454073254586, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016432498517012918, 'l1_Layer_2': 0.00010038590354933897, 'l1_Layer_3': 0.00015001051377901543, 'n_units_Layer_1': 235, 'n_units_Layer_2': 125, 'n_units_Layer_3': 115}. Best is trial 424 with value: 9.931326717353622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.93 | sMAPE for Validation Set is: 12.74% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 33.05 | sMAPE for Test Set is: 19.08% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:45:49,585]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:45:57,047]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:46:22,679]\u001b[0m Trial 423 finished with value: 9.931075164983172 and parameters: {'n_hidden': 3, 'learning_rate': 0.002134500372220497, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11802317057324754, 'dropout_rate_Layer_2': 0.32323286734903944, 'dropout_rate_Layer_3': 0.10661707541548171, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00163406997463879, 'l1_Layer_2': 0.00014433011256021676, 'l1_Layer_3': 0.0001478203818699897, 'n_units_Layer_1': 235, 'n_units_Layer_2': 135, 'n_units_Layer_3': 120}. Best is trial 423 with value: 9.931075164983172.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.93 | sMAPE for Validation Set is: 12.47% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 33.00 | sMAPE for Test Set is: 18.94% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:46:29,806]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:46:35,022]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:46:40,162]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:46:43,152]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:46:47,851]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:47:12,445]\u001b[0m Trial 433 finished with value: 11.076919055500065 and parameters: {'n_hidden': 3, 'learning_rate': 0.01090293335623609, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13833089178340646, 'dropout_rate_Layer_2': 0.10727520655403361, 'dropout_rate_Layer_3': 0.1965489622966931, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.640171617921252e-05, 'l1_Layer_2': 0.0033622859344868577, 'l1_Layer_3': 0.004254468979252236, 'n_units_Layer_1': 145, 'n_units_Layer_2': 155, 'n_units_Layer_3': 300}. Best is trial 423 with value: 9.931075164983172.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.08 | sMAPE for Validation Set is: 13.84% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 36.81 | sMAPE for Test Set is: 21.18% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:47:15,144]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:47:20,092]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:47:27,557]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:47:33,065]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:47:35,455]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:47:47,582]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:48:07,147]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:48:14,119]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:48:28,917]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:48:44,391]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:49:00,941]\u001b[0m Trial 440 finished with value: 9.964111991328233 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016069836569470976, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13520143473044935, 'dropout_rate_Layer_2': 0.3282578364476422, 'dropout_rate_Layer_3': 0.05303472713833374, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004634899972502839, 'l1_Layer_2': 9.244821930233797e-05, 'l1_Layer_3': 0.0006508504749918945, 'n_units_Layer_1': 230, 'n_units_Layer_2': 120, 'n_units_Layer_3': 55}. Best is trial 423 with value: 9.931075164983172.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.96 | sMAPE for Validation Set is: 12.56% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 33.63 | sMAPE for Test Set is: 19.20% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:49:08,840]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:49:31,715]\u001b[0m Trial 444 finished with value: 10.021462624485933 and parameters: {'n_hidden': 3, 'learning_rate': 0.005043909911410946, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12681781841491152, 'dropout_rate_Layer_2': 0.05711520425160864, 'dropout_rate_Layer_3': 0.01650490572164643, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.767173158755747e-05, 'l1_Layer_2': 0.00010890961029798394, 'l1_Layer_3': 4.461393382599768e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 265, 'n_units_Layer_3': 160}. Best is trial 423 with value: 9.931075164983172.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.02 | sMAPE for Validation Set is: 12.66% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 32.46 | sMAPE for Test Set is: 18.93% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:49:38,643]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:49:51,159]\u001b[0m Trial 446 finished with value: 9.901294062772498 and parameters: {'n_hidden': 3, 'learning_rate': 0.004768932079344061, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1322547525332124, 'dropout_rate_Layer_2': 0.06272456764163649, 'dropout_rate_Layer_3': 0.017585562953469053, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.7187669399680152e-05, 'l1_Layer_2': 7.413898476682441e-05, 'l1_Layer_3': 4.840919545790257e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 265, 'n_units_Layer_3': 160}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.90 | sMAPE for Validation Set is: 12.47% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 32.71 | sMAPE for Test Set is: 18.87% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:50:15,800]\u001b[0m Trial 448 finished with value: 10.129360199764898 and parameters: {'n_hidden': 3, 'learning_rate': 0.004707830109180148, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12571811113971468, 'dropout_rate_Layer_2': 0.061911089397234276, 'dropout_rate_Layer_3': 0.014367810857891189, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.530151398826162e-05, 'l1_Layer_2': 0.00010653170820523504, 'l1_Layer_3': 5.141554826650315e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 255, 'n_units_Layer_3': 155}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.13 | sMAPE for Validation Set is: 12.62% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 33.26 | sMAPE for Test Set is: 19.24% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:50:21,072]\u001b[0m Trial 449 finished with value: 10.24080120568835 and parameters: {'n_hidden': 3, 'learning_rate': 0.004794762553188602, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12661207673275918, 'dropout_rate_Layer_2': 0.06425636231119622, 'dropout_rate_Layer_3': 0.013793088811747456, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.607319041586537e-05, 'l1_Layer_2': 0.00010075220547870266, 'l1_Layer_3': 5.105803223757104e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 255, 'n_units_Layer_3': 160}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.24 | sMAPE for Validation Set is: 12.64% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 34.11 | sMAPE for Test Set is: 19.58% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:50:33,051]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:50:55,642]\u001b[0m Trial 451 finished with value: 10.832453466474012 and parameters: {'n_hidden': 3, 'learning_rate': 0.010302126407611575, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14167416152957216, 'dropout_rate_Layer_2': 0.17517124723641678, 'dropout_rate_Layer_3': 0.27495458619082774, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.2824462152293736e-05, 'l1_Layer_2': 0.0028674215397321563, 'l1_Layer_3': 0.004608514157584723, 'n_units_Layer_1': 150, 'n_units_Layer_2': 175, 'n_units_Layer_3': 300}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.83 | sMAPE for Validation Set is: 13.75% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 39.14 | sMAPE for Test Set is: 21.98% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:51:02,604]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:51:02,999]\u001b[0m Trial 452 finished with value: 11.350202311341768 and parameters: {'n_hidden': 3, 'learning_rate': 0.011545670169572045, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1360966266393267, 'dropout_rate_Layer_2': 0.17315039195161652, 'dropout_rate_Layer_3': 0.26124424091796733, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3604357591022467e-05, 'l1_Layer_2': 0.0030975492123703273, 'l1_Layer_3': 0.003571345220347901, 'n_units_Layer_1': 145, 'n_units_Layer_2': 175, 'n_units_Layer_3': 300}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.35 | sMAPE for Validation Set is: 14.23% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 41.95 | sMAPE for Test Set is: 23.53% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:51:13,335]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:51:18,983]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:51:51,512]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:51:58,703]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:52:04,317]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:52:19,089]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:52:31,015]\u001b[0m Trial 457 finished with value: 11.268517606484822 and parameters: {'n_hidden': 4, 'learning_rate': 0.015380812789573721, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13780211849097448, 'dropout_rate_Layer_2': 0.16104041993172769, 'dropout_rate_Layer_3': 0.2855193977307656, 'dropout_rate_Layer_4': 0.3197730873862237, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.5419401490458272e-05, 'l1_Layer_2': 0.0008197504181178488, 'l1_Layer_3': 0.003203959893386187, 'l1_Layer_4': 3.001953749395814e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 65, 'n_units_Layer_3': 280, 'n_units_Layer_4': 205}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.27 | sMAPE for Validation Set is: 14.93% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 36.28 | sMAPE for Test Set is: 20.76% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:53:20,857]\u001b[0m Trial 462 finished with value: 10.506509010716302 and parameters: {'n_hidden': 3, 'learning_rate': 0.010329781598308852, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2353639608004647, 'dropout_rate_Layer_2': 0.3896486540761426, 'dropout_rate_Layer_3': 0.19844252978558774, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002121095615300492, 'l1_Layer_2': 0.0030185401055948654, 'l1_Layer_3': 0.01869713241908149, 'n_units_Layer_1': 255, 'n_units_Layer_2': 145, 'n_units_Layer_3': 225}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.51 | sMAPE for Validation Set is: 13.47% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 35.16 | sMAPE for Test Set is: 20.20% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:53:25,810]\u001b[0m Trial 461 finished with value: 10.055698578655166 and parameters: {'n_hidden': 3, 'learning_rate': 0.004228958813993208, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14027350111458378, 'dropout_rate_Layer_2': 0.06402101522935953, 'dropout_rate_Layer_3': 0.005239355271611642, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.77457626610837e-05, 'l1_Layer_2': 0.0001489252918483118, 'l1_Layer_3': 3.779471157479899e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 250, 'n_units_Layer_3': 175}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.06 | sMAPE for Validation Set is: 12.60% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 33.30 | sMAPE for Test Set is: 19.20% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:53:32,994]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:53:52,692]\u001b[0m Trial 465 finished with value: 12.308105545035067 and parameters: {'n_hidden': 3, 'learning_rate': 0.010633953747821669, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25241556217974925, 'dropout_rate_Layer_2': 0.3730287614953564, 'dropout_rate_Layer_3': 0.18374372935761812, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013285142224564022, 'l1_Layer_2': 0.08507225415210792, 'l1_Layer_3': 0.03406483014455578, 'n_units_Layer_1': 250, 'n_units_Layer_2': 130, 'n_units_Layer_3': 220}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.31 | sMAPE for Validation Set is: 16.16% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 44.17 | sMAPE for Test Set is: 24.50% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:53:57,580]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:54:18,372]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:54:39,553]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:54:49,632]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:54:52,813]\u001b[0m Trial 463 finished with value: 11.251098833137384 and parameters: {'n_hidden': 4, 'learning_rate': 0.027166827352510435, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1466345493487766, 'dropout_rate_Layer_2': 0.21063976716159985, 'dropout_rate_Layer_3': 0.28320503680277676, 'dropout_rate_Layer_4': 0.3641330892462296, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.3920600086340156e-05, 'l1_Layer_2': 0.0016681195360199893, 'l1_Layer_3': 0.004374157943509572, 'l1_Layer_4': 2.0712045327930145e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 55, 'n_units_Layer_3': 300, 'n_units_Layer_4': 200}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.25 | sMAPE for Validation Set is: 14.54% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 40.93 | sMAPE for Test Set is: 22.94% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:54:57,505]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:55:00,467]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:55:02,683]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:55:05,378]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:55:37,282]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:56:25,151]\u001b[0m Trial 476 finished with value: 10.52072263775369 and parameters: {'n_hidden': 3, 'learning_rate': 0.017098501100489442, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3033008377101276, 'dropout_rate_Layer_2': 0.39440101551458306, 'dropout_rate_Layer_3': 0.3333368246273834, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8214323854080314e-05, 'l1_Layer_2': 0.00343158282000553, 'l1_Layer_3': 0.0005744707256328662, 'n_units_Layer_1': 240, 'n_units_Layer_2': 115, 'n_units_Layer_3': 230}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.52 | sMAPE for Validation Set is: 13.39% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 36.64 | sMAPE for Test Set is: 20.94% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:56:28,086]\u001b[0m Trial 475 finished with value: 9.969411590592157 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015661366098471269, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19041438840758165, 'dropout_rate_Layer_2': 0.33111916914691225, 'dropout_rate_Layer_3': 0.18035483325682994, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006185380391192357, 'l1_Layer_2': 6.730669991429779e-05, 'l1_Layer_3': 0.000870359131537291, 'n_units_Layer_1': 190, 'n_units_Layer_2': 130, 'n_units_Layer_3': 60}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.97 | sMAPE for Validation Set is: 12.91% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 33.24 | sMAPE for Test Set is: 19.16% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:56:37,983]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:56:59,197]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:57:15,146]\u001b[0m Trial 477 finished with value: 10.174344854550212 and parameters: {'n_hidden': 3, 'learning_rate': 0.004510313018272009, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11589158875584246, 'dropout_rate_Layer_2': 0.06417787702846996, 'dropout_rate_Layer_3': 0.0001871072794537177, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.19358948807123e-05, 'l1_Layer_2': 9.992479416803734e-05, 'l1_Layer_3': 3.4572011631399796e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 240, 'n_units_Layer_3': 180}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.17 | sMAPE for Validation Set is: 12.69% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 33.24 | sMAPE for Test Set is: 19.21% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:57:46,551]\u001b[0m Trial 480 finished with value: 10.610304730360292 and parameters: {'n_hidden': 4, 'learning_rate': 0.005404558165404603, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1285520157095189, 'dropout_rate_Layer_2': 0.06784622360598569, 'dropout_rate_Layer_3': 0.013106039586414748, 'dropout_rate_Layer_4': 0.20214205742839392, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.821248606841818e-05, 'l1_Layer_2': 0.00014093714310698687, 'l1_Layer_3': 3.901491249759472e-05, 'l1_Layer_4': 0.015629650776796615, 'n_units_Layer_1': 285, 'n_units_Layer_2': 250, 'n_units_Layer_3': 175, 'n_units_Layer_4': 50}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.61 | sMAPE for Validation Set is: 13.26% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 34.68 | sMAPE for Test Set is: 19.92% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:59:06,704]\u001b[0m Trial 481 finished with value: 11.446519217340196 and parameters: {'n_hidden': 4, 'learning_rate': 0.03280671149085784, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.171121957586915, 'dropout_rate_Layer_2': 0.22495061999154542, 'dropout_rate_Layer_3': 0.28668051441455783, 'dropout_rate_Layer_4': 0.36814587181555386, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.1106756362035243e-05, 'l1_Layer_2': 0.0007747814217126997, 'l1_Layer_3': 0.008385525801707035, 'l1_Layer_4': 1.615768690875208e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 55, 'n_units_Layer_3': 275, 'n_units_Layer_4': 205}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.45 | sMAPE for Validation Set is: 14.40% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 37.58 | sMAPE for Test Set is: 21.28% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:59:14,100]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:59:39,438]\u001b[0m Trial 482 finished with value: 11.314200589252808 and parameters: {'n_hidden': 4, 'learning_rate': 0.03568504361446859, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17643459511038495, 'dropout_rate_Layer_2': 0.2142329415440105, 'dropout_rate_Layer_3': 0.29006013705110584, 'dropout_rate_Layer_4': 0.372115565973002, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.3605503137838317e-05, 'l1_Layer_2': 0.0007641902974316215, 'l1_Layer_3': 0.010570815415688837, 'l1_Layer_4': 1.4270569733425252e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 50, 'n_units_Layer_3': 275, 'n_units_Layer_4': 220}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.31 | sMAPE for Validation Set is: 14.63% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 40.99 | sMAPE for Test Set is: 23.18% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:59:46,215]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:59:56,831]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:00:04,236]\u001b[0m Trial 484 finished with value: 10.477761190705682 and parameters: {'n_hidden': 4, 'learning_rate': 0.005034006799426816, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11204768557238225, 'dropout_rate_Layer_2': 0.05207336005070816, 'dropout_rate_Layer_3': 0.01888364778559624, 'dropout_rate_Layer_4': 0.14726197752929876, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.085651777572786e-05, 'l1_Layer_2': 0.0001439944044954836, 'l1_Layer_3': 3.0832888609027295e-05, 'l1_Layer_4': 0.01968386056254729, 'n_units_Layer_1': 285, 'n_units_Layer_2': 250, 'n_units_Layer_3': 150, 'n_units_Layer_4': 105}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.48 | sMAPE for Validation Set is: 13.25% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 34.40 | sMAPE for Test Set is: 19.84% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:00:11,082]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:00:16,553]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:01:14,547]\u001b[0m Trial 489 finished with value: 11.086144308102641 and parameters: {'n_hidden': 4, 'learning_rate': 0.02734238911996038, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19032110071887526, 'dropout_rate_Layer_2': 0.207565672485274, 'dropout_rate_Layer_3': 0.3425351177332864, 'dropout_rate_Layer_4': 0.3380456782951659, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.3816625585970553e-05, 'l1_Layer_2': 0.0003388295847015154, 'l1_Layer_3': 0.00988030104076645, 'l1_Layer_4': 4.995575073685166e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 70, 'n_units_Layer_3': 300, 'n_units_Layer_4': 200}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.09 | sMAPE for Validation Set is: 14.33% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 40.83 | sMAPE for Test Set is: 22.89% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:01:21,406]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:01:34,750]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:01:41,278]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:01:51,562]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:01:59,615]\u001b[0m Trial 490 finished with value: 11.042876220388786 and parameters: {'n_hidden': 4, 'learning_rate': 0.0316233728966152, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19444109154026665, 'dropout_rate_Layer_2': 0.20629337541199283, 'dropout_rate_Layer_3': 0.3470460111387324, 'dropout_rate_Layer_4': 0.3292645406525401, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.5094685711509794e-05, 'l1_Layer_2': 0.0003373939924042682, 'l1_Layer_3': 0.0077513503280207145, 'l1_Layer_4': 4.9779767567094884e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 70, 'n_units_Layer_3': 300, 'n_units_Layer_4': 200}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.04 | sMAPE for Validation Set is: 14.21% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 39.23 | sMAPE for Test Set is: 22.09% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:02:06,636]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:02:26,111]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:02:36,251]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:03:08,434]\u001b[0m Trial 499 finished with value: 10.567617266093775 and parameters: {'n_hidden': 4, 'learning_rate': 0.004383214456791009, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14618722220448088, 'dropout_rate_Layer_2': 0.05698857912159798, 'dropout_rate_Layer_3': 0.01006302647068976, 'dropout_rate_Layer_4': 0.20216057056358594, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.915919465824648e-05, 'l1_Layer_2': 0.00011584410796526242, 'l1_Layer_3': 3.3555669496540414e-05, 'l1_Layer_4': 0.011565385462056503, 'n_units_Layer_1': 295, 'n_units_Layer_2': 255, 'n_units_Layer_3': 170, 'n_units_Layer_4': 105}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.57 | sMAPE for Validation Set is: 13.46% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 35.18 | sMAPE for Test Set is: 20.19% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:03:18,422]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:03:28,379]\u001b[0m Trial 498 finished with value: 13.752097481597957 and parameters: {'n_hidden': 4, 'learning_rate': 0.04797889280746513, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19793738835534447, 'dropout_rate_Layer_2': 0.27443290652902874, 'dropout_rate_Layer_3': 0.34832172678468815, 'dropout_rate_Layer_4': 0.30441756335158265, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.2962247804017412e-05, 'l1_Layer_2': 0.00037802659758252475, 'l1_Layer_3': 0.03094211130085203, 'l1_Layer_4': 5.717027537887304e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 80, 'n_units_Layer_3': 300, 'n_units_Layer_4': 180}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.75 | sMAPE for Validation Set is: 18.47% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 47.43 | sMAPE for Test Set is: 26.45% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:03:40,011]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:03:57,469]\u001b[0m Trial 501 finished with value: 10.613238711703424 and parameters: {'n_hidden': 4, 'learning_rate': 0.0043382223882012984, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1414710633021264, 'dropout_rate_Layer_2': 0.07075824737091685, 'dropout_rate_Layer_3': 0.019151667854598528, 'dropout_rate_Layer_4': 0.23775297505074622, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.825218999857245e-05, 'l1_Layer_2': 8.75341283542079e-05, 'l1_Layer_3': 2.4227225843500656e-05, 'l1_Layer_4': 0.04188234924325192, 'n_units_Layer_1': 280, 'n_units_Layer_2': 235, 'n_units_Layer_3': 175, 'n_units_Layer_4': 125}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.61 | sMAPE for Validation Set is: 13.50% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 34.83 | sMAPE for Test Set is: 20.16% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:04:02,517]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:04:02,884]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:05:59,631]\u001b[0m Trial 505 finished with value: 11.747995997380947 and parameters: {'n_hidden': 4, 'learning_rate': 0.023387900415106865, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22063981277584824, 'dropout_rate_Layer_2': 0.2475683481362927, 'dropout_rate_Layer_3': 0.3853398930212332, 'dropout_rate_Layer_4': 0.33778806979206344, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.028696742676213e-05, 'l1_Layer_2': 0.00011934131960121234, 'l1_Layer_3': 0.006084278356704909, 'l1_Layer_4': 6.070195062744718e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 80, 'n_units_Layer_3': 290, 'n_units_Layer_4': 190}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.75 | sMAPE for Validation Set is: 14.73% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 44.60 | sMAPE for Test Set is: 23.95% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:06:04,336]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:06:17,276]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:06:37,010]\u001b[0m Trial 506 finished with value: 11.705831399860775 and parameters: {'n_hidden': 4, 'learning_rate': 0.026579039909497615, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21572862113829439, 'dropout_rate_Layer_2': 0.2553570085306544, 'dropout_rate_Layer_3': 0.37661329422028084, 'dropout_rate_Layer_4': 0.3376669345400156, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.0126697246277422e-05, 'l1_Layer_2': 6.263139054056356e-05, 'l1_Layer_3': 0.0020676943111031455, 'l1_Layer_4': 5.418421765033347e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 75, 'n_units_Layer_3': 290, 'n_units_Layer_4': 155}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.71 | sMAPE for Validation Set is: 14.90% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 40.46 | sMAPE for Test Set is: 23.04% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:06:44,757]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:06:51,624]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:07:41,946]\u001b[0m Trial 509 finished with value: 11.2138251407808 and parameters: {'n_hidden': 4, 'learning_rate': 0.02881508326613082, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10462499971643813, 'dropout_rate_Layer_2': 0.20047102103483108, 'dropout_rate_Layer_3': 0.3551210309201658, 'dropout_rate_Layer_4': 0.2685503351958142, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.4937832740236127e-05, 'l1_Layer_2': 5.880024859303738e-05, 'l1_Layer_3': 0.0023357587930767565, 'l1_Layer_4': 4.478791865858813e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 70, 'n_units_Layer_3': 265, 'n_units_Layer_4': 155}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.21 | sMAPE for Validation Set is: 14.60% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 37.94 | sMAPE for Test Set is: 21.61% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:07:49,221]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:08:07,190]\u001b[0m Trial 514 finished with value: 30.285778580830748 and parameters: {'n_hidden': 3, 'learning_rate': 0.012927514001183022, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3237827085171652, 'dropout_rate_Layer_2': 0.3915991232773604, 'dropout_rate_Layer_3': 0.32372099583853753, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1192496629057071e-05, 'l1_Layer_2': 0.004594116380813576, 'l1_Layer_3': 0.0006628765189973547, 'n_units_Layer_1': 265, 'n_units_Layer_2': 115, 'n_units_Layer_3': 235}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.29 | sMAPE for Validation Set is: 38.41% | rMAE for Validation Set is: 1.79\n",
      "MAE for Test Set is: 160.89 | sMAPE for Test Set is: 107.72% | rMAE for Test Set is: 2.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:08:11,600]\u001b[0m Trial 512 finished with value: 10.241248446354431 and parameters: {'n_hidden': 4, 'learning_rate': 0.004760177599149844, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12177595831128989, 'dropout_rate_Layer_2': 0.05324883784246123, 'dropout_rate_Layer_3': 0.0004807156034152323, 'dropout_rate_Layer_4': 0.16689462688426024, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.1952640291909886e-05, 'l1_Layer_2': 8.365181632335027e-05, 'l1_Layer_3': 1.9649444490947403e-05, 'l1_Layer_4': 0.0650959526797281, 'n_units_Layer_1': 290, 'n_units_Layer_2': 250, 'n_units_Layer_3': 160, 'n_units_Layer_4': 70}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.24 | sMAPE for Validation Set is: 12.95% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 33.66 | sMAPE for Test Set is: 19.42% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:08:16,704]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:08:20,374]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:08:30,418]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:08:36,093]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:08:42,930]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:08:55,634]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:09:01,059]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:09:10,999]\u001b[0m Trial 517 finished with value: 10.511304153596889 and parameters: {'n_hidden': 4, 'learning_rate': 0.004360973346731261, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1312679133477213, 'dropout_rate_Layer_2': 0.04361498261991734, 'dropout_rate_Layer_3': 0.02066727818529412, 'dropout_rate_Layer_4': 0.13525278772607424, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.585301177484601e-05, 'l1_Layer_2': 7.733856589023046e-05, 'l1_Layer_3': 2.1053763000200412e-05, 'l1_Layer_4': 0.03028511384603865, 'n_units_Layer_1': 300, 'n_units_Layer_2': 240, 'n_units_Layer_3': 120, 'n_units_Layer_4': 95}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.51 | sMAPE for Validation Set is: 13.27% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 34.54 | sMAPE for Test Set is: 19.89% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:09:18,748]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:09:26,787]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:09:44,993]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:09:54,697]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:10:42,142]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:10:42,449]\u001b[0m Trial 528 finished with value: 11.260410648386795 and parameters: {'n_hidden': 4, 'learning_rate': 0.05316121027292878, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09748266940529154, 'dropout_rate_Layer_2': 0.18603938981814847, 'dropout_rate_Layer_3': 0.3384483536342856, 'dropout_rate_Layer_4': 0.27252560063685005, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.559871938814808e-05, 'l1_Layer_2': 2.8425863632462606e-05, 'l1_Layer_3': 0.019657900597465135, 'l1_Layer_4': 0.00045529705982984525, 'n_units_Layer_1': 205, 'n_units_Layer_2': 90, 'n_units_Layer_3': 265, 'n_units_Layer_4': 235}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.26 | sMAPE for Validation Set is: 14.47% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 38.15 | sMAPE for Test Set is: 21.75% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:11:01,022]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:11:11,442]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:11:43,233]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:12:20,770]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:13:22,401]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:13:28,035]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:14:03,206]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:14:15,755]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:14:22,856]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:14:28,117]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:14:35,351]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:14:42,540]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:15:12,110]\u001b[0m Trial 538 finished with value: 24.00614845520957 and parameters: {'n_hidden': 3, 'learning_rate': 0.0204672377167336, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2646016894317332, 'dropout_rate_Layer_2': 0.33441434829691274, 'dropout_rate_Layer_3': 0.3290025204747181, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.558906020005898e-05, 'l1_Layer_2': 0.008733196606451828, 'l1_Layer_3': 0.0004950798197314477, 'n_units_Layer_1': 230, 'n_units_Layer_2': 55, 'n_units_Layer_3': 295}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.01 | sMAPE for Validation Set is: 28.07% | rMAE for Validation Set is: 1.42\n",
      "MAE for Test Set is: 150.61 | sMAPE for Test Set is: 95.54% | rMAE for Test Set is: 2.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:15:17,540]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:15:32,279]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:16:11,807]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:16:17,418]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:18:06,511]\u001b[0m Trial 545 finished with value: 12.710980667979134 and parameters: {'n_hidden': 4, 'learning_rate': 0.02159628667898262, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1455449555741519, 'dropout_rate_Layer_2': 0.17680558140412736, 'dropout_rate_Layer_3': 0.39580693840869613, 'dropout_rate_Layer_4': 0.3100753178017465, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.3953964973198853e-05, 'l1_Layer_2': 0.000449731461224836, 'l1_Layer_3': 0.002735468879431427, 'l1_Layer_4': 2.398797737235398e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 90, 'n_units_Layer_3': 280, 'n_units_Layer_4': 130}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.71 | sMAPE for Validation Set is: 16.74% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 46.81 | sMAPE for Test Set is: 25.57% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:18:14,437]\u001b[0m Trial 547 finished with value: 12.898481586330211 and parameters: {'n_hidden': 4, 'learning_rate': 0.06172883718874023, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.145622521301457, 'dropout_rate_Layer_2': 0.1760842615921617, 'dropout_rate_Layer_3': 0.3959352844381143, 'dropout_rate_Layer_4': 0.3246170617933753, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.5389777938714566e-05, 'l1_Layer_2': 0.00042383070459866385, 'l1_Layer_3': 0.0024577380279025038, 'l1_Layer_4': 2.8139989736948684e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 90, 'n_units_Layer_3': 280, 'n_units_Layer_4': 190}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.90 | sMAPE for Validation Set is: 16.24% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 47.76 | sMAPE for Test Set is: 25.12% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:18:19,679]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:18:26,500]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:18:37,269]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:18:44,607]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:18:51,698]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:18:59,712]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:19:04,619]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:19:11,345]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:19:11,412]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:19:19,877]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:19:30,576]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:19:37,218]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:19:42,648]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:19:47,718]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:19:52,573]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:19:57,366]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:20:07,759]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:20:13,198]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:20:18,138]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:20:29,916]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:20:45,628]\u001b[0m Trial 558 finished with value: 9.930912616026468 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016371228941033577, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16978240626919622, 'dropout_rate_Layer_2': 0.3150143208402095, 'dropout_rate_Layer_3': 0.19994671380318677, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005221110073034558, 'l1_Layer_2': 7.096935904882441e-05, 'l1_Layer_3': 0.0008382029063907748, 'n_units_Layer_1': 190, 'n_units_Layer_2': 135, 'n_units_Layer_3': 65}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.93 | sMAPE for Validation Set is: 12.61% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 33.37 | sMAPE for Test Set is: 19.20% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:20:49,883]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:20:50,268]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:20:58,566]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:21:10,056]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:21:16,131]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:21:18,610]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:21:29,954]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:21:40,018]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:21:45,506]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:21:50,347]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:21:50,611]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:21:59,104]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:21:59,234]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:22:06,662]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:22:13,411]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:22:26,494]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:22:34,159]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:23:01,146]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:23:08,976]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:23:14,533]\u001b[0m Trial 587 finished with value: 10.232666214182835 and parameters: {'n_hidden': 3, 'learning_rate': 0.010092757558421176, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24671413118827687, 'dropout_rate_Layer_2': 0.3969239189693614, 'dropout_rate_Layer_3': 0.22661986306544463, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003008087380563564, 'l1_Layer_2': 0.0015273196625737568, 'l1_Layer_3': 0.004200651341375709, 'n_units_Layer_1': 225, 'n_units_Layer_2': 165, 'n_units_Layer_3': 180}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.23 | sMAPE for Validation Set is: 12.95% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 34.76 | sMAPE for Test Set is: 19.98% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:23:38,725]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:23:44,093]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:23:48,537]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:23:50,861]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:23:56,106]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:23:59,416]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:24:18,964]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:24:28,751]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:24:51,038]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:25:01,138]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:25:06,499]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:25:26,277]\u001b[0m Trial 598 finished with value: 10.125478226370431 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031284244815053997, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20338383812535138, 'dropout_rate_Layer_2': 0.3713080105109841, 'dropout_rate_Layer_3': 0.039730540627876954, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00485734073535464, 'l1_Layer_2': 3.203845688293071e-05, 'l1_Layer_3': 0.00026372039816549857, 'n_units_Layer_1': 180, 'n_units_Layer_2': 120, 'n_units_Layer_3': 100}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.13 | sMAPE for Validation Set is: 12.88% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 33.68 | sMAPE for Test Set is: 19.51% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:25:30,954]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:25:38,357]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:25:42,954]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:25:48,022]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:25:52,456]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:26:05,851]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:26:40,804]\u001b[0m Trial 608 finished with value: 10.474426099645804 and parameters: {'n_hidden': 3, 'learning_rate': 0.00585071872367727, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12756299879143665, 'dropout_rate_Layer_2': 0.08203884200653518, 'dropout_rate_Layer_3': 0.010261693519835885, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.8657567989277136e-05, 'l1_Layer_2': 0.00029494455205861416, 'l1_Layer_3': 5.2264575560737464e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 255, 'n_units_Layer_3': 170}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.47 | sMAPE for Validation Set is: 13.11% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 34.51 | sMAPE for Test Set is: 19.82% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:26:41,361]\u001b[0m Trial 606 finished with value: 11.389843601017247 and parameters: {'n_hidden': 4, 'learning_rate': 0.0925720962995761, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16216071861141768, 'dropout_rate_Layer_2': 0.12613250640697662, 'dropout_rate_Layer_3': 0.36018959694053476, 'dropout_rate_Layer_4': 0.15588013048838933, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.5644719296431595e-05, 'l1_Layer_2': 3.995863304308413e-05, 'l1_Layer_3': 0.00930710184254322, 'l1_Layer_4': 0.00020115883471448083, 'n_units_Layer_1': 165, 'n_units_Layer_2': 85, 'n_units_Layer_3': 285, 'n_units_Layer_4': 200}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.39 | sMAPE for Validation Set is: 14.75% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 39.31 | sMAPE for Test Set is: 22.39% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:27:08,922]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:27:14,034]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:27:21,444]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:27:56,413]\u001b[0m Trial 613 finished with value: 10.7030774034113 and parameters: {'n_hidden': 3, 'learning_rate': 0.007686251872017554, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18542171867645593, 'dropout_rate_Layer_2': 0.31464474136186016, 'dropout_rate_Layer_3': 0.16996013705120452, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011418141017551675, 'l1_Layer_2': 0.000111091593386494, 'l1_Layer_3': 3.478464954864831e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 150, 'n_units_Layer_3': 105}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.70 | sMAPE for Validation Set is: 13.53% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 35.39 | sMAPE for Test Set is: 20.27% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:28:01,788]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:28:11,347]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:28:16,848]\u001b[0m Trial 610 finished with value: 10.023106371916873 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006229275749049496, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18091402011054825, 'dropout_rate_Layer_2': 0.3102898996938154, 'dropout_rate_Layer_3': 0.16950121225504822, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012387946471314245, 'l1_Layer_2': 0.00010884045687681158, 'l1_Layer_3': 0.0015034341267401968, 'n_units_Layer_1': 200, 'n_units_Layer_2': 160, 'n_units_Layer_3': 105}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.02 | sMAPE for Validation Set is: 12.59% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 33.22 | sMAPE for Test Set is: 19.19% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:28:21,913]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:28:26,621]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:28:36,990]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:29:01,082]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:29:42,514]\u001b[0m Trial 618 finished with value: 11.107565848245747 and parameters: {'n_hidden': 4, 'learning_rate': 0.05870161636256337, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0978317949545057, 'dropout_rate_Layer_2': 0.18610545361933722, 'dropout_rate_Layer_3': 0.34265304422659326, 'dropout_rate_Layer_4': 0.2698194169399618, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.3507946471083406e-05, 'l1_Layer_2': 2.1380317124136787e-05, 'l1_Layer_3': 0.02038259371787426, 'l1_Layer_4': 0.001766528632003894, 'n_units_Layer_1': 210, 'n_units_Layer_2': 70, 'n_units_Layer_3': 265, 'n_units_Layer_4': 185}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.11 | sMAPE for Validation Set is: 14.15% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 36.59 | sMAPE for Test Set is: 20.77% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:29:48,153]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:29:55,093]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:30:02,111]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:30:09,665]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:30:40,094]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:30:52,435]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:31:00,133]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:31:06,481]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:31:12,050]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:31:59,326]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:32:09,196]\u001b[0m Trial 626 finished with value: 12.113510952990373 and parameters: {'n_hidden': 4, 'learning_rate': 0.03832706594785193, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08349203227712859, 'dropout_rate_Layer_2': 0.19541855631745475, 'dropout_rate_Layer_3': 0.32361175983644863, 'dropout_rate_Layer_4': 0.340831662611571, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.0544876609696204e-05, 'l1_Layer_2': 8.389065203815002e-05, 'l1_Layer_3': 0.012076760757779794, 'l1_Layer_4': 0.001704490184821517, 'n_units_Layer_1': 260, 'n_units_Layer_2': 70, 'n_units_Layer_3': 230, 'n_units_Layer_4': 185}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.11 | sMAPE for Validation Set is: 15.39% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 46.96 | sMAPE for Test Set is: 25.60% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:32:56,240]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:33:16,604]\u001b[0m Trial 634 finished with value: 10.203168699506053 and parameters: {'n_hidden': 3, 'learning_rate': 0.005029896554953312, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0001779081475429382, 'dropout_rate_Layer_2': 0.05900218673163543, 'dropout_rate_Layer_3': 0.007462399849912659, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.381815369755339e-05, 'l1_Layer_2': 0.00016870894183726893, 'l1_Layer_3': 3.9130856074368545e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 255, 'n_units_Layer_3': 145}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.20 | sMAPE for Validation Set is: 12.73% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 34.22 | sMAPE for Test Set is: 19.73% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:33:39,169]\u001b[0m Trial 635 finished with value: 10.580724482864865 and parameters: {'n_hidden': 3, 'learning_rate': 0.006736324348463857, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2082387545361689, 'dropout_rate_Layer_2': 0.188628003263527, 'dropout_rate_Layer_3': 0.05122825870003263, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.028088224460230272, 'l1_Layer_2': 0.08112415195509959, 'l1_Layer_3': 2.265645177493998e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 230, 'n_units_Layer_3': 185}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.58 | sMAPE for Validation Set is: 13.22% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 34.51 | sMAPE for Test Set is: 19.79% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:33:46,002]\u001b[0m Trial 632 finished with value: 11.440699486874559 and parameters: {'n_hidden': 4, 'learning_rate': 0.01456392285597708, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08457516496605869, 'dropout_rate_Layer_2': 0.19766917934113074, 'dropout_rate_Layer_3': 0.32219283045494596, 'dropout_rate_Layer_4': 0.2972409849040165, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.928883247542057e-05, 'l1_Layer_2': 8.564408531206527e-05, 'l1_Layer_3': 0.013968713271133184, 'l1_Layer_4': 0.0014249455247705445, 'n_units_Layer_1': 210, 'n_units_Layer_2': 120, 'n_units_Layer_3': 235, 'n_units_Layer_4': 185}. Best is trial 446 with value: 9.901294062772498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.44 | sMAPE for Validation Set is: 14.77% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 41.02 | sMAPE for Test Set is: 22.98% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:33:53,489]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:34:00,918]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:34:20,643]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:34:26,084]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:34:33,637]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:34:46,022]\u001b[0m Trial 636 finished with value: 9.61329101938997 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018341419959342254, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0010185378239364056, 'dropout_rate_Layer_2': 0.051981623368119435, 'dropout_rate_Layer_3': 0.006880089493686162, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.5774487700817705e-05, 'l1_Layer_2': 0.00017929487669278527, 'l1_Layer_3': 3.77589467743449e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 255, 'n_units_Layer_3': 145}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.61 | sMAPE for Validation Set is: 11.94% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 31.30 | sMAPE for Test Set is: 18.26% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:35:43,430]\u001b[0m Trial 642 finished with value: 9.647949487101878 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017748531048134195, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013224126830375488, 'dropout_rate_Layer_2': 0.06448302563195317, 'dropout_rate_Layer_3': 0.012514284132122144, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.6639412427111606e-05, 'l1_Layer_2': 0.00018155502681242868, 'l1_Layer_3': 5.272411260691779e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 260, 'n_units_Layer_3': 215}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.65 | sMAPE for Validation Set is: 11.99% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 32.42 | sMAPE for Test Set is: 18.72% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:36:29,599]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:37:12,833]\u001b[0m Trial 643 finished with value: 9.768684054637534 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026012695929267045, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14304850336451227, 'dropout_rate_Layer_2': 0.36239243529331366, 'dropout_rate_Layer_3': 0.23807898662022695, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014399419891134272, 'l1_Layer_2': 4.91605316161289e-05, 'l1_Layer_3': 0.00029313513789062885, 'n_units_Layer_1': 215, 'n_units_Layer_2': 165, 'n_units_Layer_3': 75}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.77 | sMAPE for Validation Set is: 12.33% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 32.85 | sMAPE for Test Set is: 18.93% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:37:17,702]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:37:22,787]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:37:30,181]\u001b[0m Trial 645 finished with value: 10.224374720335453 and parameters: {'n_hidden': 3, 'learning_rate': 0.00710286981065017, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14618026601696546, 'dropout_rate_Layer_2': 0.372658716556595, 'dropout_rate_Layer_3': 0.29353006631521966, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015346404429180927, 'l1_Layer_2': 1.011885315054148e-05, 'l1_Layer_3': 0.00028826095023445, 'n_units_Layer_1': 220, 'n_units_Layer_2': 105, 'n_units_Layer_3': 75}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.22 | sMAPE for Validation Set is: 12.95% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 34.21 | sMAPE for Test Set is: 19.52% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:37:36,956]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:38:09,590]\u001b[0m Trial 650 finished with value: 10.044100589050707 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016095335787972708, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007343740165385925, 'dropout_rate_Layer_2': 0.025914469653608507, 'dropout_rate_Layer_3': 0.00764616933764253, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.828189446361794e-05, 'l1_Layer_2': 0.0001682795391745792, 'l1_Layer_3': 2.9388602179973553e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 250, 'n_units_Layer_3': 210}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.04 | sMAPE for Validation Set is: 12.53% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 33.63 | sMAPE for Test Set is: 19.41% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:38:23,988]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:38:29,457]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:38:34,602]\u001b[0m Trial 651 finished with value: 10.387334118368905 and parameters: {'n_hidden': 3, 'learning_rate': 0.006679646733944531, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19561721431149634, 'dropout_rate_Layer_2': 0.19120023624046517, 'dropout_rate_Layer_3': 0.05161517561283022, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.023298850337322884, 'l1_Layer_2': 0.09704356039427572, 'l1_Layer_3': 2.559618140481562e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 55, 'n_units_Layer_3': 170}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.39 | sMAPE for Validation Set is: 13.07% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 34.10 | sMAPE for Test Set is: 19.61% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:38:56,768]\u001b[0m Trial 653 finished with value: 10.441044068780469 and parameters: {'n_hidden': 3, 'learning_rate': 0.006925605188601203, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.206098660819808, 'dropout_rate_Layer_2': 0.20517307510745805, 'dropout_rate_Layer_3': 0.05142208277161263, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.019082776451835252, 'l1_Layer_2': 0.09867633448739925, 'l1_Layer_3': 2.861797905739765e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 190, 'n_units_Layer_3': 270}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.44 | sMAPE for Validation Set is: 13.02% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 34.44 | sMAPE for Test Set is: 19.75% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:39:39,553]\u001b[0m Trial 655 finished with value: 10.271884997108574 and parameters: {'n_hidden': 3, 'learning_rate': 0.011838272924359985, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3357663078709464, 'dropout_rate_Layer_2': 0.33581531174382084, 'dropout_rate_Layer_3': 0.17301874276844526, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011311381317036875, 'l1_Layer_2': 0.0034713797659846495, 'l1_Layer_3': 0.0047909733682818525, 'n_units_Layer_1': 225, 'n_units_Layer_2': 165, 'n_units_Layer_3': 160}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.27 | sMAPE for Validation Set is: 12.99% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 35.00 | sMAPE for Test Set is: 20.20% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:39:46,668]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:39:46,999]\u001b[0m Trial 654 finished with value: 9.70244504977427 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014444247767289823, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012305262668034816, 'dropout_rate_Layer_2': 0.03294465818966821, 'dropout_rate_Layer_3': 0.0061040972746811105, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.688809390725958e-05, 'l1_Layer_2': 0.00016547235261792117, 'l1_Layer_3': 2.804144312317797e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 255, 'n_units_Layer_3': 220}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.70 | sMAPE for Validation Set is: 12.08% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 33.41 | sMAPE for Test Set is: 19.17% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:39:54,405]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:40:04,356]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:40:48,604]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:40:54,176]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:40:59,106]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:41:03,573]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:41:08,831]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:41:29,423]\u001b[0m Trial 664 finished with value: 10.57455377361184 and parameters: {'n_hidden': 3, 'learning_rate': 0.005916708303181854, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2096416683912221, 'dropout_rate_Layer_2': 0.21442411576016818, 'dropout_rate_Layer_3': 0.056416473626846916, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03935066941783893, 'l1_Layer_2': 0.07984305053019021, 'l1_Layer_3': 3.3955303833577834e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 195, 'n_units_Layer_3': 185}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.57 | sMAPE for Validation Set is: 13.45% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 34.13 | sMAPE for Test Set is: 19.74% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:41:36,704]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:41:59,041]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:42:48,238]\u001b[0m Trial 667 finished with value: 9.787075370854284 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020835058479576956, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03515219796354413, 'dropout_rate_Layer_2': 0.025501270890591718, 'dropout_rate_Layer_3': 0.013174872915226118, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.368853295249445e-05, 'l1_Layer_2': 0.00017297841607654115, 'l1_Layer_3': 3.995205426012638e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 255, 'n_units_Layer_3': 215}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.79 | sMAPE for Validation Set is: 12.07% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 33.13 | sMAPE for Test Set is: 19.02% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:42:56,299]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:43:08,061]\u001b[0m Trial 668 finished with value: 9.893063395835833 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018899664301986105, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.032311175914939136, 'dropout_rate_Layer_2': 0.029337950195474142, 'dropout_rate_Layer_3': 0.013513348973325328, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.315049945476942e-05, 'l1_Layer_2': 0.00017584197198834573, 'l1_Layer_3': 4.0217553440128386e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 255, 'n_units_Layer_3': 215}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.89 | sMAPE for Validation Set is: 12.42% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 32.48 | sMAPE for Test Set is: 18.87% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:43:18,239]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:43:35,595]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:44:14,201]\u001b[0m Trial 671 finished with value: 9.95978738735952 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013886216653882452, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.035747639972261186, 'dropout_rate_Layer_2': 0.0152769221398611, 'dropout_rate_Layer_3': 0.013191013045428614, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.031866482106534e-05, 'l1_Layer_2': 0.0001786269596092056, 'l1_Layer_3': 3.354299937431279e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 255, 'n_units_Layer_3': 210}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.96 | sMAPE for Validation Set is: 12.28% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 31.93 | sMAPE for Test Set is: 18.58% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:44:44,351]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:44:59,192]\u001b[0m Trial 674 finished with value: 10.384560922999178 and parameters: {'n_hidden': 3, 'learning_rate': 0.00897872532944538, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3495774825966573, 'dropout_rate_Layer_2': 0.3280880776744799, 'dropout_rate_Layer_3': 0.16590558355270288, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011901771190655343, 'l1_Layer_2': 0.0009101882708401039, 'l1_Layer_3': 0.004058883368406072, 'n_units_Layer_1': 225, 'n_units_Layer_2': 175, 'n_units_Layer_3': 165}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.38 | sMAPE for Validation Set is: 13.11% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 34.95 | sMAPE for Test Set is: 20.09% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:45:08,981]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:45:28,975]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:45:38,423]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:45:49,003]\u001b[0m Trial 675 finished with value: 9.815241494089976 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013235567384445523, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03498515635674411, 'dropout_rate_Layer_2': 0.017792842808181088, 'dropout_rate_Layer_3': 0.011511935962726061, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.40430080424512e-05, 'l1_Layer_2': 0.00018061547121756176, 'l1_Layer_3': 3.687875187589215e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 255, 'n_units_Layer_3': 220}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.82 | sMAPE for Validation Set is: 12.28% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 32.24 | sMAPE for Test Set is: 18.81% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:46:23,933]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:46:30,935]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:46:38,007]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:47:02,756]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:47:07,319]\u001b[0m Trial 680 finished with value: 9.642339057362946 and parameters: {'n_hidden': 3, 'learning_rate': 0.001156588740687658, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03450362995618525, 'dropout_rate_Layer_2': 0.014378467715867326, 'dropout_rate_Layer_3': 0.008774025494672391, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.221847654893865e-05, 'l1_Layer_2': 0.00030392248234559086, 'l1_Layer_3': 2.9723739871257915e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 265, 'n_units_Layer_3': 210}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.64 | sMAPE for Validation Set is: 11.98% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 32.76 | sMAPE for Test Set is: 18.93% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:47:15,254]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:47:29,867]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:47:39,453]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:47:52,175]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:48:10,216]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:48:15,370]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:48:32,693]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:48:40,853]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:48:50,151]\u001b[0m Trial 690 finished with value: 10.661055116307137 and parameters: {'n_hidden': 3, 'learning_rate': 0.005433110674198585, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24621277585061688, 'dropout_rate_Layer_2': 0.2080732407664969, 'dropout_rate_Layer_3': 0.04885737464142021, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.016200711438195504, 'l1_Layer_2': 0.07478574626335847, 'l1_Layer_3': 1.4885673853743418e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 190, 'n_units_Layer_3': 155}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.66 | sMAPE for Validation Set is: 13.71% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 33.88 | sMAPE for Test Set is: 19.49% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:48:55,064]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:48:57,397]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:49:06,124]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:50:04,796]\u001b[0m Trial 697 finished with value: 11.253471138184297 and parameters: {'n_hidden': 4, 'learning_rate': 0.051058950866698594, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09677539156149115, 'dropout_rate_Layer_2': 0.17918237677599302, 'dropout_rate_Layer_3': 0.34484017098409103, 'dropout_rate_Layer_4': 0.27046251599877136, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.2307067932026044e-05, 'l1_Layer_2': 2.5122065575960234e-05, 'l1_Layer_3': 0.028375928795186602, 'l1_Layer_4': 0.0006824933629848725, 'n_units_Layer_1': 200, 'n_units_Layer_2': 85, 'n_units_Layer_3': 240, 'n_units_Layer_4': 230}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.25 | sMAPE for Validation Set is: 14.68% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 39.18 | sMAPE for Test Set is: 22.34% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:50:17,436]\u001b[0m Trial 695 finished with value: 11.109960913436149 and parameters: {'n_hidden': 4, 'learning_rate': 0.05849986804637491, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0980165879633179, 'dropout_rate_Layer_2': 0.1865475687256264, 'dropout_rate_Layer_3': 0.33787835893161505, 'dropout_rate_Layer_4': 0.2787008290621958, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.286535926455908e-05, 'l1_Layer_2': 2.8146071082608957e-05, 'l1_Layer_3': 0.025706774223560065, 'l1_Layer_4': 0.0005932180019608825, 'n_units_Layer_1': 205, 'n_units_Layer_2': 85, 'n_units_Layer_3': 265, 'n_units_Layer_4': 240}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.11 | sMAPE for Validation Set is: 14.23% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 40.35 | sMAPE for Test Set is: 22.64% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:50:23,109]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:51:01,850]\u001b[0m Trial 699 finished with value: 10.098305235521755 and parameters: {'n_hidden': 3, 'learning_rate': 0.0054861535324700105, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18095545387586418, 'dropout_rate_Layer_2': 0.18545241169177018, 'dropout_rate_Layer_3': 0.0650878126726699, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.017535286411501653, 'l1_Layer_2': 0.09827790452319772, 'l1_Layer_3': 1.6916564094402986e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 195, 'n_units_Layer_3': 155}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.10 | sMAPE for Validation Set is: 12.60% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 33.50 | sMAPE for Test Set is: 19.08% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:51:02,288]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:51:48,987]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:51:51,268]\u001b[0m Trial 701 finished with value: 9.854803896349901 and parameters: {'n_hidden': 3, 'learning_rate': 0.001017696696280912, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.031046907582755242, 'dropout_rate_Layer_2': 0.00788347669092198, 'dropout_rate_Layer_3': 0.009215792626888469, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.1262395167376035e-05, 'l1_Layer_2': 0.00015538948112765434, 'l1_Layer_3': 2.112648102218979e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 265, 'n_units_Layer_3': 215}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.85 | sMAPE for Validation Set is: 12.25% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 33.52 | sMAPE for Test Set is: 19.22% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:52:01,319]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:52:18,458]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:52:25,993]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:52:36,557]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:53:24,369]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:53:41,568]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:53:47,114]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:53:57,279]\u001b[0m Trial 708 finished with value: 9.701172331458364 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008872495415973008, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02065085387685554, 'dropout_rate_Layer_2': 0.019507286011804306, 'dropout_rate_Layer_3': 0.025063498275932117, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.4822278020517455e-05, 'l1_Layer_2': 0.0003905779810823979, 'l1_Layer_3': 3.172178113384382e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 255, 'n_units_Layer_3': 200}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.70 | sMAPE for Validation Set is: 12.08% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 32.75 | sMAPE for Test Set is: 18.90% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:54:02,387]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:54:08,990]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:54:14,315]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:54:38,966]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:54:46,386]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:55:15,132]\u001b[0m Trial 715 finished with value: 9.73932223352862 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017301272925618746, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017665738207125418, 'dropout_rate_Layer_2': 0.0001440733529843828, 'dropout_rate_Layer_3': 0.01387734196274416, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.1002726757173944e-05, 'l1_Layer_2': 0.0002580435797971079, 'l1_Layer_3': 3.5911956110866554e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 265, 'n_units_Layer_3': 210}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.74 | sMAPE for Validation Set is: 12.12% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 32.85 | sMAPE for Test Set is: 18.87% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:55:59,307]\u001b[0m Trial 717 finished with value: 9.793971609643052 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009519790093542575, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02617388706522355, 'dropout_rate_Layer_2': 0.0005912274132743103, 'dropout_rate_Layer_3': 0.00016003806869546548, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.550654096055407e-05, 'l1_Layer_2': 0.00013392702672519705, 'l1_Layer_3': 2.8012067148414418e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 255, 'n_units_Layer_3': 215}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.79 | sMAPE for Validation Set is: 12.12% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 33.56 | sMAPE for Test Set is: 19.25% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:56:06,459]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:56:14,493]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:56:28,775]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:56:33,818]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:57:11,580]\u001b[0m Trial 720 finished with value: 9.708981945989741 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007526516660667894, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010140514651979887, 'dropout_rate_Layer_2': 0.006510186749474137, 'dropout_rate_Layer_3': 0.00029240234662000243, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.564128233626549e-05, 'l1_Layer_2': 0.0001874228070485294, 'l1_Layer_3': 3.311111427534655e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 260, 'n_units_Layer_3': 220}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.71 | sMAPE for Validation Set is: 12.06% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 32.55 | sMAPE for Test Set is: 18.90% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:57:53,642]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:58:01,178]\u001b[0m Trial 723 finished with value: 9.667370792083457 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008303222217138288, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00900812337139105, 'dropout_rate_Layer_2': 0.0008946415686096838, 'dropout_rate_Layer_3': 0.006693487846590365, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006433198832190074, 'l1_Layer_2': 0.00018917292751423025, 'l1_Layer_3': 3.2998462682359675e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 260, 'n_units_Layer_3': 220}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.67 | sMAPE for Validation Set is: 12.12% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 33.55 | sMAPE for Test Set is: 19.04% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:58:06,525]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:58:11,486]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:58:25,775]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:58:43,852]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:58:53,782]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:59:13,846]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:59:21,081]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:59:36,262]\u001b[0m Trial 725 finished with value: 11.064079092911948 and parameters: {'n_hidden': 4, 'learning_rate': 0.042321677987947774, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06374611935802568, 'dropout_rate_Layer_2': 0.14993490800804057, 'dropout_rate_Layer_3': 0.29906610684359014, 'dropout_rate_Layer_4': 0.32893423674826183, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.234560511410657e-05, 'l1_Layer_2': 1.3409199485292632e-05, 'l1_Layer_3': 0.01023552564410957, 'l1_Layer_4': 9.471421388960349e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 85, 'n_units_Layer_3': 260, 'n_units_Layer_4': 275}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.06 | sMAPE for Validation Set is: 14.30% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 38.53 | sMAPE for Test Set is: 21.82% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:59:40,298]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:59:55,149]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:00:05,017]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:00:32,525]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:00:47,584]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:00:53,044]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:01:03,338]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:02:05,475]\u001b[0m Trial 741 finished with value: 9.778818202134175 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009572544840639269, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014334332562749786, 'dropout_rate_Layer_2': 0.01402934929980206, 'dropout_rate_Layer_3': 0.00603163253316261, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.7960044144305244e-05, 'l1_Layer_2': 0.00022150544731612423, 'l1_Layer_3': 2.9334581702798913e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 260, 'n_units_Layer_3': 230}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.78 | sMAPE for Validation Set is: 12.08% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 33.00 | sMAPE for Test Set is: 19.01% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:02:54,095]\u001b[0m Trial 742 finished with value: 10.729580334720225 and parameters: {'n_hidden': 4, 'learning_rate': 0.020552009547688023, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09198409417542168, 'dropout_rate_Layer_2': 0.1633886351029021, 'dropout_rate_Layer_3': 0.3660095486664894, 'dropout_rate_Layer_4': 0.28018449897697123, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.046188538193357e-05, 'l1_Layer_2': 0.0018199709542926347, 'l1_Layer_3': 0.0021883802660874903, 'l1_Layer_4': 4.8009765353976464e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 70, 'n_units_Layer_3': 280, 'n_units_Layer_4': 160}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.73 | sMAPE for Validation Set is: 13.61% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 38.25 | sMAPE for Test Set is: 21.64% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:03:00,639]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:03:20,545]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:03:32,891]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:03:45,450]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:03:53,007]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:03:59,760]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:04:05,034]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:04:18,271]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:04:27,983]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:04:34,906]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:04:40,625]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:04:59,488]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:05:04,919]\u001b[0m Trial 737 finished with value: 10.175123414575943 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015461287320805172, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16125691618467522, 'dropout_rate_Layer_2': 0.33852399632089847, 'dropout_rate_Layer_3': 0.31279480589103237, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003632042273673562, 'l1_Layer_2': 1.73747636398712e-05, 'l1_Layer_3': 0.0005952513687382525, 'n_units_Layer_1': 60, 'n_units_Layer_2': 75, 'n_units_Layer_3': 110}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.18 | sMAPE for Validation Set is: 13.23% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 33.54 | sMAPE for Test Set is: 19.33% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:06:14,788]\u001b[0m Trial 756 finished with value: 9.627349754072435 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009727516886259325, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009510859109991155, 'dropout_rate_Layer_2': 0.000965679663112437, 'dropout_rate_Layer_3': 0.024937920491478006, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.9773532770094705e-05, 'l1_Layer_2': 0.0004149148395881899, 'l1_Layer_3': 3.9703436294112576e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 265, 'n_units_Layer_3': 230}. Best is trial 636 with value: 9.61329101938997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.63 | sMAPE for Validation Set is: 11.92% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 32.30 | sMAPE for Test Set is: 18.78% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:06:55,284]\u001b[0m Trial 755 finished with value: 9.569334946495639 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009587233333850378, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012006725432507163, 'dropout_rate_Layer_2': 0.0004905763785506374, 'dropout_rate_Layer_3': 0.02316418635862494, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011784531186254104, 'l1_Layer_2': 0.00041320463290157357, 'l1_Layer_3': 3.8171826857094964e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 265, 'n_units_Layer_3': 205}. Best is trial 755 with value: 9.569334946495639.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.57 | sMAPE for Validation Set is: 11.85% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 32.35 | sMAPE for Test Set is: 18.55% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:07:00,330]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:07:07,976]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:07:42,670]\u001b[0m Trial 757 finished with value: 9.578755418166546 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009284742064423318, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013834427728080814, 'dropout_rate_Layer_2': 0.0018500911700671113, 'dropout_rate_Layer_3': 0.023974738911749977, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0026085527809999814, 'l1_Layer_2': 0.0004331310512693134, 'l1_Layer_3': 3.8122507142370984e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 265, 'n_units_Layer_3': 240}. Best is trial 755 with value: 9.569334946495639.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.58 | sMAPE for Validation Set is: 12.03% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 32.18 | sMAPE for Test Set is: 18.59% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:07:49,524]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:08:07,250]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:08:21,416]\u001b[0m Trial 760 finished with value: 10.348969933556 and parameters: {'n_hidden': 3, 'learning_rate': 0.00575155699567259, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3447886326322784, 'dropout_rate_Layer_2': 0.33005736531916374, 'dropout_rate_Layer_3': 0.15721693262291753, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.051792827407989e-05, 'l1_Layer_2': 0.000819248925117212, 'l1_Layer_3': 0.004676289512527074, 'n_units_Layer_1': 220, 'n_units_Layer_2': 170, 'n_units_Layer_3': 170}. Best is trial 755 with value: 9.569334946495639.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.35 | sMAPE for Validation Set is: 13.25% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 34.35 | sMAPE for Test Set is: 19.81% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:08:51,918]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:08:58,524]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:09:15,045]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:09:22,513]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:09:31,966]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:09:44,176]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:09:58,788]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:10:07,122]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:10:14,908]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:10:19,860]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:10:49,468]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:10:52,592]\u001b[0m Trial 764 finished with value: 9.497372093893297 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008252389896296881, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00889777789952879, 'dropout_rate_Layer_2': 0.0014101322442471032, 'dropout_rate_Layer_3': 0.024600356095718052, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0021312947037512367, 'l1_Layer_2': 0.0004400802864427817, 'l1_Layer_3': 3.76900069097264e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 270, 'n_units_Layer_3': 225}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.50 | sMAPE for Validation Set is: 11.85% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 31.93 | sMAPE for Test Set is: 18.42% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:11:14,422]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:11:19,996]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:11:25,059]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:11:35,416]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.96 | sMAPE for Validation Set is: 13.98% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 42.29 | sMAPE for Test Set is: 23.67% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:11:37,963]\u001b[0m Trial 775 finished with value: 10.957428742174331 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027724289527638443, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1259738413269876, 'dropout_rate_Layer_2': 0.14502215623797923, 'dropout_rate_Layer_3': 0.33050973715228843, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.653491038058963e-05, 'l1_Layer_2': 3.4082629806393476e-05, 'l1_Layer_3': 0.00370827043156225, 'n_units_Layer_1': 200, 'n_units_Layer_2': 105, 'n_units_Layer_3': 295}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:12:25,677]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:12:42,654]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:13:02,422]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:13:07,707]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:13:10,852]\u001b[0m Trial 781 finished with value: 9.610037820911941 and parameters: {'n_hidden': 3, 'learning_rate': 0.001406396102140512, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01549676135587589, 'dropout_rate_Layer_2': 0.012272065109155588, 'dropout_rate_Layer_3': 0.021583985723476334, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018701474311981182, 'l1_Layer_2': 0.0004750396822293754, 'l1_Layer_3': 2.292014292825279e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 175, 'n_units_Layer_3': 215}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.61 | sMAPE for Validation Set is: 12.14% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 32.17 | sMAPE for Test Set is: 18.56% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:13:18,161]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:13:32,624]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:13:42,189]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:13:47,256]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:14:07,704]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:14:12,879]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:14:17,353]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:14:22,304]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:14:29,758]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:14:34,990]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:14:35,694]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:14:41,417]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:14:46,546]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:14:55,852]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:15:00,987]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:15:05,982]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:15:22,887]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:15:30,680]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:15:37,486]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:15:46,163]\u001b[0m Trial 797 finished with value: 10.629362675206844 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018650737980385511, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12665451152317111, 'dropout_rate_Layer_2': 0.14151373886482657, 'dropout_rate_Layer_3': 0.2970204969211354, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.701798655344464e-05, 'l1_Layer_2': 0.001000422740684042, 'l1_Layer_3': 0.01147320582271706, 'n_units_Layer_1': 200, 'n_units_Layer_2': 105, 'n_units_Layer_3': 295}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.63 | sMAPE for Validation Set is: 13.24% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 35.47 | sMAPE for Test Set is: 20.48% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:16:02,482]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:16:07,915]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:16:23,320]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:16:30,448]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:16:37,374]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:16:44,697]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:16:49,945]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:17:20,185]\u001b[0m Trial 813 finished with value: 10.371714455819442 and parameters: {'n_hidden': 3, 'learning_rate': 0.005316062811053242, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3407990317531642, 'dropout_rate_Layer_2': 0.2516321717001011, 'dropout_rate_Layer_3': 0.1621234101469298, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.297487493356263e-05, 'l1_Layer_2': 0.00018479170481181632, 'l1_Layer_3': 0.001521902491255587, 'n_units_Layer_1': 200, 'n_units_Layer_2': 220, 'n_units_Layer_3': 150}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.37 | sMAPE for Validation Set is: 13.11% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 36.33 | sMAPE for Test Set is: 20.84% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:17:27,527]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:17:30,558]\u001b[0m Trial 805 finished with value: 9.497501929059375 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009349937802209284, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0050477693422701884, 'dropout_rate_Layer_2': 0.005307140739660366, 'dropout_rate_Layer_3': 0.007623129215937885, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004716049479600606, 'l1_Layer_2': 0.00030624531973466666, 'l1_Layer_3': 2.433853107583469e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 265, 'n_units_Layer_3': 200}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.50 | sMAPE for Validation Set is: 11.83% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 32.12 | sMAPE for Test Set is: 18.56% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:17:35,409]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:17:42,201]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:17:49,422]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:17:49,775]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:17:58,423]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:18:03,919]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:18:13,176]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:18:40,452]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:18:45,590]\u001b[0m Trial 823 finished with value: 10.481503705809681 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029116091255026377, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2897054172663959, 'dropout_rate_Layer_2': 0.34198575168638234, 'dropout_rate_Layer_3': 0.22860186945372243, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00034580781913525047, 'l1_Layer_2': 6.701964261210424e-05, 'l1_Layer_3': 0.0070030207173446294, 'n_units_Layer_1': 270, 'n_units_Layer_2': 170, 'n_units_Layer_3': 180}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.48 | sMAPE for Validation Set is: 13.30% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 35.45 | sMAPE for Test Set is: 20.43% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:19:24,778]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:19:29,609]\u001b[0m Trial 825 finished with value: 10.622335766209792 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018648201654527345, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1351756350614043, 'dropout_rate_Layer_2': 0.14547850430825662, 'dropout_rate_Layer_3': 0.2971798936291426, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.570812543504439e-05, 'l1_Layer_2': 0.001975301694177673, 'l1_Layer_3': 0.01091290058358209, 'n_units_Layer_1': 185, 'n_units_Layer_2': 110, 'n_units_Layer_3': 295}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.62 | sMAPE for Validation Set is: 13.52% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 35.81 | sMAPE for Test Set is: 20.75% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:19:34,303]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:19:39,776]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:19:45,018]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:20:12,134]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:20:32,429]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:20:39,884]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:20:46,529]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:21:24,116]\u001b[0m Trial 831 finished with value: 9.648189135805412 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009367805094082324, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01517083380414886, 'dropout_rate_Layer_2': 2.599912497398009e-05, 'dropout_rate_Layer_3': 0.007150173523163826, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002299186990907785, 'l1_Layer_2': 0.00021560502515231722, 'l1_Layer_3': 1.9387851490996157e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 270, 'n_units_Layer_3': 220}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.65 | sMAPE for Validation Set is: 12.06% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 32.64 | sMAPE for Test Set is: 18.81% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:21:24,463]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:21:31,127]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:21:35,998]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:21:37,647]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:21:45,200]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:21:47,979]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:22:27,541]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:22:34,712]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:22:42,957]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:22:57,125]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:23:22,534]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:23:29,035]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:23:29,418]\u001b[0m Trial 841 finished with value: 9.580659242502138 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009372324285556163, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03137713307033174, 'dropout_rate_Layer_2': 0.009892647040167117, 'dropout_rate_Layer_3': 0.01670196102271308, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0035828467318866695, 'l1_Layer_2': 0.0003610716557773459, 'l1_Layer_3': 2.4353899678409444e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 270, 'n_units_Layer_3': 225}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.58 | sMAPE for Validation Set is: 12.03% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 32.67 | sMAPE for Test Set is: 18.77% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:23:37,710]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:23:43,078]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:23:50,035]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:24:14,622]\u001b[0m Trial 848 finished with value: 10.666332695799388 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018845650717723077, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12378804136516298, 'dropout_rate_Layer_2': 0.12835816108262188, 'dropout_rate_Layer_3': 0.3192411421833702, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.693553432969743e-05, 'l1_Layer_2': 0.0008626731755153263, 'l1_Layer_3': 0.009482232351885018, 'n_units_Layer_1': 190, 'n_units_Layer_2': 100, 'n_units_Layer_3': 295}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.67 | sMAPE for Validation Set is: 13.44% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 35.81 | sMAPE for Test Set is: 20.74% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:24:24,802]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:24:29,425]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:24:32,053]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:24:37,117]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:25:01,315]\u001b[0m Trial 854 finished with value: 10.461283048153811 and parameters: {'n_hidden': 3, 'learning_rate': 0.007945175465107037, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010079540912869944, 'dropout_rate_Layer_2': 0.1646220859622658, 'dropout_rate_Layer_3': 0.04684034569750212, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.017378828011111094, 'l1_Layer_2': 0.028206179086489525, 'l1_Layer_3': 0.0011515444384563895, 'n_units_Layer_1': 100, 'n_units_Layer_2': 185, 'n_units_Layer_3': 260}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.46 | sMAPE for Validation Set is: 13.20% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 34.12 | sMAPE for Test Set is: 19.71% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:25:06,961]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:25:16,483]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:25:22,150]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:25:27,285]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:25:33,908]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:25:41,901]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:25:46,614]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:25:52,053]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:25:58,925]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:26:04,521]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:26:28,567]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:26:38,727]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:26:46,151]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:26:51,012]\u001b[0m Trial 867 finished with value: 10.723701659341101 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025108319384266747, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28498187431631267, 'dropout_rate_Layer_2': 0.0672984787494847, 'dropout_rate_Layer_3': 0.27592989984328603, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.730699410041802e-05, 'l1_Layer_2': 0.0009228103434987301, 'l1_Layer_3': 0.005495760687004466, 'n_units_Layer_1': 180, 'n_units_Layer_2': 125, 'n_units_Layer_3': 285}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:26:51,166]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.72 | sMAPE for Validation Set is: 13.71% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 35.28 | sMAPE for Test Set is: 20.49% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:27:00,966]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:27:06,425]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:28:05,342]\u001b[0m Trial 874 finished with value: 10.627872705086649 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012778470547823299, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28550880149191343, 'dropout_rate_Layer_2': 0.08260254306472198, 'dropout_rate_Layer_3': 0.2949494490142538, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.017844349926384e-05, 'l1_Layer_2': 0.0009629578796465804, 'l1_Layer_3': 0.005713061322756679, 'n_units_Layer_1': 170, 'n_units_Layer_2': 135, 'n_units_Layer_3': 280}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.63 | sMAPE for Validation Set is: 13.31% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 35.16 | sMAPE for Test Set is: 20.29% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:28:22,591]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:28:27,926]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:28:33,099]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:28:37,921]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:28:47,635]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.60 | sMAPE for Validation Set is: 12.00% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 32.27 | sMAPE for Test Set is: 18.65% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:29:56,644]\u001b[0m Trial 875 finished with value: 9.603431314471935 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008500143386853991, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00470039808035232, 'dropout_rate_Layer_2': 2.048778134886901e-05, 'dropout_rate_Layer_3': 0.03287997114862801, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016780821674218852, 'l1_Layer_2': 0.00041290507786445423, 'l1_Layer_3': 4.5378312665084956e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 255, 'n_units_Layer_3': 215}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:30:07,573]\u001b[0m Trial 880 finished with value: 9.722009838724047 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010521792023811018, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03817755771148436, 'dropout_rate_Layer_2': 7.791054284202181e-05, 'dropout_rate_Layer_3': 0.007966138348483792, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0031015312791268885, 'l1_Layer_2': 0.0002415254397118516, 'l1_Layer_3': 3.335375655479431e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 270, 'n_units_Layer_3': 230}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.72 | sMAPE for Validation Set is: 12.24% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 32.61 | sMAPE for Test Set is: 18.72% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:30:14,719]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:30:22,322]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:30:36,996]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:30:41,470]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:31:09,668]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:31:13,861]\u001b[0m Trial 885 finished with value: 10.343963471409106 and parameters: {'n_hidden': 3, 'learning_rate': 0.006962156252387624, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023310142614377378, 'dropout_rate_Layer_2': 0.18105025672226593, 'dropout_rate_Layer_3': 0.050072869690519495, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06881052424032641, 'l1_Layer_2': 0.09883722916887726, 'l1_Layer_3': 0.00253498421416668, 'n_units_Layer_1': 90, 'n_units_Layer_2': 180, 'n_units_Layer_3': 255}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.34 | sMAPE for Validation Set is: 13.01% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 33.76 | sMAPE for Test Set is: 19.52% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:31:16,743]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:31:46,354]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:31:46,481]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:31:53,526]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:31:56,171]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:32:00,641]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:32:06,122]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:32:12,750]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:32:15,863]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:32:20,857]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:32:23,526]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:32:30,162]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:32:35,740]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:33:03,143]\u001b[0m Trial 901 finished with value: 10.476022776749325 and parameters: {'n_hidden': 3, 'learning_rate': 0.008279611803923973, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04518358709714364, 'dropout_rate_Layer_2': 0.2588024642010476, 'dropout_rate_Layer_3': 0.05186440793673673, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08702325294979867, 'l1_Layer_2': 0.05341163328187857, 'l1_Layer_3': 0.009178702287984336, 'n_units_Layer_1': 95, 'n_units_Layer_2': 190, 'n_units_Layer_3': 185}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.48 | sMAPE for Validation Set is: 13.03% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 34.43 | sMAPE for Test Set is: 19.70% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:33:37,689]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:33:47,157]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:34:44,259]\u001b[0m Trial 898 finished with value: 9.645895824849717 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013425642147566997, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1420506166580109, 'dropout_rate_Layer_2': 0.3259374421252633, 'dropout_rate_Layer_3': 0.22792951114068738, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009547050291781775, 'l1_Layer_2': 3.596359090914482e-05, 'l1_Layer_3': 0.0007915750371874165, 'n_units_Layer_1': 190, 'n_units_Layer_2': 135, 'n_units_Layer_3': 60}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.65 | sMAPE for Validation Set is: 12.25% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 32.56 | sMAPE for Test Set is: 18.75% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:34:58,942]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:35:04,977]\u001b[0m Trial 904 finished with value: 9.645017452062397 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010646586159479814, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01643682861457175, 'dropout_rate_Layer_2': 0.018961629974172774, 'dropout_rate_Layer_3': 0.014039713449081824, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00431879848525062, 'l1_Layer_2': 0.00024182005914476462, 'l1_Layer_3': 2.6058287773490137e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 255, 'n_units_Layer_3': 210}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.65 | sMAPE for Validation Set is: 12.12% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 32.43 | sMAPE for Test Set is: 18.63% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:35:16,958]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:35:31,642]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:35:48,525]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:35:56,244]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:36:05,693]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:37:16,970]\u001b[0m Trial 909 finished with value: 9.497741617144152 and parameters: {'n_hidden': 3, 'learning_rate': 0.001104106082081001, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01452982119542162, 'dropout_rate_Layer_2': 0.019035356240665182, 'dropout_rate_Layer_3': 0.00017435809783233544, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0043527878918509875, 'l1_Layer_2': 0.00023690996379039996, 'l1_Layer_3': 1.969597116438031e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 255, 'n_units_Layer_3': 210}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.50 | sMAPE for Validation Set is: 11.91% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 32.06 | sMAPE for Test Set is: 18.52% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:37:25,313]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:37:31,940]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:37:36,901]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:38:17,313]\u001b[0m Trial 913 finished with value: 10.629792248798703 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019812687654821343, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2672551680001453, 'dropout_rate_Layer_2': 0.08372683248094286, 'dropout_rate_Layer_3': 0.28041574773169564, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.287371315890506e-05, 'l1_Layer_2': 0.0018889798075433493, 'l1_Layer_3': 0.008897713239564824, 'n_units_Layer_1': 160, 'n_units_Layer_2': 145, 'n_units_Layer_3': 285}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.63 | sMAPE for Validation Set is: 13.39% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 35.25 | sMAPE for Test Set is: 20.34% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:39:01,197]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:39:13,678]\u001b[0m Trial 916 finished with value: 9.617723903682645 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010237870655621316, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007098311174505649, 'dropout_rate_Layer_2': 0.00990252664532725, 'dropout_rate_Layer_3': 0.00484547222756882, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007401021748197249, 'l1_Layer_2': 0.00043236047594578215, 'l1_Layer_3': 1.3730894160858382e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 250, 'n_units_Layer_3': 205}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.62 | sMAPE for Validation Set is: 12.03% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 32.70 | sMAPE for Test Set is: 18.82% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:39:21,908]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:39:45,446]\u001b[0m Trial 918 finished with value: 10.327745357270127 and parameters: {'n_hidden': 3, 'learning_rate': 0.008330548308310676, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0334217471097758, 'dropout_rate_Layer_2': 0.2961692323961524, 'dropout_rate_Layer_3': 0.08188368775086062, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.050069145495542006, 'l1_Layer_2': 0.08236534505006315, 'l1_Layer_3': 0.0016652334047284447, 'n_units_Layer_1': 280, 'n_units_Layer_2': 185, 'n_units_Layer_3': 230}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.33 | sMAPE for Validation Set is: 12.95% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 33.03 | sMAPE for Test Set is: 19.18% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:39:56,498]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:40:01,271]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:40:11,223]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:41:27,387]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:41:32,916]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:42:24,789]\u001b[0m Trial 924 finished with value: 9.899245448414396 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006690921147691192, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12732053229914064, 'dropout_rate_Layer_2': 0.2748238464511688, 'dropout_rate_Layer_3': 0.232125971908191, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00040123260893739374, 'l1_Layer_2': 2.5501106647453972e-05, 'l1_Layer_3': 0.00036278174861550613, 'n_units_Layer_1': 210, 'n_units_Layer_2': 165, 'n_units_Layer_3': 60}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.90 | sMAPE for Validation Set is: 12.50% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 33.54 | sMAPE for Test Set is: 19.13% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:42:31,749]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:42:59,591]\u001b[0m Trial 926 finished with value: 9.700881266496259 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022650023211206903, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11974371340181844, 'dropout_rate_Layer_2': 0.363357118674358, 'dropout_rate_Layer_3': 0.13034665834379883, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011019026727742615, 'l1_Layer_2': 2.2678872613414648e-05, 'l1_Layer_3': 0.0006271351003174537, 'n_units_Layer_1': 180, 'n_units_Layer_2': 155, 'n_units_Layer_3': 115}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.70 | sMAPE for Validation Set is: 12.41% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 32.84 | sMAPE for Test Set is: 18.85% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:43:06,601]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:43:11,678]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:43:18,573]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:43:28,750]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:43:46,182]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:43:53,879]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:43:56,077]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:44:02,828]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:44:35,972]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:44:42,935]\u001b[0m Trial 935 finished with value: 10.16349836283778 and parameters: {'n_hidden': 3, 'learning_rate': 0.00724850333170914, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2741498412631849, 'dropout_rate_Layer_2': 0.3588358575280178, 'dropout_rate_Layer_3': 0.15006648842469633, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1315574375766653e-05, 'l1_Layer_2': 0.0007601298856584752, 'l1_Layer_3': 0.0023926225374371834, 'n_units_Layer_1': 220, 'n_units_Layer_2': 165, 'n_units_Layer_3': 130}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.16 | sMAPE for Validation Set is: 12.83% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 34.45 | sMAPE for Test Set is: 20.26% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:44:47,734]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:44:53,488]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:44:58,267]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:45:05,104]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:45:05,999]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:45:11,049]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:45:35,836]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:45:43,818]\u001b[0m Trial 945 finished with value: 10.711805459311998 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016529360713495188, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27793926677303904, 'dropout_rate_Layer_2': 0.05871375071802048, 'dropout_rate_Layer_3': 0.28096712284365166, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.8046044052500267e-05, 'l1_Layer_2': 0.000487393752904192, 'l1_Layer_3': 0.0060511137965969155, 'n_units_Layer_1': 175, 'n_units_Layer_2': 125, 'n_units_Layer_3': 290}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.71 | sMAPE for Validation Set is: 13.56% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 35.41 | sMAPE for Test Set is: 20.42% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:45:48,531]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:45:49,075]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:45:57,343]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:46:10,009]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:46:15,294]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:46:37,385]\u001b[0m Trial 952 finished with value: 28.945690888461673 and parameters: {'n_hidden': 3, 'learning_rate': 0.041341895950293306, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27146000124237446, 'dropout_rate_Layer_2': 0.3652148348273785, 'dropout_rate_Layer_3': 0.21792975918052526, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.230601237345573e-05, 'l1_Layer_2': 0.0015788760094669748, 'l1_Layer_3': 0.002158192352190526, 'n_units_Layer_1': 185, 'n_units_Layer_2': 115, 'n_units_Layer_3': 120}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.95 | sMAPE for Validation Set is: 35.78% | rMAE for Validation Set is: 1.71\n",
      "MAE for Test Set is: 161.91 | sMAPE for Test Set is: 108.90% | rMAE for Test Set is: 2.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:46:42,390]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:46:49,356]\u001b[0m Trial 948 finished with value: 10.574693066119261 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015473376899592824, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2862985509061269, 'dropout_rate_Layer_2': 0.06880142652806545, 'dropout_rate_Layer_3': 0.2546958983750491, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.011587218994711e-05, 'l1_Layer_2': 0.0005281893072803506, 'l1_Layer_3': 0.00590409058480845, 'n_units_Layer_1': 175, 'n_units_Layer_2': 140, 'n_units_Layer_3': 295}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.57 | sMAPE for Validation Set is: 13.17% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 34.89 | sMAPE for Test Set is: 20.13% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:47:12,063]\u001b[0m Trial 954 finished with value: 10.685166120848843 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024254256506483487, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25233078924699753, 'dropout_rate_Layer_2': 0.06482610489724712, 'dropout_rate_Layer_3': 0.25312906143696107, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.9396015746406523e-05, 'l1_Layer_2': 0.0005052518509498169, 'l1_Layer_3': 0.006008010981063432, 'n_units_Layer_1': 175, 'n_units_Layer_2': 125, 'n_units_Layer_3': 295}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.69 | sMAPE for Validation Set is: 13.35% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 35.58 | sMAPE for Test Set is: 20.57% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:47:31,397]\u001b[0m Trial 955 finished with value: 9.923305780048478 and parameters: {'n_hidden': 3, 'learning_rate': 0.001295647916232624, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015235329805091121, 'dropout_rate_Layer_2': 0.013917829324917613, 'dropout_rate_Layer_3': 0.009139810503738677, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007406461344683518, 'l1_Layer_2': 0.0002039052062781033, 'l1_Layer_3': 2.3076988872893988e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 260, 'n_units_Layer_3': 220}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.92 | sMAPE for Validation Set is: 12.46% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 33.65 | sMAPE for Test Set is: 19.30% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:47:46,579]\u001b[0m Trial 957 finished with value: 26.715873679288944 and parameters: {'n_hidden': 3, 'learning_rate': 0.013560176938191051, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3967384629735433, 'dropout_rate_Layer_2': 0.3136545674931816, 'dropout_rate_Layer_3': 0.07598459257442734, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.78441764009019e-05, 'l1_Layer_2': 0.01816785579696008, 'l1_Layer_3': 0.0010596525734134041, 'n_units_Layer_1': 300, 'n_units_Layer_2': 225, 'n_units_Layer_3': 90}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.72 | sMAPE for Validation Set is: 32.44% | rMAE for Validation Set is: 1.58\n",
      "MAE for Test Set is: 153.51 | sMAPE for Test Set is: 98.94% | rMAE for Test Set is: 2.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:47:53,653]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:48:04,121]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:48:11,621]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:48:36,413]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:48:36,594]\u001b[0m Trial 956 finished with value: 9.654586345328077 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013716581411573488, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014256481804260403, 'dropout_rate_Layer_2': 0.013622954438298664, 'dropout_rate_Layer_3': 0.04879803990673813, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005687849846886872, 'l1_Layer_2': 0.000207102801495602, 'l1_Layer_3': 2.2578033870783988e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 260, 'n_units_Layer_3': 220}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.65 | sMAPE for Validation Set is: 12.04% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 33.37 | sMAPE for Test Set is: 18.91% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:48:48,276]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:48:55,286]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:49:01,035]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:49:07,696]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:49:14,864]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:49:23,271]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:49:52,085]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:50:00,111]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:50:05,005]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:50:11,379]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:50:16,596]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:50:23,390]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:50:31,106]\u001b[0m Trial 962 finished with value: 9.576544081503231 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015053217395315966, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006541481124676795, 'dropout_rate_Layer_2': 0.007177505406268535, 'dropout_rate_Layer_3': 0.04245322329036949, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004333391845014524, 'l1_Layer_2': 0.000254453874136185, 'l1_Layer_3': 1.973937888657653e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 275, 'n_units_Layer_3': 240}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.58 | sMAPE for Validation Set is: 12.10% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 32.06 | sMAPE for Test Set is: 18.55% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:50:36,941]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:50:46,519]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:51:06,399]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:51:13,581]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:51:18,521]\u001b[0m Trial 975 finished with value: 20.986974311141328 and parameters: {'n_hidden': 3, 'learning_rate': 0.0073651121943991635, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15182909952870546, 'dropout_rate_Layer_2': 0.2730484017638156, 'dropout_rate_Layer_3': 0.2868977281208281, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008634502772619588, 'l1_Layer_2': 0.006632725807210414, 'l1_Layer_3': 0.007636428790451467, 'n_units_Layer_1': 215, 'n_units_Layer_2': 160, 'n_units_Layer_3': 140}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.99 | sMAPE for Validation Set is: 23.88% | rMAE for Validation Set is: 1.24\n",
      "MAE for Test Set is: 140.50 | sMAPE for Test Set is: 85.19% | rMAE for Test Set is: 2.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:51:23,333]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:51:28,335]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:51:35,333]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:51:45,777]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:51:50,588]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:51:55,891]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:52:02,538]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:52:08,466]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:52:15,549]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:52:20,562]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:52:42,299]\u001b[0m Trial 985 finished with value: 10.533194271252809 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022946877387525536, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25697339342436176, 'dropout_rate_Layer_2': 0.08475606639541756, 'dropout_rate_Layer_3': 0.27827899306500886, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014646693410086016, 'l1_Layer_2': 0.0009896750540434136, 'l1_Layer_3': 0.0060464330004625045, 'n_units_Layer_1': 170, 'n_units_Layer_2': 125, 'n_units_Layer_3': 295}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.53 | sMAPE for Validation Set is: 13.23% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 34.59 | sMAPE for Test Set is: 20.07% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:53:20,271]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:53:30,721]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:53:40,104]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:53:50,151]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:53:55,568]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:54:03,120]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:54:22,799]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:55:04,516]\u001b[0m Trial 999 finished with value: 10.339644117790451 and parameters: {'n_hidden': 3, 'learning_rate': 0.006805646519933725, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36638695137483934, 'dropout_rate_Layer_2': 0.34918813347511, 'dropout_rate_Layer_3': 0.16678717835080561, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.965605458521139e-05, 'l1_Layer_2': 0.0006817198136682246, 'l1_Layer_3': 0.0021075046249622886, 'n_units_Layer_1': 215, 'n_units_Layer_2': 180, 'n_units_Layer_3': 165}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.34 | sMAPE for Validation Set is: 13.13% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 33.98 | sMAPE for Test Set is: 19.61% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:55:14,845]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:55:20,438]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:55:27,232]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:55:42,558]\u001b[0m Trial 991 finished with value: 9.711939667074818 and parameters: {'n_hidden': 3, 'learning_rate': 0.002562269546574605, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1186489876985924, 'dropout_rate_Layer_2': 0.34373705828875956, 'dropout_rate_Layer_3': 0.16202657552973426, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002848085027217108, 'l1_Layer_2': 2.7839100699213263e-05, 'l1_Layer_3': 0.00016443746512149413, 'n_units_Layer_1': 175, 'n_units_Layer_2': 300, 'n_units_Layer_3': 115}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.71 | sMAPE for Validation Set is: 12.27% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 32.94 | sMAPE for Test Set is: 18.95% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:55:49,663]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:55:59,911]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:56:33,914]\u001b[0m Trial 1006 finished with value: 10.536363680589135 and parameters: {'n_hidden': 3, 'learning_rate': 0.004983302998705796, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05583441414529398, 'dropout_rate_Layer_2': 0.2952889936087819, 'dropout_rate_Layer_3': 0.06685218306705679, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.920114604572533e-05, 'l1_Layer_2': 0.08276562814451023, 'l1_Layer_3': 0.00012182789489063475, 'n_units_Layer_1': 90, 'n_units_Layer_2': 225, 'n_units_Layer_3': 275}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.54 | sMAPE for Validation Set is: 13.19% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 35.08 | sMAPE for Test Set is: 20.19% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:57:01,587]\u001b[0m Trial 1007 finished with value: 10.333376580376866 and parameters: {'n_hidden': 3, 'learning_rate': 0.008019620007622264, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3575190615495914, 'dropout_rate_Layer_2': 0.3553041228958885, 'dropout_rate_Layer_3': 0.12258246385153837, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.902432391199469e-05, 'l1_Layer_2': 0.0005010756329195996, 'l1_Layer_3': 0.002077381931952612, 'n_units_Layer_1': 245, 'n_units_Layer_2': 200, 'n_units_Layer_3': 185}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.33 | sMAPE for Validation Set is: 13.02% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 34.36 | sMAPE for Test Set is: 20.29% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:57:08,238]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:58:47,874]\u001b[0m Trial 1009 finished with value: 9.836046878416889 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024802996581574314, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15687475718126015, 'dropout_rate_Layer_2': 0.343925533244111, 'dropout_rate_Layer_3': 0.15930359031781252, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00029742594690307107, 'l1_Layer_2': 2.5844831260236963e-05, 'l1_Layer_3': 0.012022678395667234, 'n_units_Layer_1': 170, 'n_units_Layer_2': 290, 'n_units_Layer_3': 115}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.84 | sMAPE for Validation Set is: 12.44% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 33.06 | sMAPE for Test Set is: 19.11% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:58:48,792]\u001b[0m Trial 1003 finished with value: 9.810858216312345 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024979872628415655, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12041564689152043, 'dropout_rate_Layer_2': 0.34838471540231547, 'dropout_rate_Layer_3': 0.15223416355908637, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.647658244016075e-05, 'l1_Layer_2': 2.4394770195629988e-05, 'l1_Layer_3': 0.00014646874926616134, 'n_units_Layer_1': 175, 'n_units_Layer_2': 170, 'n_units_Layer_3': 120}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.81 | sMAPE for Validation Set is: 12.45% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 33.08 | sMAPE for Test Set is: 19.03% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:59:01,424]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:59:25,808]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:59:28,110]\u001b[0m Trial 1012 finished with value: 10.848514914042013 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035673938072730864, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3058943474646402, 'dropout_rate_Layer_2': 0.04931635038261001, 'dropout_rate_Layer_3': 0.23943062333337353, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.767777059622355e-05, 'l1_Layer_2': 0.0004924754272530894, 'l1_Layer_3': 0.004383485496197453, 'n_units_Layer_1': 185, 'n_units_Layer_2': 125, 'n_units_Layer_3': 290}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.85 | sMAPE for Validation Set is: 13.76% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 36.02 | sMAPE for Test Set is: 20.80% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:59:35,406]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:59:40,181]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:59:55,989]\u001b[0m Trial 1013 finished with value: 10.309049219090625 and parameters: {'n_hidden': 3, 'learning_rate': 0.01985953349755768, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23077099543266538, 'dropout_rate_Layer_2': 0.36930911623862483, 'dropout_rate_Layer_3': 0.12441638481001219, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.911869824431471e-05, 'l1_Layer_2': 0.0003757841739576358, 'l1_Layer_3': 0.009250366361902816, 'n_units_Layer_1': 245, 'n_units_Layer_2': 195, 'n_units_Layer_3': 185}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.31 | sMAPE for Validation Set is: 13.01% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 34.71 | sMAPE for Test Set is: 20.00% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:00:03,440]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:00:26,497]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:00:31,503]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:00:36,224]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:00:41,460]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:00:46,775]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:00:53,525]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:00:58,510]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:01:16,761]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:01:21,319]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:01:28,359]\u001b[0m Trial 1018 finished with value: 9.917936477625615 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036743567292225527, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15575559463725275, 'dropout_rate_Layer_2': 0.34549045369887543, 'dropout_rate_Layer_3': 0.15277854881028988, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.479835731286487e-05, 'l1_Layer_2': 1.2223079653260622e-05, 'l1_Layer_3': 0.009554618100728825, 'n_units_Layer_1': 180, 'n_units_Layer_2': 295, 'n_units_Layer_3': 145}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.92 | sMAPE for Validation Set is: 12.56% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 33.31 | sMAPE for Test Set is: 19.10% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:01:38,335]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:01:54,812]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:02:15,274]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:02:15,546]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:02:43,119]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:03:05,731]\u001b[0m Trial 1031 finished with value: 10.6833808726039 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022480829879110028, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2620418938642773, 'dropout_rate_Layer_2': 0.059982704893746484, 'dropout_rate_Layer_3': 0.23578826882746803, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.734794890802117e-05, 'l1_Layer_2': 0.002003648123350991, 'l1_Layer_3': 0.006261767797621507, 'n_units_Layer_1': 150, 'n_units_Layer_2': 130, 'n_units_Layer_3': 290}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.68 | sMAPE for Validation Set is: 13.44% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 34.95 | sMAPE for Test Set is: 20.25% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:03:12,983]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:03:19,919]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:04:00,192]\u001b[0m Trial 1033 finished with value: 10.525644423628654 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008915910456284615, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2634978701005057, 'dropout_rate_Layer_2': 0.059080172310044796, 'dropout_rate_Layer_3': 0.26706044996394784, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.641006579037178e-05, 'l1_Layer_2': 0.00027022419680999615, 'l1_Layer_3': 0.005907414633235641, 'n_units_Layer_1': 155, 'n_units_Layer_2': 115, 'n_units_Layer_3': 290}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.53 | sMAPE for Validation Set is: 13.27% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 34.41 | sMAPE for Test Set is: 19.94% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:04:07,305]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:04:25,070]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:04:31,869]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:04:52,060]\u001b[0m Trial 1036 finished with value: 9.555935701702339 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009461127455237798, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006597805413156821, 'dropout_rate_Layer_2': 0.03135051196861669, 'dropout_rate_Layer_3': 0.03509151838309987, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009165591941828835, 'l1_Layer_2': 0.00018507644017605877, 'l1_Layer_3': 4.323140150131809e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 255, 'n_units_Layer_3': 210}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.56 | sMAPE for Validation Set is: 11.87% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 32.09 | sMAPE for Test Set is: 18.54% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:05:16,319]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:05:21,903]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:05:48,905]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:05:54,091]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:06:01,646]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:06:11,586]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:06:24,416]\u001b[0m Trial 1047 finished with value: 11.302640582320857 and parameters: {'n_hidden': 3, 'learning_rate': 0.02305380752986316, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22351583380851664, 'dropout_rate_Layer_2': 0.3105123940176913, 'dropout_rate_Layer_3': 0.13602479485189417, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.795352006557826e-05, 'l1_Layer_2': 0.00019206459032414618, 'l1_Layer_3': 0.04502518321360525, 'n_units_Layer_1': 280, 'n_units_Layer_2': 130, 'n_units_Layer_3': 130}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.30 | sMAPE for Validation Set is: 14.18% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 37.55 | sMAPE for Test Set is: 21.07% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:06:31,399]\u001b[0m Trial 1043 finished with value: 10.537914725451053 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007267326126102001, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28751178581274855, 'dropout_rate_Layer_2': 0.10087752177126483, 'dropout_rate_Layer_3': 0.23048809934444517, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001034495720078373, 'l1_Layer_2': 0.0002624140563300924, 'l1_Layer_3': 0.005813290410594921, 'n_units_Layer_1': 165, 'n_units_Layer_2': 120, 'n_units_Layer_3': 270}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.54 | sMAPE for Validation Set is: 13.36% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 34.46 | sMAPE for Test Set is: 19.96% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:06:34,201]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:06:39,351]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:06:54,175]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:07:01,390]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:07:10,698]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:07:15,766]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:07:21,414]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:07:51,119]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:07:58,207]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:08:03,803]\u001b[0m Trial 1051 finished with value: 10.502316979429576 and parameters: {'n_hidden': 3, 'learning_rate': 0.000713578090789028, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.244978503947939, 'dropout_rate_Layer_2': 0.08566570080416301, 'dropout_rate_Layer_3': 0.22917319431536973, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00027742041823728265, 'l1_Layer_2': 0.0006360648828070459, 'l1_Layer_3': 0.009063942975164002, 'n_units_Layer_1': 165, 'n_units_Layer_2': 115, 'n_units_Layer_3': 295}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.50 | sMAPE for Validation Set is: 13.18% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 34.37 | sMAPE for Test Set is: 19.94% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:08:09,059]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:08:13,576]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:08:20,568]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:08:28,018]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:08:31,474]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:08:36,331]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:08:40,735]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:08:45,982]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:08:53,202]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:08:58,480]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:09:07,970]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:09:11,527]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:09:16,664]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:09:26,003]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:09:28,429]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:09:34,072]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:09:42,948]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:09:48,837]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:09:55,316]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:09:58,071]\u001b[0m Trial 1073 finished with value: 10.104857192217084 and parameters: {'n_hidden': 3, 'learning_rate': 0.00766199601890433, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03766391698476289, 'dropout_rate_Layer_2': 0.27039109534079814, 'dropout_rate_Layer_3': 0.06113154908894729, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07241285948014975, 'l1_Layer_2': 0.07872870094050324, 'l1_Layer_3': 2.4381034843560446e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 60, 'n_units_Layer_3': 225}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.10 | sMAPE for Validation Set is: 12.67% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 33.28 | sMAPE for Test Set is: 19.14% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:10:03,562]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:10:10,697]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:10:11,066]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:10:18,927]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:10:19,037]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:10:27,842]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:10:27,864]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:10:49,142]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:10:56,665]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:11:02,141]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:11:09,394]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:11:24,016]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:11:31,153]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:11:44,481]\u001b[0m Trial 1092 finished with value: 10.648788196689813 and parameters: {'n_hidden': 3, 'learning_rate': 0.006920289616833747, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.186262835030107, 'dropout_rate_Layer_2': 0.25398158112225455, 'dropout_rate_Layer_3': 0.044673140636142486, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06272655622536961, 'l1_Layer_2': 0.09981445272586387, 'l1_Layer_3': 2.6511360736148754e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 280, 'n_units_Layer_3': 190}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.65 | sMAPE for Validation Set is: 13.45% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 35.39 | sMAPE for Test Set is: 20.32% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:11:50,860]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:11:56,495]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:12:03,013]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:12:08,716]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:12:13,816]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:12:32,808]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:12:42,843]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:12:48,423]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:12:54,918]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:13:12,958]\u001b[0m Trial 1086 finished with value: 10.215751401556714 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005655031062121203, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27192055130127374, 'dropout_rate_Layer_2': 0.0900566420280267, 'dropout_rate_Layer_3': 0.253203808309108, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00043583429946460715, 'l1_Layer_2': 0.0006697539749476776, 'l1_Layer_3': 0.006107715288201387, 'n_units_Layer_1': 165, 'n_units_Layer_2': 120, 'n_units_Layer_3': 290}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.22 | sMAPE for Validation Set is: 12.86% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 33.60 | sMAPE for Test Set is: 19.43% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:13:17,886]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:13:22,939]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:13:30,006]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:13:35,374]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:13:42,216]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:13:52,117]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:13:52,775]\u001b[0m Trial 1102 finished with value: 11.557451997975399 and parameters: {'n_hidden': 3, 'learning_rate': 0.00447276680751008, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13595233733109363, 'dropout_rate_Layer_2': 0.3795412459477569, 'dropout_rate_Layer_3': 0.12714283987502684, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9207562080310806e-05, 'l1_Layer_2': 0.00555190252581442, 'l1_Layer_3': 0.054222425218024124, 'n_units_Layer_1': 140, 'n_units_Layer_2': 300, 'n_units_Layer_3': 110}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.56 | sMAPE for Validation Set is: 15.09% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 39.95 | sMAPE for Test Set is: 22.51% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:14:00,075]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:14:05,076]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:14:11,923]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:14:17,119]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:14:22,601]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:14:44,506]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:14:49,529]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:14:56,312]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:15:01,477]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:15:35,444]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:15:42,990]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:15:53,267]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:16:00,600]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:16:18,232]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:16:25,034]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:16:34,566]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:16:34,820]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:16:42,325]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:16:47,568]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:16:54,111]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:16:55,022]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:17:06,883]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:17:12,469]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:17:19,534]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:17:23,990]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:17:29,793]\u001b[0m Trial 1131 finished with value: 10.017293191977275 and parameters: {'n_hidden': 3, 'learning_rate': 0.005839123738202992, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21291618780402785, 'dropout_rate_Layer_2': 0.28991710673937443, 'dropout_rate_Layer_3': 0.25553952127661994, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.048638609553891, 'l1_Layer_2': 0.000723698414078946, 'l1_Layer_3': 2.4707984743212103e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 280, 'n_units_Layer_3': 180}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.02 | sMAPE for Validation Set is: 12.54% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 32.98 | sMAPE for Test Set is: 18.94% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:17:32,144]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:17:36,963]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:17:37,443]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:17:44,645]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:17:49,604]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:18:32,505]\u001b[0m Trial 1141 finished with value: 9.821923144907037 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010045367067411442, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006686789248656273, 'dropout_rate_Layer_2': 0.014024351264336696, 'dropout_rate_Layer_3': 0.029390676414049917, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.526226307926982e-05, 'l1_Layer_2': 0.00013998181268134246, 'l1_Layer_3': 3.7469993353453804e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 270, 'n_units_Layer_3': 210}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.82 | sMAPE for Validation Set is: 12.20% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 32.28 | sMAPE for Test Set is: 18.75% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:18:39,390]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:18:46,798]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:19:38,395]\u001b[0m Trial 1138 finished with value: 9.702662980933871 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031980573209424903, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1441153336515266, 'dropout_rate_Layer_2': 0.34579381761643596, 'dropout_rate_Layer_3': 0.1913129441450701, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000111081609389541, 'l1_Layer_2': 3.700839189202241e-05, 'l1_Layer_3': 0.0005024435807779432, 'n_units_Layer_1': 170, 'n_units_Layer_2': 285, 'n_units_Layer_3': 175}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.70 | sMAPE for Validation Set is: 12.23% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 32.61 | sMAPE for Test Set is: 18.86% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:19:44,038]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:19:49,333]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:19:54,092]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:20:09,150]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:20:13,785]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:20:16,647]\u001b[0m Trial 1144 finished with value: 9.8152256566053 and parameters: {'n_hidden': 3, 'learning_rate': 0.003010983268212464, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15174490941581678, 'dropout_rate_Layer_2': 0.3455774575057989, 'dropout_rate_Layer_3': 0.15775261258835674, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001116549820610029, 'l1_Layer_2': 3.876236356386803e-05, 'l1_Layer_3': 0.0004896512261493564, 'n_units_Layer_1': 170, 'n_units_Layer_2': 260, 'n_units_Layer_3': 180}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.82 | sMAPE for Validation Set is: 12.46% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 33.17 | sMAPE for Test Set is: 19.07% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:20:28,369]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:20:35,374]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:20:52,640]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:20:53,529]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:21:00,632]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:21:06,992]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:21:12,714]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:21:31,779]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:21:47,953]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:21:49,465]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:21:57,589]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:21:57,908]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:22:03,186]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:22:08,300]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:22:12,571]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:22:15,723]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:22:22,297]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:22:24,946]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:22:29,945]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:22:30,611]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:22:37,218]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:22:41,750]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:22:44,371]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:22:49,515]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:22:56,490]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:23:02,075]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:23:06,716]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:23:14,165]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:23:21,882]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:23:34,511]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:23:41,641]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:23:46,992]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:23:53,709]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:23:59,398]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:24:08,730]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:24:14,379]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:24:33,614]\u001b[0m Trial 1180 finished with value: 9.950797593873306 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035560874572783045, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1595785105826932, 'dropout_rate_Layer_2': 0.3489511542419113, 'dropout_rate_Layer_3': 0.179548851450888, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.484032030669891e-05, 'l1_Layer_2': 5.4693086333208025e-05, 'l1_Layer_3': 0.00022126393001454937, 'n_units_Layer_1': 165, 'n_units_Layer_2': 285, 'n_units_Layer_3': 225}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.95 | sMAPE for Validation Set is: 12.56% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 33.60 | sMAPE for Test Set is: 19.31% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:24:40,772]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:25:10,918]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:25:20,672]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:25:56,253]\u001b[0m Trial 1191 finished with value: 10.085011012674045 and parameters: {'n_hidden': 3, 'learning_rate': 0.004824638085041906, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012820676046114898, 'dropout_rate_Layer_2': 0.24560646403582811, 'dropout_rate_Layer_3': 0.05702593848930601, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07040184544086316, 'l1_Layer_2': 0.015968734873973354, 'l1_Layer_3': 4.214240779939494e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 290, 'n_units_Layer_3': 245}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.09 | sMAPE for Validation Set is: 12.66% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 33.30 | sMAPE for Test Set is: 19.16% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:26:15,300]\u001b[0m Trial 1190 finished with value: 9.697674198417024 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008871157941267642, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019280007311967752, 'dropout_rate_Layer_2': 0.03491462495547181, 'dropout_rate_Layer_3': 0.007146124379621376, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.8612788102241554e-05, 'l1_Layer_2': 0.00016525177834600095, 'l1_Layer_3': 1.2369779625201468e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 260, 'n_units_Layer_3': 205}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.70 | sMAPE for Validation Set is: 12.07% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 32.04 | sMAPE for Test Set is: 18.62% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:26:16,149]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:26:22,770]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:26:23,442]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:26:29,349]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:26:34,703]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:26:41,222]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:26:41,726]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:26:48,556]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:26:50,698]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:26:58,472]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:27:15,730]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:27:20,390]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:27:37,236]\u001b[0m Trial 1201 finished with value: 10.045733557537728 and parameters: {'n_hidden': 3, 'learning_rate': 0.005216050386007696, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.032933697220227924, 'dropout_rate_Layer_2': 0.32196817273935574, 'dropout_rate_Layer_3': 0.054950976635681784, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0609412613499577, 'l1_Layer_2': 0.07741153957158226, 'l1_Layer_3': 3.463470935184758e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 280, 'n_units_Layer_3': 230}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.05 | sMAPE for Validation Set is: 12.55% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 33.65 | sMAPE for Test Set is: 19.27% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:28:01,900]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:28:20,026]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:28:32,151]\u001b[0m Trial 1206 finished with value: 10.618360051522709 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006449562984867847, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3151833324352675, 'dropout_rate_Layer_2': 0.0705481076234273, 'dropout_rate_Layer_3': 0.27405588817986715, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.833027040350132e-05, 'l1_Layer_2': 0.0010337313042576306, 'l1_Layer_3': 0.007933061519901507, 'n_units_Layer_1': 165, 'n_units_Layer_2': 120, 'n_units_Layer_3': 280}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.62 | sMAPE for Validation Set is: 13.31% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 35.32 | sMAPE for Test Set is: 20.46% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:28:36,664]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:28:42,473]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:29:26,580]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:29:31,342]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:29:37,035]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:29:43,613]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:29:53,384]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:30:01,547]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:30:06,309]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:30:13,568]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:30:19,267]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:30:26,146]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:30:32,911]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:30:37,930]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:30:48,750]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:30:53,477]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:30:57,813]\u001b[0m Trial 1214 finished with value: 10.600678432880168 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006640555142383377, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31450562581610636, 'dropout_rate_Layer_2': 0.03985795246457235, 'dropout_rate_Layer_3': 0.22758796780095442, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.834752538230144e-05, 'l1_Layer_2': 0.0005634746919797193, 'l1_Layer_3': 0.0074288118806054935, 'n_units_Layer_1': 165, 'n_units_Layer_2': 120, 'n_units_Layer_3': 280}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.60 | sMAPE for Validation Set is: 13.40% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 34.90 | sMAPE for Test Set is: 20.23% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:30:58,256]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:31:07,992]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:31:13,314]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:31:20,207]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:31:35,616]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:31:42,239]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:31:47,600]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:31:47,623]\u001b[0m Trial 1226 finished with value: 30.526033597329917 and parameters: {'n_hidden': 3, 'learning_rate': 0.002293399258313531, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11653984369425796, 'dropout_rate_Layer_2': 0.33269909237292894, 'dropout_rate_Layer_3': 0.19733751575320418, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8751177736046083e-05, 'l1_Layer_2': 3.7593946288745494e-05, 'l1_Layer_3': 0.0006203116206144644, 'n_units_Layer_1': 185, 'n_units_Layer_2': 295, 'n_units_Layer_3': 165}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.53 | sMAPE for Validation Set is: 38.42% | rMAE for Validation Set is: 1.81\n",
      "MAE for Test Set is: 163.36 | sMAPE for Test Set is: 110.46% | rMAE for Test Set is: 2.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:31:56,393]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:32:36,339]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:32:48,019]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:32:53,789]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:32:58,594]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:33:05,634]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:33:10,203]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:33:20,016]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:33:35,686]\u001b[0m Trial 1233 finished with value: 10.558139837636185 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006871892948086078, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3301607201010859, 'dropout_rate_Layer_2': 0.039882452107963165, 'dropout_rate_Layer_3': 0.2127397053144437, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.806102939523096e-05, 'l1_Layer_2': 0.001273848007132657, 'l1_Layer_3': 0.011870362935368353, 'n_units_Layer_1': 165, 'n_units_Layer_2': 120, 'n_units_Layer_3': 270}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.56 | sMAPE for Validation Set is: 13.24% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 34.70 | sMAPE for Test Set is: 20.10% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:34:02,122]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:34:07,613]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:34:10,404]\u001b[0m Trial 1243 finished with value: 10.822532405453687 and parameters: {'n_hidden': 3, 'learning_rate': 0.051601372509903, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32036632395919423, 'dropout_rate_Layer_2': 0.3771423745287951, 'dropout_rate_Layer_3': 0.10714258802647321, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1110296188981587e-05, 'l1_Layer_2': 0.0018641602222641042, 'l1_Layer_3': 0.010574940793016485, 'n_units_Layer_1': 260, 'n_units_Layer_2': 160, 'n_units_Layer_3': 100}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.82 | sMAPE for Validation Set is: 14.01% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 38.82 | sMAPE for Test Set is: 22.01% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:34:20,279]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:34:25,344]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:34:32,505]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:34:39,660]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:34:46,689]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:34:52,693]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:34:59,360]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:35:06,520]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:35:12,233]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:35:44,353]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:35:50,968]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:36:03,935]\u001b[0m Trial 1247 finished with value: 10.534940693889029 and parameters: {'n_hidden': 3, 'learning_rate': 0.000641718646598035, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32279767399134696, 'dropout_rate_Layer_2': 0.03411262142980933, 'dropout_rate_Layer_3': 0.2146628085441518, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.0071134621887444e-05, 'l1_Layer_2': 0.0012554061239792797, 'l1_Layer_3': 0.01131210113552206, 'n_units_Layer_1': 165, 'n_units_Layer_2': 115, 'n_units_Layer_3': 280}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.53 | sMAPE for Validation Set is: 13.17% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 34.78 | sMAPE for Test Set is: 20.09% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:36:09,281]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:36:23,558]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:36:29,031]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:36:36,055]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:36:45,546]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:36:51,254]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:36:58,920]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:37:05,518]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:37:10,731]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:37:18,266]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:37:25,857]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:37:40,636]\u001b[0m Trial 1257 finished with value: 9.688469444599898 and parameters: {'n_hidden': 3, 'learning_rate': 0.000815912023150394, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015734797113062277, 'dropout_rate_Layer_2': 0.018337500102087945, 'dropout_rate_Layer_3': 0.0001237359226825066, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011450280986300462, 'l1_Layer_2': 0.0002468247901950388, 'l1_Layer_3': 2.1350585595423603e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 250, 'n_units_Layer_3': 235}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.69 | sMAPE for Validation Set is: 12.15% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 32.49 | sMAPE for Test Set is: 18.74% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:37:50,684]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:38:05,578]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:38:11,046]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:38:17,915]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:38:24,927]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:38:32,450]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:38:57,434]\u001b[0m Trial 1269 finished with value: 9.70418266952593 and parameters: {'n_hidden': 3, 'learning_rate': 0.000998948130292098, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 9.689924060439503e-05, 'dropout_rate_Layer_2': 0.01640162984462433, 'dropout_rate_Layer_3': 0.020527429157542795, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.7597287657290488e-05, 'l1_Layer_2': 0.000189582209475917, 'l1_Layer_3': 2.5917756138204515e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 260, 'n_units_Layer_3': 200}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.70 | sMAPE for Validation Set is: 11.97% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 32.61 | sMAPE for Test Set is: 18.91% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:39:19,033]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:39:24,389]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:39:58,547]\u001b[0m Trial 1277 finished with value: 10.588612365704895 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009777369646279052, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31799817287016074, 'dropout_rate_Layer_2': 0.017435271056981838, 'dropout_rate_Layer_3': 0.22578859147449354, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015759462479278643, 'l1_Layer_2': 0.0007272867003238592, 'l1_Layer_3': 0.01552642327839216, 'n_units_Layer_1': 165, 'n_units_Layer_2': 105, 'n_units_Layer_3': 270}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.59 | sMAPE for Validation Set is: 13.24% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 34.90 | sMAPE for Test Set is: 20.22% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:40:53,912]\u001b[0m Trial 1279 finished with value: 9.709017706459017 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005636197755592635, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0065919511889700085, 'dropout_rate_Layer_2': 0.023912447848670658, 'dropout_rate_Layer_3': 0.034958516354357025, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011698616830891088, 'l1_Layer_2': 0.0001349234567251034, 'l1_Layer_3': 1.9694913979016807e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 255, 'n_units_Layer_3': 200}. Best is trial 764 with value: 9.497372093893297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.71 | sMAPE for Validation Set is: 12.10% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 32.68 | sMAPE for Test Set is: 18.77% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:41:00,990]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:41:58,647]\u001b[0m Trial 1280 finished with value: 9.482111840754248 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008806571885108492, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006647261986156152, 'dropout_rate_Layer_2': 0.025929033932403162, 'dropout_rate_Layer_3': 0.025513055784295285, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014364528406726313, 'l1_Layer_2': 0.00012402202872966884, 'l1_Layer_3': 2.0745007290019373e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 255, 'n_units_Layer_3': 190}. Best is trial 1280 with value: 9.482111840754248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.48 | sMAPE for Validation Set is: 11.77% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 32.02 | sMAPE for Test Set is: 18.49% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:42:03,377]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:42:10,336]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:42:15,561]\u001b[0m Trial 1282 finished with value: 10.517318370328935 and parameters: {'n_hidden': 3, 'learning_rate': 0.000964543284595568, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3154859680978521, 'dropout_rate_Layer_2': 0.03799976580494651, 'dropout_rate_Layer_3': 0.20927040933061816, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016382194021018125, 'l1_Layer_2': 0.0006098267619166697, 'l1_Layer_3': 0.01661502902925338, 'n_units_Layer_1': 170, 'n_units_Layer_2': 110, 'n_units_Layer_3': 270}. Best is trial 1280 with value: 9.482111840754248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.52 | sMAPE for Validation Set is: 13.14% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 34.56 | sMAPE for Test Set is: 19.98% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:42:22,705]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:42:27,858]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:42:33,753]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:42:50,955]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:42:57,878]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:43:05,396]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:43:13,633]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:43:42,470]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:43:52,083]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:43:57,955]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:44:02,759]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:44:07,618]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:44:14,597]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:44:49,987]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:44:54,878]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:44:59,426]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:45:11,312]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:45:28,373]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:45:33,492]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:45:39,322]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:45:45,927]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:45:53,279]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:46:00,258]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:46:06,470]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:46:24,201]\u001b[0m Trial 1294 finished with value: 9.511594035674296 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010811650961033855, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006995696130995974, 'dropout_rate_Layer_2': 0.04276398551988085, 'dropout_rate_Layer_3': 0.028312439341451664, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012576322635838467, 'l1_Layer_2': 0.00012654814793114504, 'l1_Layer_3': 1.0154769477719244e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 255, 'n_units_Layer_3': 190}. Best is trial 1280 with value: 9.482111840754248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.51 | sMAPE for Validation Set is: 11.91% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 32.04 | sMAPE for Test Set is: 18.46% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:46:33,464]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:46:40,630]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:46:46,724]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:46:51,640]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:46:56,679]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:47:00,946]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:47:03,676]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:47:08,763]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:47:11,401]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:47:19,300]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:47:24,840]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:47:26,966]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:47:32,150]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:48:12,064]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:48:19,105]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:48:26,587]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:48:34,699]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:48:39,774]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:48:46,390]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:48:56,869]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:49:09,368]\u001b[0m Trial 1323 finished with value: 10.548598061211726 and parameters: {'n_hidden': 3, 'learning_rate': 0.000831354603169217, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2983653460908029, 'dropout_rate_Layer_2': 0.04252170036923608, 'dropout_rate_Layer_3': 0.198765929226492, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.08529707287325e-05, 'l1_Layer_2': 0.0016130724538181286, 'l1_Layer_3': 0.018246047118964694, 'n_units_Layer_1': 160, 'n_units_Layer_2': 120, 'n_units_Layer_3': 250}. Best is trial 1280 with value: 9.482111840754248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.55 | sMAPE for Validation Set is: 13.26% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 34.41 | sMAPE for Test Set is: 20.04% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:49:14,286]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:49:19,165]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:49:22,279]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:49:26,718]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:49:34,060]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:49:38,776]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:50:01,623]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.20 | sMAPE for Validation Set is: 30.07% | rMAE for Validation Set is: 1.43\n",
      "MAE for Test Set is: 137.51 | sMAPE for Test Set is: 82.21% | rMAE for Test Set is: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:50:05,937]\u001b[0m Trial 1338 finished with value: 24.202722015434137 and parameters: {'n_hidden': 3, 'learning_rate': 0.02566125242561938, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14754640633758997, 'dropout_rate_Layer_2': 0.3788694320553893, 'dropout_rate_Layer_3': 0.16595611024879808, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018103634393129404, 'l1_Layer_2': 1.9394432067393268e-05, 'l1_Layer_3': 0.0005215711505699629, 'n_units_Layer_1': 150, 'n_units_Layer_2': 235, 'n_units_Layer_3': 175}. Best is trial 1280 with value: 9.482111840754248.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:50:13,925]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:50:14,236]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:50:22,689]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:50:27,496]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:50:35,008]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:50:40,126]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:50:57,622]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:51:04,778]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:51:12,265]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:51:16,991]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:51:20,037]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:51:24,086]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:51:28,990]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:51:31,253]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:51:36,721]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:51:49,315]\u001b[0m Trial 1355 finished with value: 32.825906327352406 and parameters: {'n_hidden': 4, 'learning_rate': 0.01938695714802433, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2812752673744851, 'dropout_rate_Layer_2': 0.261151473492517, 'dropout_rate_Layer_3': 0.10042723989291838, 'dropout_rate_Layer_4': 0.04362430873933859, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00016466958567683878, 'l1_Layer_2': 0.0022027429324651005, 'l1_Layer_3': 0.0010405196110492292, 'l1_Layer_4': 0.030908820599780194, 'n_units_Layer_1': 210, 'n_units_Layer_2': 135, 'n_units_Layer_3': 130, 'n_units_Layer_4': 80}. Best is trial 1280 with value: 9.482111840754248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.83 | sMAPE for Validation Set is: 42.76% | rMAE for Validation Set is: 1.94\n",
      "MAE for Test Set is: 165.59 | sMAPE for Test Set is: 113.27% | rMAE for Test Set is: 2.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:52:01,356]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:52:08,097]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:52:14,272]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:52:20,811]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:52:43,722]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:52:48,849]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:53:08,641]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:53:51,888]\u001b[0m Trial 1360 finished with value: 9.65003311853391 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008965082653806449, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 6.13066322031515e-05, 'dropout_rate_Layer_2': 0.28592717203687446, 'dropout_rate_Layer_3': 0.008394259784386165, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002202226798492668, 'l1_Layer_2': 0.00011471973129251581, 'l1_Layer_3': 6.416044261823512e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 280, 'n_units_Layer_3': 225}. Best is trial 1280 with value: 9.482111840754248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.65 | sMAPE for Validation Set is: 12.01% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 32.24 | sMAPE for Test Set is: 18.70% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:53:58,970]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:54:06,207]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:54:13,585]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:54:19,527]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:54:26,849]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:54:33,611]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:54:38,560]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:55:08,517]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:55:13,753]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:55:19,024]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:55:21,040]\u001b[0m Trial 1363 finished with value: 9.629651063460877 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007095859692487322, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007047331635562009, 'dropout_rate_Layer_2': 0.0135650115458896, 'dropout_rate_Layer_3': 0.018770831632917994, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00694765454526943, 'l1_Layer_2': 0.00011568218724347244, 'l1_Layer_3': 2.279582197384801e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 265, 'n_units_Layer_3': 235}. Best is trial 1280 with value: 9.482111840754248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.63 | sMAPE for Validation Set is: 12.05% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 32.72 | sMAPE for Test Set is: 18.79% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:55:26,791]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:55:31,305]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:55:35,798]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:55:41,009]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:55:43,758]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:56:00,791]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:56:04,681]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:56:17,447]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:56:24,389]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:56:34,371]\u001b[0m Trial 1379 finished with value: 9.939042179988528 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026162095266569958, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1288889217891071, 'dropout_rate_Layer_2': 0.32054964070525704, 'dropout_rate_Layer_3': 0.22577434380346204, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004147753260940173, 'l1_Layer_2': 2.4733049853286364e-05, 'l1_Layer_3': 0.00035079534383877266, 'n_units_Layer_1': 175, 'n_units_Layer_2': 165, 'n_units_Layer_3': 155}. Best is trial 1280 with value: 9.482111840754248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.94 | sMAPE for Validation Set is: 12.52% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 33.06 | sMAPE for Test Set is: 19.04% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:56:38,575]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:56:41,990]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:56:46,865]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:56:50,008]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:57:03,532]\u001b[0m Trial 1384 finished with value: 10.545312877305172 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007865020496437016, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31252312682873007, 'dropout_rate_Layer_2': 0.02801504488882367, 'dropout_rate_Layer_3': 0.17141271070675684, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012318934090564784, 'l1_Layer_2': 0.0004093875908657586, 'l1_Layer_3': 0.024450713035087362, 'n_units_Layer_1': 170, 'n_units_Layer_2': 115, 'n_units_Layer_3': 255}. Best is trial 1280 with value: 9.482111840754248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.55 | sMAPE for Validation Set is: 13.18% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 34.70 | sMAPE for Test Set is: 20.15% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:57:07,426]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:57:08,413]\u001b[0m Trial 1389 finished with value: 22.53953034513712 and parameters: {'n_hidden': 3, 'learning_rate': 0.012911340118823566, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31235144431174505, 'dropout_rate_Layer_2': 0.3192028773102351, 'dropout_rate_Layer_3': 0.1794142903403331, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.158362600584086e-05, 'l1_Layer_2': 0.014177543521470565, 'l1_Layer_3': 0.003215370035307947, 'n_units_Layer_1': 280, 'n_units_Layer_2': 100, 'n_units_Layer_3': 155}. Best is trial 1280 with value: 9.482111840754248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.54 | sMAPE for Validation Set is: 26.24% | rMAE for Validation Set is: 1.34\n",
      "MAE for Test Set is: 140.96 | sMAPE for Test Set is: 85.49% | rMAE for Test Set is: 2.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:57:12,768]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:57:15,320]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:57:17,149]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:57:20,297]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:57:24,593]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:57:27,137]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:57:30,419]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:57:30,741]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:57:36,402]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:57:36,669]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:57:41,248]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:57:44,483]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:57:46,533]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:58:03,386]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:58:07,727]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:58:11,189]\u001b[0m Trial 1404 finished with value: 10.681908639201017 and parameters: {'n_hidden': 3, 'learning_rate': 0.000806963266335237, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3089122808174507, 'dropout_rate_Layer_2': 0.017919856268222175, 'dropout_rate_Layer_3': 0.2179372989851282, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.71830768872432e-05, 'l1_Layer_2': 0.00041189452115404223, 'l1_Layer_3': 0.022074083922602617, 'n_units_Layer_1': 165, 'n_units_Layer_2': 110, 'n_units_Layer_3': 260}. Best is trial 1280 with value: 9.482111840754248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.68 | sMAPE for Validation Set is: 13.36% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 35.44 | sMAPE for Test Set is: 20.49% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:58:14,891]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:58:16,959]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:58:19,879]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:58:21,436]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:58:25,835]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:58:29,590]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:58:34,260]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:58:38,850]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:58:42,315]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:58:49,797]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:58:53,436]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:58:56,539]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:59:04,441]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:59:15,739]\u001b[0m Trial 1411 finished with value: 9.893824432007206 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013753556980868689, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12269553752110075, 'dropout_rate_Layer_2': 0.3657597190066384, 'dropout_rate_Layer_3': 0.2752639761932867, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010297698302797242, 'l1_Layer_2': 4.418369240795782e-05, 'l1_Layer_3': 0.0008179700827749815, 'n_units_Layer_1': 195, 'n_units_Layer_2': 210, 'n_units_Layer_3': 165}. Best is trial 1280 with value: 9.482111840754248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.89 | sMAPE for Validation Set is: 12.56% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 33.27 | sMAPE for Test Set is: 19.17% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 05:59:19,084]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:59:22,980]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:59:23,446]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:59:28,048]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:59:28,392]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:59:32,830]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:59:33,427]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:59:41,083]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:59:45,060]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:59:49,588]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:59:53,920]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 05:59:58,186]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:00:01,841]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:00:12,421]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:00:15,749]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:00:16,172]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:00:20,736]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:00:21,394]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:00:25,126]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:00:25,729]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:00:31,311]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:00:34,584]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:00:37,543]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:00:41,020]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:00:44,743]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:00:47,517]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:00:49,348]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:00:53,263]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:00:57,559]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:01:01,360]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:01:05,992]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:01:09,656]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:01:14,351]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:01:22,335]\u001b[0m Trial 1453 finished with value: 10.073055814711076 and parameters: {'n_hidden': 3, 'learning_rate': 0.0074116486647772635, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0004746995533154042, 'dropout_rate_Layer_2': 0.2900080941931715, 'dropout_rate_Layer_3': 0.12951888992848135, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09964375586146847, 'l1_Layer_2': 0.03937403901478956, 'l1_Layer_3': 3.18522470818034e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 280, 'n_units_Layer_3': 250}. Best is trial 1280 with value: 9.482111840754248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.07 | sMAPE for Validation Set is: 12.66% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 33.46 | sMAPE for Test Set is: 19.05% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 06:01:26,170]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:01:47,601]\u001b[0m Trial 1457 finished with value: 10.132416114913687 and parameters: {'n_hidden': 3, 'learning_rate': 0.008803119064826634, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38059787158698105, 'dropout_rate_Layer_2': 0.3498929766487673, 'dropout_rate_Layer_3': 0.11971420336078709, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.374130872377141e-05, 'l1_Layer_2': 0.0002673875716691308, 'l1_Layer_3': 0.0019731322933227765, 'n_units_Layer_1': 250, 'n_units_Layer_2': 225, 'n_units_Layer_3': 190}. Best is trial 1280 with value: 9.482111840754248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.13 | sMAPE for Validation Set is: 12.73% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 33.98 | sMAPE for Test Set is: 19.93% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 06:01:51,763]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:01:56,528]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:01:59,654]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:02:02,548]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:02:03,315]\u001b[0m Trial 1458 finished with value: 10.4297696398268 and parameters: {'n_hidden': 3, 'learning_rate': 0.009936172520315745, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37815748451373027, 'dropout_rate_Layer_2': 0.3522932014608521, 'dropout_rate_Layer_3': 0.06870555681746746, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.997793604336925e-05, 'l1_Layer_2': 0.0002774885000368954, 'l1_Layer_3': 0.005238766004859809, 'n_units_Layer_1': 245, 'n_units_Layer_2': 230, 'n_units_Layer_3': 210}. Best is trial 1280 with value: 9.482111840754248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.43 | sMAPE for Validation Set is: 13.05% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 35.30 | sMAPE for Test Set is: 20.72% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 06:02:07,110]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:02:25,544]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:02:29,309]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:02:38,232]\u001b[0m Trial 1463 finished with value: 9.824745298426466 and parameters: {'n_hidden': 3, 'learning_rate': 0.001237353176944243, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01970311110786751, 'dropout_rate_Layer_2': 9.118304758300036e-05, 'dropout_rate_Layer_3': 0.007087524791253696, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009180820628798982, 'l1_Layer_2': 0.0003040824085969621, 'l1_Layer_3': 1.9175460442308652e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 250, 'n_units_Layer_3': 230}. Best is trial 1280 with value: 9.482111840754248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.82 | sMAPE for Validation Set is: 12.24% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 33.10 | sMAPE for Test Set is: 19.01% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 06:02:41,888]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:02:45,883]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:02:49,929]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:02:53,983]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:02:58,088]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:03:01,940]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:03:02,655]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:03:07,815]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:03:08,841]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:03:13,457]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:03:13,786]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:03:18,852]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:03:21,223]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:03:25,061]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:03:28,802]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:03:32,715]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:03:36,479]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:03:41,550]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:03:47,300]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:03:50,632]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:03:53,837]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:03:57,143]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:04:17,565]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:04:22,725]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:04:26,166]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:04:29,586]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:04:30,177]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:04:34,940]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:04:35,645]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:04:41,304]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:04:51,138]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:04:54,919]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:04:58,106]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 06:05:04,105]\u001b[0m Trial 1496 finished with value: 10.176247239423644 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009441250660457067, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12592661275162598, 'dropout_rate_Layer_2': 0.2513752761479423, 'dropout_rate_Layer_3': 0.23809987989501424, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003228243947671883, 'l1_Layer_2': 1.6651520105934565e-05, 'l1_Layer_3': 0.00040933677593123886, 'n_units_Layer_1': 215, 'n_units_Layer_2': 180, 'n_units_Layer_3': 70}. Best is trial 1280 with value: 9.482111840754248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.18 | sMAPE for Validation Set is: 12.81% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 34.39 | sMAPE for Test Set is: 19.79% | rMAE for Test Set is: 0.57\n",
      "for 2022-01-01, MAE is:14.67 & sMAPE is:11.17% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :14.67 & 11.17% & 0.20\n",
      "for 2022-01-02, MAE is:17.31 & sMAPE is:14.28% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :15.99 & 12.72% & 0.22\n",
      "for 2022-01-03, MAE is:11.09 & sMAPE is:8.85% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :14.36 & 11.43% & 0.22\n",
      "for 2022-01-04, MAE is:21.66 & sMAPE is:15.31% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :16.18 & 12.40% & 0.63\n",
      "for 2022-01-05, MAE is:7.52 & sMAPE is:5.60% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :14.45 & 11.04% & 0.55\n",
      "for 2022-01-06, MAE is:56.08 & sMAPE is:32.50% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :21.39 & 14.62% & 0.66\n",
      "for 2022-01-07, MAE is:26.52 & sMAPE is:15.45% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :22.12 & 14.74% & 0.73\n",
      "for 2022-01-08, MAE is:14.63 & sMAPE is:9.83% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :21.18 & 14.12% & 0.72\n",
      "for 2022-01-09, MAE is:26.58 & sMAPE is:18.26% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :21.78 & 14.58% & 0.74\n",
      "for 2022-01-10, MAE is:43.95 & sMAPE is:21.23% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :24.00 & 15.25% & 0.73\n",
      "for 2022-01-11, MAE is:8.32 & sMAPE is:5.26% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :22.58 & 14.34% & 0.74\n",
      "for 2022-01-12, MAE is:8.84 & sMAPE is:6.19% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :21.43 & 13.66% & 0.75\n",
      "for 2022-01-13, MAE is:8.31 & sMAPE is:6.23% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :20.42 & 13.09% & 0.70\n",
      "for 2022-01-14, MAE is:7.04 & sMAPE is:5.48% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :19.47 & 12.55% & 0.67\n",
      "for 2022-01-15, MAE is:20.56 & sMAPE is:13.42% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :19.54 & 12.60% & 0.72\n",
      "for 2022-01-16, MAE is:14.35 & sMAPE is:10.60% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :19.21 & 12.48% & 0.70\n",
      "for 2022-01-17, MAE is:7.47 & sMAPE is:5.56% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :18.52 & 12.07% & 0.67\n",
      "for 2022-01-18, MAE is:24.83 & sMAPE is:14.29% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :18.87 & 12.20% & 0.70\n",
      "for 2022-01-19, MAE is:7.01 & sMAPE is:5.07% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :18.25 & 11.82% & 0.76\n",
      "for 2022-01-20, MAE is:4.73 & sMAPE is:3.67% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :17.57 & 11.41% & 0.78\n",
      "for 2022-01-21, MAE is:6.53 & sMAPE is:4.77% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :17.05 & 11.10% & 0.77\n",
      "for 2022-01-22, MAE is:6.27 & sMAPE is:4.58% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :16.56 & 10.80% & 0.75\n",
      "for 2022-01-23, MAE is:5.36 & sMAPE is:3.95% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :16.07 & 10.50% & 0.74\n",
      "for 2022-01-24, MAE is:5.31 & sMAPE is:4.05% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :15.62 & 10.23% & 0.74\n",
      "for 2022-01-25, MAE is:25.01 & sMAPE is:16.85% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :16.00 & 10.50% & 0.75\n",
      "for 2022-01-26, MAE is:11.08 & sMAPE is:7.96% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :15.81 & 10.40% & 0.79\n",
      "for 2022-01-27, MAE is:5.40 & sMAPE is:4.29% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :15.42 & 10.17% & 0.81\n",
      "for 2022-01-28, MAE is:12.17 & sMAPE is:9.17% & rMAE is:4.49 ||| daily mean of MAE & sMAPE & rMAE till now are :15.31 & 10.14% & 0.94\n",
      "for 2022-01-29, MAE is:24.57 & sMAPE is:22.99% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :15.63 & 10.58% & 0.93\n",
      "for 2022-01-30, MAE is:11.17 & sMAPE is:9.21% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :15.48 & 10.54% & 0.92\n",
      "for 2022-01-31, MAE is:37.02 & sMAPE is:23.27% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :16.17 & 10.95% & 0.93\n",
      "for 2022-02-01, MAE is:17.35 & sMAPE is:11.41% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :16.21 & 10.96% & 0.92\n",
      "for 2022-02-02, MAE is:15.88 & sMAPE is:12.03% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :16.20 & 10.99% & 0.93\n",
      "for 2022-02-03, MAE is:12.23 & sMAPE is:8.29% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :16.08 & 10.91% & 0.92\n",
      "for 2022-02-04, MAE is:13.74 & sMAPE is:10.32% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :16.02 & 10.90% & 0.92\n",
      "for 2022-02-05, MAE is:4.35 & sMAPE is:3.79% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :15.69 & 10.70% & 0.91\n",
      "for 2022-02-06, MAE is:7.32 & sMAPE is:6.96% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :15.47 & 10.60% & 0.90\n",
      "for 2022-02-07, MAE is:6.36 & sMAPE is:5.24% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :15.23 & 10.46% & 0.88\n",
      "for 2022-02-08, MAE is:6.90 & sMAPE is:5.69% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :15.01 & 10.34% & 0.87\n",
      "for 2022-02-09, MAE is:6.04 & sMAPE is:5.08% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :14.79 & 10.20% & 0.85\n",
      "for 2022-02-10, MAE is:4.20 & sMAPE is:3.49% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :14.53 & 10.04% & 0.84\n",
      "for 2022-02-11, MAE is:5.93 & sMAPE is:4.61% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :14.33 & 9.91% & 0.85\n",
      "for 2022-02-12, MAE is:9.94 & sMAPE is:8.45% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :14.22 & 9.88% & 0.87\n",
      "for 2022-02-13, MAE is:5.87 & sMAPE is:5.55% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :14.03 & 9.78% & 0.86\n",
      "for 2022-02-14, MAE is:3.89 & sMAPE is:3.57% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :13.81 & 9.64% & 0.84\n",
      "for 2022-02-15, MAE is:6.34 & sMAPE is:5.83% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :13.65 & 9.56% & 0.84\n",
      "for 2022-02-16, MAE is:3.88 & sMAPE is:3.56% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :13.44 & 9.43% & 0.83\n",
      "for 2022-02-17, MAE is:3.59 & sMAPE is:3.50% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :13.23 & 9.31% & 0.81\n",
      "for 2022-02-18, MAE is:10.35 & sMAPE is:9.84% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :13.17 & 9.32% & 0.81\n",
      "for 2022-02-19, MAE is:5.95 & sMAPE is:5.68% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :13.03 & 9.24% & 0.80\n",
      "for 2022-02-20, MAE is:6.28 & sMAPE is:6.21% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :12.90 & 9.19% & 0.82\n",
      "for 2022-02-21, MAE is:7.51 & sMAPE is:7.31% & rMAE is:2.73 ||| daily mean of MAE & sMAPE & rMAE till now are :12.79 & 9.15% & 0.85\n",
      "for 2022-02-22, MAE is:15.58 & sMAPE is:12.79% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :12.85 & 9.22% & 0.86\n",
      "for 2022-02-23, MAE is:6.71 & sMAPE is:6.17% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :12.73 & 9.16% & 0.88\n",
      "for 2022-02-24, MAE is:14.64 & sMAPE is:13.53% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :12.77 & 9.24% & 0.88\n",
      "for 2022-02-25, MAE is:9.97 & sMAPE is:8.33% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :12.72 & 9.22% & 0.88\n",
      "for 2022-02-26, MAE is:19.62 & sMAPE is:15.09% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :12.84 & 9.33% & 0.87\n",
      "for 2022-02-27, MAE is:7.23 & sMAPE is:5.40% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :12.74 & 9.26% & 0.86\n",
      "for 2022-02-28, MAE is:9.57 & sMAPE is:6.93% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :12.69 & 9.22% & 0.85\n",
      "for 2022-03-01, MAE is:10.85 & sMAPE is:7.74% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :12.66 & 9.20% & 0.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-03-02, MAE is:9.45 & sMAPE is:6.32% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :12.60 & 9.15% & 0.83\n",
      "for 2022-03-03, MAE is:19.23 & sMAPE is:12.73% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :12.71 & 9.21% & 0.82\n",
      "for 2022-03-04, MAE is:50.45 & sMAPE is:25.12% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :13.31 & 9.46% & 0.82\n",
      "for 2022-03-05, MAE is:13.69 & sMAPE is:7.71% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :13.32 & 9.43% & 0.81\n",
      "for 2022-03-06, MAE is:16.01 & sMAPE is:8.81% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :13.36 & 9.42% & 0.81\n",
      "for 2022-03-07, MAE is:49.13 & sMAPE is:16.53% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :13.90 & 9.53% & 0.80\n",
      "for 2022-03-08, MAE is:71.91 & sMAPE is:24.25% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :14.77 & 9.75% & 0.80\n",
      "for 2022-03-09, MAE is:17.51 & sMAPE is:7.95% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :14.81 & 9.72% & 0.79\n",
      "for 2022-03-10, MAE is:13.32 & sMAPE is:6.39% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :14.78 & 9.67% & 0.78\n",
      "for 2022-03-11, MAE is:22.14 & sMAPE is:10.82% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :14.89 & 9.69% & 0.78\n",
      "for 2022-03-12, MAE is:13.03 & sMAPE is:6.87% & rMAE is:2.37 ||| daily mean of MAE & sMAPE & rMAE till now are :14.86 & 9.65% & 0.80\n",
      "for 2022-03-13, MAE is:17.79 & sMAPE is:10.48% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :14.90 & 9.66% & 0.80\n",
      "for 2022-03-14, MAE is:22.08 & sMAPE is:11.67% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :15.00 & 9.69% & 0.80\n",
      "for 2022-03-15, MAE is:16.45 & sMAPE is:7.17% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :15.02 & 9.66% & 0.79\n",
      "for 2022-03-16, MAE is:14.77 & sMAPE is:7.30% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :15.02 & 9.63% & 0.79\n",
      "for 2022-03-17, MAE is:7.99 & sMAPE is:4.58% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :14.93 & 9.56% & 0.78\n",
      "for 2022-03-18, MAE is:7.92 & sMAPE is:4.43% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :14.84 & 9.49% & 0.78\n",
      "for 2022-03-19, MAE is:15.34 & sMAPE is:8.82% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :14.84 & 9.48% & 0.79\n",
      "for 2022-03-20, MAE is:6.59 & sMAPE is:3.93% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :14.74 & 9.41% & 0.78\n",
      "for 2022-03-21, MAE is:12.27 & sMAPE is:7.07% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :14.71 & 9.38% & 0.78\n",
      "for 2022-03-22, MAE is:15.91 & sMAPE is:8.20% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :14.72 & 9.37% & 0.78\n",
      "for 2022-03-23, MAE is:20.53 & sMAPE is:9.86% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :14.79 & 9.38% & 0.79\n",
      "for 2022-03-24, MAE is:8.87 & sMAPE is:4.70% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :14.72 & 9.32% & 0.79\n",
      "for 2022-03-25, MAE is:9.65 & sMAPE is:5.15% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :14.66 & 9.27% & 0.80\n",
      "for 2022-03-26, MAE is:9.85 & sMAPE is:5.40% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :14.60 & 9.22% & 0.80\n",
      "for 2022-03-27, MAE is:11.58 & sMAPE is:6.31% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :14.57 & 9.19% & 0.79\n",
      "for 2022-03-28, MAE is:7.88 & sMAPE is:4.30% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :14.49 & 9.13% & 0.79\n",
      "for 2022-03-29, MAE is:17.40 & sMAPE is:8.83% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :14.52 & 9.13% & 0.81\n",
      "for 2022-03-30, MAE is:22.13 & sMAPE is:10.24% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :14.61 & 9.14% & 0.81\n",
      "for 2022-03-31, MAE is:15.70 & sMAPE is:6.94% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :14.62 & 9.12% & 0.81\n",
      "for 2022-04-01, MAE is:5.97 & sMAPE is:3.10% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :14.53 & 9.05% & 0.81\n",
      "for 2022-04-02, MAE is:8.03 & sMAPE is:4.36% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :14.46 & 9.00% & 0.82\n",
      "for 2022-04-03, MAE is:9.77 & sMAPE is:5.33% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :14.41 & 8.96% & 0.83\n",
      "for 2022-04-04, MAE is:6.79 & sMAPE is:3.85% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :14.33 & 8.91% & 0.82\n",
      "for 2022-04-05, MAE is:7.49 & sMAPE is:4.17% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :14.25 & 8.86% & 0.82\n",
      "for 2022-04-06, MAE is:14.04 & sMAPE is:7.51% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :14.25 & 8.84% & 0.81\n",
      "for 2022-04-07, MAE is:8.74 & sMAPE is:5.16% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :14.19 & 8.81% & 0.81\n",
      "for 2022-04-08, MAE is:8.43 & sMAPE is:4.90% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :14.14 & 8.77% & 0.80\n",
      "for 2022-04-09, MAE is:8.39 & sMAPE is:4.96% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :14.08 & 8.73% & 0.80\n",
      "for 2022-04-10, MAE is:8.04 & sMAPE is:4.81% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :14.02 & 8.69% & 0.80\n",
      "for 2022-04-11, MAE is:15.79 & sMAPE is:8.34% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :14.03 & 8.68% & 0.80\n",
      "for 2022-04-12, MAE is:10.34 & sMAPE is:5.57% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :14.00 & 8.65% & 0.80\n",
      "for 2022-04-13, MAE is:12.25 & sMAPE is:6.91% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :13.98 & 8.64% & 0.80\n",
      "for 2022-04-14, MAE is:12.65 & sMAPE is:6.84% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :13.97 & 8.62% & 0.80\n",
      "for 2022-04-15, MAE is:9.03 & sMAPE is:4.74% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :13.92 & 8.58% & 0.80\n",
      "for 2022-04-16, MAE is:20.00 & sMAPE is:11.89% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :13.98 & 8.61% & 0.80\n",
      "for 2022-04-17, MAE is:26.48 & sMAPE is:18.42% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :14.10 & 8.71% & 0.80\n",
      "for 2022-04-18, MAE is:36.78 & sMAPE is:28.04% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :14.31 & 8.88% & 0.80\n",
      "for 2022-04-19, MAE is:31.95 & sMAPE is:17.09% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :14.47 & 8.96% & 0.82\n",
      "for 2022-04-20, MAE is:8.77 & sMAPE is:4.66% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :14.42 & 8.92% & 0.82\n",
      "for 2022-04-21, MAE is:5.50 & sMAPE is:2.95% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :14.34 & 8.87% & 0.82\n",
      "for 2022-04-22, MAE is:13.70 & sMAPE is:8.45% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :14.33 & 8.86% & 0.82\n",
      "for 2022-04-23, MAE is:15.69 & sMAPE is:10.10% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :14.34 & 8.87% & 0.82\n",
      "for 2022-04-24, MAE is:46.40 & sMAPE is:34.80% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :14.62 & 9.10% & 0.82\n",
      "for 2022-04-25, MAE is:43.50 & sMAPE is:23.51% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :14.87 & 9.23% & 0.82\n",
      "for 2022-04-26, MAE is:5.04 & sMAPE is:2.62% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :14.79 & 9.17% & 0.82\n",
      "for 2022-04-27, MAE is:19.56 & sMAPE is:9.85% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :14.83 & 9.18% & 0.82\n",
      "for 2022-04-28, MAE is:12.98 & sMAPE is:6.18% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :14.81 & 9.15% & 0.82\n",
      "for 2022-04-29, MAE is:15.79 & sMAPE is:7.15% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :14.82 & 9.13% & 0.82\n",
      "for 2022-04-30, MAE is:8.53 & sMAPE is:4.32% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :14.77 & 9.09% & 0.81\n",
      "for 2022-05-01, MAE is:9.97 & sMAPE is:5.18% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :14.73 & 9.06% & 0.81\n",
      "for 2022-05-02, MAE is:7.56 & sMAPE is:3.62% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :14.67 & 9.02% & 0.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-05-03, MAE is:16.38 & sMAPE is:7.51% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :14.69 & 9.00% & 0.81\n",
      "for 2022-05-04, MAE is:13.42 & sMAPE is:5.91% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :14.68 & 8.98% & 0.81\n",
      "for 2022-05-05, MAE is:7.53 & sMAPE is:3.35% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :14.62 & 8.93% & 0.80\n",
      "for 2022-05-06, MAE is:13.75 & sMAPE is:6.25% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :14.61 & 8.91% & 0.81\n",
      "for 2022-05-07, MAE is:10.53 & sMAPE is:5.37% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :14.58 & 8.89% & 0.82\n",
      "for 2022-05-08, MAE is:20.04 & sMAPE is:11.09% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :14.62 & 8.90% & 0.83\n",
      "for 2022-05-09, MAE is:7.80 & sMAPE is:3.87% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :14.57 & 8.86% & 0.83\n",
      "for 2022-05-10, MAE is:11.72 & sMAPE is:6.11% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :14.55 & 8.84% & 0.83\n",
      "for 2022-05-11, MAE is:16.90 & sMAPE is:9.51% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :14.57 & 8.85% & 0.82\n",
      "for 2022-05-12, MAE is:26.13 & sMAPE is:17.34% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :14.65 & 8.91% & 0.82\n",
      "for 2022-05-13, MAE is:37.82 & sMAPE is:29.87% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :14.83 & 9.07% & 0.82\n",
      "for 2022-05-14, MAE is:31.00 & sMAPE is:28.68% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :14.95 & 9.22% & 0.81\n",
      "for 2022-05-15, MAE is:32.90 & sMAPE is:27.08% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :15.08 & 9.35% & 0.81\n",
      "for 2022-05-16, MAE is:8.78 & sMAPE is:5.11% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :15.03 & 9.32% & 0.81\n",
      "for 2022-05-17, MAE is:8.81 & sMAPE is:5.08% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :14.99 & 9.29% & 0.81\n",
      "for 2022-05-18, MAE is:12.49 & sMAPE is:7.13% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :14.97 & 9.27% & 0.81\n",
      "for 2022-05-19, MAE is:10.21 & sMAPE is:5.36% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :14.94 & 9.24% & 0.81\n",
      "for 2022-05-20, MAE is:4.86 & sMAPE is:2.66% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :14.86 & 9.20% & 0.80\n",
      "for 2022-05-21, MAE is:40.03 & sMAPE is:28.51% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :15.04 & 9.33% & 0.81\n",
      "for 2022-05-22, MAE is:14.12 & sMAPE is:9.23% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :15.04 & 9.33% & 0.81\n",
      "for 2022-05-23, MAE is:12.04 & sMAPE is:6.91% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :15.02 & 9.31% & 0.81\n",
      "for 2022-05-24, MAE is:35.08 & sMAPE is:31.92% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :15.15 & 9.47% & 0.81\n",
      "for 2022-05-25, MAE is:13.57 & sMAPE is:9.24% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :15.14 & 9.47% & 0.81\n",
      "for 2022-05-26, MAE is:91.76 & sMAPE is:108.35% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :15.67 & 10.15% & 0.81\n",
      "for 2022-05-27, MAE is:58.36 & sMAPE is:90.70% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :15.96 & 10.70% & 0.80\n",
      "for 2022-05-28, MAE is:64.87 & sMAPE is:148.03% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :16.29 & 11.62% & 0.80\n",
      "for 2022-05-29, MAE is:45.66 & sMAPE is:38.06% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :16.49 & 11.80% & 0.81\n",
      "for 2022-05-30, MAE is:28.35 & sMAPE is:17.47% & rMAE is:3.44 ||| daily mean of MAE & sMAPE & rMAE till now are :16.57 & 11.84% & 0.83\n",
      "for 2022-05-31, MAE is:22.10 & sMAPE is:13.51% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :16.60 & 11.85% & 0.83\n",
      "for 2022-06-01, MAE is:18.96 & sMAPE is:11.12% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :16.62 & 11.84% & 0.83\n",
      "for 2022-06-02, MAE is:7.73 & sMAPE is:4.75% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :16.56 & 11.80% & 0.82\n",
      "for 2022-06-03, MAE is:6.04 & sMAPE is:3.81% & rMAE is:0.05 ||| daily mean of MAE & sMAPE & rMAE till now are :16.49 & 11.75% & 0.82\n",
      "for 2022-06-04, MAE is:12.42 & sMAPE is:8.50% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :16.47 & 11.73% & 0.81\n",
      "for 2022-06-05, MAE is:19.15 & sMAPE is:13.50% & rMAE is:2.34 ||| daily mean of MAE & sMAPE & rMAE till now are :16.48 & 11.74% & 0.82\n",
      "for 2022-06-06, MAE is:69.69 & sMAPE is:73.11% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :16.82 & 12.13% & 0.82\n",
      "for 2022-06-07, MAE is:27.85 & sMAPE is:17.75% & rMAE is:2.61 ||| daily mean of MAE & sMAPE & rMAE till now are :16.89 & 12.16% & 0.83\n",
      "for 2022-06-08, MAE is:6.99 & sMAPE is:4.09% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :16.83 & 12.11% & 0.83\n",
      "for 2022-06-09, MAE is:8.61 & sMAPE is:5.23% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :16.78 & 12.07% & 0.83\n",
      "for 2022-06-10, MAE is:6.47 & sMAPE is:4.06% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :16.71 & 12.02% & 0.84\n",
      "for 2022-06-11, MAE is:40.90 & sMAPE is:36.83% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :16.86 & 12.17% & 0.84\n",
      "for 2022-06-12, MAE is:44.45 & sMAPE is:48.80% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :17.03 & 12.40% & 0.85\n",
      "for 2022-06-13, MAE is:17.35 & sMAPE is:12.11% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :17.03 & 12.40% & 0.84\n",
      "for 2022-06-14, MAE is:23.91 & sMAPE is:13.50% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :17.08 & 12.40% & 0.84\n",
      "for 2022-06-15, MAE is:10.56 & sMAPE is:5.80% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :17.04 & 12.36% & 0.84\n",
      "for 2022-06-16, MAE is:23.65 & sMAPE is:13.07% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :17.08 & 12.37% & 0.84\n",
      "for 2022-06-17, MAE is:22.00 & sMAPE is:10.59% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :17.11 & 12.36% & 0.84\n",
      "for 2022-06-18, MAE is:23.94 & sMAPE is:15.00% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :17.15 & 12.37% & 0.84\n",
      "for 2022-06-19, MAE is:41.05 & sMAPE is:28.39% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :17.29 & 12.47% & 0.84\n",
      "for 2022-06-20, MAE is:53.86 & sMAPE is:21.52% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :17.50 & 12.52% & 0.84\n",
      "for 2022-06-21, MAE is:27.89 & sMAPE is:10.71% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :17.56 & 12.51% & 0.84\n",
      "for 2022-06-22, MAE is:14.65 & sMAPE is:6.61% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :17.54 & 12.47% & 0.84\n",
      "for 2022-06-23, MAE is:12.69 & sMAPE is:5.56% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :17.52 & 12.43% & 0.83\n",
      "for 2022-06-24, MAE is:23.91 & sMAPE is:11.40% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :17.55 & 12.43% & 0.83\n",
      "for 2022-06-25, MAE is:12.39 & sMAPE is:6.50% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :17.52 & 12.40% & 0.83\n",
      "for 2022-06-26, MAE is:35.46 & sMAPE is:23.35% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :17.62 & 12.46% & 0.84\n",
      "for 2022-06-27, MAE is:12.13 & sMAPE is:5.70% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :17.59 & 12.42% & 0.83\n",
      "for 2022-06-28, MAE is:7.58 & sMAPE is:3.50% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :17.54 & 12.37% & 0.83\n",
      "for 2022-06-29, MAE is:34.71 & sMAPE is:14.95% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :17.63 & 12.38% & 0.83\n",
      "for 2022-06-30, MAE is:35.03 & sMAPE is:13.52% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :17.73 & 12.39% & 0.83\n",
      "for 2022-07-01, MAE is:24.25 & sMAPE is:10.01% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :17.76 & 12.38% & 0.83\n",
      "for 2022-07-02, MAE is:35.10 & sMAPE is:18.40% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :17.86 & 12.41% & 0.83\n",
      "for 2022-07-03, MAE is:49.87 & sMAPE is:28.21% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :18.03 & 12.50% & 0.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-07-04, MAE is:19.36 & sMAPE is:9.08% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :18.04 & 12.48% & 0.84\n",
      "for 2022-07-05, MAE is:6.11 & sMAPE is:2.73% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :17.98 & 12.42% & 0.84\n",
      "for 2022-07-06, MAE is:19.86 & sMAPE is:8.90% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :17.99 & 12.41% & 0.84\n",
      "for 2022-07-07, MAE is:37.28 & sMAPE is:18.65% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :18.09 & 12.44% & 0.84\n",
      "for 2022-07-08, MAE is:16.69 & sMAPE is:8.61% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :18.08 & 12.42% & 0.83\n",
      "for 2022-07-09, MAE is:92.48 & sMAPE is:63.88% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :18.47 & 12.69% & 0.84\n",
      "for 2022-07-10, MAE is:93.44 & sMAPE is:82.78% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :18.87 & 13.06% & 0.84\n",
      "for 2022-07-11, MAE is:102.33 & sMAPE is:42.41% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :19.30 & 13.21% & 0.84\n",
      "for 2022-07-12, MAE is:31.99 & sMAPE is:11.36% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :19.37 & 13.20% & 0.84\n",
      "for 2022-07-13, MAE is:49.82 & sMAPE is:20.12% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :19.52 & 13.24% & 0.84\n",
      "for 2022-07-14, MAE is:42.53 & sMAPE is:16.27% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :19.64 & 13.25% & 0.84\n",
      "for 2022-07-15, MAE is:39.94 & sMAPE is:17.49% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :19.74 & 13.27% & 0.84\n",
      "for 2022-07-16, MAE is:117.39 & sMAPE is:77.81% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :20.24 & 13.60% & 0.84\n",
      "for 2022-07-17, MAE is:61.79 & sMAPE is:30.08% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :20.45 & 13.68% & 0.84\n",
      "for 2022-07-18, MAE is:50.94 & sMAPE is:17.27% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :20.60 & 13.70% & 0.85\n",
      "for 2022-07-19, MAE is:18.27 & sMAPE is:5.85% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :20.59 & 13.66% & 0.84\n",
      "for 2022-07-20, MAE is:47.47 & sMAPE is:18.20% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :20.73 & 13.68% & 0.84\n",
      "for 2022-07-21, MAE is:38.33 & sMAPE is:12.46% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :20.81 & 13.68% & 0.84\n",
      "for 2022-07-22, MAE is:20.41 & sMAPE is:6.84% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :20.81 & 13.65% & 0.84\n",
      "for 2022-07-23, MAE is:29.14 & sMAPE is:10.40% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :20.85 & 13.63% & 0.84\n",
      "for 2022-07-24, MAE is:97.23 & sMAPE is:42.89% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :21.22 & 13.77% & 0.84\n",
      "for 2022-07-25, MAE is:64.78 & sMAPE is:24.95% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :21.44 & 13.83% & 0.84\n",
      "for 2022-07-26, MAE is:90.77 & sMAPE is:36.13% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :21.77 & 13.93% & 0.84\n",
      "for 2022-07-27, MAE is:74.36 & sMAPE is:29.58% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :22.02 & 14.01% & 0.85\n",
      "for 2022-07-28, MAE is:115.68 & sMAPE is:31.69% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :22.47 & 14.09% & 0.85\n",
      "for 2022-07-29, MAE is:39.49 & sMAPE is:9.78% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :22.55 & 14.07% & 0.84\n",
      "for 2022-07-30, MAE is:55.84 & sMAPE is:15.46% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :22.71 & 14.08% & 0.84\n",
      "for 2022-07-31, MAE is:86.83 & sMAPE is:26.38% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :23.01 & 14.14% & 0.85\n",
      "for 2022-08-01, MAE is:48.78 & sMAPE is:13.93% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :23.13 & 14.14% & 0.84\n",
      "for 2022-08-02, MAE is:79.56 & sMAPE is:24.55% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :23.40 & 14.19% & 0.84\n",
      "for 2022-08-03, MAE is:71.51 & sMAPE is:23.79% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :23.62 & 14.23% & 0.85\n",
      "for 2022-08-04, MAE is:54.37 & sMAPE is:16.09% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :23.76 & 14.24% & 0.84\n",
      "for 2022-08-05, MAE is:45.61 & sMAPE is:13.41% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :23.86 & 14.24% & 0.84\n",
      "for 2022-08-06, MAE is:74.15 & sMAPE is:27.48% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :24.09 & 14.30% & 0.84\n",
      "for 2022-08-07, MAE is:98.64 & sMAPE is:38.40% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :24.44 & 14.41% & 0.85\n",
      "for 2022-08-08, MAE is:49.25 & sMAPE is:14.23% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :24.55 & 14.41% & 0.85\n",
      "for 2022-08-09, MAE is:47.68 & sMAPE is:14.01% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :24.65 & 14.40% & 0.85\n",
      "for 2022-08-10, MAE is:40.45 & sMAPE is:12.25% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :24.72 & 14.39% & 0.85\n",
      "for 2022-08-11, MAE is:41.17 & sMAPE is:11.86% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :24.80 & 14.38% & 0.85\n",
      "for 2022-08-12, MAE is:50.66 & sMAPE is:13.00% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :24.91 & 14.38% & 0.85\n",
      "for 2022-08-13, MAE is:49.00 & sMAPE is:13.63% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :25.02 & 14.37% & 0.85\n",
      "for 2022-08-14, MAE is:47.04 & sMAPE is:13.68% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :25.12 & 14.37% & 0.84\n",
      "for 2022-08-15, MAE is:27.78 & sMAPE is:6.80% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :25.13 & 14.34% & 0.84\n",
      "for 2022-08-16, MAE is:37.13 & sMAPE is:8.67% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :25.18 & 14.31% & 0.84\n",
      "for 2022-08-17, MAE is:75.92 & sMAPE is:16.54% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :25.40 & 14.32% & 0.84\n",
      "for 2022-08-18, MAE is:65.97 & sMAPE is:13.04% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :25.58 & 14.32% & 0.84\n",
      "for 2022-08-19, MAE is:24.60 & sMAPE is:5.02% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :25.58 & 14.28% & 0.83\n",
      "for 2022-08-20, MAE is:47.37 & sMAPE is:10.77% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :25.67 & 14.26% & 0.83\n",
      "for 2022-08-21, MAE is:113.98 & sMAPE is:31.00% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :26.05 & 14.33% & 0.84\n",
      "for 2022-08-22, MAE is:77.58 & sMAPE is:15.01% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :26.27 & 14.34% & 0.83\n",
      "for 2022-08-23, MAE is:29.22 & sMAPE is:5.48% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :26.28 & 14.30% & 0.83\n",
      "for 2022-08-24, MAE is:68.22 & sMAPE is:12.76% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :26.46 & 14.29% & 0.83\n",
      "for 2022-08-25, MAE is:32.81 & sMAPE is:5.82% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :26.49 & 14.26% & 0.83\n",
      "for 2022-08-26, MAE is:100.82 & sMAPE is:16.76% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :26.80 & 14.27% & 0.83\n",
      "for 2022-08-27, MAE is:51.81 & sMAPE is:8.81% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :26.90 & 14.24% & 0.83\n",
      "for 2022-08-28, MAE is:77.39 & sMAPE is:15.26% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :27.11 & 14.25% & 0.83\n",
      "for 2022-08-29, MAE is:87.90 & sMAPE is:13.59% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :27.37 & 14.24% & 0.83\n",
      "for 2022-08-30, MAE is:48.00 & sMAPE is:7.28% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :27.45 & 14.22% & 0.83\n",
      "for 2022-08-31, MAE is:47.48 & sMAPE is:7.92% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :27.53 & 14.19% & 0.83\n",
      "for 2022-09-01, MAE is:54.74 & sMAPE is:9.55% & rMAE is:2.37 ||| daily mean of MAE & sMAPE & rMAE till now are :27.64 & 14.17% & 0.84\n",
      "for 2022-09-02, MAE is:160.51 & sMAPE is:33.66% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :28.19 & 14.25% & 0.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-09-03, MAE is:57.06 & sMAPE is:16.00% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :28.30 & 14.26% & 0.83\n",
      "for 2022-09-04, MAE is:113.56 & sMAPE is:35.44% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :28.65 & 14.34% & 0.83\n",
      "for 2022-09-05, MAE is:85.48 & sMAPE is:23.05% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :28.88 & 14.38% & 0.83\n",
      "for 2022-09-06, MAE is:96.80 & sMAPE is:24.26% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :29.15 & 14.42% & 0.83\n",
      "for 2022-09-07, MAE is:45.82 & sMAPE is:10.09% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :29.22 & 14.40% & 0.83\n",
      "for 2022-09-08, MAE is:33.00 & sMAPE is:7.67% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :29.23 & 14.37% & 0.82\n",
      "for 2022-09-09, MAE is:63.63 & sMAPE is:18.85% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :29.37 & 14.39% & 0.82\n",
      "for 2022-09-10, MAE is:41.24 & sMAPE is:10.20% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :29.42 & 14.37% & 0.82\n",
      "for 2022-09-11, MAE is:38.70 & sMAPE is:9.74% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :29.45 & 14.36% & 0.82\n",
      "for 2022-09-12, MAE is:45.18 & sMAPE is:11.00% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :29.51 & 14.34% & 0.82\n",
      "for 2022-09-13, MAE is:45.97 & sMAPE is:12.17% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :29.58 & 14.34% & 0.82\n",
      "for 2022-09-14, MAE is:51.07 & sMAPE is:12.31% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :29.66 & 14.33% & 0.82\n",
      "for 2022-09-15, MAE is:45.83 & sMAPE is:12.90% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :29.73 & 14.32% & 0.82\n",
      "for 2022-09-16, MAE is:78.88 & sMAPE is:26.53% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :29.92 & 14.37% & 0.82\n",
      "for 2022-09-17, MAE is:91.11 & sMAPE is:37.79% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :30.15 & 14.46% & 0.82\n",
      "for 2022-09-18, MAE is:178.33 & sMAPE is:102.66% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :30.72 & 14.80% & 0.82\n",
      "for 2022-09-19, MAE is:116.54 & sMAPE is:48.41% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :31.05 & 14.93% & 0.82\n",
      "for 2022-09-20, MAE is:97.34 & sMAPE is:29.08% & rMAE is:3.74 ||| daily mean of MAE & sMAPE & rMAE till now are :31.30 & 14.98% & 0.83\n",
      "for 2022-09-21, MAE is:65.00 & sMAPE is:17.64% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :31.43 & 14.99% & 0.83\n",
      "for 2022-09-22, MAE is:37.30 & sMAPE is:10.06% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :31.45 & 14.97% & 0.83\n",
      "for 2022-09-23, MAE is:19.20 & sMAPE is:5.53% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :31.40 & 14.93% & 0.83\n",
      "for 2022-09-24, MAE is:17.16 & sMAPE is:5.07% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :31.35 & 14.90% & 0.83\n",
      "for 2022-09-25, MAE is:33.69 & sMAPE is:11.93% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :31.36 & 14.89% & 0.83\n",
      "for 2022-09-26, MAE is:57.02 & sMAPE is:24.57% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :31.45 & 14.92% & 0.83\n",
      "for 2022-09-27, MAE is:41.73 & sMAPE is:15.34% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :31.49 & 14.92% & 0.83\n",
      "for 2022-09-28, MAE is:19.28 & sMAPE is:6.71% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :31.45 & 14.89% & 0.82\n",
      "for 2022-09-29, MAE is:36.78 & sMAPE is:11.69% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :31.47 & 14.88% & 0.82\n",
      "for 2022-09-30, MAE is:53.21 & sMAPE is:20.38% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :31.54 & 14.90% & 0.82\n",
      "for 2022-10-01, MAE is:174.73 & sMAPE is:108.33% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :32.07 & 15.24% & 0.82\n",
      "for 2022-10-02, MAE is:75.08 & sMAPE is:49.94% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :32.22 & 15.37% & 0.82\n",
      "for 2022-10-03, MAE is:73.37 & sMAPE is:34.54% & rMAE is:2.14 ||| daily mean of MAE & sMAPE & rMAE till now are :32.37 & 15.44% & 0.83\n",
      "for 2022-10-04, MAE is:38.85 & sMAPE is:19.59% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :32.40 & 15.45% & 0.82\n",
      "for 2022-10-05, MAE is:127.14 & sMAPE is:119.80% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :32.74 & 15.83% & 0.82\n",
      "for 2022-10-06, MAE is:62.23 & sMAPE is:128.08% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :32.84 & 16.23% & 0.82\n",
      "for 2022-10-07, MAE is:41.53 & sMAPE is:99.19% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :32.87 & 16.53% & 0.82\n",
      "for 2022-10-08, MAE is:15.17 & sMAPE is:34.72% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :32.81 & 16.59% & 0.82\n",
      "for 2022-10-09, MAE is:43.69 & sMAPE is:62.58% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :32.85 & 16.76% & 0.82\n",
      "for 2022-10-10, MAE is:52.07 & sMAPE is:45.95% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :32.92 & 16.86% & 0.82\n",
      "for 2022-10-11, MAE is:45.99 & sMAPE is:30.65% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :32.96 & 16.91% & 0.82\n",
      "for 2022-10-12, MAE is:52.18 & sMAPE is:31.10% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :33.03 & 16.96% & 0.81\n",
      "for 2022-10-13, MAE is:66.81 & sMAPE is:33.93% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :33.15 & 17.02% & 0.81\n",
      "for 2022-10-14, MAE is:23.83 & sMAPE is:11.51% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :33.12 & 17.00% & 0.81\n",
      "for 2022-10-15, MAE is:33.02 & sMAPE is:20.01% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :33.12 & 17.01% & 0.81\n",
      "for 2022-10-16, MAE is:52.39 & sMAPE is:43.17% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :33.18 & 17.10% & 0.81\n",
      "for 2022-10-17, MAE is:19.77 & sMAPE is:14.26% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :33.14 & 17.09% & 0.81\n",
      "for 2022-10-18, MAE is:18.03 & sMAPE is:11.08% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :33.08 & 17.07% & 0.81\n",
      "for 2022-10-19, MAE is:16.42 & sMAPE is:10.66% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :33.03 & 17.05% & 0.81\n",
      "for 2022-10-20, MAE is:21.61 & sMAPE is:16.96% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :32.99 & 17.05% & 0.81\n",
      "for 2022-10-21, MAE is:23.51 & sMAPE is:16.04% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :32.96 & 17.04% & 0.81\n",
      "for 2022-10-22, MAE is:10.76 & sMAPE is:7.88% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :32.88 & 17.01% & 0.81\n",
      "for 2022-10-23, MAE is:29.56 & sMAPE is:26.84% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :32.87 & 17.04% & 0.81\n",
      "for 2022-10-24, MAE is:22.61 & sMAPE is:29.49% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :32.84 & 17.09% & 0.81\n",
      "for 2022-10-25, MAE is:27.87 & sMAPE is:27.30% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :32.82 & 17.12% & 0.80\n",
      "for 2022-10-26, MAE is:15.02 & sMAPE is:12.88% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :32.76 & 17.11% & 0.80\n",
      "for 2022-10-27, MAE is:17.08 & sMAPE is:15.31% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :32.71 & 17.10% & 0.80\n",
      "for 2022-10-28, MAE is:11.75 & sMAPE is:11.49% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :32.64 & 17.08% & 0.80\n",
      "for 2022-10-29, MAE is:10.51 & sMAPE is:10.39% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :32.56 & 17.06% & 0.80\n",
      "for 2022-10-30, MAE is:15.23 & sMAPE is:12.61% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :32.51 & 17.04% & 0.80\n",
      "for 2022-10-31, MAE is:33.70 & sMAPE is:26.16% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :32.51 & 17.07% & 0.80\n",
      "for 2022-11-01, MAE is:29.51 & sMAPE is:38.70% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :32.50 & 17.15% & 0.80\n",
      "for 2022-11-02, MAE is:27.08 & sMAPE is:42.66% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :32.48 & 17.23% & 0.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-11-03, MAE is:20.65 & sMAPE is:26.86% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :32.44 & 17.26% & 0.80\n",
      "for 2022-11-04, MAE is:14.04 & sMAPE is:20.74% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :32.38 & 17.27% & 0.80\n",
      "for 2022-11-05, MAE is:20.82 & sMAPE is:38.18% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :32.35 & 17.34% & 0.79\n",
      "for 2022-11-06, MAE is:11.42 & sMAPE is:31.46% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :32.28 & 17.39% & 0.79\n",
      "for 2022-11-07, MAE is:16.79 & sMAPE is:48.68% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :32.23 & 17.49% & 0.79\n",
      "for 2022-11-08, MAE is:16.05 & sMAPE is:33.80% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :32.18 & 17.54% & 0.79\n",
      "for 2022-11-09, MAE is:12.42 & sMAPE is:32.96% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :32.12 & 17.59% & 0.79\n",
      "for 2022-11-10, MAE is:16.16 & sMAPE is:50.61% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :32.06 & 17.69% & 0.79\n",
      "for 2022-11-11, MAE is:25.62 & sMAPE is:175.40% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :32.04 & 18.19% & 0.79\n",
      "for 2022-11-12, MAE is:5.86 & sMAPE is:129.16% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :31.96 & 18.54% & 0.78\n",
      "for 2022-11-13, MAE is:22.17 & sMAPE is:120.14% & rMAE is:2.56 ||| daily mean of MAE & sMAPE & rMAE till now are :31.93 & 18.86% & 0.79\n",
      "for 2022-11-14, MAE is:39.27 & sMAPE is:107.42% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :31.95 & 19.14% & 0.79\n",
      "for 2022-11-15, MAE is:30.13 & sMAPE is:62.35% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :31.95 & 19.28% & 0.80\n",
      "for 2022-11-16, MAE is:5.34 & sMAPE is:19.18% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :31.86 & 19.28% & 0.80\n",
      "for 2022-11-17, MAE is:27.07 & sMAPE is:70.92% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :31.85 & 19.44% & 0.80\n",
      "for 2022-11-18, MAE is:76.96 & sMAPE is:108.25% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :31.99 & 19.72% & 0.80\n",
      "for 2022-11-19, MAE is:69.09 & sMAPE is:53.86% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :32.10 & 19.82% & 0.80\n",
      "for 2022-11-20, MAE is:30.63 & sMAPE is:21.72% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :32.10 & 19.83% & 0.79\n",
      "for 2022-11-21, MAE is:60.98 & sMAPE is:33.04% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :32.19 & 19.87% & 0.79\n",
      "for 2022-11-22, MAE is:33.74 & sMAPE is:21.46% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :32.19 & 19.87% & 0.79\n",
      "for 2022-11-23, MAE is:17.67 & sMAPE is:12.45% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :32.15 & 19.85% & 0.79\n",
      "for 2022-11-24, MAE is:39.16 & sMAPE is:25.76% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :32.17 & 19.87% & 0.79\n",
      "for 2022-11-25, MAE is:40.25 & sMAPE is:22.80% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :32.20 & 19.88% & 0.79\n",
      "for 2022-11-26, MAE is:9.58 & sMAPE is:5.11% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :32.13 & 19.83% & 0.79\n",
      "for 2022-11-27, MAE is:20.29 & sMAPE is:14.38% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :32.09 & 19.82% & 0.79\n",
      "for 2022-11-28, MAE is:52.00 & sMAPE is:29.06% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :32.15 & 19.84% & 0.79\n",
      "for 2022-11-29, MAE is:178.03 & sMAPE is:63.47% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :32.59 & 19.97% & 0.79\n",
      "for 2022-11-30, MAE is:95.79 & sMAPE is:29.05% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :32.78 & 20.00% & 0.79\n",
      "for 2022-12-01, MAE is:64.68 & sMAPE is:19.90% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :32.87 & 20.00% & 0.79\n",
      "for 2022-12-02, MAE is:46.85 & sMAPE is:14.93% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :32.91 & 19.99% & 0.79\n",
      "for 2022-12-03, MAE is:16.37 & sMAPE is:6.21% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :32.87 & 19.94% & 0.79\n",
      "for 2022-12-04, MAE is:31.28 & sMAPE is:11.78% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :32.86 & 19.92% & 0.79\n",
      "for 2022-12-05, MAE is:54.18 & sMAPE is:20.04% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :32.92 & 19.92% & 0.78\n",
      "for 2022-12-06, MAE is:80.39 & sMAPE is:25.74% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :33.06 & 19.94% & 0.79\n",
      "for 2022-12-07, MAE is:54.10 & sMAPE is:17.01% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :33.13 & 19.93% & 0.79\n",
      "for 2022-12-08, MAE is:99.02 & sMAPE is:28.68% & rMAE is:2.62 ||| daily mean of MAE & sMAPE & rMAE till now are :33.32 & 19.96% & 0.79\n",
      "for 2022-12-09, MAE is:84.28 & sMAPE is:22.07% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :33.47 & 19.96% & 0.79\n",
      "for 2022-12-10, MAE is:36.10 & sMAPE is:10.15% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :33.47 & 19.93% & 0.79\n",
      "for 2022-12-11, MAE is:24.26 & sMAPE is:7.25% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :33.45 & 19.90% & 0.79\n",
      "for 2022-12-12, MAE is:123.38 & sMAPE is:30.92% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :33.71 & 19.93% & 0.79\n",
      "for 2022-12-13, MAE is:103.69 & sMAPE is:24.01% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :33.91 & 19.94% & 0.79\n",
      "for 2022-12-14, MAE is:105.81 & sMAPE is:25.15% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :34.12 & 19.95% & 0.79\n",
      "for 2022-12-15, MAE is:58.40 & sMAPE is:15.28% & rMAE is:3.46 ||| daily mean of MAE & sMAPE & rMAE till now are :34.19 & 19.94% & 0.80\n",
      "for 2022-12-16, MAE is:86.50 & sMAPE is:21.89% & rMAE is:3.22 ||| daily mean of MAE & sMAPE & rMAE till now are :34.33 & 19.95% & 0.81\n",
      "for 2022-12-17, MAE is:72.81 & sMAPE is:25.96% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :34.44 & 19.96% & 0.81\n",
      "for 2022-12-18, MAE is:34.41 & sMAPE is:16.77% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :34.44 & 19.95% & 0.81\n",
      "for 2022-12-19, MAE is:45.65 & sMAPE is:24.03% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :34.48 & 19.97% & 0.80\n",
      "for 2022-12-20, MAE is:25.09 & sMAPE is:14.88% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :34.45 & 19.95% & 0.80\n",
      "for 2022-12-21, MAE is:27.81 & sMAPE is:13.53% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :34.43 & 19.93% & 0.80\n",
      "for 2022-12-22, MAE is:16.77 & sMAPE is:8.97% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :34.38 & 19.90% & 0.80\n",
      "for 2022-12-23, MAE is:21.70 & sMAPE is:11.67% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :34.35 & 19.88% & 0.80\n",
      "for 2022-12-24, MAE is:26.88 & sMAPE is:18.87% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :34.32 & 19.88% & 0.80\n",
      "for 2022-12-25, MAE is:10.04 & sMAPE is:8.22% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :34.26 & 19.84% & 0.79\n",
      "for 2022-12-26, MAE is:20.58 & sMAPE is:20.34% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :34.22 & 19.85% & 0.79\n",
      "for 2022-12-27, MAE is:26.54 & sMAPE is:21.22% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :34.20 & 19.85% & 0.79\n",
      "for 2022-12-28, MAE is:15.56 & sMAPE is:13.47% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :34.15 & 19.83% & 0.79\n",
      "for 2022-12-29, MAE is:15.22 & sMAPE is:22.72% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :34.09 & 19.84% & 0.79\n",
      "for 2022-12-30, MAE is:15.82 & sMAPE is:20.90% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :34.04 & 19.84% & 0.79\n",
      "for 2022-12-31, MAE is:37.93 & sMAPE is:40.25% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :34.05 & 19.90% & 0.79\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3 (PC Version - Run on Laptop)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:06:02,858]\u001b[0m A new study created in RDB with name: NO_2_2023\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:06:19,367]\u001b[0m Trial 0 finished with value: 113.9168786146699 and parameters: {'n_hidden': 4, 'learning_rate': 0.015411398377195636, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.026944434287923837, 'dropout_rate_Layer_2': 0.09638497887573566, 'dropout_rate_Layer_3': 0.33287133781863076, 'dropout_rate_Layer_4': 0.2783537690235772, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.005357197008352461, 'l1_Layer_2': 1.0869557132347091e-05, 'l1_Layer_3': 0.006876916793563019, 'l1_Layer_4': 3.0322016846513597e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 195, 'n_units_Layer_3': 55, 'n_units_Layer_4': 285}. Best is trial 0 with value: 113.9168786146699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 113.92 | sMAPE for Validation Set is: 61.26% | rMAE for Validation Set is: 1.89\n",
      "MAE for Test Set is: 19.67 | sMAPE for Test Set is: 24.20% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:06:21,547]\u001b[0m Trial 1 finished with value: 80.13467118350486 and parameters: {'n_hidden': 4, 'learning_rate': 0.0056425207500339, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3204578325800487, 'dropout_rate_Layer_2': 0.025085495847558592, 'dropout_rate_Layer_3': 0.03971222862127832, 'dropout_rate_Layer_4': 0.3650017030546744, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00024562251573837976, 'l1_Layer_2': 0.00525928895412815, 'l1_Layer_3': 1.5509858499604722e-05, 'l1_Layer_4': 0.0005050352273607406, 'n_units_Layer_1': 60, 'n_units_Layer_2': 125, 'n_units_Layer_3': 60, 'n_units_Layer_4': 235}. Best is trial 1 with value: 80.13467118350486.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 80.13 | sMAPE for Validation Set is: 38.87% | rMAE for Validation Set is: 1.33\n",
      "MAE for Test Set is: 29.73 | sMAPE for Test Set is: 33.00% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:06:27,932]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:06:35,099]\u001b[0m Trial 4 finished with value: 81.20017456447833 and parameters: {'n_hidden': 4, 'learning_rate': 0.05963133492207411, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10155733600684465, 'dropout_rate_Layer_2': 0.2002040660654615, 'dropout_rate_Layer_3': 0.13064809762843207, 'dropout_rate_Layer_4': 0.1271736531663333, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.0093232759677168e-05, 'l1_Layer_2': 2.0971004327339183e-05, 'l1_Layer_3': 1.5401621484778412e-05, 'l1_Layer_4': 0.0008102537774915304, 'n_units_Layer_1': 55, 'n_units_Layer_2': 240, 'n_units_Layer_3': 110, 'n_units_Layer_4': 90}. Best is trial 1 with value: 80.13467118350486.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 81.20 | sMAPE for Validation Set is: 39.78% | rMAE for Validation Set is: 1.34\n",
      "MAE for Test Set is: 53.36 | sMAPE for Test Set is: 47.39% | rMAE for Test Set is: 2.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:06:35,482]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:06:38,306]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:06:38,581]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:06:41,681]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:06:43,652]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:06:46,090]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:06:48,379]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:06:50,606]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:07:03,268]\u001b[0m Trial 13 finished with value: 33.08558914928241 and parameters: {'n_hidden': 4, 'learning_rate': 0.008047855953304652, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2676633882222206, 'dropout_rate_Layer_2': 0.011338420622813983, 'dropout_rate_Layer_3': 0.253492580239629, 'dropout_rate_Layer_4': 0.3042466289034892, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00550669126748317, 'l1_Layer_2': 0.05183999037685096, 'l1_Layer_3': 0.0015557158819946054, 'l1_Layer_4': 5.247591536730497e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 130, 'n_units_Layer_3': 70, 'n_units_Layer_4': 270}. Best is trial 13 with value: 33.08558914928241.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.09 | sMAPE for Validation Set is: 19.34% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.57 | sMAPE for Test Set is: 19.11% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:07:06,519]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:07:09,542]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:07:11,887]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:07:14,399]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:07:14,795]\u001b[0m Trial 10 finished with value: 42.308407821346705 and parameters: {'n_hidden': 4, 'learning_rate': 0.0192937825867414, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08536213719724889, 'dropout_rate_Layer_2': 0.28803680312187047, 'dropout_rate_Layer_3': 0.3288658411034068, 'dropout_rate_Layer_4': 0.1209443608896335, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00032198500157358377, 'l1_Layer_2': 1.7310052557674764e-05, 'l1_Layer_3': 0.01938638514302041, 'l1_Layer_4': 0.0006323691975620114, 'n_units_Layer_1': 215, 'n_units_Layer_2': 300, 'n_units_Layer_3': 300, 'n_units_Layer_4': 125}. Best is trial 13 with value: 33.08558914928241.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.31 | sMAPE for Validation Set is: 24.47% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 20.62 | sMAPE for Test Set is: 27.21% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:07:18,264]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:07:20,852]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:07:23,750]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:07:26,675]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:07:30,167]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:07:35,791]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:07:36,040]\u001b[0m Trial 18 finished with value: 67.70073668482915 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005255941386900496, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11240253619263717, 'dropout_rate_Layer_2': 0.37857963985785054, 'dropout_rate_Layer_3': 0.30687554948992557, 'dropout_rate_Layer_4': 0.21743997260105874, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.010587538072649236, 'l1_Layer_2': 1.0973074455780894e-05, 'l1_Layer_3': 0.002615149696202668, 'l1_Layer_4': 0.00693519722373768, 'n_units_Layer_1': 250, 'n_units_Layer_2': 210, 'n_units_Layer_3': 150, 'n_units_Layer_4': 250}. Best is trial 13 with value: 33.08558914928241.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 67.70 | sMAPE for Validation Set is: 31.88% | rMAE for Validation Set is: 1.12\n",
      "MAE for Test Set is: 18.64 | sMAPE for Test Set is: 22.48% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:07:39,318]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:07:44,947]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:07:48,256]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:07:52,191]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:07:57,986]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:08:02,152]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:08:05,217]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:08:07,073]\u001b[0m Trial 28 finished with value: 78.1302224938144 and parameters: {'n_hidden': 3, 'learning_rate': 0.047835604729226634, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32920838431058175, 'dropout_rate_Layer_2': 0.1162387053962998, 'dropout_rate_Layer_3': 0.379230371378988, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009069466796974636, 'l1_Layer_2': 0.003082582215776732, 'l1_Layer_3': 0.0004550454278015315, 'n_units_Layer_1': 300, 'n_units_Layer_2': 95, 'n_units_Layer_3': 75}. Best is trial 13 with value: 33.08558914928241.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 78.13 | sMAPE for Validation Set is: 38.61% | rMAE for Validation Set is: 1.29\n",
      "MAE for Test Set is: 48.53 | sMAPE for Test Set is: 44.52% | rMAE for Test Set is: 2.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:08:09,780]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:08:12,196]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:08:14,260]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:08:16,477]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:08:18,476]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:08:23,529]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:08:23,973]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:08:27,732]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:08:30,235]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:08:32,953]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:08:34,980]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:08:37,588]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:08:39,526]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:08:41,794]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:08:44,590]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:08:47,139]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:08:53,498]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:08:56,248]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:08:59,839]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:09:04,584]\u001b[0m Trial 50 finished with value: 36.25136099219322 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008224235706844128, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17092413465692854, 'dropout_rate_Layer_2': 0.0041295040756569095, 'dropout_rate_Layer_3': 0.39652806790189604, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.5010312347643094e-05, 'l1_Layer_2': 1.897120111150712e-05, 'l1_Layer_3': 0.03115877564073729, 'n_units_Layer_1': 215, 'n_units_Layer_2': 240, 'n_units_Layer_3': 50}. Best is trial 13 with value: 33.08558914928241.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.25 | sMAPE for Validation Set is: 21.24% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 19.12 | sMAPE for Test Set is: 24.89% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:09:11,647]\u001b[0m Trial 53 finished with value: 142.9513806719665 and parameters: {'n_hidden': 4, 'learning_rate': 0.06300455156514495, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3972778590703437, 'dropout_rate_Layer_2': 0.37409105482345756, 'dropout_rate_Layer_3': 0.09809037904245632, 'dropout_rate_Layer_4': 0.1895011705380681, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.010636909862951188, 'l1_Layer_2': 3.6719561491266966e-05, 'l1_Layer_3': 0.0003844723346430312, 'l1_Layer_4': 0.0029834161240213973, 'n_units_Layer_1': 65, 'n_units_Layer_2': 235, 'n_units_Layer_3': 260, 'n_units_Layer_4': 185}. Best is trial 13 with value: 33.08558914928241.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 142.95 | sMAPE for Validation Set is: 87.27% | rMAE for Validation Set is: 2.37\n",
      "MAE for Test Set is: 28.37 | sMAPE for Test Set is: 34.48% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:09:15,625]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:09:19,003]\u001b[0m Trial 54 finished with value: 75.22107574335134 and parameters: {'n_hidden': 3, 'learning_rate': 0.013107056836385782, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06057356729772008, 'dropout_rate_Layer_2': 0.2634160533765255, 'dropout_rate_Layer_3': 0.3156291798555635, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.043151567160247255, 'l1_Layer_2': 4.080039711776452e-05, 'l1_Layer_3': 6.864167505519342e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 110, 'n_units_Layer_3': 50}. Best is trial 13 with value: 33.08558914928241.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 75.22 | sMAPE for Validation Set is: 37.45% | rMAE for Validation Set is: 1.25\n",
      "MAE for Test Set is: 43.72 | sMAPE for Test Set is: 41.84% | rMAE for Test Set is: 1.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:09:23,696]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:09:24,346]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:09:27,577]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:09:30,679]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:09:33,175]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:09:35,442]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:09:37,568]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:09:42,230]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:09:47,303]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:09:53,322]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:09:55,165]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:09:57,663]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:10:03,842]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:10:06,412]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:10:09,759]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:10:14,953]\u001b[0m Trial 61 finished with value: 32.83117236212201 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014988591768520824, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32578955123802794, 'dropout_rate_Layer_2': 0.2527305429769102, 'dropout_rate_Layer_3': 0.290096843040617, 'dropout_rate_Layer_4': 0.2086269682421156, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01043795145377489, 'l1_Layer_2': 0.011754106697410178, 'l1_Layer_3': 0.0009645848001989428, 'l1_Layer_4': 0.0014680587996873723, 'n_units_Layer_1': 280, 'n_units_Layer_2': 55, 'n_units_Layer_3': 50, 'n_units_Layer_4': 190}. Best is trial 61 with value: 32.83117236212201.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.83 | sMAPE for Validation Set is: 19.21% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.43 | sMAPE for Test Set is: 18.79% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:10:18,510]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:10:28,580]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:10:30,583]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:10:33,489]\u001b[0m Trial 73 finished with value: 91.73605019025963 and parameters: {'n_hidden': 4, 'learning_rate': 0.009583304600448168, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22735721471819553, 'dropout_rate_Layer_2': 0.11332440494633036, 'dropout_rate_Layer_3': 0.14835249063726552, 'dropout_rate_Layer_4': 0.341410307236796, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00012536365764390838, 'l1_Layer_2': 0.0007949021675398003, 'l1_Layer_3': 0.0008589135847168248, 'l1_Layer_4': 0.00021794694004033323, 'n_units_Layer_1': 170, 'n_units_Layer_2': 210, 'n_units_Layer_3': 250, 'n_units_Layer_4': 165}. Best is trial 61 with value: 32.83117236212201.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 91.74 | sMAPE for Validation Set is: 46.75% | rMAE for Validation Set is: 1.52\n",
      "MAE for Test Set is: 26.65 | sMAPE for Test Set is: 36.37% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:10:36,355]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:10:36,640]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:10:40,346]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:10:41,381]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:10:44,236]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:10:47,515]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:10:49,314]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:10:51,109]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:10:53,922]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:10:54,009]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:10:59,678]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:10:59,802]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:11:03,704]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:11:05,965]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:11:09,741]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:11:11,903]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:11:16,129]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:11:21,941]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:11:25,009]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:11:29,389]\u001b[0m Trial 94 finished with value: 68.49634462184856 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028935906601024563, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34506180346709625, 'dropout_rate_Layer_2': 0.010403415105415627, 'dropout_rate_Layer_3': 0.03754801872678964, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05055401575627164, 'l1_Layer_2': 0.09895928085281244, 'l1_Layer_3': 8.340443859586724e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 65, 'n_units_Layer_3': 290}. Best is trial 61 with value: 32.83117236212201.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 68.50 | sMAPE for Validation Set is: 32.59% | rMAE for Validation Set is: 1.13\n",
      "MAE for Test Set is: 20.87 | sMAPE for Test Set is: 24.61% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:11:29,577]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:11:39,446]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:11:42,481]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:11:43,024]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:11:46,499]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:11:48,152]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:11:55,871]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:12:32,875]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:12:36,152]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:12:38,519]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:12:41,034]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:12:42,998]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:12:51,014]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:13:00,073]\u001b[0m Trial 108 finished with value: 32.20436321506731 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005359337917512999, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1499359168131192, 'dropout_rate_Layer_2': 0.21779149288358943, 'dropout_rate_Layer_3': 0.3955891689800058, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0741700651250236, 'l1_Layer_2': 1.0947098143348864e-05, 'l1_Layer_3': 0.007485933106905165, 'n_units_Layer_1': 230, 'n_units_Layer_2': 225, 'n_units_Layer_3': 55}. Best is trial 108 with value: 32.20436321506731.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.20 | sMAPE for Validation Set is: 18.80% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.27 | sMAPE for Test Set is: 18.72% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:13:03,496]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:13:13,397]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:13:15,726]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:13:18,403]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:13:21,030]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:13:24,898]\u001b[0m Trial 110 finished with value: 31.851008004817547 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005215312268503316, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1592929149679532, 'dropout_rate_Layer_2': 0.22795315529127527, 'dropout_rate_Layer_3': 0.3997891091651121, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06311532311659414, 'l1_Layer_2': 1.235392426638812e-05, 'l1_Layer_3': 0.006721104229338343, 'n_units_Layer_1': 235, 'n_units_Layer_2': 230, 'n_units_Layer_3': 125}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:13:25,044]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.85 | sMAPE for Validation Set is: 18.78% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.43 | sMAPE for Test Set is: 19.01% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:13:34,995]\u001b[0m Trial 118 finished with value: 32.30346714562544 and parameters: {'n_hidden': 3, 'learning_rate': 0.00277323371843438, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22284695185578635, 'dropout_rate_Layer_2': 0.23282237722767787, 'dropout_rate_Layer_3': 0.21803270824488044, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08264257172154135, 'l1_Layer_2': 0.00010424673338381009, 'l1_Layer_3': 0.00849930404388468, 'n_units_Layer_1': 295, 'n_units_Layer_2': 205, 'n_units_Layer_3': 105}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.30 | sMAPE for Validation Set is: 18.91% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.65 | sMAPE for Test Set is: 19.20% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:13:47,001]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:13:49,713]\u001b[0m Trial 117 finished with value: 32.44838050498476 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012499296057786491, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11723415838756952, 'dropout_rate_Layer_2': 0.07463034777245739, 'dropout_rate_Layer_3': 0.09710353426022714, 'dropout_rate_Layer_4': 0.12142684065645618, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.010995802721295012, 'l1_Layer_2': 0.07552879501499031, 'l1_Layer_3': 0.004309440609404266, 'l1_Layer_4': 1.5843215260926804e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 60, 'n_units_Layer_3': 90, 'n_units_Layer_4': 170}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.45 | sMAPE for Validation Set is: 18.87% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.45 | sMAPE for Test Set is: 18.85% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:13:54,457]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:14:00,760]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:14:07,221]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:14:22,656]\u001b[0m Trial 122 finished with value: 33.40963616885841 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012688395183100688, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09936456429091778, 'dropout_rate_Layer_2': 0.14469601143681676, 'dropout_rate_Layer_3': 0.09776503413664904, 'dropout_rate_Layer_4': 0.12037666549692624, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.009652342586301122, 'l1_Layer_2': 0.0699473921330805, 'l1_Layer_3': 0.00543595427108421, 'l1_Layer_4': 1.4192352514116653e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 60, 'n_units_Layer_3': 65, 'n_units_Layer_4': 165}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.41 | sMAPE for Validation Set is: 19.61% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.88 | sMAPE for Test Set is: 19.49% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:14:28,794]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:14:31,822]\u001b[0m Trial 124 finished with value: 79.21043869129328 and parameters: {'n_hidden': 4, 'learning_rate': 0.003565349683385013, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39210049806512226, 'dropout_rate_Layer_2': 0.3281371655833709, 'dropout_rate_Layer_3': 0.01509040247660462, 'dropout_rate_Layer_4': 0.17258933519123124, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.09480513111795479, 'l1_Layer_2': 0.08559701379355047, 'l1_Layer_3': 0.009547436383333066, 'l1_Layer_4': 0.0004393680911091563, 'n_units_Layer_1': 255, 'n_units_Layer_2': 170, 'n_units_Layer_3': 300, 'n_units_Layer_4': 155}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 79.21 | sMAPE for Validation Set is: 38.28% | rMAE for Validation Set is: 1.31\n",
      "MAE for Test Set is: 17.21 | sMAPE for Test Set is: 22.67% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:14:34,776]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:14:38,115]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:14:41,281]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:14:44,905]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:14:47,233]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:14:48,861]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:14:50,894]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:14:51,446]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:14:56,049]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:14:59,526]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:15:03,682]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:15:05,446]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:15:09,855]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:15:10,245]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:15:13,540]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:15:13,726]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:15:17,598]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:15:17,771]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:15:22,013]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:15:24,743]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:15:28,208]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:15:30,753]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:15:33,363]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:15:36,763]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:15:37,305]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:15:40,713]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:15:43,034]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:15:46,531]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:15:51,705]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:15:52,146]\u001b[0m Trial 153 finished with value: 32.57178190075374 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031052226122164463, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21427489722836057, 'dropout_rate_Layer_2': 0.22814572779582748, 'dropout_rate_Layer_3': 0.2309315164158462, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09394127148332063, 'l1_Layer_2': 7.176175169592316e-05, 'l1_Layer_3': 0.007099307404638527, 'n_units_Layer_1': 300, 'n_units_Layer_2': 185, 'n_units_Layer_3': 110}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.57 | sMAPE for Validation Set is: 19.01% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.90 | sMAPE for Test Set is: 19.24% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:15:55,095]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:15:57,358]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:15:57,487]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:16:02,290]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:16:05,691]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:16:17,615]\u001b[0m Trial 160 finished with value: 36.4513896539602 and parameters: {'n_hidden': 4, 'learning_rate': 0.0045394593939751616, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21375462780086998, 'dropout_rate_Layer_2': 0.1026749065560032, 'dropout_rate_Layer_3': 0.1586011762134865, 'dropout_rate_Layer_4': 0.3279963983109237, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00016419690307118722, 'l1_Layer_2': 1.2180070725014604e-05, 'l1_Layer_3': 0.0022684333387555217, 'l1_Layer_4': 0.0005086554633161128, 'n_units_Layer_1': 300, 'n_units_Layer_2': 140, 'n_units_Layer_3': 260, 'n_units_Layer_4': 145}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.45 | sMAPE for Validation Set is: 20.68% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 15.75 | sMAPE for Test Set is: 20.25% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:16:20,169]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:16:23,846]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:16:26,639]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:16:29,664]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:16:29,940]\u001b[0m Trial 162 finished with value: 36.616294912469456 and parameters: {'n_hidden': 4, 'learning_rate': 0.004843512055497606, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008661109913089576, 'dropout_rate_Layer_2': 0.07807089015771299, 'dropout_rate_Layer_3': 0.14366234380433757, 'dropout_rate_Layer_4': 0.33586832156400326, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0001834189261748187, 'l1_Layer_2': 1.0834480520928262e-05, 'l1_Layer_3': 0.00010312515647261815, 'l1_Layer_4': 0.0005589384984789828, 'n_units_Layer_1': 300, 'n_units_Layer_2': 140, 'n_units_Layer_3': 265, 'n_units_Layer_4': 145}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.62 | sMAPE for Validation Set is: 21.33% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 16.32 | sMAPE for Test Set is: 21.18% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:16:34,090]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:16:34,252]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:16:38,284]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:16:38,549]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:16:51,783]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:16:52,093]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:16:56,021]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:16:59,014]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:17:02,988]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:17:05,404]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:17:08,236]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:17:14,487]\u001b[0m Trial 173 finished with value: 37.52194965059309 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005754578875152147, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21091621551619963, 'dropout_rate_Layer_2': 0.08725301849256098, 'dropout_rate_Layer_3': 0.1598850613883943, 'dropout_rate_Layer_4': 0.3578023055434309, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0001084124482006735, 'l1_Layer_2': 1.3376011687044621e-05, 'l1_Layer_3': 0.0020650865500487325, 'l1_Layer_4': 0.00019381710068785415, 'n_units_Layer_1': 290, 'n_units_Layer_2': 140, 'n_units_Layer_3': 255, 'n_units_Layer_4': 210}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.52 | sMAPE for Validation Set is: 21.60% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 18.49 | sMAPE for Test Set is: 23.66% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:17:20,077]\u001b[0m Trial 179 finished with value: 36.99819038551391 and parameters: {'n_hidden': 4, 'learning_rate': 0.009695952081114952, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37954796553637415, 'dropout_rate_Layer_2': 0.13977437371207851, 'dropout_rate_Layer_3': 0.2849093895999796, 'dropout_rate_Layer_4': 0.17801933678332615, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.9913223753379346e-05, 'l1_Layer_2': 0.002242760622528668, 'l1_Layer_3': 0.0006354897540215684, 'l1_Layer_4': 2.6212928385907565e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 175, 'n_units_Layer_3': 190, 'n_units_Layer_4': 235}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.00 | sMAPE for Validation Set is: 21.20% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 16.30 | sMAPE for Test Set is: 21.30% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:17:26,166]\u001b[0m Trial 180 finished with value: 37.11258486733757 and parameters: {'n_hidden': 4, 'learning_rate': 0.010136149008424801, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36085245513712716, 'dropout_rate_Layer_2': 0.02451191922967859, 'dropout_rate_Layer_3': 0.25864725924316884, 'dropout_rate_Layer_4': 0.3964151402690561, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.001007597167648762, 'l1_Layer_2': 7.906990922906755e-05, 'l1_Layer_3': 0.000523632423209387, 'l1_Layer_4': 2.6434882879872842e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 180, 'n_units_Layer_3': 85, 'n_units_Layer_4': 240}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:17:26,239]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.11 | sMAPE for Validation Set is: 21.38% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 16.58 | sMAPE for Test Set is: 21.26% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:17:31,236]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:17:33,371]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:17:36,745]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:17:38,012]\u001b[0m Trial 182 finished with value: 40.53795241811421 and parameters: {'n_hidden': 4, 'learning_rate': 0.015822897820787017, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39742704507178644, 'dropout_rate_Layer_2': 0.014351126904556435, 'dropout_rate_Layer_3': 0.26127873003751495, 'dropout_rate_Layer_4': 0.1759908762751471, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008473290379801798, 'l1_Layer_2': 0.000560922734565989, 'l1_Layer_3': 0.00029528397793736593, 'l1_Layer_4': 1.0048631940753835e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 165, 'n_units_Layer_3': 215, 'n_units_Layer_4': 230}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.54 | sMAPE for Validation Set is: 23.92% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 19.18 | sMAPE for Test Set is: 24.92% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:17:41,090]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:17:43,556]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:17:46,281]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:17:53,496]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:17:58,665]\u001b[0m Trial 190 finished with value: 38.57916705085356 and parameters: {'n_hidden': 4, 'learning_rate': 0.00577052715996168, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2027684319859976, 'dropout_rate_Layer_2': 0.13626453854655318, 'dropout_rate_Layer_3': 0.11527419284891463, 'dropout_rate_Layer_4': 0.31027463291755686, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.0866571496281297e-05, 'l1_Layer_2': 0.0002638847864065735, 'l1_Layer_3': 0.00020398148378853964, 'l1_Layer_4': 0.00396411186994971, 'n_units_Layer_1': 240, 'n_units_Layer_2': 135, 'n_units_Layer_3': 190, 'n_units_Layer_4': 115}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.58 | sMAPE for Validation Set is: 22.78% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 19.05 | sMAPE for Test Set is: 24.26% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:18:01,364]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:18:04,188]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:18:07,206]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:18:10,066]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:18:12,596]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:18:15,312]\u001b[0m Trial 191 finished with value: 34.91808927157738 and parameters: {'n_hidden': 4, 'learning_rate': 0.015056535697399459, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35685512634052935, 'dropout_rate_Layer_2': 0.0012961225693124967, 'dropout_rate_Layer_3': 0.24971497698235678, 'dropout_rate_Layer_4': 0.10006075669089703, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001250792204701807, 'l1_Layer_2': 0.00030701413214782446, 'l1_Layer_3': 9.793847273137231e-05, 'l1_Layer_4': 1.2001400929496199e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 140, 'n_units_Layer_3': 215, 'n_units_Layer_4': 240}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.92 | sMAPE for Validation Set is: 20.46% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 16.06 | sMAPE for Test Set is: 20.62% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:18:16,836]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:18:20,357]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:18:22,259]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:18:28,212]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:18:33,047]\u001b[0m Trial 200 finished with value: 38.11615764537781 and parameters: {'n_hidden': 4, 'learning_rate': 0.014419810407153026, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3536655935164572, 'dropout_rate_Layer_2': 0.024630023212737346, 'dropout_rate_Layer_3': 0.25035116436384214, 'dropout_rate_Layer_4': 0.08196232845438274, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0012993791458435879, 'l1_Layer_2': 0.0002637540308459045, 'l1_Layer_3': 9.704640147298868e-05, 'l1_Layer_4': 1.2833849244109477e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 135, 'n_units_Layer_3': 200, 'n_units_Layer_4': 240}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.12 | sMAPE for Validation Set is: 21.88% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 17.08 | sMAPE for Test Set is: 22.30% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:18:36,074]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:18:36,319]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:18:39,434]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:18:39,607]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:18:43,831]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:18:45,531]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:18:46,080]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:18:50,230]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:18:55,960]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:19:05,424]\u001b[0m Trial 212 finished with value: 36.79173621788372 and parameters: {'n_hidden': 4, 'learning_rate': 0.017397547927119304, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3513636296893672, 'dropout_rate_Layer_2': 0.03015357880750727, 'dropout_rate_Layer_3': 0.2779043430303571, 'dropout_rate_Layer_4': 0.025225604184348743, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00794822947839878, 'l1_Layer_2': 0.00010956449211781693, 'l1_Layer_3': 0.0003150926705295458, 'l1_Layer_4': 1.9382031051899335e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 155, 'n_units_Layer_3': 210, 'n_units_Layer_4': 225}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.79 | sMAPE for Validation Set is: 21.24% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 16.22 | sMAPE for Test Set is: 21.03% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:19:09,257]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:19:13,284]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:19:17,908]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:19:19,931]\u001b[0m Trial 211 finished with value: 33.0161720891727 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012748336019376633, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1304218717900287, 'dropout_rate_Layer_2': 0.036876609360382694, 'dropout_rate_Layer_3': 0.2474176553991368, 'dropout_rate_Layer_4': 0.18533681750876105, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.016338607502780024, 'l1_Layer_2': 0.03352042375754211, 'l1_Layer_3': 0.002026250847853686, 'l1_Layer_4': 1.572081991998988e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 50, 'n_units_Layer_3': 90, 'n_units_Layer_4': 155}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.02 | sMAPE for Validation Set is: 19.09% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.56 | sMAPE for Test Set is: 18.81% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:19:22,541]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:19:28,836]\u001b[0m Trial 218 finished with value: 37.18614116186425 and parameters: {'n_hidden': 4, 'learning_rate': 0.01573928316519996, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38304134635629483, 'dropout_rate_Layer_2': 0.025671499409884724, 'dropout_rate_Layer_3': 0.3171783368046018, 'dropout_rate_Layer_4': 0.02790040754383901, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.023110631717930437, 'l1_Layer_2': 0.00039479815479603273, 'l1_Layer_3': 0.00031488050843723927, 'l1_Layer_4': 1.930757505430029e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 165, 'n_units_Layer_3': 215, 'n_units_Layer_4': 230}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.19 | sMAPE for Validation Set is: 21.98% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 17.14 | sMAPE for Test Set is: 22.15% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:19:32,373]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:19:34,687]\u001b[0m Trial 217 finished with value: 37.349575202447305 and parameters: {'n_hidden': 4, 'learning_rate': 0.017799330113970568, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38637571587772335, 'dropout_rate_Layer_2': 0.019925833172588874, 'dropout_rate_Layer_3': 0.3135455416344062, 'dropout_rate_Layer_4': 0.020423688394040095, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02338206605758623, 'l1_Layer_2': 0.0004919558444486647, 'l1_Layer_3': 0.0003182239585317887, 'l1_Layer_4': 1.7504436855296082e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 160, 'n_units_Layer_3': 215, 'n_units_Layer_4': 225}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.35 | sMAPE for Validation Set is: 21.52% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 15.63 | sMAPE for Test Set is: 20.21% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:19:36,402]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:19:39,427]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:19:41,988]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:19:44,148]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:19:46,392]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:19:52,310]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:19:56,262]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:19:59,381]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:20:04,323]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:20:06,511]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:20:09,726]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:20:10,334]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:20:13,674]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:20:16,525]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:20:19,542]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:20:22,322]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:20:24,851]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:20:27,943]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:20:28,053]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:20:32,024]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:20:32,118]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:20:38,462]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:20:38,540]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:20:42,220]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:20:42,517]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:20:46,834]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:20:47,193]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:20:54,704]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:20:57,540]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:21:00,072]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:21:03,116]\u001b[0m Trial 248 finished with value: 35.72442707992355 and parameters: {'n_hidden': 4, 'learning_rate': 0.011943206164872655, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34074877547721777, 'dropout_rate_Layer_2': 0.04897002496616637, 'dropout_rate_Layer_3': 0.21000169709817298, 'dropout_rate_Layer_4': 0.05903052342043992, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03765865853754236, 'l1_Layer_2': 0.0014663108541150337, 'l1_Layer_3': 0.0004948933674385128, 'l1_Layer_4': 1.7930068007306058e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 200, 'n_units_Layer_3': 240, 'n_units_Layer_4': 265}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.72 | sMAPE for Validation Set is: 21.08% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 16.07 | sMAPE for Test Set is: 21.41% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:21:07,729]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:21:11,577]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:21:14,456]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:21:16,945]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:21:17,224]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:21:21,283]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:21:21,718]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:21:25,884]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:21:28,369]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:21:31,662]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:21:36,515]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:21:39,763]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:21:42,704]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:21:45,172]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:21:48,114]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:21:50,613]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:21:50,733]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:21:56,491]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:21:56,572]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:22:01,044]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:22:03,510]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:22:09,247]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:22:11,559]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:22:13,771]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:22:16,008]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:22:18,963]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:22:22,070]\u001b[0m Trial 271 finished with value: 33.24384027348773 and parameters: {'n_hidden': 4, 'learning_rate': 0.00711057558815442, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29814783015999785, 'dropout_rate_Layer_2': 0.020750614305186477, 'dropout_rate_Layer_3': 0.23327813881245987, 'dropout_rate_Layer_4': 0.017975685909643088, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03960597928907672, 'l1_Layer_2': 0.0007188152962480988, 'l1_Layer_3': 0.001563249946794765, 'l1_Layer_4': 8.378166460257111e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 185, 'n_units_Layer_3': 255, 'n_units_Layer_4': 215}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.24 | sMAPE for Validation Set is: 19.26% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.53 | sMAPE for Test Set is: 18.87% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:22:25,801]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:22:29,392]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:22:34,631]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:22:38,604]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:22:41,699]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:22:44,112]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:22:47,128]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:22:50,409]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:22:54,289]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:22:56,668]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:22:59,055]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:23:02,662]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:23:06,434]\u001b[0m Trial 281 finished with value: 36.0191650462639 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005139337357242093, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20731126821990703, 'dropout_rate_Layer_2': 0.11933771785051633, 'dropout_rate_Layer_3': 0.1438090148429069, 'dropout_rate_Layer_4': 0.38077176405555824, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00012361683428802872, 'l1_Layer_2': 1.0764840499144158e-05, 'l1_Layer_3': 0.002503029122295861, 'l1_Layer_4': 0.00014228622689464778, 'n_units_Layer_1': 300, 'n_units_Layer_2': 150, 'n_units_Layer_3': 240, 'n_units_Layer_4': 240}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.02 | sMAPE for Validation Set is: 20.79% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 16.83 | sMAPE for Test Set is: 21.69% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:23:10,739]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:23:12,611]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:23:13,647]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:23:18,106]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:23:20,277]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:23:20,511]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:23:24,736]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:23:25,070]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:23:29,629]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:23:31,916]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:23:34,675]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:23:37,679]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:23:45,839]\u001b[0m Trial 301 finished with value: 34.161795220297364 and parameters: {'n_hidden': 4, 'learning_rate': 0.004095402595497905, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3126639935387159, 'dropout_rate_Layer_2': 0.03640993551785281, 'dropout_rate_Layer_3': 0.23476121502381417, 'dropout_rate_Layer_4': 0.14030543715167065, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003762426614517821, 'l1_Layer_2': 0.003248700145350427, 'l1_Layer_3': 0.003806001188243382, 'l1_Layer_4': 4.365067287899061e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 185, 'n_units_Layer_3': 250, 'n_units_Layer_4': 215}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.16 | sMAPE for Validation Set is: 19.84% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 15.27 | sMAPE for Test Set is: 19.93% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:23:48,871]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:23:52,556]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:23:55,004]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:24:04,379]\u001b[0m Trial 306 finished with value: 37.024797082284756 and parameters: {'n_hidden': 4, 'learning_rate': 0.000540618791931402, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1758587424015512, 'dropout_rate_Layer_2': 0.15983262272631676, 'dropout_rate_Layer_3': 0.130521337050673, 'dropout_rate_Layer_4': 0.3545759760177451, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00015280659270870141, 'l1_Layer_2': 2.194819724842665e-05, 'l1_Layer_3': 0.00496788536110149, 'l1_Layer_4': 0.0006155518686529124, 'n_units_Layer_1': 240, 'n_units_Layer_2': 200, 'n_units_Layer_3': 235, 'n_units_Layer_4': 300}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.02 | sMAPE for Validation Set is: 21.31% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 17.48 | sMAPE for Test Set is: 22.45% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:24:06,938]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:24:07,211]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:24:14,715]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:24:17,424]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:24:24,227]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:24:27,663]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:24:30,107]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:24:31,887]\u001b[0m Trial 313 finished with value: 36.68834106726353 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020681096225010145, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22368461701612158, 'dropout_rate_Layer_2': 0.11158292615842921, 'dropout_rate_Layer_3': 0.06568789136686264, 'dropout_rate_Layer_4': 0.38863898183811546, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0004489879184198474, 'l1_Layer_2': 1.0574792638367233e-05, 'l1_Layer_3': 0.005432856232765179, 'l1_Layer_4': 0.0017991736529573922, 'n_units_Layer_1': 285, 'n_units_Layer_2': 195, 'n_units_Layer_3': 210, 'n_units_Layer_4': 90}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.69 | sMAPE for Validation Set is: 20.86% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 16.68 | sMAPE for Test Set is: 21.92% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:24:34,336]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:24:34,551]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:24:39,323]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:24:43,232]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:24:46,249]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:24:50,926]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:24:54,177]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:24:56,633]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:24:59,157]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:25:02,876]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:25:07,945]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:25:10,657]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:25:13,047]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:25:17,970]\u001b[0m Trial 324 finished with value: 33.408369461410096 and parameters: {'n_hidden': 4, 'learning_rate': 0.003500063590413014, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3457204467769251, 'dropout_rate_Layer_2': 0.028475899107528846, 'dropout_rate_Layer_3': 0.21107545817878476, 'dropout_rate_Layer_4': 0.07202892222983945, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.011637156991330767, 'l1_Layer_2': 0.00020522304005979883, 'l1_Layer_3': 0.001624394526145424, 'l1_Layer_4': 1.4214621070600986e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 195, 'n_units_Layer_3': 260, 'n_units_Layer_4': 255}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.41 | sMAPE for Validation Set is: 19.56% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.76 | sMAPE for Test Set is: 19.36% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:25:20,820]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:25:26,078]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:25:29,103]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:25:31,721]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:25:35,534]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:25:38,426]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:25:40,851]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:25:43,187]\u001b[0m Trial 332 finished with value: 33.24936835370473 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021353342501250453, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34534026507943255, 'dropout_rate_Layer_2': 0.041737763473595015, 'dropout_rate_Layer_3': 0.23129036358048854, 'dropout_rate_Layer_4': 0.1076990323214742, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.007945745659357505, 'l1_Layer_2': 0.002621315235464893, 'l1_Layer_3': 0.003944653697891149, 'l1_Layer_4': 1.309054132015284e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 215, 'n_units_Layer_3': 290, 'n_units_Layer_4': 265}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.25 | sMAPE for Validation Set is: 19.13% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.40 | sMAPE for Test Set is: 18.68% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:25:43,821]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:25:47,099]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:25:49,999]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:25:55,957]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:25:58,941]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:26:12,033]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:26:14,638]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:26:20,937]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:26:28,370]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:26:36,958]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:26:39,813]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:26:50,481]\u001b[0m Trial 347 finished with value: 32.84230531640116 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014619540101284902, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09490915426062374, 'dropout_rate_Layer_2': 0.05034833358730369, 'dropout_rate_Layer_3': 0.2714217221411547, 'dropout_rate_Layer_4': 0.1880688927586567, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.012138729753945456, 'l1_Layer_2': 0.05025813900549929, 'l1_Layer_3': 0.0013870669716270752, 'l1_Layer_4': 0.0005649165718416418, 'n_units_Layer_1': 100, 'n_units_Layer_2': 55, 'n_units_Layer_3': 110, 'n_units_Layer_4': 155}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.84 | sMAPE for Validation Set is: 19.12% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.56 | sMAPE for Test Set is: 18.93% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:27:00,394]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:27:07,440]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:27:11,458]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:27:21,305]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:27:24,648]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:27:26,879]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:27:28,896]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:27:37,692]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:27:42,128]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:27:42,302]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:27:46,266]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:27:49,548]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:27:52,901]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:27:53,545]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:27:58,775]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:28:09,126]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:28:14,280]\u001b[0m Trial 366 finished with value: 36.64164367667124 and parameters: {'n_hidden': 4, 'learning_rate': 0.002373788623453425, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17903004760323757, 'dropout_rate_Layer_2': 0.2321592399288236, 'dropout_rate_Layer_3': 0.1466630977512458, 'dropout_rate_Layer_4': 0.374632589093182, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 8.061081562113976e-05, 'l1_Layer_2': 3.671406878867349e-05, 'l1_Layer_3': 0.00453575468365252, 'l1_Layer_4': 0.00027212312450030946, 'n_units_Layer_1': 285, 'n_units_Layer_2': 155, 'n_units_Layer_3': 275, 'n_units_Layer_4': 95}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.64 | sMAPE for Validation Set is: 20.90% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 17.47 | sMAPE for Test Set is: 22.35% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:28:18,264]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:28:22,729]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:28:24,455]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:28:26,133]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:28:28,881]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:28:30,842]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:28:33,480]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:28:37,533]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:28:39,409]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:28:42,576]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:28:45,017]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:28:49,324]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:28:52,871]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:28:56,115]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:28:56,241]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:29:00,099]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:29:07,134]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:29:08,595]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:29:10,891]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:29:13,866]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:29:13,987]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:29:19,453]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:29:22,669]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:29:25,966]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:29:29,822]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:29:32,270]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:29:35,589]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:29:38,250]\u001b[0m Trial 388 finished with value: 33.08176595351106 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015634394050381302, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25797713620789947, 'dropout_rate_Layer_2': 0.055610964998589085, 'dropout_rate_Layer_3': 0.22172935428420262, 'dropout_rate_Layer_4': 0.22280745063142082, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0665036755967875, 'l1_Layer_2': 0.0009260774685126165, 'l1_Layer_3': 0.00015030062662724257, 'l1_Layer_4': 3.890188324502474e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 115, 'n_units_Layer_3': 140, 'n_units_Layer_4': 230}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.08 | sMAPE for Validation Set is: 19.25% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.38 | sMAPE for Test Set is: 18.71% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:29:40,913]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:29:43,631]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:29:47,843]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:29:53,011]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:29:59,043]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:30:09,014]\u001b[0m Trial 397 finished with value: 33.05481913800791 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011651683163181252, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18686056449384866, 'dropout_rate_Layer_2': 0.2997654378922071, 'dropout_rate_Layer_3': 0.2047579809898274, 'dropout_rate_Layer_4': 0.33384564747946377, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0007370260918786192, 'l1_Layer_2': 1.8437295916086936e-05, 'l1_Layer_3': 0.016785412628031248, 'l1_Layer_4': 3.2374735737850525e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 150, 'n_units_Layer_3': 265, 'n_units_Layer_4': 105}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.05 | sMAPE for Validation Set is: 19.25% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.40 | sMAPE for Test Set is: 18.89% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:30:12,553]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:30:16,194]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:30:16,467]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:30:20,946]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:30:22,517]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:30:26,094]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:30:36,007]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:30:38,455]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:30:41,938]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:30:55,439]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:30:59,748]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:31:02,383]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:31:05,922]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:31:06,016]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:31:10,047]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:31:17,279]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:31:21,127]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:31:24,051]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:31:25,361]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:31:29,229]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:31:34,972]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:31:38,069]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:31:40,856]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:32:03,083]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:32:05,666]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:32:07,743]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:32:11,198]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:32:13,363]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:32:17,554]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:32:20,900]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:32:26,695]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:32:28,456]\u001b[0m Trial 430 finished with value: 33.80568953616437 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016867701393600658, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3770279232623191, 'dropout_rate_Layer_2': 0.026741236128409923, 'dropout_rate_Layer_3': 0.27947299739882103, 'dropout_rate_Layer_4': 0.026065481740940227, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03057090684171793, 'l1_Layer_2': 0.0004969499280189283, 'l1_Layer_3': 0.0003991460665235145, 'l1_Layer_4': 1.2108772865920462e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 185, 'n_units_Layer_3': 145, 'n_units_Layer_4': 225}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.81 | sMAPE for Validation Set is: 19.54% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.67 | sMAPE for Test Set is: 18.96% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:32:30,751]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:32:34,423]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:32:36,735]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:32:39,432]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:32:44,579]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:32:50,467]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:32:52,816]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:32:54,677]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:32:57,180]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:33:03,127]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:33:37,730]\u001b[0m Trial 444 finished with value: 32.20066832951661 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015093407791694075, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11359566876249763, 'dropout_rate_Layer_2': 0.2848653290136674, 'dropout_rate_Layer_3': 0.26514184339272345, 'dropout_rate_Layer_4': 0.19641960107731124, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.014956191576927718, 'l1_Layer_2': 0.0003740793863538906, 'l1_Layer_3': 0.000978955769459345, 'l1_Layer_4': 8.135248937810914e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 55, 'n_units_Layer_3': 125, 'n_units_Layer_4': 175}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.20 | sMAPE for Validation Set is: 18.86% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.15 | sMAPE for Test Set is: 18.54% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:33:42,897]\u001b[0m Trial 441 finished with value: 32.37492571082972 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014659811372726055, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09651060070864036, 'dropout_rate_Layer_2': 0.0026800049716912827, 'dropout_rate_Layer_3': 0.3802843408860146, 'dropout_rate_Layer_4': 0.35913180782123877, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02439312014041813, 'l1_Layer_2': 0.08445548746539666, 'l1_Layer_3': 0.0010301182509447457, 'l1_Layer_4': 0.0012960787395070263, 'n_units_Layer_1': 105, 'n_units_Layer_2': 60, 'n_units_Layer_3': 105, 'n_units_Layer_4': 190}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.37 | sMAPE for Validation Set is: 18.87% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.38 | sMAPE for Test Set is: 18.69% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:33:44,672]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:33:48,293]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:33:51,053]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:33:54,625]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:33:57,416]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:34:00,888]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:34:02,814]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:34:04,352]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:34:16,942]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:34:31,053]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:34:33,092]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:34:43,636]\u001b[0m Trial 456 finished with value: 33.825780560723906 and parameters: {'n_hidden': 4, 'learning_rate': 0.002154680328287803, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3400831364765249, 'dropout_rate_Layer_2': 0.021290387968044628, 'dropout_rate_Layer_3': 0.2568248328065241, 'dropout_rate_Layer_4': 0.18468474792404607, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.035054652176816754, 'l1_Layer_2': 0.0019182143695192114, 'l1_Layer_3': 0.0005393449300484641, 'l1_Layer_4': 4.043567470318023e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 200, 'n_units_Layer_3': 140, 'n_units_Layer_4': 230}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.83 | sMAPE for Validation Set is: 19.71% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.52 | sMAPE for Test Set is: 18.81% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:34:47,079]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:34:48,714]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:34:51,502]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:34:52,883]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:34:58,555]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:35:07,371]\u001b[0m Trial 462 finished with value: 35.89182674740724 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007161995823913897, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07154609322130698, 'dropout_rate_Layer_2': 0.3053614160035882, 'dropout_rate_Layer_3': 0.10586398594179017, 'dropout_rate_Layer_4': 0.2330643201324732, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006860000206420816, 'l1_Layer_2': 5.397682095883532e-05, 'l1_Layer_3': 0.00036217214542322437, 'l1_Layer_4': 1.1049807293546813e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 55, 'n_units_Layer_3': 230, 'n_units_Layer_4': 110}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.89 | sMAPE for Validation Set is: 20.84% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 15.58 | sMAPE for Test Set is: 20.46% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:35:23,038]\u001b[0m Trial 463 finished with value: 32.65127019466967 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011329159935164568, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07256201947222515, 'dropout_rate_Layer_2': 0.015524733609483837, 'dropout_rate_Layer_3': 0.03135337349308524, 'dropout_rate_Layer_4': 0.37064200091214516, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.026871287317332602, 'l1_Layer_2': 0.0049698971513657715, 'l1_Layer_3': 0.0008046668375834123, 'l1_Layer_4': 5.119448869405583e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 50, 'n_units_Layer_3': 130, 'n_units_Layer_4': 180}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.65 | sMAPE for Validation Set is: 19.12% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.56 | sMAPE for Test Set is: 18.81% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:35:25,651]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:35:26,880]\u001b[0m Trial 464 finished with value: 32.729519922813225 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006438264472462535, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06762623957413527, 'dropout_rate_Layer_2': 0.32286543740221185, 'dropout_rate_Layer_3': 0.10005141116129662, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009993622455186705, 'l1_Layer_2': 5.9022984285186185e-05, 'l1_Layer_3': 0.0005936432898770196, 'n_units_Layer_1': 230, 'n_units_Layer_2': 50, 'n_units_Layer_3': 225}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.73 | sMAPE for Validation Set is: 19.09% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.44 | sMAPE for Test Set is: 18.99% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:35:30,134]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:35:30,534]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:35:34,438]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:35:37,325]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:35:50,974]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:36:12,244]\u001b[0m Trial 472 finished with value: 32.96816890577031 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007478081947105041, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06818797738236967, 'dropout_rate_Layer_2': 0.31385732578152914, 'dropout_rate_Layer_3': 0.10249026132779074, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007451345680298757, 'l1_Layer_2': 6.30462299880047e-05, 'l1_Layer_3': 0.00039311984268185993, 'n_units_Layer_1': 200, 'n_units_Layer_2': 50, 'n_units_Layer_3': 225}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.97 | sMAPE for Validation Set is: 19.24% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.64 | sMAPE for Test Set is: 19.07% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:36:18,999]\u001b[0m Trial 468 finished with value: 31.917421703652735 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012053859014083165, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12450648565440939, 'dropout_rate_Layer_2': 0.003502654180955291, 'dropout_rate_Layer_3': 0.06750577295900041, 'dropout_rate_Layer_4': 0.364073719845099, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02609707671502663, 'l1_Layer_2': 0.04247357226292868, 'l1_Layer_3': 0.0009338741772949049, 'l1_Layer_4': 0.00011103870647861693, 'n_units_Layer_1': 105, 'n_units_Layer_2': 55, 'n_units_Layer_3': 125, 'n_units_Layer_4': 180}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.92 | sMAPE for Validation Set is: 18.65% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.09 | sMAPE for Test Set is: 18.40% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:36:22,350]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:36:24,745]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:36:27,274]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:36:30,978]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:36:35,582]\u001b[0m Trial 473 finished with value: 32.91209842409946 and parameters: {'n_hidden': 4, 'learning_rate': 0.0031420125542292563, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29956368441946507, 'dropout_rate_Layer_2': 0.0481830943173025, 'dropout_rate_Layer_3': 0.24960355666162212, 'dropout_rate_Layer_4': 0.19162337222156026, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.009047960932747979, 'l1_Layer_2': 0.00033133244580346114, 'l1_Layer_3': 0.0001852766600885443, 'l1_Layer_4': 5.657901243945375e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 200, 'n_units_Layer_3': 130, 'n_units_Layer_4': 225}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.91 | sMAPE for Validation Set is: 19.26% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.27 | sMAPE for Test Set is: 18.61% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:36:38,267]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:36:42,061]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:36:47,751]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:36:50,372]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:36:52,932]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:36:55,758]\u001b[0m Trial 478 finished with value: 32.90427642616813 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007687389895410817, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06816010212181503, 'dropout_rate_Layer_2': 0.31718348557772, 'dropout_rate_Layer_3': 0.10229846082335618, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008644216780012794, 'l1_Layer_2': 6.64049908891882e-05, 'l1_Layer_3': 0.0003346968121815699, 'n_units_Layer_1': 190, 'n_units_Layer_2': 50, 'n_units_Layer_3': 225}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.90 | sMAPE for Validation Set is: 19.05% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.59 | sMAPE for Test Set is: 18.95% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:36:56,169]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:37:00,226]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:37:06,902]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:37:10,387]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:37:13,419]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:37:16,767]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:37:19,747]\u001b[0m Trial 486 finished with value: 32.30637024881065 and parameters: {'n_hidden': 4, 'learning_rate': 0.002887943976910019, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2997470851042416, 'dropout_rate_Layer_2': 0.035075635724681385, 'dropout_rate_Layer_3': 0.20971410236472754, 'dropout_rate_Layer_4': 0.15710079779744807, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.012246420337116502, 'l1_Layer_2': 0.0002846420378849317, 'l1_Layer_3': 7.202908548366836e-05, 'l1_Layer_4': 5.3445891752865406e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 190, 'n_units_Layer_3': 125, 'n_units_Layer_4': 215}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.31 | sMAPE for Validation Set is: 18.85% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.38 | sMAPE for Test Set is: 18.78% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:37:20,087]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:37:26,880]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:37:28,227]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:37:32,678]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:37:34,800]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:37:38,104]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:37:40,261]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:37:44,143]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:37:53,601]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:38:05,647]\u001b[0m Trial 500 finished with value: 32.19828417104937 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009762376838621227, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12361721359729776, 'dropout_rate_Layer_2': 0.26125078120212974, 'dropout_rate_Layer_3': 0.3811894717085419, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.028620018447588585, 'l1_Layer_2': 0.00022458591210403945, 'l1_Layer_3': 0.06130475445019898, 'n_units_Layer_1': 220, 'n_units_Layer_2': 210, 'n_units_Layer_3': 275}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.20 | sMAPE for Validation Set is: 18.85% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.53 | sMAPE for Test Set is: 18.98% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:38:12,789]\u001b[0m Trial 501 finished with value: 33.117739521855526 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012548165836634222, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31394592154666734, 'dropout_rate_Layer_2': 0.01591211618192672, 'dropout_rate_Layer_3': 0.2106357887120809, 'dropout_rate_Layer_4': 0.008986002304950266, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01350439348162717, 'l1_Layer_2': 0.00029898045790727017, 'l1_Layer_3': 0.00025595538528994425, 'l1_Layer_4': 0.006325285500202882, 'n_units_Layer_1': 190, 'n_units_Layer_2': 95, 'n_units_Layer_3': 135, 'n_units_Layer_4': 200}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.12 | sMAPE for Validation Set is: 19.31% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.80 | sMAPE for Test Set is: 19.16% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:38:15,734]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:38:26,116]\u001b[0m Trial 502 finished with value: 33.076090109980974 and parameters: {'n_hidden': 3, 'learning_rate': 0.000691481803043296, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07175248431759286, 'dropout_rate_Layer_2': 0.3140280663981438, 'dropout_rate_Layer_3': 0.09505166471579889, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0062054659282410555, 'l1_Layer_2': 6.344464488625858e-05, 'l1_Layer_3': 0.0002924403875363276, 'n_units_Layer_1': 185, 'n_units_Layer_2': 55, 'n_units_Layer_3': 220}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.08 | sMAPE for Validation Set is: 19.24% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.56 | sMAPE for Test Set is: 19.05% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:38:35,769]\u001b[0m Trial 504 finished with value: 32.50579845498172 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012321726068762423, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3175603270097516, 'dropout_rate_Layer_2': 0.01023503763254624, 'dropout_rate_Layer_3': 0.21259962664556678, 'dropout_rate_Layer_4': 0.020081700750642605, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.013075633262104085, 'l1_Layer_2': 0.000444449027400554, 'l1_Layer_3': 0.00011078696828378255, 'l1_Layer_4': 0.0009642315470762629, 'n_units_Layer_1': 190, 'n_units_Layer_2': 95, 'n_units_Layer_3': 145, 'n_units_Layer_4': 175}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.51 | sMAPE for Validation Set is: 19.01% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.08 | sMAPE for Test Set is: 18.50% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:38:42,699]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:38:45,585]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:38:50,852]\u001b[0m Trial 505 finished with value: 32.63146730436737 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011805252252050599, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2720194360766526, 'dropout_rate_Layer_2': 0.005857939640905011, 'dropout_rate_Layer_3': 0.21088821047015266, 'dropout_rate_Layer_4': 0.1623581996346663, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.013745478872467671, 'l1_Layer_2': 0.00045847059307475683, 'l1_Layer_3': 0.00011548898188468985, 'l1_Layer_4': 0.0006821994402257843, 'n_units_Layer_1': 190, 'n_units_Layer_2': 100, 'n_units_Layer_3': 145, 'n_units_Layer_4': 175}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.63 | sMAPE for Validation Set is: 19.05% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.30 | sMAPE for Test Set is: 18.71% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:38:53,560]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:38:57,467]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:39:15,808]\u001b[0m Trial 510 finished with value: 32.39728953447977 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007075439220090016, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07136443337655426, 'dropout_rate_Layer_2': 0.3435324308930896, 'dropout_rate_Layer_3': 0.08459431224539796, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.015599199562269614, 'l1_Layer_2': 0.0002866851942905871, 'l1_Layer_3': 0.0005709436828451814, 'n_units_Layer_1': 190, 'n_units_Layer_2': 75, 'n_units_Layer_3': 190}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.40 | sMAPE for Validation Set is: 19.01% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.52 | sMAPE for Test Set is: 19.05% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:39:20,263]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:39:27,427]\u001b[0m Trial 511 finished with value: 33.003125013514826 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015581937504768877, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10990473661467248, 'dropout_rate_Layer_2': 0.009787308835824123, 'dropout_rate_Layer_3': 0.12279656187011306, 'dropout_rate_Layer_4': 0.3421651509419537, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.009844745308392012, 'l1_Layer_2': 0.0009493282348972677, 'l1_Layer_3': 0.005194851969956562, 'l1_Layer_4': 6.605958407498698e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 55, 'n_units_Layer_3': 120, 'n_units_Layer_4': 190}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.00 | sMAPE for Validation Set is: 19.23% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.45 | sMAPE for Test Set is: 18.91% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:39:30,824]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:39:34,629]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:39:34,673]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:39:38,749]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:39:51,524]\u001b[0m Trial 516 finished with value: 32.32764958825413 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011977245723898482, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12066987331162743, 'dropout_rate_Layer_2': 0.3445302778842654, 'dropout_rate_Layer_3': 0.0015338749235272453, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01645929641878335, 'l1_Layer_2': 0.00029277211833018935, 'l1_Layer_3': 0.0006214614137847891, 'n_units_Layer_1': 205, 'n_units_Layer_2': 75, 'n_units_Layer_3': 180}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.33 | sMAPE for Validation Set is: 18.77% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.30 | sMAPE for Test Set is: 18.68% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:39:56,393]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:39:59,640]\u001b[0m Trial 518 finished with value: 32.43276528224044 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011556017189239718, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11894157697226232, 'dropout_rate_Layer_2': 0.33904201821630947, 'dropout_rate_Layer_3': 0.029050428499239972, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.018957144887419432, 'l1_Layer_2': 0.00034045450343650734, 'l1_Layer_3': 0.0005932596546840964, 'n_units_Layer_1': 155, 'n_units_Layer_2': 75, 'n_units_Layer_3': 185}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.43 | sMAPE for Validation Set is: 18.90% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.21 | sMAPE for Test Set is: 18.61% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:40:03,360]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:40:06,168]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:40:09,215]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:40:14,446]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:40:16,572]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:40:19,350]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:40:24,673]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:40:29,922]\u001b[0m Trial 524 finished with value: 33.03467691627294 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013062446574303819, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2734783436513643, 'dropout_rate_Layer_2': 0.0008102331828964277, 'dropout_rate_Layer_3': 0.21794249699719626, 'dropout_rate_Layer_4': 0.1471800248993294, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.023497904724652834, 'l1_Layer_2': 0.00031988277874602747, 'l1_Layer_3': 8.387389605001416e-05, 'l1_Layer_4': 7.254011973000723e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 105, 'n_units_Layer_3': 130, 'n_units_Layer_4': 170}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.03 | sMAPE for Validation Set is: 19.30% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.29 | sMAPE for Test Set is: 18.80% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:40:32,744]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:40:35,874]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:40:46,897]\u001b[0m Trial 530 finished with value: 32.803464780357736 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011932294136541713, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3127625436100997, 'dropout_rate_Layer_2': 0.00807290158646716, 'dropout_rate_Layer_3': 0.21605816076056605, 'dropout_rate_Layer_4': 0.14838147509987812, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.020484738809233575, 'l1_Layer_2': 0.0001747314399612343, 'l1_Layer_3': 8.021870403253814e-05, 'l1_Layer_4': 0.012382134834609681, 'n_units_Layer_1': 205, 'n_units_Layer_2': 100, 'n_units_Layer_3': 130, 'n_units_Layer_4': 185}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.80 | sMAPE for Validation Set is: 19.15% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.57 | sMAPE for Test Set is: 19.20% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:40:49,339]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:40:49,961]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:40:52,729]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:40:55,159]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:41:08,773]\u001b[0m Trial 536 finished with value: 32.717554540070296 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014148992589954005, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04036241208113689, 'dropout_rate_Layer_2': 0.3502872797437613, 'dropout_rate_Layer_3': 0.03907996505880445, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.021670031999324043, 'l1_Layer_2': 0.0009223814203135762, 'l1_Layer_3': 0.0005777298204163937, 'n_units_Layer_1': 200, 'n_units_Layer_2': 75, 'n_units_Layer_3': 185}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.72 | sMAPE for Validation Set is: 19.00% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.45 | sMAPE for Test Set is: 18.87% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:41:20,932]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:41:24,300]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:41:27,755]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:41:31,565]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:41:34,910]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:41:39,455]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:41:41,456]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:41:42,980]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:41:45,326]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:41:49,173]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:41:51,183]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:41:51,852]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:41:56,078]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:41:59,178]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:42:04,092]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:42:06,392]\u001b[0m Trial 549 finished with value: 32.96022436002113 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017522612910489566, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2523499970593526, 'dropout_rate_Layer_2': 0.0030669248703069224, 'dropout_rate_Layer_3': 0.22274166567053566, 'dropout_rate_Layer_4': 0.18819237066127711, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.030542660155109622, 'l1_Layer_2': 0.00026553715765562455, 'l1_Layer_3': 7.143775939146833e-05, 'l1_Layer_4': 0.014112171584155873, 'n_units_Layer_1': 210, 'n_units_Layer_2': 100, 'n_units_Layer_3': 160, 'n_units_Layer_4': 160}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.96 | sMAPE for Validation Set is: 19.13% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.73 | sMAPE for Test Set is: 19.14% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:42:07,664]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:42:21,354]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:42:42,228]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:42:55,573]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:42:56,243]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:43:00,495]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:43:12,655]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:43:18,787]\u001b[0m Trial 558 finished with value: 32.40858188873563 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007957086405154337, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.254343485525065, 'dropout_rate_Layer_2': 0.006081502288824092, 'dropout_rate_Layer_3': 0.21307969027200976, 'dropout_rate_Layer_4': 0.17570312146985695, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0160537930914662, 'l1_Layer_2': 0.00025192756220095066, 'l1_Layer_3': 6.495345136383408e-05, 'l1_Layer_4': 0.014849786908572724, 'n_units_Layer_1': 210, 'n_units_Layer_2': 100, 'n_units_Layer_3': 160, 'n_units_Layer_4': 150}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.41 | sMAPE for Validation Set is: 19.07% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.56 | sMAPE for Test Set is: 19.11% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:43:21,594]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:43:24,910]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:43:29,673]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:43:32,809]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:43:44,008]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:43:50,856]\u001b[0m Trial 560 finished with value: 32.13893331830062 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005032925842376816, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03247078642550209, 'dropout_rate_Layer_2': 0.13491314684022035, 'dropout_rate_Layer_3': 0.28565120789996373, 'dropout_rate_Layer_4': 0.35054101196032106, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.051564679582116524, 'l1_Layer_2': 3.357539972606469e-05, 'l1_Layer_3': 0.006604806501046629, 'l1_Layer_4': 0.0006438773957595667, 'n_units_Layer_1': 130, 'n_units_Layer_2': 220, 'n_units_Layer_3': 125, 'n_units_Layer_4': 185}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.14 | sMAPE for Validation Set is: 18.75% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.44 | sMAPE for Test Set is: 18.82% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:43:54,284]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:43:59,853]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:44:02,622]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:44:05,832]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:44:18,237]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:44:21,396]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:44:24,172]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:44:28,548]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:44:31,173]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:44:38,789]\u001b[0m Trial 566 finished with value: 32.40718586454067 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005651007291387028, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03281561184418708, 'dropout_rate_Layer_2': 0.15995393881661935, 'dropout_rate_Layer_3': 0.27794636425840213, 'dropout_rate_Layer_4': 0.357743518060757, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.06759194231873503, 'l1_Layer_2': 3.3278095060941014e-05, 'l1_Layer_3': 0.004047119722346962, 'l1_Layer_4': 0.0014575037772663888, 'n_units_Layer_1': 125, 'n_units_Layer_2': 260, 'n_units_Layer_3': 130, 'n_units_Layer_4': 175}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.41 | sMAPE for Validation Set is: 18.97% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.50 | sMAPE for Test Set is: 18.89% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:44:41,655]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:44:50,441]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:44:56,278]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:45:02,484]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:45:09,151]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:45:15,866]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:45:18,650]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:45:26,958]\u001b[0m Trial 582 finished with value: 32.54243099485918 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011789681864472544, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3012808517176781, 'dropout_rate_Layer_2': 0.03674723154540151, 'dropout_rate_Layer_3': 0.23217172533101774, 'dropout_rate_Layer_4': 0.011448046603856097, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05154947644411648, 'l1_Layer_2': 0.0003116862272910656, 'l1_Layer_3': 0.00015221299142247148, 'l1_Layer_4': 0.006104253641143376, 'n_units_Layer_1': 195, 'n_units_Layer_2': 100, 'n_units_Layer_3': 150, 'n_units_Layer_4': 155}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.54 | sMAPE for Validation Set is: 18.90% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.29 | sMAPE for Test Set is: 18.64% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:45:44,541]\u001b[0m Trial 584 finished with value: 32.48487892485087 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008395076625286865, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2968070600554712, 'dropout_rate_Layer_2': 0.03954915889132758, 'dropout_rate_Layer_3': 0.1979882381389334, 'dropout_rate_Layer_4': 0.16632997688930043, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04738172415502539, 'l1_Layer_2': 0.0008131885258786744, 'l1_Layer_3': 3.44009195138212e-05, 'l1_Layer_4': 0.0008644102815614886, 'n_units_Layer_1': 195, 'n_units_Layer_2': 90, 'n_units_Layer_3': 135, 'n_units_Layer_4': 150}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.48 | sMAPE for Validation Set is: 18.88% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.29 | sMAPE for Test Set is: 18.60% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:45:47,333]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:45:49,745]\u001b[0m Trial 585 finished with value: 32.18538608590651 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014922074115620075, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.041997254300583306, 'dropout_rate_Layer_2': 0.353853659592373, 'dropout_rate_Layer_3': 0.02690890920031691, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0174717569884787, 'l1_Layer_2': 0.0010961001054712609, 'l1_Layer_3': 0.0005511477476469845, 'n_units_Layer_1': 155, 'n_units_Layer_2': 75, 'n_units_Layer_3': 125}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.19 | sMAPE for Validation Set is: 18.82% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.26 | sMAPE for Test Set is: 18.71% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:45:55,761]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:45:57,785]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:46:02,971]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:46:06,579]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:46:26,631]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:46:30,030]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:46:32,837]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:46:33,069]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:46:37,282]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:46:39,964]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:46:43,398]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:46:49,709]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:46:53,839]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:46:57,028]\u001b[0m Trial 598 finished with value: 35.93168543534156 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014496280010518842, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.043785404830252006, 'dropout_rate_Layer_2': 0.35443500385464866, 'dropout_rate_Layer_3': 0.03523294539927253, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.020555226997603697, 'l1_Layer_2': 0.001099896835731244, 'l1_Layer_3': 0.0014138172989517897, 'n_units_Layer_1': 155, 'n_units_Layer_2': 75, 'n_units_Layer_3': 100}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.93 | sMAPE for Validation Set is: 21.14% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 17.64 | sMAPE for Test Set is: 21.78% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:46:57,797]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:47:00,871]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:47:05,250]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:47:08,431]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:47:10,719]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:47:14,289]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:47:17,208]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:47:24,029]\u001b[0m Trial 604 finished with value: 32.3123052719696 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012140073328762292, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.298804214154192, 'dropout_rate_Layer_2': 0.009088554533521205, 'dropout_rate_Layer_3': 0.20964823144880804, 'dropout_rate_Layer_4': 0.1537340199055485, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04943363934269714, 'l1_Layer_2': 0.0002834013143035142, 'l1_Layer_3': 3.64694253383297e-05, 'l1_Layer_4': 0.000797379721937846, 'n_units_Layer_1': 180, 'n_units_Layer_2': 80, 'n_units_Layer_3': 105, 'n_units_Layer_4': 170}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.31 | sMAPE for Validation Set is: 18.85% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.15 | sMAPE for Test Set is: 18.63% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:47:36,341]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:47:38,317]\u001b[0m Trial 609 finished with value: 32.496629438007346 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010176355555663594, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09217385990205235, 'dropout_rate_Layer_2': 0.33156091169462926, 'dropout_rate_Layer_3': 0.022796793842740613, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.016262553668506062, 'l1_Layer_2': 0.0014019854866471186, 'l1_Layer_3': 0.0005320227963333695, 'n_units_Layer_1': 175, 'n_units_Layer_2': 80, 'n_units_Layer_3': 180}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.50 | sMAPE for Validation Set is: 18.93% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.53 | sMAPE for Test Set is: 18.95% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:47:41,098]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:47:44,043]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:47:51,668]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:47:54,286]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:47:58,507]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:47:58,726]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:48:03,895]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:48:07,544]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:48:14,015]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:48:20,278]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:48:30,348]\u001b[0m Trial 622 finished with value: 34.317604650927215 and parameters: {'n_hidden': 3, 'learning_rate': 0.03306524887049145, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08786591262246289, 'dropout_rate_Layer_2': 0.3633448954952766, 'dropout_rate_Layer_3': 0.04945851482617564, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03104233948041876, 'l1_Layer_2': 0.000471563558393107, 'l1_Layer_3': 0.00047795695083536626, 'n_units_Layer_1': 125, 'n_units_Layer_2': 105, 'n_units_Layer_3': 185}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.32 | sMAPE for Validation Set is: 19.90% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 15.06 | sMAPE for Test Set is: 20.00% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:48:32,666]\u001b[0m Trial 621 finished with value: 32.47572323468034 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012985111012745014, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08326694351583001, 'dropout_rate_Layer_2': 0.3648576656065974, 'dropout_rate_Layer_3': 0.044377089634353335, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.016038485044107056, 'l1_Layer_2': 0.0005247699482686078, 'l1_Layer_3': 0.00021634498177863212, 'n_units_Layer_1': 130, 'n_units_Layer_2': 105, 'n_units_Layer_3': 180}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.48 | sMAPE for Validation Set is: 18.90% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.39 | sMAPE for Test Set is: 18.83% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:48:37,688]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:48:40,569]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:48:43,230]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:48:46,062]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:48:48,833]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:48:52,738]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:48:52,955]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:48:58,990]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:49:02,425]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:49:04,704]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:49:07,543]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:49:11,789]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:49:15,699]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:49:22,379]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:49:25,257]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:49:28,188]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:49:31,932]\u001b[0m Trial 631 finished with value: 32.2506953076072 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006337938289361479, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05795383698333415, 'dropout_rate_Layer_2': 0.1642050980082039, 'dropout_rate_Layer_3': 0.014322421563778664, 'dropout_rate_Layer_4': 0.11398108117168898, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03532866468693246, 'l1_Layer_2': 8.942976285741522e-05, 'l1_Layer_3': 0.004655873597917435, 'l1_Layer_4': 3.057142064601938e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 190, 'n_units_Layer_3': 125, 'n_units_Layer_4': 185}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.25 | sMAPE for Validation Set is: 19.05% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.43 | sMAPE for Test Set is: 19.09% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:49:34,128]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:49:48,891]\u001b[0m Trial 642 finished with value: 33.28208392629188 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010744226310789413, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28851728729588677, 'dropout_rate_Layer_2': 0.03053699564449366, 'dropout_rate_Layer_3': 0.21668961848864574, 'dropout_rate_Layer_4': 0.030981397439172272, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.011519258238982108, 'l1_Layer_2': 0.00017755445091210156, 'l1_Layer_3': 5.230483512389753e-05, 'l1_Layer_4': 0.015757847961713704, 'n_units_Layer_1': 190, 'n_units_Layer_2': 70, 'n_units_Layer_3': 140, 'n_units_Layer_4': 150}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.28 | sMAPE for Validation Set is: 19.18% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.73 | sMAPE for Test Set is: 19.05% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:49:52,271]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:49:54,760]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:49:57,726]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:50:00,425]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:50:05,509]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:50:08,996]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:50:12,382]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:50:20,495]\u001b[0m Trial 641 finished with value: 32.17928399840325 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006218997375370615, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07646624630893605, 'dropout_rate_Layer_2': 0.12522102084005526, 'dropout_rate_Layer_3': 0.10688055024495957, 'dropout_rate_Layer_4': 0.12089380224570014, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03225897363945624, 'l1_Layer_2': 1.3287367453844802e-05, 'l1_Layer_3': 0.007553895823352429, 'l1_Layer_4': 4.205126483788754e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 200, 'n_units_Layer_3': 135, 'n_units_Layer_4': 165}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.18 | sMAPE for Validation Set is: 18.66% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.59 | sMAPE for Test Set is: 18.81% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:50:25,718]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:50:26,223]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:50:30,408]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:50:30,739]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:50:34,792]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:50:37,293]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:50:42,133]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:50:42,291]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:50:57,560]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:51:00,376]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:51:03,410]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:51:04,212]\u001b[0m Trial 659 finished with value: 33.13107098652331 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008893046215090758, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30343618395945576, 'dropout_rate_Layer_2': 0.013786016895602278, 'dropout_rate_Layer_3': 0.19395076971308328, 'dropout_rate_Layer_4': 0.13359462108185477, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.008210998994749537, 'l1_Layer_2': 0.0002204865623241103, 'l1_Layer_3': 8.225408633411984e-05, 'l1_Layer_4': 0.010665344399591282, 'n_units_Layer_1': 195, 'n_units_Layer_2': 80, 'n_units_Layer_3': 140, 'n_units_Layer_4': 145}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.13 | sMAPE for Validation Set is: 19.26% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.56 | sMAPE for Test Set is: 19.10% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:51:07,729]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:51:10,530]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:51:13,398]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:51:16,211]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:51:19,269]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:51:21,851]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:51:22,514]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:51:26,139]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:51:28,037]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:51:29,799]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:51:32,752]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:51:35,552]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:51:38,287]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:51:46,083]\u001b[0m Trial 673 finished with value: 32.25753153579306 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014491297091989998, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09480252174654155, 'dropout_rate_Layer_2': 0.39624546290494417, 'dropout_rate_Layer_3': 0.04313592738813638, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.029054007486461263, 'l1_Layer_2': 0.006117105871846595, 'l1_Layer_3': 0.0010095560526867241, 'n_units_Layer_1': 170, 'n_units_Layer_2': 75, 'n_units_Layer_3': 175}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.26 | sMAPE for Validation Set is: 18.98% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 15.20 | sMAPE for Test Set is: 19.90% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:51:48,640]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:51:54,649]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:51:57,321]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:51:59,866]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:52:02,417]\u001b[0m Trial 676 finished with value: 32.185092888392326 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010525391231584079, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2282363305220306, 'dropout_rate_Layer_2': 0.2577663701480707, 'dropout_rate_Layer_3': 0.16182893232709133, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09634128736169713, 'l1_Layer_2': 1.3236083970561114e-05, 'l1_Layer_3': 4.492067423992432e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 210, 'n_units_Layer_3': 160}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.19 | sMAPE for Validation Set is: 18.74% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.48 | sMAPE for Test Set is: 18.90% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:52:05,400]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:52:07,676]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:52:12,268]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:52:14,457]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:52:16,491]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:52:18,299]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:52:19,457]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:52:21,712]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:52:22,416]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:52:25,135]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:52:27,570]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:52:37,707]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:52:47,625]\u001b[0m Trial 693 finished with value: 32.90264052788417 and parameters: {'n_hidden': 4, 'learning_rate': 0.001049850553498279, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28890335588841687, 'dropout_rate_Layer_2': 0.02709493511417224, 'dropout_rate_Layer_3': 0.21480440882266746, 'dropout_rate_Layer_4': 0.015110491985629158, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01052142461659794, 'l1_Layer_2': 0.00019788382535886596, 'l1_Layer_3': 4.166589565919849e-05, 'l1_Layer_4': 0.011298758572373419, 'n_units_Layer_1': 190, 'n_units_Layer_2': 75, 'n_units_Layer_3': 130, 'n_units_Layer_4': 150}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.90 | sMAPE for Validation Set is: 19.03% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.47 | sMAPE for Test Set is: 18.77% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:52:52,012]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:52:58,452]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:53:04,018]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:53:16,708]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:53:22,979]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:53:26,901]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:53:56,625]\u001b[0m Trial 701 finished with value: 32.47087648275956 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012759139819329638, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11524509082088158, 'dropout_rate_Layer_2': 0.03173305643120957, 'dropout_rate_Layer_3': 0.28537914236199935, 'dropout_rate_Layer_4': 0.37512014198112525, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0474349765166366, 'l1_Layer_2': 0.010025390985353773, 'l1_Layer_3': 0.0007824499360102116, 'l1_Layer_4': 4.6862461260437126e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 65, 'n_units_Layer_3': 115, 'n_units_Layer_4': 200}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.47 | sMAPE for Validation Set is: 19.06% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.54 | sMAPE for Test Set is: 19.10% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:53:57,200]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:54:00,466]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:54:03,521]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:54:06,060]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:54:06,270]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:54:10,770]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:54:12,308]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:54:18,481]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:54:21,754]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:54:25,239]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:54:27,015]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:54:28,987]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:54:30,481]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:54:36,702]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:54:40,063]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:54:42,838]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:54:56,610]\u001b[0m Trial 718 finished with value: 32.416744506056084 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012696653670470777, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13642419478708653, 'dropout_rate_Layer_2': 0.33631875736093736, 'dropout_rate_Layer_3': 0.36055244912357665, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.025676801103141692, 'l1_Layer_2': 0.0007458601012106798, 'l1_Layer_3': 0.0006668501431975175, 'n_units_Layer_1': 135, 'n_units_Layer_2': 70, 'n_units_Layer_3': 195}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.42 | sMAPE for Validation Set is: 19.05% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.63 | sMAPE for Test Set is: 19.25% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:54:59,950]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:55:02,786]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:55:06,532]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:55:07,228]\u001b[0m Trial 714 finished with value: 32.56599134445191 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007819843986503507, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008503238196304393, 'dropout_rate_Layer_2': 0.03279976305650645, 'dropout_rate_Layer_3': 0.2851587089496806, 'dropout_rate_Layer_4': 0.3651616066221279, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05692257565561342, 'l1_Layer_2': 0.010176310842656933, 'l1_Layer_3': 0.005679965196118187, 'l1_Layer_4': 0.0013393635227391158, 'n_units_Layer_1': 160, 'n_units_Layer_2': 200, 'n_units_Layer_3': 215, 'n_units_Layer_4': 175}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.57 | sMAPE for Validation Set is: 18.96% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.76 | sMAPE for Test Set is: 19.38% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:55:10,257]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:55:14,469]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:55:19,062]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:55:21,237]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:55:25,081]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:55:27,438]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:55:30,977]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:55:34,382]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:55:35,947]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:55:39,239]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:55:43,189]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:55:46,141]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:55:46,499]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:55:50,489]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:55:50,800]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:55:54,627]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:55:56,484]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:55:57,181]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:56:00,358]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:56:05,569]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:56:07,454]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:56:10,451]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:56:12,920]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:56:17,692]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:56:20,908]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:56:25,000]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:56:26,851]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:56:29,069]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:56:30,498]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:56:33,175]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:56:35,881]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:56:37,931]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:56:38,491]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:56:41,957]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:56:42,711]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:56:47,019]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:56:49,690]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:56:52,186]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:56:58,578]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:57:02,547]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:57:06,920]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:57:12,734]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:57:17,326]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:57:20,497]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:57:26,450]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:57:39,253]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:57:42,568]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:57:48,439]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:57:51,368]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:57:51,486]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:57:54,860]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:57:58,503]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:58:01,469]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:58:04,193]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:58:06,797]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:58:08,804]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:58:11,088]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:58:15,035]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:58:17,964]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:58:19,910]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:58:21,923]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:58:25,154]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:58:28,168]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:58:30,935]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:58:33,793]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:58:39,381]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:58:41,756]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:58:44,074]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:58:56,351]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:58:58,810]\u001b[0m Trial 783 finished with value: 32.039371900449694 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015189039101246053, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10375767923435646, 'dropout_rate_Layer_2': 0.029845382633459344, 'dropout_rate_Layer_3': 0.2670048580534522, 'dropout_rate_Layer_4': 0.3706721758202703, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.020190422928548, 'l1_Layer_2': 6.642135972402804e-05, 'l1_Layer_3': 0.0009279063382873762, 'l1_Layer_4': 5.076390505242501e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 55, 'n_units_Layer_3': 105, 'n_units_Layer_4': 165}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.04 | sMAPE for Validation Set is: 18.91% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.31 | sMAPE for Test Set is: 18.82% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:59:01,500]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:59:05,386]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:59:06,179]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:59:09,627]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:59:10,335]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:59:14,282]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:59:14,541]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:59:19,528]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:59:22,190]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:59:22,637]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:59:27,273]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:59:28,719]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:59:31,673]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:59:33,872]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:59:35,987]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:59:39,150]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:59:39,299]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:59:45,699]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:59:48,322]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 08:59:56,522]\u001b[0m Trial 809 finished with value: 32.693008881354466 and parameters: {'n_hidden': 4, 'learning_rate': 0.0025529627884842985, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2789861769243106, 'dropout_rate_Layer_2': 0.12896962589086652, 'dropout_rate_Layer_3': 0.21671993583842625, 'dropout_rate_Layer_4': 0.1671280587494586, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.013543474929831555, 'l1_Layer_2': 0.000231868646615815, 'l1_Layer_3': 0.0001696279309336707, 'l1_Layer_4': 0.0003299687286556721, 'n_units_Layer_1': 205, 'n_units_Layer_2': 90, 'n_units_Layer_3': 165, 'n_units_Layer_4': 210}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.69 | sMAPE for Validation Set is: 19.03% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 13.96 | sMAPE for Test Set is: 18.40% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 08:59:59,722]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:00:02,487]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:00:05,246]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:00:07,699]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:00:09,987]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:00:11,952]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:00:13,758]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:00:16,350]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:00:20,114]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:00:33,755]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:00:36,605]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:00:39,063]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:00:52,508]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:00:55,998]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:00:58,448]\u001b[0m Trial 821 finished with value: 31.87621472210635 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018368957017158149, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05845463030266248, 'dropout_rate_Layer_2': 0.29017943199815177, 'dropout_rate_Layer_3': 0.13005800851378346, 'dropout_rate_Layer_4': 0.3262017954747066, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02800927942927842, 'l1_Layer_2': 0.00012039919273498113, 'l1_Layer_3': 0.000753158257168496, 'l1_Layer_4': 0.0010174689481267578, 'n_units_Layer_1': 75, 'n_units_Layer_2': 165, 'n_units_Layer_3': 135, 'n_units_Layer_4': 160}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.88 | sMAPE for Validation Set is: 18.67% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.36 | sMAPE for Test Set is: 18.70% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:01:01,633]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:01:04,276]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:01:07,812]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:01:10,721]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:01:13,696]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:01:16,137]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:01:20,113]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:01:22,616]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:01:27,159]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:01:30,284]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:01:32,546]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:01:41,308]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:01:43,170]\u001b[0m Trial 836 finished with value: 32.28364247059134 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023387225876811855, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12957445159028272, 'dropout_rate_Layer_2': 0.3553530784667196, 'dropout_rate_Layer_3': 0.3932531734497251, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.026656537664693128, 'l1_Layer_2': 0.00021699169200020704, 'l1_Layer_3': 0.00022077528772233515, 'n_units_Layer_1': 140, 'n_units_Layer_2': 60, 'n_units_Layer_3': 210}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.28 | sMAPE for Validation Set is: 19.07% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.65 | sMAPE for Test Set is: 19.40% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:01:47,137]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:01:51,064]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:01:55,123]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:01:58,975]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:02:01,853]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:02:04,851]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:02:08,623]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:02:11,778]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:02:13,681]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:02:16,742]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:02:22,675]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:02:24,016]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:02:26,064]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:02:26,676]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:02:29,782]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:02:31,650]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:02:34,711]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:02:37,325]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:02:37,632]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:02:45,022]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:02:51,180]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:02:54,079]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:02:57,393]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:03:00,047]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:03:00,236]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:03:04,466]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:03:07,863]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:03:13,927]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:03:17,806]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:03:21,598]\u001b[0m Trial 865 finished with value: 32.42739365236719 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024513185943496234, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1244708253286328, 'dropout_rate_Layer_2': 0.35763038042314765, 'dropout_rate_Layer_3': 0.38636935783785115, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.025389520013703478, 'l1_Layer_2': 0.0002095589649082058, 'l1_Layer_3': 0.0002342287209757746, 'n_units_Layer_1': 125, 'n_units_Layer_2': 90, 'n_units_Layer_3': 195}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.43 | sMAPE for Validation Set is: 18.85% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.99 | sMAPE for Test Set is: 19.38% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:03:24,882]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:03:26,598]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:03:28,653]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:03:31,364]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:03:32,183]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:03:36,085]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:03:36,774]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:03:39,348]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:03:40,222]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:03:42,537]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:03:43,370]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:03:47,868]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:03:51,248]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:03:58,288]\u001b[0m Trial 882 finished with value: 32.46481737837223 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018121264491158427, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1277790852403481, 'dropout_rate_Layer_2': 0.39837269638006184, 'dropout_rate_Layer_3': 0.3994097494899973, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.041371294840322176, 'l1_Layer_2': 0.0002210841829529306, 'l1_Layer_3': 0.0003077421356714145, 'n_units_Layer_1': 145, 'n_units_Layer_2': 60, 'n_units_Layer_3': 210}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.46 | sMAPE for Validation Set is: 19.00% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.52 | sMAPE for Test Set is: 19.07% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:04:01,378]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:04:03,995]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:04:04,821]\u001b[0m Trial 884 finished with value: 32.76403851599223 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022375576496494903, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.128511022153286, 'dropout_rate_Layer_2': 0.35531760343468405, 'dropout_rate_Layer_3': 0.3546700762080379, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.027362604022646664, 'l1_Layer_2': 0.00021928212342218882, 'l1_Layer_3': 0.00039152156555619945, 'n_units_Layer_1': 145, 'n_units_Layer_2': 90, 'n_units_Layer_3': 195}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.76 | sMAPE for Validation Set is: 19.09% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.71 | sMAPE for Test Set is: 19.19% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:04:09,372]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:04:12,622]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:04:16,136]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:04:26,646]\u001b[0m Trial 891 finished with value: 33.75568802474154 and parameters: {'n_hidden': 4, 'learning_rate': 0.002029853418859423, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3372641735109421, 'dropout_rate_Layer_2': 0.024049635032355167, 'dropout_rate_Layer_3': 0.25822160587168974, 'dropout_rate_Layer_4': 0.18546586630215472, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03266347009884088, 'l1_Layer_2': 0.0025210390034510776, 'l1_Layer_3': 6.492321549319573e-05, 'l1_Layer_4': 5.61432137837599e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 200, 'n_units_Layer_3': 140, 'n_units_Layer_4': 235}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.76 | sMAPE for Validation Set is: 19.68% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 15.10 | sMAPE for Test Set is: 19.98% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:04:39,249]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:04:42,718]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:04:43,450]\u001b[0m Trial 890 finished with value: 32.966003993781804 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013352804958661423, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06300460336491724, 'dropout_rate_Layer_2': 0.03177598093591513, 'dropout_rate_Layer_3': 0.03576163781312863, 'dropout_rate_Layer_4': 0.13603909796706884, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02766470522495009, 'l1_Layer_2': 0.06983148791269894, 'l1_Layer_3': 0.0010141034512004172, 'l1_Layer_4': 2.3779058637588112e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 255, 'n_units_Layer_3': 50, 'n_units_Layer_4': 190}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.97 | sMAPE for Validation Set is: 19.11% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.56 | sMAPE for Test Set is: 18.88% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:04:47,838]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:04:49,170]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:04:55,470]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:05:04,999]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:05:10,826]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:05:16,805]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:05:20,130]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:05:34,059]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:05:37,065]\u001b[0m Trial 896 finished with value: 32.121695587755475 and parameters: {'n_hidden': 3, 'learning_rate': 0.001082023973957395, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0431117245628579, 'dropout_rate_Layer_2': 0.03330400461641034, 'dropout_rate_Layer_3': 0.039458217842421296, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03694376539148537, 'l1_Layer_2': 0.051017931495762885, 'l1_Layer_3': 0.0014822347763393732, 'n_units_Layer_1': 230, 'n_units_Layer_2': 265, 'n_units_Layer_3': 55}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.12 | sMAPE for Validation Set is: 19.08% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.48 | sMAPE for Test Set is: 18.87% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:05:40,489]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:05:41,943]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:05:43,856]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:05:46,710]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:05:48,985]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:05:49,036]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:05:53,252]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:05:53,286]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:05:58,871]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:05:59,283]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:06:03,384]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:06:05,634]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:06:07,883]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:06:09,619]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:06:11,616]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:06:13,336]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:06:15,543]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:06:18,118]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:06:24,412]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:06:27,329]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:06:29,851]\u001b[0m Trial 921 finished with value: 32.64374936339353 and parameters: {'n_hidden': 3, 'learning_rate': 0.003031845386038715, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19395230957421516, 'dropout_rate_Layer_2': 0.3731068449769887, 'dropout_rate_Layer_3': 0.30392010410022835, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.024626849768567466, 'l1_Layer_2': 0.0001435507223843998, 'l1_Layer_3': 0.00043589192477061565, 'n_units_Layer_1': 110, 'n_units_Layer_2': 70, 'n_units_Layer_3': 190}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.64 | sMAPE for Validation Set is: 19.07% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.72 | sMAPE for Test Set is: 19.29% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:06:34,903]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:06:38,415]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:06:40,637]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:06:44,480]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:06:48,770]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:06:49,010]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:06:53,638]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:06:54,098]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:06:58,239]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:07:01,169]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:07:01,554]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:07:32,256]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:07:35,235]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:07:37,966]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:07:40,240]\u001b[0m Trial 935 finished with value: 31.95488935034646 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006805254456483277, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21825410788235747, 'dropout_rate_Layer_2': 0.2083351713571461, 'dropout_rate_Layer_3': 0.14984190460118682, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.019742349159426652, 'l1_Layer_2': 3.6391418256096584e-05, 'l1_Layer_3': 0.013482378797414781, 'n_units_Layer_1': 220, 'n_units_Layer_2': 145, 'n_units_Layer_3': 110}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.95 | sMAPE for Validation Set is: 18.79% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.65 | sMAPE for Test Set is: 19.17% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:07:53,574]\u001b[0m Trial 939 finished with value: 32.08832072606078 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020235262249475076, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0543062939318548, 'dropout_rate_Layer_2': 0.3415371886039474, 'dropout_rate_Layer_3': 0.34498280729718034, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.04258029214943072, 'l1_Layer_2': 0.0001808605709996211, 'l1_Layer_3': 0.0008447652982352972, 'n_units_Layer_1': 120, 'n_units_Layer_2': 90, 'n_units_Layer_3': 160}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.09 | sMAPE for Validation Set is: 18.79% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.56 | sMAPE for Test Set is: 19.01% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:07:57,427]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:08:01,380]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:08:04,306]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:08:06,339]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:08:10,323]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:08:18,509]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:08:25,424]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:08:28,804]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:08:31,768]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:08:33,276]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:08:37,543]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:08:38,067]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:08:41,900]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:08:42,533]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:08:48,365]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:08:51,036]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:08:51,689]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:08:57,109]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:09:00,079]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:09:00,276]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:09:07,294]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:09:10,347]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:09:14,598]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:09:17,853]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:09:20,321]\u001b[0m Trial 960 finished with value: 32.79531835587442 and parameters: {'n_hidden': 3, 'learning_rate': 0.003920970382645349, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09942204368725244, 'dropout_rate_Layer_2': 0.32253477436015154, 'dropout_rate_Layer_3': 0.3895132065683863, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06742363876332941, 'l1_Layer_2': 9.824458710701127e-05, 'l1_Layer_3': 2.748705362736531e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 90, 'n_units_Layer_3': 170}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.80 | sMAPE for Validation Set is: 19.32% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 15.04 | sMAPE for Test Set is: 20.03% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:09:23,555]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:09:26,560]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:09:27,002]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:09:30,884]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:09:34,919]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:09:39,201]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:09:44,488]\u001b[0m Trial 969 finished with value: 32.46937230968498 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014011827455448949, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07528094253173634, 'dropout_rate_Layer_2': 0.34087270093251243, 'dropout_rate_Layer_3': 0.3800858741456474, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.028024731469109953, 'l1_Layer_2': 0.00040852027154204357, 'l1_Layer_3': 0.0012608966597691276, 'n_units_Layer_1': 155, 'n_units_Layer_2': 80, 'n_units_Layer_3': 205}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.47 | sMAPE for Validation Set is: 18.86% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.67 | sMAPE for Test Set is: 19.00% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:09:45,309]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:09:48,648]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:09:49,312]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:09:53,328]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:09:57,985]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:10:00,851]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:10:02,717]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:10:05,738]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:10:05,916]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:10:10,830]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:10:13,369]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:10:14,132]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:10:17,631]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:10:20,006]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:10:20,297]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:10:24,894]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:10:25,203]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:10:29,262]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:10:29,925]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:10:34,101]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:10:34,260]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:10:39,292]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:10:39,956]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:10:44,687]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:10:47,653]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:10:50,944]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:10:55,569]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:10:58,353]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:11:11,707]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:11:14,619]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:11:15,537]\u001b[0m Trial 999 finished with value: 32.30090498936576 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011456950334483166, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13592517446919367, 'dropout_rate_Layer_2': 0.3362805520486236, 'dropout_rate_Layer_3': 0.3564152968865833, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009780856541096243, 'l1_Layer_2': 0.00014296130561670484, 'l1_Layer_3': 0.000655843302082725, 'n_units_Layer_1': 125, 'n_units_Layer_2': 65, 'n_units_Layer_3': 175}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.30 | sMAPE for Validation Set is: 18.90% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.40 | sMAPE for Test Set is: 18.92% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:11:20,563]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:11:21,455]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:11:25,262]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:11:28,371]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:11:39,497]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:11:42,881]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:11:47,271]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:11:50,737]\u001b[0m Trial 1006 finished with value: 32.242291643171114 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009257964995960057, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16683084176018675, 'dropout_rate_Layer_2': 0.3752712523765153, 'dropout_rate_Layer_3': 0.3470416620436195, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01378179982592636, 'l1_Layer_2': 0.000135987849864533, 'l1_Layer_3': 0.0019225766581928406, 'n_units_Layer_1': 135, 'n_units_Layer_2': 50, 'n_units_Layer_3': 155}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.24 | sMAPE for Validation Set is: 18.88% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.48 | sMAPE for Test Set is: 19.07% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:11:51,019]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:11:56,203]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:11:59,120]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:12:02,420]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:12:04,412]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:12:14,825]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:12:17,427]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:12:19,224]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:12:21,309]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:12:24,580]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:12:27,428]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:12:31,391]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:12:33,428]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:12:33,937]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:12:37,818]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:12:38,630]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:12:43,083]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:12:43,201]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:12:47,622]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:12:49,692]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:12:52,567]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:13:05,051]\u001b[0m Trial 1032 finished with value: 32.50730910798469 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014957660673356379, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04581190468193945, 'dropout_rate_Layer_2': 0.3495645284797894, 'dropout_rate_Layer_3': 0.3531163517898531, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01616778548070149, 'l1_Layer_2': 0.00027005879824150176, 'l1_Layer_3': 0.0006323864834499116, 'n_units_Layer_1': 130, 'n_units_Layer_2': 65, 'n_units_Layer_3': 195}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.51 | sMAPE for Validation Set is: 18.94% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.42 | sMAPE for Test Set is: 18.96% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:13:07,471]\u001b[0m Trial 1033 finished with value: 33.89841973536286 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011667440254262418, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29605269565807585, 'dropout_rate_Layer_2': 0.0392465433238592, 'dropout_rate_Layer_3': 0.20408732103008154, 'dropout_rate_Layer_4': 0.20135139992124276, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.007454661019680073, 'l1_Layer_2': 0.0004390695540885494, 'l1_Layer_3': 0.00018852956081328505, 'l1_Layer_4': 2.0296418436820166e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 220, 'n_units_Layer_3': 140, 'n_units_Layer_4': 210}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.90 | sMAPE for Validation Set is: 19.68% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.62 | sMAPE for Test Set is: 19.11% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:13:10,515]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:13:10,887]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:13:15,264]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:13:16,958]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:13:19,524]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:13:21,326]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:13:24,355]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:13:24,818]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:13:28,775]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:13:31,031]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:13:35,871]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:13:38,011]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:13:41,056]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:13:43,950]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:13:46,889]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:13:49,856]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:13:56,116]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:13:58,601]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:14:04,940]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:14:08,296]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:14:12,732]\u001b[0m Trial 1051 finished with value: 32.50173779591058 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007353473348254135, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1047724450510383, 'dropout_rate_Layer_2': 0.37374977202141724, 'dropout_rate_Layer_3': 0.39950573045112636, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.024474467880384352, 'l1_Layer_2': 0.00019270095626568203, 'l1_Layer_3': 0.001900192987448975, 'n_units_Layer_1': 140, 'n_units_Layer_2': 75, 'n_units_Layer_3': 175}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.50 | sMAPE for Validation Set is: 19.10% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.60 | sMAPE for Test Set is: 19.20% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:14:15,928]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:14:23,403]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:14:27,396]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:14:27,920]\u001b[0m Trial 1055 finished with value: 32.54131299025631 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012311514985624272, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14385864397005138, 'dropout_rate_Layer_2': 0.3728886037228305, 'dropout_rate_Layer_3': 0.3863784225196527, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.022035064190701517, 'l1_Layer_2': 4.929313322406923e-05, 'l1_Layer_3': 0.001872642184871253, 'n_units_Layer_1': 140, 'n_units_Layer_2': 75, 'n_units_Layer_3': 175}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.54 | sMAPE for Validation Set is: 19.06% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.61 | sMAPE for Test Set is: 19.14% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:14:31,872]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:14:35,526]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:14:41,269]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:14:44,387]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:14:47,508]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:14:47,895]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:14:51,899]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:15:03,727]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:15:06,264]\u001b[0m Trial 1067 finished with value: 32.098214104365375 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007239675559305501, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14428063708232397, 'dropout_rate_Layer_2': 0.21294913071632904, 'dropout_rate_Layer_3': 0.10361208081358206, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05528553324022737, 'l1_Layer_2': 2.0626498456608693e-05, 'l1_Layer_3': 0.010348304378778402, 'n_units_Layer_1': 235, 'n_units_Layer_2': 225, 'n_units_Layer_3': 70}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.10 | sMAPE for Validation Set is: 18.65% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.48 | sMAPE for Test Set is: 18.82% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:15:06,921]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:15:10,822]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:15:10,993]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:15:15,017]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:15:15,948]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:15:21,849]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:15:27,451]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:15:30,609]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:15:40,091]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:15:50,130]\u001b[0m Trial 1077 finished with value: 32.02558638039748 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007075169738817946, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13924259254712906, 'dropout_rate_Layer_2': 0.256950436860999, 'dropout_rate_Layer_3': 0.08368769361905326, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.047262312976615865, 'l1_Layer_2': 2.6646140102708998e-05, 'l1_Layer_3': 0.014898188450066286, 'n_units_Layer_1': 230, 'n_units_Layer_2': 250, 'n_units_Layer_3': 80}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.03 | sMAPE for Validation Set is: 18.71% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.45 | sMAPE for Test Set is: 18.88% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:15:53,119]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:16:13,183]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:16:16,582]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:16:19,927]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:16:42,512]\u001b[0m Trial 1083 finished with value: 31.990172653640002 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011895969411802162, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09215057437554033, 'dropout_rate_Layer_2': 0.01684840305655248, 'dropout_rate_Layer_3': 0.27646738118406883, 'dropout_rate_Layer_4': 0.38019208044086505, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.09410161318310185, 'l1_Layer_2': 3.41794791237037e-05, 'l1_Layer_3': 0.0006761729409820091, 'l1_Layer_4': 8.353280154704418e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 140, 'n_units_Layer_3': 115, 'n_units_Layer_4': 175}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.99 | sMAPE for Validation Set is: 18.66% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.31 | sMAPE for Test Set is: 18.65% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:16:45,118]\u001b[0m Trial 1078 finished with value: 32.5444232682942 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006036097078236816, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08842646452166956, 'dropout_rate_Layer_2': 0.30119370935165957, 'dropout_rate_Layer_3': 0.27451647270241786, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.08409984418101744, 'l1_Layer_2': 0.004451746203436729, 'l1_Layer_3': 0.004980834224466462, 'n_units_Layer_1': 235, 'n_units_Layer_2': 55, 'n_units_Layer_3': 140}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.54 | sMAPE for Validation Set is: 19.20% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.79 | sMAPE for Test Set is: 19.38% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:16:49,221]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:16:51,949]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:16:58,451]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:17:01,934]\u001b[0m Trial 1087 finished with value: 32.13737129224023 and parameters: {'n_hidden': 3, 'learning_rate': 0.0046393679732214, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13084143277067956, 'dropout_rate_Layer_2': 0.25914285377529434, 'dropout_rate_Layer_3': 0.055008871873202005, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06853990317266298, 'l1_Layer_2': 1.058556440070668e-05, 'l1_Layer_3': 0.014431750839730745, 'n_units_Layer_1': 290, 'n_units_Layer_2': 225, 'n_units_Layer_3': 70}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.14 | sMAPE for Validation Set is: 19.01% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.61 | sMAPE for Test Set is: 19.44% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:17:04,145]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:17:07,642]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:17:14,350]\u001b[0m Trial 1089 finished with value: 33.637276705008425 and parameters: {'n_hidden': 3, 'learning_rate': 0.000977279640448783, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09671708900413975, 'dropout_rate_Layer_2': 0.3193950294762914, 'dropout_rate_Layer_3': 0.343769240788545, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0029498529198350044, 'l1_Layer_2': 0.00015338884057525964, 'l1_Layer_3': 0.00013793832249302907, 'n_units_Layer_1': 210, 'n_units_Layer_2': 80, 'n_units_Layer_3': 205}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.64 | sMAPE for Validation Set is: 19.55% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.90 | sMAPE for Test Set is: 19.34% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:17:17,447]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:18:05,516]\u001b[0m Trial 1093 finished with value: 32.94096856644034 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005941629169292815, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.040666743484582296, 'dropout_rate_Layer_2': 0.052120526247500645, 'dropout_rate_Layer_3': 0.2638509675803125, 'dropout_rate_Layer_4': 0.3882940235443228, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.08016277424039918, 'l1_Layer_2': 0.003244961154903193, 'l1_Layer_3': 0.0009570345411219463, 'l1_Layer_4': 0.0001590271354143196, 'n_units_Layer_1': 250, 'n_units_Layer_2': 150, 'n_units_Layer_3': 145, 'n_units_Layer_4': 205}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.94 | sMAPE for Validation Set is: 19.13% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.72 | sMAPE for Test Set is: 18.98% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:18:14,053]\u001b[0m Trial 1091 finished with value: 32.42623199367934 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005830010598357643, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06266025839063594, 'dropout_rate_Layer_2': 0.12511951681080696, 'dropout_rate_Layer_3': 0.2749548729775046, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09197277629054144, 'l1_Layer_2': 0.002969967335533192, 'l1_Layer_3': 0.0007364764801694331, 'n_units_Layer_1': 225, 'n_units_Layer_2': 155, 'n_units_Layer_3': 130}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.43 | sMAPE for Validation Set is: 18.99% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.43 | sMAPE for Test Set is: 18.88% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:18:18,873]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:18:23,751]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:18:27,341]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:18:32,347]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:18:38,633]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:18:43,370]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:18:46,248]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:19:10,545]\u001b[0m Trial 1094 finished with value: 32.18467996013508 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005073414137797412, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0880086755256071, 'dropout_rate_Layer_2': 0.06205469214525497, 'dropout_rate_Layer_3': 0.2542689638784915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02404471829590108, 'l1_Layer_2': 0.003058309001185405, 'l1_Layer_3': 0.0009519604529551943, 'n_units_Layer_1': 250, 'n_units_Layer_2': 140, 'n_units_Layer_3': 145}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.18 | sMAPE for Validation Set is: 18.93% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.44 | sMAPE for Test Set is: 19.11% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:19:13,519]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:19:16,689]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:19:25,190]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:19:30,337]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:19:32,119]\u001b[0m Trial 1102 finished with value: 32.751561702055305 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006339710116408575, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06469596396210464, 'dropout_rate_Layer_2': 0.06615444060656958, 'dropout_rate_Layer_3': 0.26956400367019395, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.08478091376281398, 'l1_Layer_2': 0.0043161918774594, 'l1_Layer_3': 0.0007872597560333532, 'n_units_Layer_1': 250, 'n_units_Layer_2': 150, 'n_units_Layer_3': 140}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.75 | sMAPE for Validation Set is: 19.21% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.51 | sMAPE for Test Set is: 18.96% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:19:35,028]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:19:36,431]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:19:41,919]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:19:44,812]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:19:45,157]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:19:51,182]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:19:55,302]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:20:15,189]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:20:43,138]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:20:46,041]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:20:59,451]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:21:07,913]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:21:12,879]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:21:15,136]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:21:18,316]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:21:21,286]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:21:26,023]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:21:43,833]\u001b[0m Trial 1125 finished with value: 32.623799000594424 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008170901562774174, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11022240239296746, 'dropout_rate_Layer_2': 0.33572275358188436, 'dropout_rate_Layer_3': 0.007296133105850245, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.014708855591709308, 'l1_Layer_2': 0.00020569630860329543, 'l1_Layer_3': 0.00044625521167801556, 'n_units_Layer_1': 160, 'n_units_Layer_2': 65, 'n_units_Layer_3': 185}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.62 | sMAPE for Validation Set is: 19.12% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.54 | sMAPE for Test Set is: 19.15% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:21:48,578]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:21:52,368]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:22:11,956]\u001b[0m Trial 1121 finished with value: 32.878588455020825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005988072554960996, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04542719606341444, 'dropout_rate_Layer_2': 0.0752436210136245, 'dropout_rate_Layer_3': 0.2797700746603833, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.07580596753826414, 'l1_Layer_2': 0.005520914128406577, 'l1_Layer_3': 0.0004181041500029534, 'n_units_Layer_1': 250, 'n_units_Layer_2': 135, 'n_units_Layer_3': 145}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.88 | sMAPE for Validation Set is: 19.04% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.77 | sMAPE for Test Set is: 19.02% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:22:16,904]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:22:28,878]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:22:42,709]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:22:45,630]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:23:05,027]\u001b[0m Trial 1128 finished with value: 32.3631240809097 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005156733718612031, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07572569602297524, 'dropout_rate_Layer_2': 0.05379557988147429, 'dropout_rate_Layer_3': 0.27156486997548773, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0779824964157873, 'l1_Layer_2': 0.005287068509043216, 'l1_Layer_3': 0.0007055722725009765, 'n_units_Layer_1': 250, 'n_units_Layer_2': 170, 'n_units_Layer_3': 145}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.36 | sMAPE for Validation Set is: 19.00% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.47 | sMAPE for Test Set is: 18.95% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:23:05,415]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:23:11,089]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:23:14,005]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:23:18,842]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:23:21,856]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:23:26,837]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:23:29,778]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:23:34,880]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:24:30,487]\u001b[0m Trial 1136 finished with value: 32.36657904976906 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005005706757614832, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0591252438540558, 'dropout_rate_Layer_2': 0.06999921094886152, 'dropout_rate_Layer_3': 0.2828413169299206, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09986160699167249, 'l1_Layer_2': 0.005982682563851615, 'l1_Layer_3': 0.0004564943994294146, 'n_units_Layer_1': 245, 'n_units_Layer_2': 160, 'n_units_Layer_3': 150}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.37 | sMAPE for Validation Set is: 18.80% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.24 | sMAPE for Test Set is: 18.56% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:24:40,686]\u001b[0m Trial 1142 finished with value: 32.26959777051288 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006026678175535918, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05516560734282049, 'dropout_rate_Layer_2': 0.06709081379214522, 'dropout_rate_Layer_3': 0.2676929384240558, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06428607425397435, 'l1_Layer_2': 0.0049746502675065305, 'l1_Layer_3': 0.000621846617311454, 'n_units_Layer_1': 240, 'n_units_Layer_2': 145, 'n_units_Layer_3': 155}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.27 | sMAPE for Validation Set is: 18.85% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.23 | sMAPE for Test Set is: 18.62% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:24:44,124]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:24:52,893]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:24:57,752]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:25:00,681]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:25:07,622]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:25:19,478]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:25:22,485]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:25:25,609]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:25:31,202]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:26:40,226]\u001b[0m Trial 1152 finished with value: 32.50707109218647 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005858516333824765, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06079857807555508, 'dropout_rate_Layer_2': 0.07111186717249218, 'dropout_rate_Layer_3': 0.29037516026209875, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06189226853778552, 'l1_Layer_2': 0.00620828026137418, 'l1_Layer_3': 0.0005279269386460007, 'n_units_Layer_1': 250, 'n_units_Layer_2': 140, 'n_units_Layer_3': 160}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.51 | sMAPE for Validation Set is: 19.12% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.39 | sMAPE for Test Set is: 18.94% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:26:48,548]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:26:51,573]\u001b[0m Trial 1153 finished with value: 32.25352316294414 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005697461731362247, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06325492846358559, 'dropout_rate_Layer_2': 0.06797074169495534, 'dropout_rate_Layer_3': 0.29265500418201784, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.060651852790304404, 'l1_Layer_2': 0.006138058013891391, 'l1_Layer_3': 0.0006354611709289674, 'n_units_Layer_1': 240, 'n_units_Layer_2': 145, 'n_units_Layer_3': 140}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.25 | sMAPE for Validation Set is: 18.99% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.49 | sMAPE for Test Set is: 19.08% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:26:58,349]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:27:01,910]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:27:04,767]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:27:07,478]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:28:00,069]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:28:02,924]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:28:09,981]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:28:18,662]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:28:25,377]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:28:28,631]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:28:34,902]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:28:39,063]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:28:41,891]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:28:45,414]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:28:48,123]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:29:08,445]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:29:21,067]\u001b[0m Trial 1164 finished with value: 32.40134831344615 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006180329855717267, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07011363157485703, 'dropout_rate_Layer_2': 0.07799491463210302, 'dropout_rate_Layer_3': 0.28713152233022105, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.08172122364185658, 'l1_Layer_2': 0.004783277431374045, 'l1_Layer_3': 0.0005476090548915489, 'n_units_Layer_1': 240, 'n_units_Layer_2': 140, 'n_units_Layer_3': 145}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.40 | sMAPE for Validation Set is: 19.20% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.56 | sMAPE for Test Set is: 19.19% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:30:03,212]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:30:11,820]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:30:16,517]\u001b[0m Trial 1173 finished with value: 32.63241985131131 and parameters: {'n_hidden': 3, 'learning_rate': 0.000501655488868091, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07068032139172017, 'dropout_rate_Layer_2': 0.07855583044836473, 'dropout_rate_Layer_3': 0.27517259820719886, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.08330865578095233, 'l1_Layer_2': 0.0035301169490889166, 'l1_Layer_3': 0.0003652876658898595, 'n_units_Layer_1': 245, 'n_units_Layer_2': 135, 'n_units_Layer_3': 150}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.63 | sMAPE for Validation Set is: 19.15% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.50 | sMAPE for Test Set is: 19.01% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:30:20,411]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:30:37,030]\u001b[0m Trial 1177 finished with value: 33.012265317603195 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020233131027028155, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25775849537748846, 'dropout_rate_Layer_2': 0.08425515094454139, 'dropout_rate_Layer_3': 0.21163447789668338, 'dropout_rate_Layer_4': 0.0003959115971708619, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01115618048721704, 'l1_Layer_2': 0.006897111622315398, 'l1_Layer_3': 0.0008150498302617864, 'l1_Layer_4': 1.1415022761889321e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 105, 'n_units_Layer_3': 135, 'n_units_Layer_4': 165}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.01 | sMAPE for Validation Set is: 19.52% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 15.01 | sMAPE for Test Set is: 19.91% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:30:42,148]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:30:46,983]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:31:06,990]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:31:09,964]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:31:13,534]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:31:13,899]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:31:26,806]\u001b[0m Trial 1183 finished with value: 33.68118774905995 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015916248178136792, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2558568878406711, 'dropout_rate_Layer_2': 0.08092401168957161, 'dropout_rate_Layer_3': 0.21118023305584643, 'dropout_rate_Layer_4': 0.017016703966712794, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.011828290473030889, 'l1_Layer_2': 0.00028214550059266175, 'l1_Layer_3': 0.0009575442874936449, 'l1_Layer_4': 1.4046934702671158e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 105, 'n_units_Layer_3': 135, 'n_units_Layer_4': 160}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.68 | sMAPE for Validation Set is: 19.68% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.37 | sMAPE for Test Set is: 18.77% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:32:20,203]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:32:28,732]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:32:31,257]\u001b[0m Trial 1184 finished with value: 32.37455643017421 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006077772956721417, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.057564716492107496, 'dropout_rate_Layer_2': 0.09050648431888864, 'dropout_rate_Layer_3': 0.2939217812874473, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.099028787429402, 'l1_Layer_2': 0.0066581582234816845, 'l1_Layer_3': 0.00038620729163181566, 'n_units_Layer_1': 240, 'n_units_Layer_2': 135, 'n_units_Layer_3': 145}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.37 | sMAPE for Validation Set is: 19.23% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.67 | sMAPE for Test Set is: 19.48% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:32:41,439]\u001b[0m Trial 1187 finished with value: 32.52328722488725 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010521667378250758, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1733794383452967, 'dropout_rate_Layer_2': 0.3268071906264245, 'dropout_rate_Layer_3': 0.34944047153553104, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.05656874710339142, 'l1_Layer_2': 0.00016732169167580095, 'l1_Layer_3': 0.00016099325968886008, 'n_units_Layer_1': 105, 'n_units_Layer_2': 90, 'n_units_Layer_3': 145}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.52 | sMAPE for Validation Set is: 19.03% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.57 | sMAPE for Test Set is: 19.07% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:32:45,357]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:32:49,392]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:32:54,727]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:32:59,527]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:33:02,642]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:33:05,844]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:33:15,973]\u001b[0m Trial 1188 finished with value: 32.85358167229307 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005910204766619488, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04650598521558744, 'dropout_rate_Layer_2': 0.08774994377381265, 'dropout_rate_Layer_3': 0.3042355855487313, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.08151576723386891, 'l1_Layer_2': 0.0061235760490716195, 'l1_Layer_3': 0.0003084881416855646, 'n_units_Layer_1': 240, 'n_units_Layer_2': 125, 'n_units_Layer_3': 150}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.85 | sMAPE for Validation Set is: 19.08% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.59 | sMAPE for Test Set is: 18.99% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:33:19,241]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:33:39,406]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:33:44,602]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:34:03,830]\u001b[0m Trial 1195 finished with value: 32.49073421960381 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006611677791505488, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05185806583850529, 'dropout_rate_Layer_2': 0.0915346455548269, 'dropout_rate_Layer_3': 0.29103230485739656, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0801261612758879, 'l1_Layer_2': 0.006635220197942197, 'l1_Layer_3': 0.00038630535219384796, 'n_units_Layer_1': 245, 'n_units_Layer_2': 135, 'n_units_Layer_3': 170}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.49 | sMAPE for Validation Set is: 19.08% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.47 | sMAPE for Test Set is: 18.97% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:34:05,738]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:34:09,010]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:34:09,161]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:34:14,979]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:35:04,873]\u001b[0m Trial 1203 finished with value: 32.37757886322739 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007340265735642024, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05163996591693952, 'dropout_rate_Layer_2': 0.1003278042790645, 'dropout_rate_Layer_3': 0.3149595774746475, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06021111727795818, 'l1_Layer_2': 0.0066464518638008705, 'l1_Layer_3': 0.0005381676693605644, 'n_units_Layer_1': 250, 'n_units_Layer_2': 145, 'n_units_Layer_3': 160}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.38 | sMAPE for Validation Set is: 18.83% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.54 | sMAPE for Test Set is: 18.86% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:35:05,515]\u001b[0m Trial 1204 finished with value: 32.442351567673064 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007261095517961069, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.048955613893867655, 'dropout_rate_Layer_2': 0.10333202585371022, 'dropout_rate_Layer_3': 0.314247860061648, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09989383835292526, 'l1_Layer_2': 0.005996211198373376, 'l1_Layer_3': 0.0005268842960330487, 'n_units_Layer_1': 250, 'n_units_Layer_2': 145, 'n_units_Layer_3': 170}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.44 | sMAPE for Validation Set is: 19.08% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.50 | sMAPE for Test Set is: 19.13% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:35:10,915]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:35:15,512]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:35:25,833]\u001b[0m Trial 1208 finished with value: 32.55009581377164 and parameters: {'n_hidden': 3, 'learning_rate': 0.00187024579282721, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12557186900772258, 'dropout_rate_Layer_2': 0.3947528878745492, 'dropout_rate_Layer_3': 0.39757561670404756, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.04511778737914684, 'l1_Layer_2': 0.0002376230902706378, 'l1_Layer_3': 0.00035515714221038126, 'n_units_Layer_1': 145, 'n_units_Layer_2': 60, 'n_units_Layer_3': 210}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.55 | sMAPE for Validation Set is: 18.90% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.51 | sMAPE for Test Set is: 18.89% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:35:42,490]\u001b[0m Trial 1209 finished with value: 32.12066056132539 and parameters: {'n_hidden': 3, 'learning_rate': 0.000810296996784665, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12230884334714787, 'dropout_rate_Layer_2': 0.2240857983974756, 'dropout_rate_Layer_3': 0.38054276741510507, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.05415516387856898, 'l1_Layer_2': 1.425215297375226e-05, 'l1_Layer_3': 0.007853600760795752, 'n_units_Layer_1': 220, 'n_units_Layer_2': 265, 'n_units_Layer_3': 85}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.12 | sMAPE for Validation Set is: 18.81% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.78 | sMAPE for Test Set is: 19.22% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:36:16,737]\u001b[0m Trial 1206 finished with value: 32.4048045102733 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007053432258812757, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04745081432018662, 'dropout_rate_Layer_2': 0.11737664006563285, 'dropout_rate_Layer_3': 0.31297617181394316, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09550704945586132, 'l1_Layer_2': 0.007926375840850026, 'l1_Layer_3': 0.0004547191385319299, 'n_units_Layer_1': 255, 'n_units_Layer_2': 145, 'n_units_Layer_3': 170}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.40 | sMAPE for Validation Set is: 18.88% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.30 | sMAPE for Test Set is: 18.71% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:36:21,534]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:36:37,786]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:36:42,055]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:36:43,699]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:36:46,489]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:36:50,066]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:36:54,717]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:36:58,382]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:37:06,695]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:37:08,836]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:37:12,171]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:37:15,183]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:37:35,248]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:37:38,675]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:37:48,049]\u001b[0m Trial 1225 finished with value: 32.80162631467734 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021558445194908224, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09046570345381882, 'dropout_rate_Layer_2': 0.36801349674877387, 'dropout_rate_Layer_3': 0.37577268787146023, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03912167234131775, 'l1_Layer_2': 0.00031047714630659653, 'l1_Layer_3': 0.0003125544341476595, 'n_units_Layer_1': 125, 'n_units_Layer_2': 70, 'n_units_Layer_3': 215}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.80 | sMAPE for Validation Set is: 19.11% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.27 | sMAPE for Test Set is: 18.78% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:37:52,607]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:38:04,317]\u001b[0m Trial 1220 finished with value: 32.45771170334887 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006293387406132766, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03610907721073715, 'dropout_rate_Layer_2': 0.1071066265632323, 'dropout_rate_Layer_3': 0.3136344029191973, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.07391298972863479, 'l1_Layer_2': 0.005368868742040848, 'l1_Layer_3': 0.0002315055193532671, 'n_units_Layer_1': 255, 'n_units_Layer_2': 145, 'n_units_Layer_3': 165}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.46 | sMAPE for Validation Set is: 18.86% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.38 | sMAPE for Test Set is: 18.70% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:38:09,467]\u001b[0m Trial 1227 finished with value: 33.173051793847776 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009099873381339524, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2558320391703547, 'dropout_rate_Layer_2': 0.1132827568471362, 'dropout_rate_Layer_3': 0.21757192775324663, 'dropout_rate_Layer_4': 0.021937461199737236, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.03839261048090183, 'l1_Layer_2': 0.0003210346523218689, 'l1_Layer_3': 5.331847781606745e-05, 'l1_Layer_4': 0.011068635898664919, 'n_units_Layer_1': 190, 'n_units_Layer_2': 100, 'n_units_Layer_3': 150, 'n_units_Layer_4': 150}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.17 | sMAPE for Validation Set is: 19.39% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.61 | sMAPE for Test Set is: 19.25% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:38:11,734]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:38:14,150]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:38:14,920]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:38:21,665]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:38:26,379]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:38:38,282]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:39:10,873]\u001b[0m Trial 1231 finished with value: 32.39285195953354 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005549321258877494, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03507454885941011, 'dropout_rate_Layer_2': 0.11925635071233821, 'dropout_rate_Layer_3': 0.31911675390253946, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.060419842014370576, 'l1_Layer_2': 0.005058705647632331, 'l1_Layer_3': 0.0006591105355830388, 'n_units_Layer_1': 260, 'n_units_Layer_2': 155, 'n_units_Layer_3': 160}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.39 | sMAPE for Validation Set is: 18.82% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.28 | sMAPE for Test Set is: 18.67% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:39:30,695]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:39:33,976]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:39:34,110]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:39:40,133]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:39:43,628]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:39:46,037]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:39:51,189]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:40:05,750]\u001b[0m Trial 1242 finished with value: 32.215267804612445 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017753811653365517, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11880959167393376, 'dropout_rate_Layer_2': 0.3514211041603017, 'dropout_rate_Layer_3': 0.0008930623904926725, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.028237934802711216, 'l1_Layer_2': 0.00012261611994445588, 'l1_Layer_3': 0.0010338838391398186, 'n_units_Layer_1': 150, 'n_units_Layer_2': 75, 'n_units_Layer_3': 200}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.22 | sMAPE for Validation Set is: 18.80% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.54 | sMAPE for Test Set is: 18.90% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:40:25,075]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:40:29,667]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:40:34,398]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:40:37,375]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:40:56,990]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:41:05,639]\u001b[0m Trial 1243 finished with value: 32.28917652886451 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005572998954185419, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0477816306228298, 'dropout_rate_Layer_2': 0.12161782694338656, 'dropout_rate_Layer_3': 0.3459162497747634, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.08476834885399642, 'l1_Layer_2': 0.005290565172535613, 'l1_Layer_3': 0.0004921691401525479, 'n_units_Layer_1': 250, 'n_units_Layer_2': 155, 'n_units_Layer_3': 160}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.29 | sMAPE for Validation Set is: 18.88% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.70 | sMAPE for Test Set is: 19.01% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:41:10,293]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:41:14,920]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:41:26,013]\u001b[0m Trial 1250 finished with value: 32.38289728490889 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008827823402211367, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25378287545625805, 'dropout_rate_Layer_2': 0.11183756914513861, 'dropout_rate_Layer_3': 0.20265570507451072, 'dropout_rate_Layer_4': 0.008001257867980152, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0159071469116117, 'l1_Layer_2': 0.0002794889179698227, 'l1_Layer_3': 6.10331699516376e-05, 'l1_Layer_4': 0.01479396892220383, 'n_units_Layer_1': 185, 'n_units_Layer_2': 100, 'n_units_Layer_3': 150, 'n_units_Layer_4': 150}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.38 | sMAPE for Validation Set is: 18.97% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.40 | sMAPE for Test Set is: 18.82% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:41:30,671]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:41:35,434]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:41:40,155]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:41:45,115]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:42:14,248]\u001b[0m Trial 1252 finished with value: 32.478388590767175 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005623472776939538, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05040831822553358, 'dropout_rate_Layer_2': 0.1167096467786582, 'dropout_rate_Layer_3': 0.3416815589512078, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09958842833717921, 'l1_Layer_2': 0.004748821286463808, 'l1_Layer_3': 0.0005196609969538308, 'n_units_Layer_1': 250, 'n_units_Layer_2': 170, 'n_units_Layer_3': 160}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.48 | sMAPE for Validation Set is: 18.77% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.34 | sMAPE for Test Set is: 18.61% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:42:19,696]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:42:23,232]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:42:35,079]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:42:38,337]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:42:41,061]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:42:46,023]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:42:49,475]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:42:52,201]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:42:56,880]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:43:01,480]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:43:04,896]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:43:07,749]\u001b[0m Trial 1257 finished with value: 32.48620771087027 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007068907348453388, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05031178383361816, 'dropout_rate_Layer_2': 0.10227837081921143, 'dropout_rate_Layer_3': 0.30064315209747533, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06779184535821199, 'l1_Layer_2': 0.0036268308264296636, 'l1_Layer_3': 0.0005947178192253999, 'n_units_Layer_1': 250, 'n_units_Layer_2': 170, 'n_units_Layer_3': 175}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.49 | sMAPE for Validation Set is: 19.04% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.62 | sMAPE for Test Set is: 19.04% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:43:14,499]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:43:17,736]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:43:20,453]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:43:23,887]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:43:28,427]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:43:33,009]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:43:52,970]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:43:57,688]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:44:00,667]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:44:06,970]\u001b[0m Trial 1270 finished with value: 32.505408313342095 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007994722450374552, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06238024219118777, 'dropout_rate_Layer_2': 0.3508755390459371, 'dropout_rate_Layer_3': 0.31714859688773916, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.046329169563363005, 'l1_Layer_2': 0.0076432210916663025, 'l1_Layer_3': 0.0007315332230411016, 'n_units_Layer_1': 260, 'n_units_Layer_2': 155, 'n_units_Layer_3': 165}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.51 | sMAPE for Validation Set is: 18.97% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.34 | sMAPE for Test Set is: 18.74% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:44:57,565]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:45:03,638]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:45:08,283]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:45:12,831]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:45:26,262]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:45:55,834]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:45:59,090]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:46:04,247]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:46:07,227]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:46:11,912]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:46:25,551]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:46:32,626]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:46:52,274]\u001b[0m Trial 1292 finished with value: 32.46461676062264 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012280369220142332, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06300253691253323, 'dropout_rate_Layer_2': 0.350382051125702, 'dropout_rate_Layer_3': 0.0013616314973945577, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.016771363767769356, 'l1_Layer_2': 0.00011533444359188254, 'l1_Layer_3': 0.0010864678555152806, 'n_units_Layer_1': 135, 'n_units_Layer_2': 80, 'n_units_Layer_3': 200}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.46 | sMAPE for Validation Set is: 18.96% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.30 | sMAPE for Test Set is: 18.74% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:46:55,460]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:46:58,958]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:47:02,609]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:47:05,336]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:47:08,450]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:47:11,564]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:47:16,495]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:47:28,491]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:47:33,455]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:47:38,066]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:47:50,945]\u001b[0m Trial 1291 finished with value: 32.12723141555236 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005597687345584393, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05584690944714616, 'dropout_rate_Layer_2': 0.13325171835350724, 'dropout_rate_Layer_3': 0.29193054998283074, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.037543167214445054, 'l1_Layer_2': 0.002885887514114083, 'l1_Layer_3': 0.00081630229639028, 'n_units_Layer_1': 245, 'n_units_Layer_2': 155, 'n_units_Layer_3': 150}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.13 | sMAPE for Validation Set is: 18.87% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.36 | sMAPE for Test Set is: 18.85% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:47:54,103]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:47:57,279]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:47:59,791]\u001b[0m Trial 1303 finished with value: 32.79657456293231 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011078020482113704, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28754245282788715, 'dropout_rate_Layer_2': 0.16369023549438427, 'dropout_rate_Layer_3': 0.23412060086590972, 'dropout_rate_Layer_4': 0.015753089583356427, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.015286955647177717, 'l1_Layer_2': 0.0002820314724535218, 'l1_Layer_3': 4.3995981391077834e-05, 'l1_Layer_4': 0.00020646564776698496, 'n_units_Layer_1': 115, 'n_units_Layer_2': 85, 'n_units_Layer_3': 135, 'n_units_Layer_4': 280}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.80 | sMAPE for Validation Set is: 19.38% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.54 | sMAPE for Test Set is: 19.32% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:48:04,547]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:48:07,707]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:48:10,191]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:48:13,602]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:48:26,673]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:48:26,953]\u001b[0m Trial 1309 finished with value: 32.321423099188614 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015581296597034528, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07930505727676569, 'dropout_rate_Layer_2': 0.35897609156429927, 'dropout_rate_Layer_3': 0.038299970730786295, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.029533850542838018, 'l1_Layer_2': 0.00013276806597324988, 'l1_Layer_3': 0.007902587136371738, 'n_units_Layer_1': 150, 'n_units_Layer_2': 75, 'n_units_Layer_3': 205}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.32 | sMAPE for Validation Set is: 18.80% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.30 | sMAPE for Test Set is: 18.72% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:48:32,723]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:48:34,928]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:48:38,534]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:48:45,152]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:48:48,794]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:48:51,876]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:48:56,080]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:48:59,746]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:49:06,675]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:49:09,363]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:49:53,967]\u001b[0m Trial 1322 finished with value: 32.326111943513105 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005607383631291146, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0537273885129186, 'dropout_rate_Layer_2': 0.1237836225197309, 'dropout_rate_Layer_3': 0.26374533481125495, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.053017862122221905, 'l1_Layer_2': 0.002834367792928744, 'l1_Layer_3': 0.0007706577302190695, 'n_units_Layer_1': 245, 'n_units_Layer_2': 145, 'n_units_Layer_3': 135}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.33 | sMAPE for Validation Set is: 18.79% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.42 | sMAPE for Test Set is: 18.76% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:50:06,253]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:50:10,863]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:50:17,510]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:50:22,150]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:50:25,965]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:50:29,311]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:50:34,234]\u001b[0m Trial 1323 finished with value: 32.31853563237346 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005999109996259781, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.052233815232031834, 'dropout_rate_Layer_2': 0.3638126341897925, 'dropout_rate_Layer_3': 0.28082863651652384, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.05204924847629238, 'l1_Layer_2': 0.00315529165532626, 'l1_Layer_3': 0.000714836943448557, 'n_units_Layer_1': 250, 'n_units_Layer_2': 135, 'n_units_Layer_3': 145}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.32 | sMAPE for Validation Set is: 18.84% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.43 | sMAPE for Test Set is: 18.76% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:50:39,034]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:50:44,782]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:50:58,128]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:51:03,055]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:51:23,063]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:51:27,718]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:51:36,110]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:51:44,438]\u001b[0m Trial 1334 finished with value: 32.57862012301189 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006279944386897087, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05196824174147795, 'dropout_rate_Layer_2': 0.3730790980085694, 'dropout_rate_Layer_3': 0.28445214269136093, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.04910808666351081, 'l1_Layer_2': 0.003265858353642555, 'l1_Layer_3': 0.0006720487830775807, 'n_units_Layer_1': 250, 'n_units_Layer_2': 130, 'n_units_Layer_3': 145}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.58 | sMAPE for Validation Set is: 19.04% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.58 | sMAPE for Test Set is: 19.01% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:51:49,199]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:51:57,631]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:52:00,621]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:52:03,583]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:52:10,103]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:52:13,258]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:52:26,637]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:52:35,281]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:52:43,805]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:52:47,117]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:52:56,794]\u001b[0m Trial 1338 finished with value: 32.230846469251354 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005023201981877477, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05623142342348086, 'dropout_rate_Layer_2': 0.12012014216974262, 'dropout_rate_Layer_3': 0.28637684166679017, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0521449333215104, 'l1_Layer_2': 0.001497919149030471, 'l1_Layer_3': 0.0006993439653226075, 'n_units_Layer_1': 260, 'n_units_Layer_2': 140, 'n_units_Layer_3': 145}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.23 | sMAPE for Validation Set is: 18.84% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.42 | sMAPE for Test Set is: 18.88% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:53:01,760]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:53:10,655]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:53:15,234]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:53:18,186]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:53:31,259]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:53:40,272]\u001b[0m Trial 1355 finished with value: 33.23490698291048 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017192587997046423, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13203429063959715, 'dropout_rate_Layer_2': 0.3684119445586827, 'dropout_rate_Layer_3': 0.040586010457808575, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03369503771197483, 'l1_Layer_2': 0.00017637054541543032, 'l1_Layer_3': 0.0004277215614002556, 'n_units_Layer_1': 120, 'n_units_Layer_2': 70, 'n_units_Layer_3': 165}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.23 | sMAPE for Validation Set is: 19.16% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.48 | sMAPE for Test Set is: 18.84% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:53:43,272]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:53:47,954]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:53:51,747]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:53:59,420]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:54:02,516]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:54:06,028]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:54:08,258]\u001b[0m Trial 1359 finished with value: 32.40221054798399 and parameters: {'n_hidden': 3, 'learning_rate': 0.001495518760336416, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1411889102278814, 'dropout_rate_Layer_2': 0.3206619090597177, 'dropout_rate_Layer_3': 0.06565438908627412, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.05897284285800997, 'l1_Layer_2': 0.0005095240834453178, 'l1_Layer_3': 0.0005818444568024517, 'n_units_Layer_1': 135, 'n_units_Layer_2': 90, 'n_units_Layer_3': 200}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.40 | sMAPE for Validation Set is: 18.84% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.44 | sMAPE for Test Set is: 18.79% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:54:11,603]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:54:25,626]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:54:28,966]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:54:31,860]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:54:35,086]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:54:38,355]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:54:40,863]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:54:44,515]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:54:49,231]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:54:54,219]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:55:02,773]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:55:22,294]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:55:36,048]\u001b[0m Trial 1375 finished with value: 32.11883314583888 and parameters: {'n_hidden': 3, 'learning_rate': 0.001495666022681089, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1588792061957629, 'dropout_rate_Layer_2': 0.35745749864974286, 'dropout_rate_Layer_3': 0.08783862120490793, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.05937774575314058, 'l1_Layer_2': 0.0005773691379391226, 'l1_Layer_3': 0.002438501740908778, 'n_units_Layer_1': 135, 'n_units_Layer_2': 80, 'n_units_Layer_3': 205}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.12 | sMAPE for Validation Set is: 18.82% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.25 | sMAPE for Test Set is: 18.86% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:55:39,725]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:55:42,748]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:55:47,423]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:55:50,887]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:55:53,892]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:55:54,947]\u001b[0m Trial 1370 finished with value: 32.597406466704285 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005057402558155837, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.062074963035508385, 'dropout_rate_Layer_2': 0.11135392702034816, 'dropout_rate_Layer_3': 0.26691072668409493, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.028837429886980997, 'l1_Layer_2': 0.003970737185172289, 'l1_Layer_3': 0.00044319866020019845, 'n_units_Layer_1': 250, 'n_units_Layer_2': 175, 'n_units_Layer_3': 150}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.60 | sMAPE for Validation Set is: 19.09% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.61 | sMAPE for Test Set is: 19.03% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:55:59,897]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:56:17,026]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:56:19,947]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:56:22,628]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:56:24,646]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:56:28,177]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:56:28,677]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:56:32,606]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:56:37,223]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:56:40,565]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:56:51,933]\u001b[0m Trial 1391 finished with value: 32.136403668053326 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015186136244767735, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16183807699882818, 'dropout_rate_Layer_2': 0.3865527711866344, 'dropout_rate_Layer_3': 0.0898788322255053, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.07955032576418798, 'l1_Layer_2': 0.0004984276773261322, 'l1_Layer_3': 0.0025816366932747245, 'n_units_Layer_1': 135, 'n_units_Layer_2': 75, 'n_units_Layer_3': 220}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.14 | sMAPE for Validation Set is: 18.77% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.31 | sMAPE for Test Set is: 18.82% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:56:56,716]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:57:01,453]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:57:03,582]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:57:06,898]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:57:11,816]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:57:11,918]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:57:16,887]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:57:16,946]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:57:23,743]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:57:28,518]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:57:33,319]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:57:36,767]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:57:42,572]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:57:46,279]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:57:52,586]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:57:56,081]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:58:01,356]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:58:03,325]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:58:05,984]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:58:07,891]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:58:13,926]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:58:14,412]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:58:18,459]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:58:19,313]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:58:24,167]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:58:27,030]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:58:28,098]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:58:32,034]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:58:32,561]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:58:38,436]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:58:41,215]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:58:43,931]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:58:49,531]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:58:52,097]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:58:55,163]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:58:55,298]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:59:01,492]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:59:01,971]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:59:06,374]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:59:10,292]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:59:14,929]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:59:18,339]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:59:26,623]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:59:32,870]\u001b[0m Trial 1432 finished with value: 32.58919855615614 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009544312660920218, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13647027934774675, 'dropout_rate_Layer_2': 0.22447755468299463, 'dropout_rate_Layer_3': 0.01952874600922057, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03194826722659288, 'l1_Layer_2': 1.2161754682565883e-05, 'l1_Layer_3': 0.008905790068616457, 'n_units_Layer_1': 185, 'n_units_Layer_2': 210, 'n_units_Layer_3': 95}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.59 | sMAPE for Validation Set is: 18.85% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.43 | sMAPE for Test Set is: 18.76% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 09:59:36,419]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:59:43,002]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:59:46,140]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:59:49,560]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:59:50,282]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:59:56,458]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 09:59:58,519]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:00:01,370]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:00:04,405]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:00:05,741]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:00:11,314]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:00:14,381]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:00:17,291]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:00:20,351]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:00:23,833]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:00:26,868]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:00:38,805]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:00:43,627]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:00:47,540]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:00:59,132]\u001b[0m Trial 1456 finished with value: 32.70884786740805 and parameters: {'n_hidden': 3, 'learning_rate': 0.001474614814172087, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14977476087973599, 'dropout_rate_Layer_2': 0.3599445116031089, 'dropout_rate_Layer_3': 0.10897248203727856, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06327721791847181, 'l1_Layer_2': 0.0004911011507467395, 'l1_Layer_3': 0.0015901859313721704, 'n_units_Layer_1': 180, 'n_units_Layer_2': 95, 'n_units_Layer_3': 205}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.71 | sMAPE for Validation Set is: 19.23% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.70 | sMAPE for Test Set is: 19.27% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 10:01:02,109]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:01:06,908]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:01:10,280]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:01:16,564]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:01:21,304]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:01:21,670]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:01:25,443]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:01:27,749]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:01:33,328]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:01:36,840]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:01:41,405]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:01:44,698]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:01:48,157]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:02:00,054]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:02:03,024]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:02:07,743]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:02:11,830]\u001b[0m Trial 1464 finished with value: 32.372897970620926 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006590358492217743, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07653942335016847, 'dropout_rate_Layer_2': 0.08910680102976334, 'dropout_rate_Layer_3': 0.3162378057345978, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03104298200813693, 'l1_Layer_2': 0.004714904614321295, 'l1_Layer_3': 0.001080505353171113, 'n_units_Layer_1': 245, 'n_units_Layer_2': 175, 'n_units_Layer_3': 145}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.37 | sMAPE for Validation Set is: 18.83% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.68 | sMAPE for Test Set is: 18.98% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 10:02:15,226]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:02:18,274]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:02:23,004]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:02:25,729]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:02:27,828]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:02:40,007]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:02:43,100]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:02:46,164]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:02:52,732]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:02:58,688]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:03:04,315]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:03:07,993]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:03:11,624]\u001b[0m Trial 1479 finished with value: 32.258835207132876 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006101373199529324, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08059520551925828, 'dropout_rate_Layer_2': 0.09421773236132666, 'dropout_rate_Layer_3': 0.27575218503430315, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.026209102548351414, 'l1_Layer_2': 0.0003104090250714975, 'l1_Layer_3': 0.0009715860491900418, 'n_units_Layer_1': 240, 'n_units_Layer_2': 180, 'n_units_Layer_3': 135}. Best is trial 110 with value: 31.851008004817547.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.26 | sMAPE for Validation Set is: 18.75% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.59 | sMAPE for Test Set is: 18.84% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 10:03:17,800]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:03:21,144]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:03:32,941]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:03:42,719]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:03:45,814]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:03:46,102]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:03:50,428]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:03:54,681]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:03:58,163]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:03:58,507]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:04:02,836]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:04:05,056]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:04:08,430]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 10:04:14,234]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-01-01, MAE is:14.81 & sMAPE is:14.47% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :14.81 & 14.47% & 0.83\n",
      "for 2023-01-02, MAE is:30.50 & sMAPE is:23.38% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :22.66 & 18.93% & 0.85\n",
      "for 2023-01-03, MAE is:18.86 & sMAPE is:13.03% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :21.39 & 16.96% & 1.07\n",
      "for 2023-01-04, MAE is:18.41 & sMAPE is:17.26% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :20.65 & 17.04% & 1.21\n",
      "for 2023-01-05, MAE is:29.07 & sMAPE is:22.09% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :22.33 & 18.05% & 1.11\n",
      "for 2023-01-06, MAE is:15.13 & sMAPE is:12.96% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :21.13 & 17.20% & 1.03\n",
      "for 2023-01-07, MAE is:23.22 & sMAPE is:23.17% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :21.43 & 18.05% & 1.02\n",
      "for 2023-01-08, MAE is:39.71 & sMAPE is:72.50% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :23.71 & 24.86% & 1.03\n",
      "for 2023-01-09, MAE is:41.57 & sMAPE is:36.82% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :25.70 & 26.19% & 1.16\n",
      "for 2023-01-10, MAE is:20.81 & sMAPE is:17.77% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :25.21 & 25.35% & 1.13\n",
      "for 2023-01-11, MAE is:32.58 & sMAPE is:43.27% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :25.88 & 26.98% & 1.18\n",
      "for 2023-01-12, MAE is:27.95 & sMAPE is:42.01% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :26.05 & 28.23% & 1.13\n",
      "for 2023-01-13, MAE is:30.40 & sMAPE is:47.57% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :26.39 & 29.72% & 1.10\n",
      "for 2023-01-14, MAE is:13.66 & sMAPE is:17.35% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :25.48 & 28.83% & 1.09\n",
      "for 2023-01-15, MAE is:33.13 & sMAPE is:61.55% & rMAE is:2.69 ||| daily mean of MAE & sMAPE & rMAE till now are :25.99 & 31.01% & 1.20\n",
      "for 2023-01-16, MAE is:35.66 & sMAPE is:30.27% & rMAE is:2.80 ||| daily mean of MAE & sMAPE & rMAE till now are :26.59 & 30.97% & 1.30\n",
      "for 2023-01-17, MAE is:11.37 & sMAPE is:9.27% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :25.70 & 29.69% & 1.26\n",
      "for 2023-01-18, MAE is:9.17 & sMAPE is:7.03% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :24.78 & 28.43% & 1.20\n",
      "for 2023-01-19, MAE is:26.44 & sMAPE is:19.64% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :24.87 & 27.97% & 1.16\n",
      "for 2023-01-20, MAE is:20.26 & sMAPE is:13.97% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :24.64 & 27.27% & 1.12\n",
      "for 2023-01-21, MAE is:8.67 & sMAPE is:6.01% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :23.88 & 26.26% & 1.07\n",
      "for 2023-01-22, MAE is:19.71 & sMAPE is:13.88% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :23.69 & 25.69% & 1.04\n",
      "for 2023-01-23, MAE is:47.96 & sMAPE is:26.46% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :24.74 & 25.73% & 1.03\n",
      "for 2023-01-24, MAE is:36.59 & sMAPE is:20.56% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :25.23 & 25.51% & 1.02\n",
      "for 2023-01-25, MAE is:13.68 & sMAPE is:10.31% & rMAE is:2.30 ||| daily mean of MAE & sMAPE & rMAE till now are :24.77 & 24.90% & 1.07\n",
      "for 2023-01-26, MAE is:6.33 & sMAPE is:5.18% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :24.06 & 24.15% & 1.04\n",
      "for 2023-01-27, MAE is:27.51 & sMAPE is:18.97% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :24.19 & 23.95% & 1.05\n",
      "for 2023-01-28, MAE is:7.05 & sMAPE is:6.23% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :23.58 & 23.32% & 1.02\n",
      "for 2023-01-29, MAE is:11.20 & sMAPE is:11.28% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :23.15 & 22.91% & 0.99\n",
      "for 2023-01-30, MAE is:13.59 & sMAPE is:17.06% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :22.83 & 22.71% & 0.96\n",
      "for 2023-01-31, MAE is:6.33 & sMAPE is:6.52% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :22.30 & 22.19% & 0.94\n",
      "for 2023-02-01, MAE is:8.82 & sMAPE is:9.44% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :21.88 & 21.79% & 0.91\n",
      "for 2023-02-02, MAE is:42.24 & sMAPE is:34.15% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :22.50 & 22.17% & 0.94\n",
      "for 2023-02-03, MAE is:22.01 & sMAPE is:19.40% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :22.48 & 22.08% & 0.93\n",
      "for 2023-02-04, MAE is:25.25 & sMAPE is:21.53% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :22.56 & 22.07% & 0.94\n",
      "for 2023-02-05, MAE is:6.76 & sMAPE is:5.96% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :22.12 & 21.62% & 0.93\n",
      "for 2023-02-06, MAE is:29.52 & sMAPE is:20.34% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :22.32 & 21.59% & 0.91\n",
      "for 2023-02-07, MAE is:5.98 & sMAPE is:4.85% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :21.89 & 21.15% & 0.90\n",
      "for 2023-02-08, MAE is:10.98 & sMAPE is:9.94% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :21.61 & 20.86% & 0.89\n",
      "for 2023-02-09, MAE is:7.06 & sMAPE is:7.73% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :21.25 & 20.53% & 0.88\n",
      "for 2023-02-10, MAE is:9.95 & sMAPE is:11.03% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :20.97 & 20.30% & 0.87\n",
      "for 2023-02-11, MAE is:6.67 & sMAPE is:7.59% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :20.63 & 20.00% & 0.85\n",
      "for 2023-02-12, MAE is:6.62 & sMAPE is:6.66% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :20.31 & 19.69% & 0.85\n",
      "for 2023-02-13, MAE is:3.26 & sMAPE is:3.07% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :19.92 & 19.31% & 0.83\n",
      "for 2023-02-14, MAE is:22.12 & sMAPE is:16.00% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :19.97 & 19.23% & 0.84\n",
      "for 2023-02-15, MAE is:9.73 & sMAPE is:8.01% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :19.75 & 18.99% & 0.85\n",
      "for 2023-02-16, MAE is:12.09 & sMAPE is:10.79% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :19.58 & 18.82% & 0.84\n",
      "for 2023-02-17, MAE is:14.72 & sMAPE is:16.44% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :19.48 & 18.77% & 0.85\n",
      "for 2023-02-18, MAE is:21.19 & sMAPE is:25.44% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :19.52 & 18.90% & 0.88\n",
      "for 2023-02-19, MAE is:4.92 & sMAPE is:5.01% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :19.22 & 18.63% & 0.88\n",
      "for 2023-02-20, MAE is:24.93 & sMAPE is:32.62% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :19.34 & 18.90% & 0.87\n",
      "for 2023-02-21, MAE is:23.72 & sMAPE is:26.49% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :19.42 & 19.05% & 0.87\n",
      "for 2023-02-22, MAE is:4.31 & sMAPE is:3.96% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :19.14 & 18.76% & 0.87\n",
      "for 2023-02-23, MAE is:4.19 & sMAPE is:4.01% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :18.86 & 18.49% & 0.86\n",
      "for 2023-02-24, MAE is:4.14 & sMAPE is:4.36% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :18.59 & 18.23% & 0.85\n",
      "for 2023-02-25, MAE is:5.88 & sMAPE is:6.68% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :18.36 & 18.02% & 0.84\n",
      "for 2023-02-26, MAE is:9.62 & sMAPE is:9.66% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :18.21 & 17.88% & 0.85\n",
      "for 2023-02-27, MAE is:6.63 & sMAPE is:5.36% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :18.01 & 17.66% & 0.84\n",
      "for 2023-02-28, MAE is:3.85 & sMAPE is:3.41% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :17.77 & 17.42% & 0.83\n",
      "for 2023-03-01, MAE is:8.40 & sMAPE is:6.52% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :17.61 & 17.24% & 0.83\n",
      "for 2023-03-02, MAE is:4.44 & sMAPE is:4.05% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :17.40 & 17.02% & 0.83\n",
      "for 2023-03-03, MAE is:8.47 & sMAPE is:8.21% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :17.25 & 16.88% & 0.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-03-04, MAE is:16.60 & sMAPE is:17.73% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :17.24 & 16.89% & 0.84\n",
      "for 2023-03-05, MAE is:13.46 & sMAPE is:10.95% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :17.19 & 16.80% & 0.84\n",
      "for 2023-03-06, MAE is:18.52 & sMAPE is:12.88% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :17.21 & 16.74% & 0.84\n",
      "for 2023-03-07, MAE is:18.82 & sMAPE is:16.96% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :17.23 & 16.74% & 0.85\n",
      "for 2023-03-08, MAE is:22.87 & sMAPE is:17.60% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :17.31 & 16.76% & 0.85\n",
      "for 2023-03-09, MAE is:8.20 & sMAPE is:6.48% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :17.18 & 16.61% & 0.85\n",
      "for 2023-03-10, MAE is:8.58 & sMAPE is:7.53% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :17.06 & 16.47% & 0.85\n",
      "for 2023-03-11, MAE is:7.78 & sMAPE is:7.93% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :16.92 & 16.35% & 0.85\n",
      "for 2023-03-12, MAE is:9.72 & sMAPE is:9.97% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :16.82 & 16.26% & 0.85\n",
      "for 2023-03-13, MAE is:14.58 & sMAPE is:16.54% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :16.79 & 16.27% & 0.84\n",
      "for 2023-03-14, MAE is:5.95 & sMAPE is:6.58% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :16.64 & 16.13% & 0.83\n",
      "for 2023-03-15, MAE is:7.93 & sMAPE is:7.12% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :16.52 & 16.01% & 0.83\n",
      "for 2023-03-16, MAE is:14.75 & sMAPE is:14.16% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :16.50 & 15.99% & 0.82\n",
      "for 2023-03-17, MAE is:5.89 & sMAPE is:6.50% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :16.36 & 15.86% & 0.82\n",
      "for 2023-03-18, MAE is:6.01 & sMAPE is:6.49% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :16.23 & 15.74% & 0.82\n",
      "for 2023-03-19, MAE is:3.83 & sMAPE is:4.06% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :16.07 & 15.59% & 0.82\n",
      "for 2023-03-20, MAE is:3.52 & sMAPE is:3.41% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :15.91 & 15.44% & 0.81\n",
      "for 2023-03-21, MAE is:9.48 & sMAPE is:9.23% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :15.83 & 15.36% & 0.81\n",
      "for 2023-03-22, MAE is:14.05 & sMAPE is:16.09% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :15.81 & 15.37% & 0.81\n",
      "for 2023-03-23, MAE is:13.40 & sMAPE is:17.96% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :15.78 & 15.40% & 0.81\n",
      "for 2023-03-24, MAE is:9.49 & sMAPE is:12.67% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :15.70 & 15.37% & 0.80\n",
      "for 2023-03-25, MAE is:11.31 & sMAPE is:24.32% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :15.65 & 15.47% & 0.80\n",
      "for 2023-03-26, MAE is:5.46 & sMAPE is:6.55% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :15.53 & 15.37% & 0.79\n",
      "for 2023-03-27, MAE is:8.52 & sMAPE is:9.55% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :15.45 & 15.30% & 0.79\n",
      "for 2023-03-28, MAE is:14.77 & sMAPE is:12.81% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :15.44 & 15.27% & 0.79\n",
      "for 2023-03-29, MAE is:11.43 & sMAPE is:9.73% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :15.39 & 15.21% & 0.79\n",
      "for 2023-03-30, MAE is:8.91 & sMAPE is:9.49% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :15.32 & 15.14% & 0.79\n",
      "for 2023-03-31, MAE is:10.54 & sMAPE is:10.64% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :15.27 & 15.09% & 0.78\n",
      "for 2023-04-01, MAE is:1.94 & sMAPE is:2.28% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :15.12 & 14.95% & 0.77\n",
      "for 2023-04-02, MAE is:9.50 & sMAPE is:10.58% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :15.06 & 14.91% & 0.78\n",
      "for 2023-04-03, MAE is:15.49 & sMAPE is:13.39% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :15.07 & 14.89% & 0.77\n",
      "for 2023-04-04, MAE is:9.64 & sMAPE is:7.53% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :15.01 & 14.81% & 0.77\n",
      "for 2023-04-05, MAE is:10.01 & sMAPE is:8.10% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :14.96 & 14.74% & 0.77\n",
      "for 2023-04-06, MAE is:6.94 & sMAPE is:6.49% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :14.87 & 14.66% & 0.77\n",
      "for 2023-04-07, MAE is:4.86 & sMAPE is:4.79% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :14.77 & 14.55% & 0.77\n",
      "for 2023-04-08, MAE is:5.15 & sMAPE is:5.01% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :14.67 & 14.46% & 0.76\n",
      "for 2023-04-09, MAE is:12.26 & sMAPE is:13.69% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :14.65 & 14.45% & 0.76\n",
      "for 2023-04-10, MAE is:57.06 & sMAPE is:82.54% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :15.07 & 15.13% & 0.76\n",
      "for 2023-04-11, MAE is:33.91 & sMAPE is:67.63% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :15.26 & 15.65% & 0.76\n",
      "for 2023-04-12, MAE is:7.83 & sMAPE is:8.11% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :15.18 & 15.58% & 0.76\n",
      "for 2023-04-13, MAE is:8.39 & sMAPE is:9.05% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :15.12 & 15.51% & 0.76\n",
      "for 2023-04-14, MAE is:6.56 & sMAPE is:6.67% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :15.04 & 15.43% & 0.76\n",
      "for 2023-04-15, MAE is:8.13 & sMAPE is:8.29% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :14.97 & 15.36% & 0.76\n",
      "for 2023-04-16, MAE is:3.11 & sMAPE is:3.12% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :14.86 & 15.24% & 0.76\n",
      "for 2023-04-17, MAE is:12.55 & sMAPE is:10.76% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :14.84 & 15.20% & 0.75\n",
      "for 2023-04-18, MAE is:12.19 & sMAPE is:11.61% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :14.81 & 15.17% & 0.75\n",
      "for 2023-04-19, MAE is:10.79 & sMAPE is:11.60% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :14.78 & 15.14% & 0.75\n",
      "for 2023-04-20, MAE is:4.56 & sMAPE is:4.81% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :14.68 & 15.04% & 0.75\n",
      "for 2023-04-21, MAE is:8.72 & sMAPE is:9.73% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :14.63 & 14.99% & 0.75\n",
      "for 2023-04-22, MAE is:13.30 & sMAPE is:17.53% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :14.62 & 15.02% & 0.76\n",
      "for 2023-04-23, MAE is:15.64 & sMAPE is:21.35% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :14.63 & 15.07% & 0.76\n",
      "for 2023-04-24, MAE is:7.87 & sMAPE is:8.06% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :14.57 & 15.01% & 0.75\n",
      "for 2023-04-25, MAE is:15.30 & sMAPE is:16.15% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :14.57 & 15.02% & 0.76\n",
      "for 2023-04-26, MAE is:4.86 & sMAPE is:5.07% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :14.49 & 14.94% & 0.76\n",
      "for 2023-04-27, MAE is:10.92 & sMAPE is:9.89% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :14.46 & 14.89% & 0.76\n",
      "for 2023-04-28, MAE is:6.72 & sMAPE is:6.38% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :14.39 & 14.82% & 0.76\n",
      "for 2023-04-29, MAE is:10.80 & sMAPE is:11.40% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :14.36 & 14.79% & 0.76\n",
      "for 2023-04-30, MAE is:14.71 & sMAPE is:18.10% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :14.37 & 14.82% & 0.76\n",
      "for 2023-05-01, MAE is:17.39 & sMAPE is:18.31% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :14.39 & 14.85% & 0.77\n",
      "for 2023-05-02, MAE is:9.84 & sMAPE is:9.69% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :14.35 & 14.81% & 0.76\n",
      "for 2023-05-03, MAE is:10.73 & sMAPE is:10.79% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :14.32 & 14.77% & 0.77\n",
      "for 2023-05-04, MAE is:12.57 & sMAPE is:13.80% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :14.31 & 14.76% & 0.77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-05-05, MAE is:12.44 & sMAPE is:14.13% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :14.29 & 14.76% & 0.77\n",
      "for 2023-05-06, MAE is:7.69 & sMAPE is:10.05% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :14.24 & 14.72% & 0.77\n",
      "for 2023-05-07, MAE is:13.58 & sMAPE is:19.12% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :14.24 & 14.76% & 0.77\n",
      "for 2023-05-08, MAE is:5.81 & sMAPE is:6.59% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :14.17 & 14.69% & 0.77\n",
      "for 2023-05-09, MAE is:7.94 & sMAPE is:9.48% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :14.12 & 14.65% & 0.77\n",
      "for 2023-05-10, MAE is:5.26 & sMAPE is:6.82% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :14.05 & 14.59% & 0.76\n",
      "for 2023-05-11, MAE is:5.10 & sMAPE is:5.89% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :13.99 & 14.53% & 0.76\n",
      "for 2023-05-12, MAE is:5.34 & sMAPE is:6.76% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :13.92 & 14.47% & 0.76\n",
      "for 2023-05-13, MAE is:17.79 & sMAPE is:37.03% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :13.95 & 14.64% & 0.76\n",
      "for 2023-05-14, MAE is:25.91 & sMAPE is:53.98% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :14.04 & 14.93% & 0.77\n",
      "for 2023-05-15, MAE is:5.62 & sMAPE is:6.69% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :13.98 & 14.87% & 0.77\n",
      "for 2023-05-16, MAE is:26.38 & sMAPE is:43.78% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :14.07 & 15.08% & 0.77\n",
      "for 2023-05-17, MAE is:20.98 & sMAPE is:58.27% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :14.12 & 15.40% & 0.77\n",
      "for 2023-05-18, MAE is:11.62 & sMAPE is:16.98% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :14.10 & 15.41% & 0.77\n",
      "for 2023-05-19, MAE is:9.67 & sMAPE is:12.48% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :14.07 & 15.39% & 0.77\n",
      "for 2023-05-20, MAE is:32.01 & sMAPE is:71.98% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :14.20 & 15.79% & 0.78\n",
      "for 2023-05-21, MAE is:34.05 & sMAPE is:97.20% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :14.34 & 16.37% & 0.78\n",
      "for 2023-05-22, MAE is:8.47 & sMAPE is:12.44% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :14.30 & 16.34% & 0.78\n",
      "for 2023-05-23, MAE is:15.06 & sMAPE is:34.71% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :14.30 & 16.47% & 0.79\n",
      "for 2023-05-24, MAE is:12.36 & sMAPE is:19.32% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :14.29 & 16.49% & 0.78\n",
      "for 2023-05-25, MAE is:14.21 & sMAPE is:34.94% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :14.29 & 16.62% & 0.78\n",
      "for 2023-05-26, MAE is:20.96 & sMAPE is:53.74% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :14.33 & 16.87% & 0.78\n",
      "for 2023-05-27, MAE is:25.14 & sMAPE is:63.07% & rMAE is:3.34 ||| daily mean of MAE & sMAPE & rMAE till now are :14.41 & 17.19% & 0.80\n",
      "for 2023-05-28, MAE is:32.31 & sMAPE is:86.67% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :14.53 & 17.66% & 0.81\n",
      "for 2023-05-29, MAE is:26.51 & sMAPE is:78.58% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :14.61 & 18.06% & 0.81\n",
      "for 2023-05-30, MAE is:16.40 & sMAPE is:25.00% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :14.62 & 18.11% & 0.81\n",
      "for 2023-05-31, MAE is:21.79 & sMAPE is:47.05% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :14.67 & 18.30% & 0.81\n",
      "for 2023-06-01, MAE is:11.64 & sMAPE is:27.37% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :14.65 & 18.36% & 0.81\n",
      "for 2023-06-02, MAE is:11.60 & sMAPE is:17.98% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :14.63 & 18.36% & 0.81\n",
      "for 2023-06-03, MAE is:22.80 & sMAPE is:51.80% & rMAE is:3.91 ||| daily mean of MAE & sMAPE & rMAE till now are :14.68 & 18.58% & 0.83\n",
      "for 2023-06-04, MAE is:22.18 & sMAPE is:49.03% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :14.73 & 18.77% & 0.84\n",
      "for 2023-06-05, MAE is:7.24 & sMAPE is:9.70% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :14.68 & 18.71% & 0.83\n",
      "for 2023-06-06, MAE is:5.75 & sMAPE is:7.44% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :14.62 & 18.64% & 0.83\n",
      "for 2023-06-07, MAE is:9.02 & sMAPE is:11.22% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :14.59 & 18.60% & 0.83\n",
      "for 2023-06-08, MAE is:5.40 & sMAPE is:6.99% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :14.53 & 18.52% & 0.83\n",
      "for 2023-06-09, MAE is:4.19 & sMAPE is:5.54% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :14.47 & 18.44% & 0.82\n",
      "for 2023-06-10, MAE is:21.55 & sMAPE is:48.50% & rMAE is:3.68 ||| daily mean of MAE & sMAPE & rMAE till now are :14.51 & 18.63% & 0.84\n",
      "for 2023-06-11, MAE is:25.81 & sMAPE is:74.18% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :14.58 & 18.97% & 0.85\n",
      "for 2023-06-12, MAE is:10.46 & sMAPE is:14.59% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :14.56 & 18.94% & 0.85\n",
      "for 2023-06-13, MAE is:12.32 & sMAPE is:15.25% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :14.54 & 18.92% & 0.86\n",
      "for 2023-06-14, MAE is:7.00 & sMAPE is:7.66% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :14.50 & 18.85% & 0.85\n",
      "for 2023-06-15, MAE is:14.28 & sMAPE is:14.83% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :14.49 & 18.83% & 0.85\n",
      "for 2023-06-16, MAE is:13.37 & sMAPE is:13.34% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :14.49 & 18.80% & 0.85\n",
      "for 2023-06-17, MAE is:14.46 & sMAPE is:17.01% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :14.49 & 18.79% & 0.85\n",
      "for 2023-06-18, MAE is:23.26 & sMAPE is:28.81% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :14.54 & 18.84% & 0.84\n",
      "for 2023-06-19, MAE is:7.42 & sMAPE is:7.52% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :14.50 & 18.78% & 0.84\n",
      "for 2023-06-20, MAE is:10.62 & sMAPE is:9.15% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :14.47 & 18.72% & 0.84\n",
      "for 2023-06-21, MAE is:11.95 & sMAPE is:10.56% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :14.46 & 18.67% & 0.84\n",
      "for 2023-06-22, MAE is:12.23 & sMAPE is:10.57% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :14.45 & 18.63% & 0.84\n",
      "for 2023-06-23, MAE is:17.00 & sMAPE is:16.48% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :14.46 & 18.62% & 0.84\n",
      "for 2023-06-24, MAE is:27.48 & sMAPE is:44.52% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :14.54 & 18.76% & 0.85\n",
      "for 2023-06-25, MAE is:38.92 & sMAPE is:64.82% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :14.67 & 19.03% & 0.85\n",
      "for 2023-06-26, MAE is:14.31 & sMAPE is:16.94% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :14.67 & 19.01% & 0.85\n",
      "for 2023-06-27, MAE is:6.34 & sMAPE is:7.87% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :14.63 & 18.95% & 0.85\n",
      "for 2023-06-28, MAE is:5.26 & sMAPE is:5.86% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :14.57 & 18.88% & 0.85\n",
      "for 2023-06-29, MAE is:9.59 & sMAPE is:10.35% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :14.55 & 18.83% & 0.84\n",
      "for 2023-06-30, MAE is:8.77 & sMAPE is:9.30% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :14.51 & 18.78% & 0.85\n",
      "CPU times: total: 2d 20h 17min\n",
      "Wall time: 2d 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "large_scale_predictor(zone, first_year=2018, last_year=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
